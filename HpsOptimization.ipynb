{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from Environment import Car, CarEnv\n",
    "from ModelsTorch import Actor, Critic\n",
    "from AgentTorch import PPOAgent\n",
    "import pygame\n",
    "from utils import compute_borders, scale_image\n",
    "import wandb\n",
    "import pprint\n",
    "import itertools\n",
    "import random\n",
    "import torch\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "circuit_path = 'images\\\\circuits\\\\level3.png'\n",
    "circuit_edges, finish_edges, finish_position = compute_borders(circuit_path, \"images\\\\finish_template.png\")\n",
    "track_img = pygame.image.load(circuit_path)\n",
    "finish_img = pygame.image.load(\"images\\\\finish_image.png\")\n",
    "car_img = scale_image(pygame.image.load(\"images\\\\red-car.png\"), 0.35)\n",
    "images = [(track_img, (0, 0)), (finish_img, finish_position)]\n",
    "\n",
    "car = Car(car_img, acceleration=0.2, num_radars=9)\n",
    "env = CarEnv(car, circuit_edges, finish_edges, num_actions=6)\n",
    "\n",
    "experiment = int(input('NÃºmero del experimento'))\n",
    "saves = 'saves_tfm\\\\' + str(experiment)\n",
    "wandb.tensorboard.patch(root_logdir='runs\\\\ppo_experiment_tfm\\\\'+str(experiment), tensorboard_x=False, save=False)\n",
    "\n",
    "def hp_opt(config=None):\n",
    "    # Seeds set within the function so that all trials are reproducible (resetting the state of the pseudo-random number generators).\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        actor = Actor(**config)\n",
    "        critic = Critic(**config)\n",
    "\n",
    "        wandb.watch(actor, log_freq=10)\n",
    "        wandb.watch(critic, log_freq=10)\n",
    "\n",
    "        agent = PPOAgent(actor, critic, log_dir='runs\\\\ppo_experiment_tfm\\\\'+str(experiment), **config)\n",
    "        _, _ = agent.train(env, env, images, save_path=None, updates_per_flush=20, val_fps=None, val_plot=False, val_verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 62savqn0\n",
      "Sweep URL: https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0\n",
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'Reward/Mean_val_reward'},\n",
      " 'name': 'Sweep_TFM',\n",
      " 'parameters': {'GAE_lambda': {'value': 0.95},\n",
      "                'T': {'values': [256, 512, 768, 1024]},\n",
      "                'activation': {'values': ['tanh', 'lrelu']},\n",
      "                'actor_lr': {'distribution': 'log_uniform_values',\n",
      "                             'max': 0.01,\n",
      "                             'min': 0.0001},\n",
      "                'adv_std': {'values': [True, False]},\n",
      "                'bn': {'values': [True, False]},\n",
      "                'clipping_epsilon': {'value': 0.2},\n",
      "                'critic_lr': {'distribution': 'log_uniform_values',\n",
      "                              'max': 0.01,\n",
      "                              'min': 0.0001},\n",
      "                'decay_method': {'value': 'exponential'},\n",
      "                'dropout_prob': {'values': [0, 0.1, 0.2, 0.3]},\n",
      "                'early_stopping_delta': {'value': 0.0},\n",
      "                'early_stopping_patience': {'value': 30},\n",
      "                'entropy': {'distribution': 'uniform',\n",
      "                            'max': 0.05,\n",
      "                            'min': 0.0001},\n",
      "                'epochs': {'value': 10},\n",
      "                'exponential_factor': {'distribution': 'log_uniform_values',\n",
      "                                       'max': 0.999,\n",
      "                                       'min': 0.85},\n",
      "                'gamma': {'values': [0.9, 0.95, 0.99]},\n",
      "                'hidden_sizes': {'values': [[150, 150],\n",
      "                                            [150, 250],\n",
      "                                            [150, 350],\n",
      "                                            [250, 150],\n",
      "                                            [250, 250],\n",
      "                                            [250, 350],\n",
      "                                            [350, 150],\n",
      "                                            [350, 250],\n",
      "                                            [350, 350],\n",
      "                                            [150, 150, 150],\n",
      "                                            [150, 150, 250],\n",
      "                                            [150, 150, 350],\n",
      "                                            [150, 250, 150],\n",
      "                                            [150, 250, 250],\n",
      "                                            [150, 250, 350],\n",
      "                                            [150, 350, 150],\n",
      "                                            [150, 350, 250],\n",
      "                                            [150, 350, 350],\n",
      "                                            [250, 150, 150],\n",
      "                                            [250, 150, 250],\n",
      "                                            [250, 150, 350],\n",
      "                                            [250, 250, 150],\n",
      "                                            [250, 250, 250],\n",
      "                                            [250, 250, 350],\n",
      "                                            [250, 350, 150],\n",
      "                                            [250, 350, 250],\n",
      "                                            [250, 350, 350],\n",
      "                                            [350, 150, 150],\n",
      "                                            [350, 150, 250],\n",
      "                                            [350, 150, 350],\n",
      "                                            [350, 250, 150],\n",
      "                                            [350, 250, 250],\n",
      "                                            [350, 250, 350],\n",
      "                                            [350, 350, 150],\n",
      "                                            [350, 350, 250],\n",
      "                                            [350, 350, 350],\n",
      "                                            [150, 150, 150, 150],\n",
      "                                            [150, 150, 150, 250],\n",
      "                                            [150, 150, 150, 350],\n",
      "                                            [150, 150, 250, 150],\n",
      "                                            [150, 150, 250, 250],\n",
      "                                            [150, 150, 250, 350],\n",
      "                                            [150, 150, 350, 150],\n",
      "                                            [150, 150, 350, 250],\n",
      "                                            [150, 150, 350, 350],\n",
      "                                            [150, 250, 150, 150],\n",
      "                                            [150, 250, 150, 250],\n",
      "                                            [150, 250, 150, 350],\n",
      "                                            [150, 250, 250, 150],\n",
      "                                            [150, 250, 250, 250],\n",
      "                                            [150, 250, 250, 350],\n",
      "                                            [150, 250, 350, 150],\n",
      "                                            [150, 250, 350, 250],\n",
      "                                            [150, 250, 350, 350],\n",
      "                                            [150, 350, 150, 150],\n",
      "                                            [150, 350, 150, 250],\n",
      "                                            [150, 350, 150, 350],\n",
      "                                            [150, 350, 250, 150],\n",
      "                                            [150, 350, 250, 250],\n",
      "                                            [150, 350, 250, 350],\n",
      "                                            [150, 350, 350, 150],\n",
      "                                            [150, 350, 350, 250],\n",
      "                                            [150, 350, 350, 350],\n",
      "                                            [250, 150, 150, 150],\n",
      "                                            [250, 150, 150, 250],\n",
      "                                            [250, 150, 150, 350],\n",
      "                                            [250, 150, 250, 150],\n",
      "                                            [250, 150, 250, 250],\n",
      "                                            [250, 150, 250, 350],\n",
      "                                            [250, 150, 350, 150],\n",
      "                                            [250, 150, 350, 250],\n",
      "                                            [250, 150, 350, 350],\n",
      "                                            [250, 250, 150, 150],\n",
      "                                            [250, 250, 150, 250],\n",
      "                                            [250, 250, 150, 350],\n",
      "                                            [250, 250, 250, 150],\n",
      "                                            [250, 250, 250, 250],\n",
      "                                            [250, 250, 250, 350],\n",
      "                                            [250, 250, 350, 150],\n",
      "                                            [250, 250, 350, 250],\n",
      "                                            [250, 250, 350, 350],\n",
      "                                            [250, 350, 150, 150],\n",
      "                                            [250, 350, 150, 250],\n",
      "                                            [250, 350, 150, 350],\n",
      "                                            [250, 350, 250, 150],\n",
      "                                            [250, 350, 250, 250],\n",
      "                                            [250, 350, 250, 350],\n",
      "                                            [250, 350, 350, 150],\n",
      "                                            [250, 350, 350, 250],\n",
      "                                            [250, 350, 350, 350],\n",
      "                                            [350, 150, 150, 150],\n",
      "                                            [350, 150, 150, 250],\n",
      "                                            [350, 150, 150, 350],\n",
      "                                            [350, 150, 250, 150],\n",
      "                                            [350, 150, 250, 250],\n",
      "                                            [350, 150, 250, 350],\n",
      "                                            [350, 150, 350, 150],\n",
      "                                            [350, 150, 350, 250],\n",
      "                                            [350, 150, 350, 350],\n",
      "                                            [350, 250, 150, 150],\n",
      "                                            [350, 250, 150, 250],\n",
      "                                            [350, 250, 150, 350],\n",
      "                                            [350, 250, 250, 150],\n",
      "                                            [350, 250, 250, 250],\n",
      "                                            [350, 250, 250, 350],\n",
      "                                            [350, 250, 350, 150],\n",
      "                                            [350, 250, 350, 250],\n",
      "                                            [350, 250, 350, 350],\n",
      "                                            [350, 350, 150, 150],\n",
      "                                            [350, 350, 150, 250],\n",
      "                                            [350, 350, 150, 350],\n",
      "                                            [350, 350, 250, 150],\n",
      "                                            [350, 350, 250, 250],\n",
      "                                            [350, 350, 250, 350],\n",
      "                                            [350, 350, 350, 150],\n",
      "                                            [350, 350, 350, 250],\n",
      "                                            [350, 350, 350, 350]]},\n",
      "                'initialization': {'values': ['orthogonal',\n",
      "                                              'normal',\n",
      "                                              'uniform']},\n",
      "                'input_size': {'value': 10},\n",
      "                'l1_factor': {'distribution': 'log_uniform_values',\n",
      "                              'max': 0.001,\n",
      "                              'min': 1e-06},\n",
      "                'l2_factor': {'distribution': 'log_uniform_values',\n",
      "                              'max': 0.001,\n",
      "                              'min': 1e-06},\n",
      "                'lrelu': {'values': [0.001, 0.01, 0.1]},\n",
      "                'minibatch_size': {'values': [32, 64, 128, 256]},\n",
      "                'momentum': {'values': [0.8, 0.9, 0.95, 0.99]},\n",
      "                'output_size': {'value': 6},\n",
      "                'target_kl': {'values': [0.01, 0.02, 0.03]},\n",
      "                'updates': {'value': 200},\n",
      "                'updates_per_val': {'value': 1},\n",
      "                'val_episodes': {'value': 10},\n",
      "                'value_loss_factor': {'value': 1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'62savqn0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sweep_config(sweep_decay=None):\n",
    "    combinations = []\n",
    "    number_hidden_layers = [2, 3, 4]  # Possible number of hidden layers\n",
    "    possible_hidden_sizes = [150, 250, 350]  # Possible neurons of hidden layers\n",
    "    for size in number_hidden_layers:\n",
    "        combinations.extend(itertools.product(possible_hidden_sizes, repeat=size))\n",
    "    combinations = [list(comb) for comb in combinations]  # Every possible combination\n",
    "    \n",
    "    sweep_config = {\n",
    "        \"name\": \"Sweep_TFM\",\n",
    "        \"method\": \"random\",\n",
    "        \"metric\": {\n",
    "            \"goal\": \"maximize\",\n",
    "            \"name\": \"Reward/Mean_val_reward\"\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            # Models\n",
    "            \"input_size\": {\n",
    "                \"value\": 10  # Must be even (odd number of radars + current velocity)\n",
    "            },\n",
    "            \"hidden_sizes\": {\n",
    "                \"values\": combinations\n",
    "            },\n",
    "            \"output_size\": {\n",
    "                \"value\": 6  # Number of actions\n",
    "            },\n",
    "            \"dropout_prob\": {\n",
    "                \"values\": [0, 0.1, 0.2, 0.3]\n",
    "            },\n",
    "            \"activation\": {\n",
    "                \"values\": [\"tanh\", \"lrelu\"]  # Activation layers\n",
    "            },\n",
    "            \"lrelu\": {\n",
    "                \"values\": [0.001, 0.01, 0.1]  # If activation=LeakyReLU, alpha parameter\n",
    "            },\n",
    "            \"momentum\": {\n",
    "                \"values\": [0.8, 0.9, 0.95, 0.99]  # Momentum of Batch Normalization layers (if there are)\n",
    "            },\n",
    "            \"bn\": {\n",
    "                \"values\": [True, False]  # If there are Batch Normalization layers\n",
    "            },\n",
    "            \"initialization\": {\n",
    "                \"values\": [\"orthogonal\", \"normal\", \"uniform\"]  # Initialization method (layer weights)\n",
    "            },\n",
    "                   \n",
    "            # Agent + training\n",
    "            'actor_lr': {\n",
    "                'distribution': 'log_uniform_values',   \n",
    "                'min': 1e-4,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            'critic_lr': {   \n",
    "                'distribution': 'log_uniform_values',  \n",
    "                'min': 1e-4,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            \"value_loss_factor\": {\n",
    "                'value': 1\n",
    "            },\n",
    "            \"entropy\": {\n",
    "                \"distribution\": \"uniform\",\n",
    "                \"min\": 1e-4,\n",
    "                \"max\": 5e-2\n",
    "            },\n",
    "            \"gamma\":  {\n",
    "                \"values\": [0.9, 0.95, 0.99]\n",
    "            },\n",
    "            \"GAE_lambda\": {\n",
    "                \"value\": 0.95\n",
    "            },\n",
    "            \"clipping_epsilon\": {\n",
    "                \"value\": 0.2\n",
    "            },\n",
    "            \"l1_factor\": {\n",
    "                \"distribution\": \"log_uniform_values\",\n",
    "                \"min\": 1e-6,\n",
    "                \"max\": 1e-3\n",
    "            },\n",
    "            \"l2_factor\": {\n",
    "                \"distribution\": \"log_uniform_values\",\n",
    "                \"min\": 1e-6,\n",
    "                \"max\": 1e-3\n",
    "            },\n",
    "            \"T\": {\n",
    "                \"values\": [256, 512, 768, 1024]\n",
    "            },\n",
    "            'minibatch_size': {\n",
    "                \"values\": [32, 64, 128, 256]\n",
    "            },\n",
    "            \"epochs\": {\n",
    "                \"value\": 10 #[5, 10, 15, 20]\n",
    "            },\n",
    "            \"updates\": {\n",
    "                \"value\": 200\n",
    "            },\n",
    "            \"val_episodes\": {\n",
    "                \"value\": 10\n",
    "            },\n",
    "            \"updates_per_val\": {\n",
    "                \"value\": 1\n",
    "            },\n",
    "            \"target_kl\": {\n",
    "                \"values\": [0.01, 0.02, 0.03]\n",
    "            },\n",
    "            \"adv_std\": {\n",
    "                \"values\": [True, False]\n",
    "            },\n",
    "            \"early_stopping_patience\": {\n",
    "                \"value\": 30  # If it is too low, it may interfere with plateau reduction.\n",
    "            },\n",
    "            \"early_stopping_delta\": {\n",
    "                \"value\": 0.00\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if sweep_decay == 'plateau':\n",
    "        sweep_config[\"parameters\"].update({\n",
    "            \"decay_method\": {\n",
    "                \"value\": \"plateau\"\n",
    "            },\n",
    "            \"plateau_factor\": {\n",
    "                \"distribution\": \"uniform\",\n",
    "                \"min\": 0.01,\n",
    "                \"max\": 0.9\n",
    "            },\n",
    "            \"plateau_patience\": {\n",
    "                \"values\": [5, 10]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    elif sweep_decay == 'exponential':\n",
    "        sweep_config[\"parameters\"].update({\n",
    "            \"decay_method\": {\n",
    "                \"value\": \"exponential\"\n",
    "            },\n",
    "            \"exponential_factor\": {\n",
    "                \"distribution\": \"log_uniform_values\",\n",
    "                \"min\": 0.85,\n",
    "                \"max\": 0.999\n",
    "            }\n",
    "        })\n",
    "\n",
    "    elif sweep_decay == 'linear':\n",
    "        sweep_config[\"parameters\"].update({\n",
    "            \"decay_method\": {\n",
    "                \"value\": \"linear\"\n",
    "            },\n",
    "            \"linear_end_factor\": {\n",
    "                \"distribution\": \"log_uniform_values\",\n",
    "                \"min\": 0.85,\n",
    "                \"max\": 0.999\n",
    "            }\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        sweep_config[\"parameters\"].update({\n",
    "            \"decay_method\": {\n",
    "                \"value\": None\n",
    "            },\n",
    "        })\n",
    "\n",
    "    return sweep_config\n",
    "\n",
    "sweep_config = get_sweep_config(sweep_decay='exponential')\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"TFM_project\")\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: joopscwv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.004081535403239059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0002147731490633399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0066479705680139445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9718100390147708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 150, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00034222243641892795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.9459499540515144e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mantoniosg00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_121054-joopscwv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/joopscwv' target=\"_blank\">charmed-sweep-1</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/joopscwv' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/joopscwv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.004081535403239059, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002147731490633399, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0066479705680139445, 'epochs': 10, 'exponential_factor': 0.9718100390147708, 'gamma': 0.99, 'hidden_sizes': [150, 150, 250, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.00034222243641892795, 'l2_factor': 2.9459499540515144e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 250, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.004081535403239059, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002147731490633399, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0066479705680139445, 'epochs': 10, 'exponential_factor': 0.9718100390147708, 'gamma': 0.99, 'l1_factor': 0.00034222243641892795, 'l2_factor': 2.9459499540515144e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 250, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.004081535403239059, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002147731490633399, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0066479705680139445, 'epochs': 10, 'exponential_factor': 0.9718100390147708, 'gamma': 0.99, 'l1_factor': 0.00034222243641892795, 'l2_factor': 2.9459499540515144e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.004081535403239059, 'critic_lr': 0.0002147731490633399, 'decay_method': 'exponential', 'exponential_factor': 0.9718100390147708, 'value_loss_factor': 1, 'entropy': 0.0066479705680139445, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00034222243641892795, 'l2_factor': 2.9459499540515144e-05, 'T': 512, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [150, 150, 250, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 25.62228775024414\n",
      "Critic Loss: 29.32796859741211\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 19.406448364257812\n",
      "Critic Loss: 18.770782470703125\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 29.344514846801758\n",
      "Critic Loss: 24.827627182006836\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 26.85972023010254\n",
      "Critic Loss: 19.329317092895508\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 34.7232551574707\n",
      "Critic Loss: 16.070655822753906\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 32.39527130126953\n",
      "Critic Loss: 15.63741683959961\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 37.916603088378906\n",
      "Critic Loss: 16.158361434936523\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 22.10981559753418\n",
      "Critic Loss: 21.756200790405273\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 32.27830505371094\n",
      "Critic Loss: 18.75404167175293\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 19.259639739990234\n",
      "Critic Loss: 15.035892486572266\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 19.121896743774414\n",
      "Critic Loss: 13.139371871948242\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 22.389917373657227\n",
      "Critic Loss: 6.800745010375977\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 22.975341796875\n",
      "Critic Loss: 8.325420379638672\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 22.01192855834961\n",
      "Critic Loss: 8.553993225097656\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 23.761829376220703\n",
      "Critic Loss: 6.989595890045166\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 27.666654586791992\n",
      "Critic Loss: 13.009241104125977\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 34.73404312133789\n",
      "Critic Loss: 11.727520942687988\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 23.550355911254883\n",
      "Critic Loss: 8.90110969543457\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 22.097951889038086\n",
      "Critic Loss: 7.792332649230957\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 30.325443267822266\n",
      "Critic Loss: 5.4093804359436035\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 24.047298431396484\n",
      "Critic Loss: 6.8302106857299805\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 25.021669387817383\n",
      "Critic Loss: 12.518817901611328\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 20.578975677490234\n",
      "Critic Loss: 14.394546508789062\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 24.777700424194336\n",
      "Critic Loss: 7.220086574554443\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 25.593402862548828\n",
      "Critic Loss: 11.909285545349121\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 18.54737663269043\n",
      "Critic Loss: 4.6512451171875\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 14.253300666809082\n",
      "Critic Loss: 9.194887161254883\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 21.245668411254883\n",
      "Critic Loss: 8.495304107666016\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 22.590065002441406\n",
      "Critic Loss: 6.258350372314453\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 20.666963577270508\n",
      "Critic Loss: 5.959303379058838\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 34.749122619628906\n",
      "Critic Loss: 14.54443645477295\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 29.9005184173584\n",
      "Critic Loss: 17.567537307739258\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 18.751136779785156\n",
      "Critic Loss: 11.628372192382812\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 13.136244773864746\n",
      "Critic Loss: 15.453669548034668\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 14.514164924621582\n",
      "Critic Loss: 6.912689208984375\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 17.588138580322266\n",
      "Critic Loss: 12.996827125549316\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 21.018108367919922\n",
      "Critic Loss: 12.4053955078125\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 18.728103637695312\n",
      "Critic Loss: 6.480417251586914\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 24.04057502746582\n",
      "Critic Loss: 5.850496292114258\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 26.756458282470703\n",
      "Critic Loss: 7.360244274139404\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 17.659517288208008\n",
      "Critic Loss: 11.36017894744873\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 28.15412139892578\n",
      "Critic Loss: 8.093504905700684\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 22.248193740844727\n",
      "Critic Loss: 8.826883316040039\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 31.820846557617188\n",
      "Critic Loss: 10.378008842468262\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 16.38139533996582\n",
      "Critic Loss: 8.403818130493164\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 18.61770248413086\n",
      "Critic Loss: 9.175286293029785\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 21.643308639526367\n",
      "Critic Loss: 7.51030969619751\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 24.70663070678711\n",
      "Critic Loss: 5.584529399871826\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 19.963342666625977\n",
      "Critic Loss: 11.251301765441895\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 18.42975616455078\n",
      "Critic Loss: 10.151243209838867\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 16.305646896362305\n",
      "Critic Loss: 10.743800163269043\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 21.884523391723633\n",
      "Critic Loss: 5.619811058044434\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 25.397958755493164\n",
      "Critic Loss: 13.498839378356934\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 18.910282135009766\n",
      "Critic Loss: 11.932258605957031\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 15.15639591217041\n",
      "Critic Loss: 11.714325904846191\n",
      "\n",
      "New best validation reward reached in update [55/200]\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 19.711156845092773\n",
      "Critic Loss: 7.847043991088867\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 21.85283660888672\n",
      "Critic Loss: 10.231403350830078\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 11.661158561706543\n",
      "Critic Loss: 7.895906925201416\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 12.354975700378418\n",
      "Critic Loss: 6.908552169799805\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 20.962600708007812\n",
      "Critic Loss: 10.36796760559082\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 11.497298240661621\n",
      "Critic Loss: 16.775131225585938\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 17.992464065551758\n",
      "Critic Loss: 12.493078231811523\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 26.099836349487305\n",
      "Critic Loss: 17.360254287719727\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 7.574644565582275\n",
      "Critic Loss: 11.24666690826416\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 12.271777153015137\n",
      "Critic Loss: 9.719242095947266\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 5.280670642852783\n",
      "Critic Loss: 10.336760520935059\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 7.499564170837402\n",
      "Critic Loss: 8.977191925048828\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 3.5699219703674316\n",
      "Critic Loss: 12.952448844909668\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 11.507040023803711\n",
      "Critic Loss: 10.112239837646484\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.9905988574028015\n",
      "Critic Loss: 9.393362045288086\n",
      "\n",
      "New best validation reward reached in update [70/200]\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -3.0046215057373047\n",
      "Critic Loss: 10.78197956085205\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 6.808365821838379\n",
      "Critic Loss: 11.032261848449707\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 2.3374717235565186\n",
      "Critic Loss: 8.599685668945312\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 6.528559684753418\n",
      "Critic Loss: 10.404006004333496\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 5.992228984832764\n",
      "Critic Loss: 8.881961822509766\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 3.6105802059173584\n",
      "Critic Loss: 10.516913414001465\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -1.9536868333816528\n",
      "Critic Loss: 9.070850372314453\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 6.690867900848389\n",
      "Critic Loss: 10.477523803710938\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 4.050806999206543\n",
      "Critic Loss: 8.046046257019043\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 7.498375415802002\n",
      "Critic Loss: 7.770983695983887\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 4.249454021453857\n",
      "Critic Loss: 5.612387657165527\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 1.0982342958450317\n",
      "Critic Loss: 3.991039752960205\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 2.9167656898498535\n",
      "Critic Loss: 6.092494964599609\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 4.191708087921143\n",
      "Critic Loss: 6.611959457397461\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 3.463949680328369\n",
      "Critic Loss: 7.115365982055664\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 4.846269130706787\n",
      "Critic Loss: 5.918667793273926\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.8401467204093933\n",
      "Critic Loss: 10.340326309204102\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 1.9194625616073608\n",
      "Critic Loss: 4.261927604675293\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 9.79577922821045\n",
      "Critic Loss: 7.508797645568848\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 7.448873043060303\n",
      "Critic Loss: 9.525032043457031\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 9.707527160644531\n",
      "Critic Loss: 4.988447666168213\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -1.0338473320007324\n",
      "Critic Loss: 8.110844612121582\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.009250655770301819\n",
      "Critic Loss: 5.355160236358643\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -2.54542875289917\n",
      "Critic Loss: 6.618986129760742\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 6.744439601898193\n",
      "Critic Loss: 6.583558082580566\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -1.6315672397613525\n",
      "Critic Loss: 4.468918323516846\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.2352471500635147\n",
      "Critic Loss: 4.87749719619751\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -1.7951198816299438\n",
      "Critic Loss: 4.692443370819092\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 3.3128249645233154\n",
      "Critic Loss: 6.827665328979492\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 11.125859260559082\n",
      "Critic Loss: 7.856020450592041\n",
      "\n",
      "New best validation reward reached in update [100/200]\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 1.6017900705337524\n",
      "Critic Loss: 7.7024335861206055\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.4465188980102539\n",
      "Critic Loss: 5.3425092697143555\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 4.808177471160889\n",
      "Critic Loss: 6.742486000061035\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 15.201138496398926\n",
      "Critic Loss: 6.31671667098999\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 3.0595316886901855\n",
      "Critic Loss: 3.3378543853759766\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 21.463647842407227\n",
      "Critic Loss: 7.475301265716553\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.6513704657554626\n",
      "Critic Loss: 5.626021862030029\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -0.5136485695838928\n",
      "Critic Loss: 6.635396957397461\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -3.646345376968384\n",
      "Critic Loss: 7.622546195983887\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 4.799970626831055\n",
      "Critic Loss: 3.9171345233917236\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.3172536790370941\n",
      "Critic Loss: 5.660641670227051\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 5.318936347961426\n",
      "Critic Loss: 6.222114562988281\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.5337623953819275\n",
      "Critic Loss: 7.612083435058594\n",
      "\n",
      "New best validation reward reached in update [113/200]\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 5.300836086273193\n",
      "Critic Loss: 7.528746604919434\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 9.327032089233398\n",
      "Critic Loss: 8.684004783630371\n",
      "\n",
      "New best validation reward reached in update [115/200]\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -6.822157382965088\n",
      "Critic Loss: 4.243456840515137\n",
      "\n",
      "New best validation reward reached in update [116/200]\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.15826939046382904\n",
      "Critic Loss: 3.9759366512298584\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.16011641919612885\n",
      "Critic Loss: 5.527901649475098\n",
      "\n",
      "New best validation reward reached in update [118/200]\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 3.1428046226501465\n",
      "Critic Loss: 6.203369140625\n",
      "\n",
      "New best validation reward reached in update [119/200]\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 5.6152424812316895\n",
      "Critic Loss: 13.284997940063477\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -4.828360080718994\n",
      "Critic Loss: 5.292463302612305\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 6.8099284172058105\n",
      "Critic Loss: 8.297802925109863\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 3.8348073959350586\n",
      "Critic Loss: 3.017381191253662\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 7.924578666687012\n",
      "Critic Loss: 8.835444450378418\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 11.534049987792969\n",
      "Critic Loss: 6.5246381759643555\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 5.467650413513184\n",
      "Critic Loss: 10.85633659362793\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.3698484003543854\n",
      "Critic Loss: 5.612253189086914\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 2.9777235984802246\n",
      "Critic Loss: 4.7992072105407715\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -4.755107879638672\n",
      "Critic Loss: 9.992448806762695\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -2.9820096492767334\n",
      "Critic Loss: 11.912399291992188\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -5.7696967124938965\n",
      "Critic Loss: 7.421914577484131\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 2.12414813041687\n",
      "Critic Loss: 12.781403541564941\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 2.5509281158447266\n",
      "Critic Loss: 12.585042953491211\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -2.848562240600586\n",
      "Critic Loss: 5.4535112380981445\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 3.599989652633667\n",
      "Critic Loss: 5.0135722160339355\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.38349246978759766\n",
      "Critic Loss: 13.740735054016113\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 2.5034449100494385\n",
      "Critic Loss: 6.20102071762085\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 9.119291305541992\n",
      "Critic Loss: 4.959584712982178\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 3.8367857933044434\n",
      "Critic Loss: 4.919722557067871\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 5.09846305847168\n",
      "Critic Loss: 5.218486309051514\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 3.522073268890381\n",
      "Critic Loss: 5.477055072784424\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: -1.7864084243774414\n",
      "Critic Loss: 4.307829856872559\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 2.416506052017212\n",
      "Critic Loss: 4.513624668121338\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 2.394275188446045\n",
      "Critic Loss: 9.032286643981934\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 4.254016876220703\n",
      "Critic Loss: 6.069567680358887\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 16.240467071533203\n",
      "Critic Loss: 7.679060459136963\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 2.0235321521759033\n",
      "Critic Loss: 3.8227076530456543\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: -4.267278671264648\n",
      "Critic Loss: 5.832107067108154\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: -0.5002873539924622\n",
      "Critic Loss: 4.552053451538086\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 5.635524749755859\n",
      "Critic Loss: 6.355990409851074\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 0.6883315443992615\n",
      "Critic Loss: 3.7915000915527344\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -0.4970998466014862\n",
      "Critic Loss: 9.038515090942383\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: 4.311704158782959\n",
      "Critic Loss: 4.6913604736328125\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: 5.16063117980957\n",
      "Critic Loss: 6.056656837463379\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: 1.0065268278121948\n",
      "Critic Loss: 4.040031433105469\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: -3.5866243839263916\n",
      "Critic Loss: 3.2914183139801025\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: -2.9832472801208496\n",
      "Critic Loss: 3.2226219177246094\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 1.8043220043182373\n",
      "Critic Loss: 3.6984167098999023\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 1.3856892585754395\n",
      "Critic Loss: 4.798574924468994\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: 0.13069148361682892\n",
      "Critic Loss: 4.821999549865723\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8df35c57bfa4c919831910a32aa4154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>131.33333</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>131.89999</td></tr><tr><td>Learning_rate/Actor</td><td>4e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-1.75793</td></tr><tr><td>Loss/Critic_loss</td><td>4.822</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.58908</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00914</td></tr><tr><td>Loss/Policy_loss</td><td>-1.75402</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.13069</td></tr><tr><td>Metric/Explained_variance</td><td>0.68489</td></tr><tr><td>Reward/Mean_train_reward</td><td>10.95699</td></tr><tr><td>Reward/Mean_val_reward</td><td>8.4549</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>8.81709</td></tr><tr><td>global_step</td><td>160</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-1</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/joopscwv' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/joopscwv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_121054-joopscwv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k9ou4bcn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0006178173389342254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.003042924238226867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.018354509685286766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9132888346855556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.985720538166668e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.2565996268418414e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_122919-k9ou4bcn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/k9ou4bcn' target=\"_blank\">glowing-sweep-2</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/k9ou4bcn' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/k9ou4bcn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.0006178173389342254, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003042924238226867, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018354509685286766, 'epochs': 10, 'exponential_factor': 0.9132888346855556, 'gamma': 0.95, 'hidden_sizes': [350, 350, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 2.985720538166668e-06, 'l2_factor': 3.2565996268418414e-05, 'lrelu': 0.1, 'minibatch_size': 64, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0006178173389342254, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003042924238226867, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018354509685286766, 'epochs': 10, 'exponential_factor': 0.9132888346855556, 'gamma': 0.95, 'l1_factor': 2.985720538166668e-06, 'l2_factor': 3.2565996268418414e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0006178173389342254, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003042924238226867, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018354509685286766, 'epochs': 10, 'exponential_factor': 0.9132888346855556, 'gamma': 0.95, 'l1_factor': 2.985720538166668e-06, 'l2_factor': 3.2565996268418414e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0006178173389342254, 'critic_lr': 0.003042924238226867, 'decay_method': 'exponential', 'exponential_factor': 0.9132888346855556, 'value_loss_factor': 1, 'entropy': 0.018354509685286766, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.985720538166668e-06, 'l2_factor': 3.2565996268418414e-05, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [350, 350, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 25.013566970825195\n",
      "Critic Loss: 21.67049789428711\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 19.813331604003906\n",
      "Critic Loss: 13.941776275634766\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 14.712665557861328\n",
      "Critic Loss: 8.730923652648926\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 12.410431861877441\n",
      "Critic Loss: 9.666186332702637\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 16.735294342041016\n",
      "Critic Loss: 5.269271373748779\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 12.80266284942627\n",
      "Critic Loss: 7.369750022888184\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 6.768860340118408\n",
      "Critic Loss: 6.289681911468506\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 4.695140838623047\n",
      "Critic Loss: 5.978255271911621\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.3111792206764221\n",
      "Critic Loss: 2.6533167362213135\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 3.000539541244507\n",
      "Critic Loss: 5.894951343536377\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -2.0208547115325928\n",
      "Critic Loss: 2.5196826457977295\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -4.949807643890381\n",
      "Critic Loss: 1.4190993309020996\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -1.9705941677093506\n",
      "Critic Loss: 1.7944722175598145\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -1.2531574964523315\n",
      "Critic Loss: 3.1916465759277344\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -5.300845623016357\n",
      "Critic Loss: 1.6256186962127686\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -1.019128441810608\n",
      "Critic Loss: 3.4014430046081543\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 4.867074966430664\n",
      "Critic Loss: 4.4714202880859375\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.6726537346839905\n",
      "Critic Loss: 3.0225889682769775\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.9768861532211304\n",
      "Critic Loss: 1.7384462356567383\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -3.8367903232574463\n",
      "Critic Loss: 2.554823398590088\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -4.581833362579346\n",
      "Critic Loss: 2.9795429706573486\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.0983365848660469\n",
      "Critic Loss: 1.7088255882263184\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -1.557938575744629\n",
      "Critic Loss: 3.334693431854248\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -2.414872884750366\n",
      "Critic Loss: 0.6669169068336487\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 5.1014227867126465\n",
      "Critic Loss: 3.5254008769989014\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -3.7685482501983643\n",
      "Critic Loss: 1.8458731174468994\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -2.1360416412353516\n",
      "Critic Loss: 0.8294124603271484\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -6.111128330230713\n",
      "Critic Loss: 1.2933920621871948\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -4.278857707977295\n",
      "Critic Loss: 2.5377962589263916\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.38867735862731934\n",
      "Critic Loss: 2.6188414096832275\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -1.569385051727295\n",
      "Critic Loss: 1.5483014583587646\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -6.932140350341797\n",
      "Critic Loss: 1.4886070489883423\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -5.365603446960449\n",
      "Critic Loss: 1.2348591089248657\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -1.005940318107605\n",
      "Critic Loss: 2.659998893737793\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -4.507661819458008\n",
      "Critic Loss: 3.9216487407684326\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -6.097756385803223\n",
      "Critic Loss: 2.9597837924957275\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -14.343024253845215\n",
      "Critic Loss: 4.853024959564209\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -8.14556884765625\n",
      "Critic Loss: 7.446106910705566\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -6.84049654006958\n",
      "Critic Loss: 4.228896141052246\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -5.092991352081299\n",
      "Critic Loss: 4.2275261878967285\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -3.435887336730957\n",
      "Critic Loss: 3.77000093460083\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -13.089582443237305\n",
      "Critic Loss: 6.243035793304443\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -8.8037748336792\n",
      "Critic Loss: 2.2241482734680176\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -16.60455322265625\n",
      "Critic Loss: 5.100929260253906\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -8.181777000427246\n",
      "Critic Loss: 2.8793282508850098\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -10.302240371704102\n",
      "Critic Loss: 2.613767147064209\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -14.847494125366211\n",
      "Critic Loss: 6.289422988891602\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -9.223222732543945\n",
      "Critic Loss: 1.2383474111557007\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -11.44591999053955\n",
      "Critic Loss: 4.304393291473389\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -15.85621166229248\n",
      "Critic Loss: 7.74993896484375\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -12.85283374786377\n",
      "Critic Loss: 1.69344961643219\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -16.436452865600586\n",
      "Critic Loss: 4.9312920570373535\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -12.812616348266602\n",
      "Critic Loss: 4.278768062591553\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -7.622556686401367\n",
      "Critic Loss: 3.4764437675476074\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -13.68523120880127\n",
      "Critic Loss: 1.1906554698944092\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -7.383142471313477\n",
      "Critic Loss: 4.509791851043701\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -19.32110595703125\n",
      "Critic Loss: 8.36584758758545\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -14.96143627166748\n",
      "Critic Loss: 2.174856185913086\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -14.326371192932129\n",
      "Critic Loss: 4.182867527008057\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -8.773186683654785\n",
      "Critic Loss: 5.264214038848877\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -13.058860778808594\n",
      "Critic Loss: 7.132968902587891\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -11.719393730163574\n",
      "Critic Loss: 4.870266437530518\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -18.391891479492188\n",
      "Critic Loss: 4.945464134216309\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -13.59726619720459\n",
      "Critic Loss: 2.1246225833892822\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -15.452293395996094\n",
      "Critic Loss: 2.949601650238037\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -14.05906867980957\n",
      "Critic Loss: 4.387759208679199\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -4.194183826446533\n",
      "Critic Loss: 3.3072493076324463\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -15.149557113647461\n",
      "Critic Loss: 2.817906618118286\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -12.745070457458496\n",
      "Critic Loss: 5.163804054260254\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -17.82703399658203\n",
      "Critic Loss: 4.371982574462891\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -9.758188247680664\n",
      "Critic Loss: 3.2175629138946533\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -15.9005126953125\n",
      "Critic Loss: 3.105011463165283\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -8.600722312927246\n",
      "Critic Loss: 2.177131414413452\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -14.038345336914062\n",
      "Critic Loss: 2.6320276260375977\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -7.8080573081970215\n",
      "Critic Loss: 4.035106182098389\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -15.022947311401367\n",
      "Critic Loss: 5.189887046813965\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -11.025431632995605\n",
      "Critic Loss: 1.6026618480682373\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -13.578332901000977\n",
      "Critic Loss: 3.03157377243042\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -8.87983226776123\n",
      "Critic Loss: 2.261305093765259\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -7.992293357849121\n",
      "Critic Loss: 3.7813453674316406\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -17.36321258544922\n",
      "Critic Loss: 4.849605083465576\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -15.51775074005127\n",
      "Critic Loss: 4.776481628417969\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -12.850760459899902\n",
      "Critic Loss: 1.326040506362915\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -10.32413387298584\n",
      "Critic Loss: 3.303278923034668\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -10.379542350769043\n",
      "Critic Loss: 3.1363182067871094\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -20.837268829345703\n",
      "Critic Loss: 6.515952110290527\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -7.639019966125488\n",
      "Critic Loss: 3.0776374340057373\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -14.327132225036621\n",
      "Critic Loss: 1.3700083494186401\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -11.367098808288574\n",
      "Critic Loss: 2.5457866191864014\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -7.899168014526367\n",
      "Critic Loss: 4.054317474365234\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -13.145552635192871\n",
      "Critic Loss: 1.922890067100525\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -17.09853172302246\n",
      "Critic Loss: 6.585870265960693\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -12.26278305053711\n",
      "Critic Loss: 3.2130496501922607\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -14.889774322509766\n",
      "Critic Loss: 3.6285643577575684\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -9.28960132598877\n",
      "Critic Loss: 7.376471042633057\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -7.267900466918945\n",
      "Critic Loss: 3.184333562850952\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -12.115837097167969\n",
      "Critic Loss: 3.7936413288116455\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -10.278763771057129\n",
      "Critic Loss: 2.6914806365966797\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -8.915031433105469\n",
      "Critic Loss: 3.664369821548462\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -12.34957504272461\n",
      "Critic Loss: 2.881891965866089\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -13.27584171295166\n",
      "Critic Loss: 2.789459705352783\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -12.0670747756958\n",
      "Critic Loss: 3.0782220363616943\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -12.715021133422852\n",
      "Critic Loss: 1.6991437673568726\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -11.253606796264648\n",
      "Critic Loss: 3.0457820892333984\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -10.98934268951416\n",
      "Critic Loss: 5.498193740844727\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -10.408792495727539\n",
      "Critic Loss: 4.542315483093262\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -13.376802444458008\n",
      "Critic Loss: 2.336390972137451\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -9.288787841796875\n",
      "Critic Loss: 2.540693759918213\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -8.835163116455078\n",
      "Critic Loss: 4.693008899688721\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -15.86585521697998\n",
      "Critic Loss: 4.640289306640625\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -13.319538116455078\n",
      "Critic Loss: 6.195319175720215\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -15.994601249694824\n",
      "Critic Loss: 4.630989074707031\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -1.483910083770752\n",
      "Critic Loss: 7.638916015625\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -20.82712173461914\n",
      "Critic Loss: 7.480177879333496\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -7.687585353851318\n",
      "Critic Loss: 3.6296091079711914\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -15.670625686645508\n",
      "Critic Loss: 6.707376003265381\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -13.437150001525879\n",
      "Critic Loss: 3.763425827026367\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -6.906559467315674\n",
      "Critic Loss: 3.0247223377227783\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -11.413172721862793\n",
      "Critic Loss: 4.434463024139404\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -14.375523567199707\n",
      "Critic Loss: 1.5540766716003418\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -8.05230712890625\n",
      "Critic Loss: 3.257660150527954\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -7.218062877655029\n",
      "Critic Loss: 4.888373851776123\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0442c07a67804254baafdef5ede4912e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>184.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>302.89999</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-7.32534</td></tr><tr><td>Loss/Critic_loss</td><td>4.88837</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.97592</td></tr><tr><td>Loss/KL_divergence</td><td>0.00182</td></tr><tr><td>Loss/Policy_loss</td><td>-7.30743</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-7.21806</td></tr><tr><td>Metric/Explained_variance</td><td>0.15874</td></tr><tr><td>Reward/Mean_train_reward</td><td>65.671</td></tr><tr><td>Reward/Mean_val_reward</td><td>266.89389</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>295.20016</td></tr><tr><td>global_step</td><td>122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-sweep-2</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/k9ou4bcn' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/k9ou4bcn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_122919-k9ou4bcn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iiott9cu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0008667540373874765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004633527609453167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03280638492738754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8998007601769701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0009737354579177352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0004333729750596256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_125617-iiott9cu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/iiott9cu' target=\"_blank\">super-sweep-3</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/iiott9cu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/iiott9cu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.0008667540373874765, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004633527609453167, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03280638492738754, 'epochs': 10, 'exponential_factor': 0.8998007601769701, 'gamma': 0.95, 'hidden_sizes': [250, 150, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0009737354579177352, 'l2_factor': 0.0004333729750596256, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0008667540373874765, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004633527609453167, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03280638492738754, 'epochs': 10, 'exponential_factor': 0.8998007601769701, 'gamma': 0.95, 'l1_factor': 0.0009737354579177352, 'l2_factor': 0.0004333729750596256, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0008667540373874765, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004633527609453167, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03280638492738754, 'epochs': 10, 'exponential_factor': 0.8998007601769701, 'gamma': 0.95, 'l1_factor': 0.0009737354579177352, 'l2_factor': 0.0004333729750596256, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0008667540373874765, 'critic_lr': 0.0004633527609453167, 'decay_method': 'exponential', 'exponential_factor': 0.8998007601769701, 'value_loss_factor': 1, 'entropy': 0.03280638492738754, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0009737354579177352, 'l2_factor': 0.0004333729750596256, 'T': 512, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [250, 150, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 26.50880241394043\n",
      "Critic Loss: 10.413180351257324\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 26.73112678527832\n",
      "Critic Loss: 10.237268447875977\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 18.449739456176758\n",
      "Critic Loss: 4.317195415496826\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 17.885828018188477\n",
      "Critic Loss: 4.901282787322998\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 24.43499183654785\n",
      "Critic Loss: 9.219141006469727\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 26.07575225830078\n",
      "Critic Loss: 5.447171211242676\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 13.44336223602295\n",
      "Critic Loss: 5.759003162384033\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 16.67580223083496\n",
      "Critic Loss: 3.2644827365875244\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 12.787620544433594\n",
      "Critic Loss: 3.9942049980163574\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 16.680572509765625\n",
      "Critic Loss: 3.719625473022461\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 15.959306716918945\n",
      "Critic Loss: 2.9842686653137207\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 15.626615524291992\n",
      "Critic Loss: 6.299458026885986\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 16.7512149810791\n",
      "Critic Loss: 2.710587501525879\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 19.334760665893555\n",
      "Critic Loss: 3.101470947265625\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 15.04205322265625\n",
      "Critic Loss: 4.017963409423828\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 17.225635528564453\n",
      "Critic Loss: 9.76018238067627\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 18.14704132080078\n",
      "Critic Loss: 3.5635604858398438\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 15.662217140197754\n",
      "Critic Loss: 6.400018692016602\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 17.645883560180664\n",
      "Critic Loss: 5.340641498565674\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 11.111959457397461\n",
      "Critic Loss: 2.4314498901367188\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 25.361053466796875\n",
      "Critic Loss: 8.001195907592773\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 11.904011726379395\n",
      "Critic Loss: 5.622425556182861\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 12.037034034729004\n",
      "Critic Loss: 4.787939071655273\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 11.40356731414795\n",
      "Critic Loss: 5.099217414855957\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 9.960155487060547\n",
      "Critic Loss: 4.253847122192383\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 17.176816940307617\n",
      "Critic Loss: 9.028502464294434\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 7.813797473907471\n",
      "Critic Loss: 5.031592845916748\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 13.117847442626953\n",
      "Critic Loss: 8.235218048095703\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 15.515825271606445\n",
      "Critic Loss: 6.928020477294922\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 16.66958999633789\n",
      "Critic Loss: 5.0356340408325195\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 11.807024955749512\n",
      "Critic Loss: 3.9186606407165527\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 9.85104751586914\n",
      "Critic Loss: 4.2747368812561035\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 10.826793670654297\n",
      "Critic Loss: 4.029592990875244\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 7.710705757141113\n",
      "Critic Loss: 2.5792834758758545\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 9.3095121383667\n",
      "Critic Loss: 2.759148359298706\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 5.924337863922119\n",
      "Critic Loss: 3.9898364543914795\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 13.432568550109863\n",
      "Critic Loss: 4.841870307922363\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 14.780746459960938\n",
      "Critic Loss: 5.4683990478515625\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 7.388271808624268\n",
      "Critic Loss: 3.1084351539611816\n",
      "\n",
      "New best validation reward reached in update [39/200]\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 11.9961576461792\n",
      "Critic Loss: 4.768552780151367\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 12.573089599609375\n",
      "Critic Loss: 6.789353847503662\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 17.083011627197266\n",
      "Critic Loss: 4.119965076446533\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 5.005640506744385\n",
      "Critic Loss: 3.7401764392852783\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 11.561718940734863\n",
      "Critic Loss: 3.4400696754455566\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 9.288681983947754\n",
      "Critic Loss: 3.645087480545044\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 12.959339141845703\n",
      "Critic Loss: 6.495349884033203\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 20.545608520507812\n",
      "Critic Loss: 4.7657790184021\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 4.191619873046875\n",
      "Critic Loss: 4.59797477722168\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 12.473084449768066\n",
      "Critic Loss: 4.551312446594238\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 9.32359790802002\n",
      "Critic Loss: 3.0074026584625244\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 8.940268516540527\n",
      "Critic Loss: 7.1222124099731445\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 10.737044334411621\n",
      "Critic Loss: 4.031806468963623\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 11.364648818969727\n",
      "Critic Loss: 4.812444686889648\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 8.54459285736084\n",
      "Critic Loss: 3.4967427253723145\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 13.416364669799805\n",
      "Critic Loss: 2.903193473815918\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 7.369927406311035\n",
      "Critic Loss: 2.5137135982513428\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 14.418749809265137\n",
      "Critic Loss: 6.116538047790527\n",
      "\n",
      "New best validation reward reached in update [57/200]\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 8.631695747375488\n",
      "Critic Loss: 3.3139326572418213\n",
      "\n",
      "New best validation reward reached in update [58/200]\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 9.248047828674316\n",
      "Critic Loss: 2.9586281776428223\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 3.8437752723693848\n",
      "Critic Loss: 3.238895893096924\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 6.7715020179748535\n",
      "Critic Loss: 5.049306392669678\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 7.86611795425415\n",
      "Critic Loss: 3.129833221435547\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 6.408074855804443\n",
      "Critic Loss: 2.6734843254089355\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 16.543846130371094\n",
      "Critic Loss: 5.202203750610352\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 7.907671928405762\n",
      "Critic Loss: 4.264679908752441\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 9.403334617614746\n",
      "Critic Loss: 7.26494026184082\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 17.511943817138672\n",
      "Critic Loss: 4.581905841827393\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 11.491025924682617\n",
      "Critic Loss: 2.4513561725616455\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 9.649226188659668\n",
      "Critic Loss: 4.890367031097412\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 14.330985069274902\n",
      "Critic Loss: 7.902687072753906\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 8.220996856689453\n",
      "Critic Loss: 3.1643905639648438\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 10.32646656036377\n",
      "Critic Loss: 3.4480197429656982\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 26.948850631713867\n",
      "Critic Loss: 6.078962802886963\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 9.898050308227539\n",
      "Critic Loss: 3.0646140575408936\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 4.64094877243042\n",
      "Critic Loss: 4.066489219665527\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 20.14188575744629\n",
      "Critic Loss: 6.2881622314453125\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 7.071957111358643\n",
      "Critic Loss: 5.550783157348633\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 5.04298734664917\n",
      "Critic Loss: 5.456939220428467\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 11.835256576538086\n",
      "Critic Loss: 6.431272029876709\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 10.449638366699219\n",
      "Critic Loss: 2.6809608936309814\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 6.967232704162598\n",
      "Critic Loss: 2.291092872619629\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 6.4970903396606445\n",
      "Critic Loss: 3.4088172912597656\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 7.2230095863342285\n",
      "Critic Loss: 4.607045650482178\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 9.015666961669922\n",
      "Critic Loss: 2.734610080718994\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 9.217960357666016\n",
      "Critic Loss: 3.0673208236694336\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 10.639639854431152\n",
      "Critic Loss: 6.603376388549805\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 9.453226089477539\n",
      "Critic Loss: 6.027956008911133\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 20.52789878845215\n",
      "Critic Loss: 4.583881855010986\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 9.15075397491455\n",
      "Critic Loss: 4.150486469268799\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 9.191219329833984\n",
      "Critic Loss: 3.661353588104248\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1eb9dd73364328acdd00ed4ea1c607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>93.8</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>101.3</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>1.90344</td></tr><tr><td>Loss/Critic_loss</td><td>3.66135</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.62508</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01041</td></tr><tr><td>Loss/Policy_loss</td><td>1.92395</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>9.19122</td></tr><tr><td>Metric/Explained_variance</td><td>0.31275</td></tr><tr><td>Reward/Mean_train_reward</td><td>-20.4992</td></tr><tr><td>Reward/Mean_val_reward</td><td>-10.1757</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-21.73693</td></tr><tr><td>global_step</td><td>90</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-3</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/iiott9cu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/iiott9cu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_125617-iiott9cu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: twevkyhp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0026916496147356066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0026668159874614827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.003409201408147694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9377253153912086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.204621819182447e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0004910229248869546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_130617-twevkyhp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/twevkyhp' target=\"_blank\">visionary-sweep-4</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/twevkyhp' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/twevkyhp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.0026916496147356066, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0026668159874614827, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.003409201408147694, 'epochs': 10, 'exponential_factor': 0.9377253153912086, 'gamma': 0.9, 'hidden_sizes': [350, 150, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.204621819182447e-06, 'l2_factor': 0.0004910229248869546, 'lrelu': 0.01, 'minibatch_size': 64, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0026916496147356066, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0026668159874614827, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.003409201408147694, 'epochs': 10, 'exponential_factor': 0.9377253153912086, 'gamma': 0.9, 'l1_factor': 2.204621819182447e-06, 'l2_factor': 0.0004910229248869546, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0026916496147356066, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0026668159874614827, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.003409201408147694, 'epochs': 10, 'exponential_factor': 0.9377253153912086, 'gamma': 0.9, 'l1_factor': 2.204621819182447e-06, 'l2_factor': 0.0004910229248869546, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0026916496147356066, 'critic_lr': 0.0026668159874614827, 'decay_method': 'exponential', 'exponential_factor': 0.9377253153912086, 'value_loss_factor': 1, 'entropy': 0.003409201408147694, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.204621819182447e-06, 'l2_factor': 0.0004910229248869546, 'T': 512, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [350, 150, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 21.086698532104492\n",
      "Critic Loss: 20.41200828552246\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 14.989703178405762\n",
      "Critic Loss: 15.636478424072266\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 7.445749759674072\n",
      "Critic Loss: 5.039337635040283\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 23.84583282470703\n",
      "Critic Loss: 6.339065074920654\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 21.174705505371094\n",
      "Critic Loss: 4.771347522735596\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 23.912141799926758\n",
      "Critic Loss: 5.765130519866943\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 15.945101737976074\n",
      "Critic Loss: 5.268768787384033\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 10.31522274017334\n",
      "Critic Loss: 3.1090002059936523\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.08562135696411133\n",
      "Critic Loss: 7.25698184967041\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.41736099123954773\n",
      "Critic Loss: 2.6485085487365723\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -2.808687686920166\n",
      "Critic Loss: 3.7778079509735107\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.6023635864257812\n",
      "Critic Loss: 1.7063276767730713\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 9.212531089782715\n",
      "Critic Loss: 10.185322761535645\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 22.426538467407227\n",
      "Critic Loss: 5.254711627960205\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 16.8309383392334\n",
      "Critic Loss: 2.593909740447998\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 18.904024124145508\n",
      "Critic Loss: 5.66170597076416\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 7.253063201904297\n",
      "Critic Loss: 5.19801139831543\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 10.610757827758789\n",
      "Critic Loss: 6.274113655090332\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 7.485227584838867\n",
      "Critic Loss: 20.766263961791992\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.26728150248527527\n",
      "Critic Loss: 5.6676836013793945\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -2.741752862930298\n",
      "Critic Loss: 4.1794304847717285\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -2.507355213165283\n",
      "Critic Loss: 1.9322645664215088\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -1.8862311840057373\n",
      "Critic Loss: 2.494767427444458\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -3.9362294673919678\n",
      "Critic Loss: 2.0492584705352783\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -2.9333417415618896\n",
      "Critic Loss: 0.9002761244773865\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.2994711101055145\n",
      "Critic Loss: 4.624412536621094\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.2954324185848236\n",
      "Critic Loss: 1.1067767143249512\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -2.6851401329040527\n",
      "Critic Loss: 1.8684455156326294\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -2.046281576156616\n",
      "Critic Loss: 1.500089406967163\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.7765101194381714\n",
      "Critic Loss: 2.706570863723755\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -2.359294891357422\n",
      "Critic Loss: 1.8049685955047607\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -1.3673021793365479\n",
      "Critic Loss: 1.5733060836791992\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 3.204435348510742\n",
      "Critic Loss: 10.170292854309082\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.8352589011192322\n",
      "Critic Loss: 5.26693058013916\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -1.8225390911102295\n",
      "Critic Loss: 1.7312285900115967\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 10.963228225708008\n",
      "Critic Loss: 5.49845552444458\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.7606852054595947\n",
      "Critic Loss: 4.439798831939697\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.8319197297096252\n",
      "Critic Loss: 3.80165958404541\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.06348374485969543\n",
      "Critic Loss: 4.263493537902832\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 4.144533634185791\n",
      "Critic Loss: 6.12396764755249\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -1.6836150884628296\n",
      "Critic Loss: 3.075732946395874\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -2.3235247135162354\n",
      "Critic Loss: 1.1665728092193604\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 5.113188743591309\n",
      "Critic Loss: 3.320572853088379\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 3.972498893737793\n",
      "Critic Loss: 5.996293544769287\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -2.483520984649658\n",
      "Critic Loss: 2.9094724655151367\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.5182641744613647\n",
      "Critic Loss: 2.777857780456543\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.4619883894920349\n",
      "Critic Loss: 4.536502361297607\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 4.380828857421875\n",
      "Critic Loss: 2.8648602962493896\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.3862088918685913\n",
      "Critic Loss: 3.1837778091430664\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 1.9643340110778809\n",
      "Critic Loss: 5.474869728088379\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.4678935408592224\n",
      "Critic Loss: 2.4447169303894043\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.37336862087249756\n",
      "Critic Loss: 1.5414830446243286\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.5943654775619507\n",
      "Critic Loss: 1.0686697959899902\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 2.0362679958343506\n",
      "Critic Loss: 1.391019344329834\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 2.7301578521728516\n",
      "Critic Loss: 3.076120376586914\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.900692343711853\n",
      "Critic Loss: 4.1545610427856445\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 2.756895065307617\n",
      "Critic Loss: 5.243631839752197\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -4.550550937652588\n",
      "Critic Loss: 0.8609314560890198\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -2.718130111694336\n",
      "Critic Loss: 0.7390368580818176\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -3.764708995819092\n",
      "Critic Loss: 0.7291562557220459\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -1.0220537185668945\n",
      "Critic Loss: 1.3787720203399658\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.7940859794616699\n",
      "Critic Loss: 1.1842538118362427\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.8879643678665161\n",
      "Critic Loss: 1.5703634023666382\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -2.817305326461792\n",
      "Critic Loss: 2.076263666152954\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 4.223762035369873\n",
      "Critic Loss: 2.595224618911743\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.17408400774002075\n",
      "Critic Loss: 3.3907322883605957\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.16775985062122345\n",
      "Critic Loss: 2.15130615234375\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 1.817760705947876\n",
      "Critic Loss: 2.4739980697631836\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -2.266494035720825\n",
      "Critic Loss: 0.7766382694244385\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -1.8373557329177856\n",
      "Critic Loss: 2.714388132095337\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -1.6242371797561646\n",
      "Critic Loss: 2.3086891174316406\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 4.961081504821777\n",
      "Critic Loss: 4.045411109924316\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -1.4179891347885132\n",
      "Critic Loss: 1.5549288988113403\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -2.25974440574646\n",
      "Critic Loss: 1.4844211339950562\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.07137241959571838\n",
      "Critic Loss: 2.3395047187805176\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.5612744092941284\n",
      "Critic Loss: 1.4381577968597412\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -3.748103380203247\n",
      "Critic Loss: 1.1355079412460327\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 1.5239605903625488\n",
      "Critic Loss: 0.9782483577728271\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.49600738286972046\n",
      "Critic Loss: 1.8835943937301636\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -1.688600778579712\n",
      "Critic Loss: 1.9852979183197021\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -3.2386786937713623\n",
      "Critic Loss: 0.8954273462295532\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -3.7545993328094482\n",
      "Critic Loss: 0.576454222202301\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 1.0706448554992676\n",
      "Critic Loss: 2.4780402183532715\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 1.552893877029419\n",
      "Critic Loss: 1.6201653480529785\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.7638436555862427\n",
      "Critic Loss: 1.471396565437317\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 1.511612892150879\n",
      "Critic Loss: 3.4692726135253906\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -3.2296745777130127\n",
      "Critic Loss: 0.8360357880592346\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 1.9082547426223755\n",
      "Critic Loss: 2.924071788787842\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.18510495126247406\n",
      "Critic Loss: 5.1625261306762695\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.10264153778553009\n",
      "Critic Loss: 2.804084300994873\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 1.748435616493225\n",
      "Critic Loss: 3.2674732208251953\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -3.699519395828247\n",
      "Critic Loss: 1.1409404277801514\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.48369383811950684\n",
      "Critic Loss: 1.96658456325531\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -1.0800765752792358\n",
      "Critic Loss: 2.917954683303833\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.948733925819397\n",
      "Critic Loss: 2.232807159423828\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 1.9120123386383057\n",
      "Critic Loss: 2.7864301204681396\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.618058443069458\n",
      "Critic Loss: 1.2658497095108032\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -2.666378974914551\n",
      "Critic Loss: 0.903509259223938\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.7617915868759155\n",
      "Critic Loss: 1.7853782176971436\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -2.572876453399658\n",
      "Critic Loss: 1.0699429512023926\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.5914415121078491\n",
      "Critic Loss: 1.641995906829834\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -1.9185991287231445\n",
      "Critic Loss: 1.1737282276153564\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.18412965536117554\n",
      "Critic Loss: 2.9552149772644043\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f98ab587934cd994f0f10beaff8fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>146.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>139.60001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.5138</td></tr><tr><td>Loss/Critic_loss</td><td>2.95521</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.51711</td></tr><tr><td>Loss/KL_divergence</td><td>0.01188</td></tr><tr><td>Loss/Policy_loss</td><td>-0.51203</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.18413</td></tr><tr><td>Metric/Explained_variance</td><td>0.26263</td></tr><tr><td>Reward/Mean_train_reward</td><td>9.285</td></tr><tr><td>Reward/Mean_val_reward</td><td>5.8826</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>7.09462</td></tr><tr><td>global_step</td><td>103</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-sweep-4</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/twevkyhp' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/twevkyhp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_130617-twevkyhp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dmzw3ifu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0010790805637155964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004275123415819555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03000318740599483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9227523336701128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 5.167706531893088e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00022333691764515068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_131719-dmzw3ifu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/dmzw3ifu' target=\"_blank\">major-sweep-5</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/dmzw3ifu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/dmzw3ifu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0010790805637155964, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004275123415819555, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03000318740599483, 'epochs': 10, 'exponential_factor': 0.9227523336701128, 'gamma': 0.95, 'hidden_sizes': [250, 350, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 5.167706531893088e-06, 'l2_factor': 0.00022333691764515068, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0010790805637155964, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004275123415819555, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03000318740599483, 'epochs': 10, 'exponential_factor': 0.9227523336701128, 'gamma': 0.95, 'l1_factor': 5.167706531893088e-06, 'l2_factor': 0.00022333691764515068, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0010790805637155964, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004275123415819555, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03000318740599483, 'epochs': 10, 'exponential_factor': 0.9227523336701128, 'gamma': 0.95, 'l1_factor': 5.167706531893088e-06, 'l2_factor': 0.00022333691764515068, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0010790805637155964, 'critic_lr': 0.0004275123415819555, 'decay_method': 'exponential', 'exponential_factor': 0.9227523336701128, 'value_loss_factor': 1, 'entropy': 0.03000318740599483, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 5.167706531893088e-06, 'l2_factor': 0.00022333691764515068, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [250, 350, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.2174140214920044\n",
      "Critic Loss: 34.13750076293945\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.24500590562820435\n",
      "Critic Loss: 29.572433471679688\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.19120818376541138\n",
      "Critic Loss: 20.067272186279297\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.15476056933403015\n",
      "Critic Loss: 9.665712356567383\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.1435229480266571\n",
      "Critic Loss: 6.8227033615112305\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.1482377052307129\n",
      "Critic Loss: 11.966375350952148\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.11670218408107758\n",
      "Critic Loss: 12.692585945129395\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.13538578152656555\n",
      "Critic Loss: 11.923885345458984\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.16957828402519226\n",
      "Critic Loss: 6.062622547149658\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.16214749217033386\n",
      "Critic Loss: 7.166388988494873\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.11601623147726059\n",
      "Critic Loss: 5.6209492683410645\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.11417176574468613\n",
      "Critic Loss: 9.481285095214844\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.12780919671058655\n",
      "Critic Loss: 5.766809463500977\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.1553758978843689\n",
      "Critic Loss: 6.411547660827637\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.16180452704429626\n",
      "Critic Loss: 9.869247436523438\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.10424049198627472\n",
      "Critic Loss: 7.0910539627075195\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.12705053389072418\n",
      "Critic Loss: 5.510773181915283\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.10887514054775238\n",
      "Critic Loss: 3.3788328170776367\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.15520364046096802\n",
      "Critic Loss: 5.651973247528076\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.11070569604635239\n",
      "Critic Loss: 8.381866455078125\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.1098129004240036\n",
      "Critic Loss: 4.388211250305176\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.09877344965934753\n",
      "Critic Loss: 8.151097297668457\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.09013108164072037\n",
      "Critic Loss: 5.659543991088867\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.1392376720905304\n",
      "Critic Loss: 7.018685817718506\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.07759339362382889\n",
      "Critic Loss: 8.049968719482422\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.14682859182357788\n",
      "Critic Loss: 2.004493474960327\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.12084227800369263\n",
      "Critic Loss: 5.491799354553223\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.07668732851743698\n",
      "Critic Loss: 10.97062873840332\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.07757962495088577\n",
      "Critic Loss: 2.798163414001465\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.10092834383249283\n",
      "Critic Loss: 7.568855285644531\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.09682699292898178\n",
      "Critic Loss: 8.501964569091797\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.14727939665317535\n",
      "Critic Loss: 3.0903730392456055\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.1371568739414215\n",
      "Critic Loss: 4.195549488067627\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.10647902637720108\n",
      "Critic Loss: 7.207520008087158\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.09123853594064713\n",
      "Critic Loss: 4.881318092346191\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.12740936875343323\n",
      "Critic Loss: 6.3075270652771\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.13317252695560455\n",
      "Critic Loss: 3.6725337505340576\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.07795221358537674\n",
      "Critic Loss: 6.830942153930664\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.0916411280632019\n",
      "Critic Loss: 6.133023738861084\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.0819343701004982\n",
      "Critic Loss: 3.360294818878174\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.10665461421012878\n",
      "Critic Loss: 7.442804336547852\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.14364279806613922\n",
      "Critic Loss: 5.8264336585998535\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.12712635099887848\n",
      "Critic Loss: 5.055274486541748\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.07086116075515747\n",
      "Critic Loss: 19.18288803100586\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.1022743210196495\n",
      "Critic Loss: 7.151913166046143\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.08767463266849518\n",
      "Critic Loss: 3.4964466094970703\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.20215746760368347\n",
      "Critic Loss: 5.607241630554199\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.13293419778347015\n",
      "Critic Loss: 7.008721828460693\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.2289084494113922\n",
      "Critic Loss: 5.918880462646484\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.09326275438070297\n",
      "Critic Loss: 10.892049789428711\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.09513752162456512\n",
      "Critic Loss: 8.908885955810547\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.13135606050491333\n",
      "Critic Loss: 6.553310394287109\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.1067490354180336\n",
      "Critic Loss: 5.580721378326416\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.18326038122177124\n",
      "Critic Loss: 9.94792652130127\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.08848463743925095\n",
      "Critic Loss: 4.958232402801514\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.16465795040130615\n",
      "Critic Loss: 5.935744285583496\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.18561944365501404\n",
      "Critic Loss: 5.801917552947998\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.1094323918223381\n",
      "Critic Loss: 6.794393539428711\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.12380492687225342\n",
      "Critic Loss: 6.855515480041504\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.16985279321670532\n",
      "Critic Loss: 3.49881649017334\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.09819597005844116\n",
      "Critic Loss: 9.179471969604492\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.19547602534294128\n",
      "Critic Loss: 10.60189437866211\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.13110627233982086\n",
      "Critic Loss: 6.193856239318848\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.14442482590675354\n",
      "Critic Loss: 13.329320907592773\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.1976226568222046\n",
      "Critic Loss: 9.222442626953125\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.05031248927116394\n",
      "Critic Loss: 13.517233848571777\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.10471285879611969\n",
      "Critic Loss: 6.449685573577881\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.09595657885074615\n",
      "Critic Loss: 8.15941047668457\n",
      "\n",
      "New best validation reward reached in update [68/200]\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.07628205418586731\n",
      "Critic Loss: 11.237380981445312\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.1199961006641388\n",
      "Critic Loss: 5.226808547973633\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.15856720507144928\n",
      "Critic Loss: 4.84910249710083\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.07581313699483871\n",
      "Critic Loss: 3.976745128631592\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.1211148202419281\n",
      "Critic Loss: 5.9166951179504395\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.08054868876934052\n",
      "Critic Loss: 7.12448787689209\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.15418829023838043\n",
      "Critic Loss: 4.443164348602295\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.2741491198539734\n",
      "Critic Loss: 8.291784286499023\n",
      "\n",
      "New best validation reward reached in update [76/200]\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.1367924064397812\n",
      "Critic Loss: 11.16656494140625\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.17227089405059814\n",
      "Critic Loss: 6.954180717468262\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.12404841929674149\n",
      "Critic Loss: 11.740506172180176\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.1056302860379219\n",
      "Critic Loss: 3.589664936065674\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.08639773726463318\n",
      "Critic Loss: 5.358696937561035\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.11329689621925354\n",
      "Critic Loss: 6.21518087387085\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.17086385190486908\n",
      "Critic Loss: 5.409660339355469\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.06352099031209946\n",
      "Critic Loss: 10.625205039978027\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.12935571372509003\n",
      "Critic Loss: 12.07691764831543\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.10439600795507431\n",
      "Critic Loss: 6.903955459594727\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.2105724811553955\n",
      "Critic Loss: 4.551570892333984\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.1277180165052414\n",
      "Critic Loss: 4.774580001831055\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.06895269453525543\n",
      "Critic Loss: 6.691771984100342\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.17597490549087524\n",
      "Critic Loss: 9.297219276428223\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.10189758986234665\n",
      "Critic Loss: 7.557346343994141\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.16603606939315796\n",
      "Critic Loss: 8.510115623474121\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.1369601935148239\n",
      "Critic Loss: 9.490087509155273\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.09045888483524323\n",
      "Critic Loss: 7.988528251647949\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.08667699247598648\n",
      "Critic Loss: 5.100869178771973\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.12713530659675598\n",
      "Critic Loss: 5.493325233459473\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.12168789654970169\n",
      "Critic Loss: 6.63286018371582\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.09610524773597717\n",
      "Critic Loss: 3.7362279891967773\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.13992898166179657\n",
      "Critic Loss: 5.92915678024292\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.20372992753982544\n",
      "Critic Loss: 7.931519031524658\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.11267664283514023\n",
      "Critic Loss: 6.3167619705200195\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.17425695061683655\n",
      "Critic Loss: 11.104755401611328\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.1546766608953476\n",
      "Critic Loss: 3.4112467765808105\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.2006906270980835\n",
      "Critic Loss: 8.660099983215332\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.1771765500307083\n",
      "Critic Loss: 9.006075859069824\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.14053276181221008\n",
      "Critic Loss: 3.9493961334228516\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.11152703315019608\n",
      "Critic Loss: 4.086813926696777\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.08143452554941177\n",
      "Critic Loss: 4.64971399307251\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.14939749240875244\n",
      "Critic Loss: 5.944542407989502\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.1918075680732727\n",
      "Critic Loss: 8.096085548400879\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.13094580173492432\n",
      "Critic Loss: 3.3202054500579834\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.11906065791845322\n",
      "Critic Loss: 4.651161193847656\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.12417100369930267\n",
      "Critic Loss: 4.701916217803955\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.09073395282030106\n",
      "Critic Loss: 8.347460746765137\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.17944563925266266\n",
      "Critic Loss: 7.666648864746094\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.11159709841012955\n",
      "Critic Loss: 7.491423606872559\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.1960972547531128\n",
      "Critic Loss: 7.385158061981201\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.1305473893880844\n",
      "Critic Loss: 5.1591668128967285\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.13249748945236206\n",
      "Critic Loss: 6.026834487915039\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.15828710794448853\n",
      "Critic Loss: 2.92928147315979\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68152545652c4ba59c8ef9fe087fc68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_val_ep_duration</td><td>119.6</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.00296</td></tr><tr><td>Loss/Critic_loss</td><td>2.92928</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.3711</td></tr><tr><td>Loss/KL_divergence</td><td>0.0283</td></tr><tr><td>Loss/Policy_loss</td><td>0.0441</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.15829</td></tr><tr><td>Metric/Explained_variance</td><td>0.78099</td></tr><tr><td>Reward/Mean_val_reward</td><td>-8.9214</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-8.8284</td></tr><tr><td>global_step</td><td>120</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sweep-5</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/dmzw3ifu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/dmzw3ifu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_131719-dmzw3ifu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6xcdyn8t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0034898427635440795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.001294138141313056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.022638663129059593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8767868679753683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.6854216818675228e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0007149183015068061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_132715-6xcdyn8t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/6xcdyn8t' target=\"_blank\">colorful-sweep-6</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/6xcdyn8t' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/6xcdyn8t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.0034898427635440795, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.001294138141313056, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022638663129059593, 'epochs': 10, 'exponential_factor': 0.8767868679753683, 'gamma': 0.99, 'hidden_sizes': [350, 250, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 2.6854216818675228e-05, 'l2_factor': 0.0007149183015068061, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0034898427635440795, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001294138141313056, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022638663129059593, 'epochs': 10, 'exponential_factor': 0.8767868679753683, 'gamma': 0.99, 'l1_factor': 2.6854216818675228e-05, 'l2_factor': 0.0007149183015068061, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0034898427635440795, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001294138141313056, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022638663129059593, 'epochs': 10, 'exponential_factor': 0.8767868679753683, 'gamma': 0.99, 'l1_factor': 2.6854216818675228e-05, 'l2_factor': 0.0007149183015068061, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0034898427635440795, 'critic_lr': 0.001294138141313056, 'decay_method': 'exponential', 'exponential_factor': 0.8767868679753683, 'value_loss_factor': 1, 'entropy': 0.022638663129059593, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.6854216818675228e-05, 'l2_factor': 0.0007149183015068061, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 250, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.4291744232177734\n",
      "Critic Loss: 28.799564361572266\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.15448245406150818\n",
      "Critic Loss: 6.994504928588867\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.03180084377527237\n",
      "Critic Loss: 3.4180328845977783\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.04849005118012428\n",
      "Critic Loss: 5.544382095336914\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.025637831538915634\n",
      "Critic Loss: 7.746951103210449\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.012289594858884811\n",
      "Critic Loss: 7.554975986480713\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.01750023663043976\n",
      "Critic Loss: 10.006244659423828\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.0688612312078476\n",
      "Critic Loss: 13.228191375732422\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.04814771190285683\n",
      "Critic Loss: 11.547144889831543\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.0007245102897286415\n",
      "Critic Loss: 12.763511657714844\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.025512609630823135\n",
      "Critic Loss: 7.05305290222168\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.01045308355242014\n",
      "Critic Loss: 6.2804436683654785\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.10935138165950775\n",
      "Critic Loss: 8.243328094482422\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.11613298952579498\n",
      "Critic Loss: 5.488628387451172\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.03622613102197647\n",
      "Critic Loss: 8.170860290527344\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.017490992322564125\n",
      "Critic Loss: 8.51883316040039\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.02238786220550537\n",
      "Critic Loss: 4.414859294891357\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.04651791974902153\n",
      "Critic Loss: 5.501023769378662\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.0033909911289811134\n",
      "Critic Loss: 5.947305679321289\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.0007809819653630257\n",
      "Critic Loss: 5.997531890869141\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.010208449326455593\n",
      "Critic Loss: 7.097651958465576\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.013430244289338589\n",
      "Critic Loss: 6.231281757354736\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.03758780658245087\n",
      "Critic Loss: 5.807110786437988\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.009016199968755245\n",
      "Critic Loss: 6.400576114654541\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.016205232590436935\n",
      "Critic Loss: 4.8869733810424805\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.009768848307430744\n",
      "Critic Loss: 6.415579319000244\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.019183587282896042\n",
      "Critic Loss: 3.2038912773132324\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.00821695290505886\n",
      "Critic Loss: 5.252892971038818\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.09066963940858841\n",
      "Critic Loss: 4.704721450805664\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.020218726247549057\n",
      "Critic Loss: 3.144881010055542\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.012858550064265728\n",
      "Critic Loss: 4.858443260192871\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.023559842258691788\n",
      "Critic Loss: 6.557425498962402\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.011032342910766602\n",
      "Critic Loss: 4.630990028381348\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.0036032209172844887\n",
      "Critic Loss: 3.469569444656372\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.0035722041502594948\n",
      "Critic Loss: 4.010761260986328\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.028661953285336494\n",
      "Critic Loss: 4.560430526733398\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.04612082988023758\n",
      "Critic Loss: 3.0453858375549316\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.009719614870846272\n",
      "Critic Loss: 3.1810688972473145\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.021772628650069237\n",
      "Critic Loss: 2.907208204269409\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.004383892752230167\n",
      "Critic Loss: 2.942833185195923\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.014482012949883938\n",
      "Critic Loss: 8.185786247253418\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.004944131709635258\n",
      "Critic Loss: 5.136132717132568\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.01855788752436638\n",
      "Critic Loss: 4.731991767883301\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.10098417103290558\n",
      "Critic Loss: 5.358421325683594\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.04934510588645935\n",
      "Critic Loss: 4.738457679748535\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.01249651238322258\n",
      "Critic Loss: 6.232935905456543\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.044964250177145004\n",
      "Critic Loss: 7.1046953201293945\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.003051738254725933\n",
      "Critic Loss: 5.401244163513184\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.01740240305662155\n",
      "Critic Loss: 8.105338096618652\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.009356924332678318\n",
      "Critic Loss: 4.770200729370117\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.0004725586622953415\n",
      "Critic Loss: 5.3950018882751465\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.025736946612596512\n",
      "Critic Loss: 4.139895915985107\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.006440317258238792\n",
      "Critic Loss: 4.854273319244385\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.018625661730766296\n",
      "Critic Loss: 4.596997261047363\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.0030714906752109528\n",
      "Critic Loss: 5.805296897888184\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.01555867213755846\n",
      "Critic Loss: 6.939754962921143\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.025423340499401093\n",
      "Critic Loss: 5.8720808029174805\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.037623703479766846\n",
      "Critic Loss: 4.521703720092773\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.002906937152147293\n",
      "Critic Loss: 5.270363807678223\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.02313723787665367\n",
      "Critic Loss: 4.576569080352783\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.0001737251877784729\n",
      "Critic Loss: 6.880288600921631\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.03045692667365074\n",
      "Critic Loss: 3.158487558364868\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.0026160525158047676\n",
      "Critic Loss: 3.9191579818725586\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.03814278915524483\n",
      "Critic Loss: 4.082764625549316\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.027242176234722137\n",
      "Critic Loss: 5.571130275726318\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.01662764884531498\n",
      "Critic Loss: 4.275615692138672\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.012438051402568817\n",
      "Critic Loss: 4.1982808113098145\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.010568087920546532\n",
      "Critic Loss: 6.028165817260742\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.003543236292898655\n",
      "Critic Loss: 5.623397350311279\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.013774493709206581\n",
      "Critic Loss: 3.3079257011413574\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.02431667223572731\n",
      "Critic Loss: 3.487823724746704\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.016436152160167694\n",
      "Critic Loss: 4.882822513580322\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.024571184068918228\n",
      "Critic Loss: 5.000009059906006\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.015886519104242325\n",
      "Critic Loss: 6.1494927406311035\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.01874961331486702\n",
      "Critic Loss: 4.626165390014648\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.0005967942997813225\n",
      "Critic Loss: 3.313201665878296\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.009868353605270386\n",
      "Critic Loss: 4.177088737487793\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.005100988782942295\n",
      "Critic Loss: 2.791966676712036\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.011880836449563503\n",
      "Critic Loss: 7.169136047363281\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.03058181330561638\n",
      "Critic Loss: 4.138854503631592\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.013217813335359097\n",
      "Critic Loss: 5.207517623901367\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.012353885918855667\n",
      "Critic Loss: 5.274316310882568\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.029518961906433105\n",
      "Critic Loss: 4.682951927185059\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.015930678695440292\n",
      "Critic Loss: 4.379899978637695\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.03090916946530342\n",
      "Critic Loss: 3.022334337234497\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.004983448423445225\n",
      "Critic Loss: 4.358241558074951\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.028940122574567795\n",
      "Critic Loss: 2.8396341800689697\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.018435100093483925\n",
      "Critic Loss: 4.6639604568481445\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.010739603079855442\n",
      "Critic Loss: 2.960327386856079\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.0013317978009581566\n",
      "Critic Loss: 3.5817031860351562\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.0174034982919693\n",
      "Critic Loss: 4.350593566894531\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.029734622687101364\n",
      "Critic Loss: 3.423076868057251\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.02270045131444931\n",
      "Critic Loss: 2.5431008338928223\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.004127158783376217\n",
      "Critic Loss: 4.821628570556641\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.02061665803194046\n",
      "Critic Loss: 7.469746112823486\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.024741802364587784\n",
      "Critic Loss: 2.5405282974243164\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.016764577478170395\n",
      "Critic Loss: 5.225711345672607\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.030182912945747375\n",
      "Critic Loss: 4.326320648193359\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.009431200101971626\n",
      "Critic Loss: 6.837129592895508\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.015614646486938\n",
      "Critic Loss: 4.318196773529053\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.005336693488061428\n",
      "Critic Loss: 3.869584560394287\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.002278672531247139\n",
      "Critic Loss: 5.996230602264404\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.03678680956363678\n",
      "Critic Loss: 3.2888221740722656\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.008169648237526417\n",
      "Critic Loss: 4.315008640289307\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.013030252419412136\n",
      "Critic Loss: 8.19796085357666\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.01389553677290678\n",
      "Critic Loss: 3.4783995151519775\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.0009689461439847946\n",
      "Critic Loss: 3.219648599624634\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.007121505215764046\n",
      "Critic Loss: 6.813215255737305\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.006278988905251026\n",
      "Critic Loss: 3.60508394241333\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.029511045664548874\n",
      "Critic Loss: 4.819249153137207\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.018899112939834595\n",
      "Critic Loss: 4.333902359008789\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.02156773954629898\n",
      "Critic Loss: 2.249281406402588\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.026721881702542305\n",
      "Critic Loss: 3.5304715633392334\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.008962905965745449\n",
      "Critic Loss: 3.1749699115753174\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.0038567380979657173\n",
      "Critic Loss: 4.748375415802002\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.03280400484800339\n",
      "Critic Loss: 6.610538005828857\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72f5f8b72b54b7ca7c705b878f7be0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>152.8</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>143.60001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.01013</td></tr><tr><td>Loss/Critic_loss</td><td>6.61054</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.64674</td></tr><tr><td>Loss/KL_divergence</td><td>0.00889</td></tr><tr><td>Loss/Policy_loss</td><td>0.02477</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.0328</td></tr><tr><td>Metric/Explained_variance</td><td>0.20221</td></tr><tr><td>Reward/Mean_train_reward</td><td>6.03979</td></tr><tr><td>Reward/Mean_val_reward</td><td>3.7426</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.8752</td></tr><tr><td>global_step</td><td>116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-sweep-6</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/6xcdyn8t' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/6xcdyn8t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_132715-6xcdyn8t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e5y7lb6m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00029850049215536257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.006136579764319283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.028329409312531133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9283635593197244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 4.857720946196461e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0003143359583178352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_134838-e5y7lb6m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/e5y7lb6m' target=\"_blank\">earnest-sweep-7</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/e5y7lb6m' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/e5y7lb6m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.00029850049215536257, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.006136579764319283, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.028329409312531133, 'epochs': 10, 'exponential_factor': 0.9283635593197244, 'gamma': 0.9, 'hidden_sizes': [350, 150, 250, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 4.857720946196461e-06, 'l2_factor': 0.0003143359583178352, 'lrelu': 0.01, 'minibatch_size': 64, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.00029850049215536257, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.006136579764319283, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.028329409312531133, 'epochs': 10, 'exponential_factor': 0.9283635593197244, 'gamma': 0.9, 'l1_factor': 4.857720946196461e-06, 'l2_factor': 0.0003143359583178352, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.00029850049215536257, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.006136579764319283, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.028329409312531133, 'epochs': 10, 'exponential_factor': 0.9283635593197244, 'gamma': 0.9, 'l1_factor': 4.857720946196461e-06, 'l2_factor': 0.0003143359583178352, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00029850049215536257, 'critic_lr': 0.006136579764319283, 'decay_method': 'exponential', 'exponential_factor': 0.9283635593197244, 'value_loss_factor': 1, 'entropy': 0.028329409312531133, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 4.857720946196461e-06, 'l2_factor': 0.0003143359583178352, 'T': 768, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [350, 150, 250, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 10.623713493347168\n",
      "Critic Loss: 11.993703842163086\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 10.632637977600098\n",
      "Critic Loss: 12.043622970581055\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 4.096467971801758\n",
      "Critic Loss: 7.101912498474121\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 4.474787712097168\n",
      "Critic Loss: 5.554710865020752\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 7.939154624938965\n",
      "Critic Loss: 9.96131706237793\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 3.311408758163452\n",
      "Critic Loss: 5.987813949584961\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.586148738861084\n",
      "Critic Loss: 4.691904067993164\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 4.875832557678223\n",
      "Critic Loss: 5.483379364013672\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 1.6053630113601685\n",
      "Critic Loss: 4.353066444396973\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 3.1355371475219727\n",
      "Critic Loss: 5.054018497467041\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 5.155564785003662\n",
      "Critic Loss: 4.824285507202148\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 2.985028028488159\n",
      "Critic Loss: 4.41192102432251\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.9277033805847168\n",
      "Critic Loss: 5.428734302520752\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 5.571165561676025\n",
      "Critic Loss: 4.0234479904174805\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.7300000190734863\n",
      "Critic Loss: 5.06639289855957\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.8859750032424927\n",
      "Critic Loss: 4.319578647613525\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.807530403137207\n",
      "Critic Loss: 3.9730708599090576\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.8833122253417969\n",
      "Critic Loss: 2.126953125\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.878440797328949\n",
      "Critic Loss: 3.2925398349761963\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 1.750368595123291\n",
      "Critic Loss: 2.416771173477173\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -1.338950514793396\n",
      "Critic Loss: 1.3580381870269775\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -2.0328428745269775\n",
      "Critic Loss: 1.107306718826294\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -2.7935690879821777\n",
      "Critic Loss: 1.4220194816589355\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -1.9308369159698486\n",
      "Critic Loss: 1.0712318420410156\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 1.12263822555542\n",
      "Critic Loss: 2.2000350952148438\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 2.5732262134552\n",
      "Critic Loss: 3.7592809200286865\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.671187162399292\n",
      "Critic Loss: 4.159162998199463\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -3.0005762577056885\n",
      "Critic Loss: 1.226925253868103\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.09740090370178223\n",
      "Critic Loss: 1.722548007965088\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -2.1639208793640137\n",
      "Critic Loss: 1.1389756202697754\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 4.64923095703125\n",
      "Critic Loss: 3.687781572341919\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.3908628225326538\n",
      "Critic Loss: 1.7321425676345825\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.9112147092819214\n",
      "Critic Loss: 2.989764451980591\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.9906436204910278\n",
      "Critic Loss: 1.9442789554595947\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.9878650903701782\n",
      "Critic Loss: 1.80352783203125\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.5349143743515015\n",
      "Critic Loss: 1.153476357460022\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -1.0608088970184326\n",
      "Critic Loss: 2.459425926208496\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -1.2931056022644043\n",
      "Critic Loss: 1.7978661060333252\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 4.200708389282227\n",
      "Critic Loss: 5.311702251434326\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 4.873900890350342\n",
      "Critic Loss: 3.326146125793457\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -3.965735673904419\n",
      "Critic Loss: 1.0638341903686523\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 3.531010866165161\n",
      "Critic Loss: 2.5097362995147705\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 1.7867083549499512\n",
      "Critic Loss: 2.8262205123901367\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.5658794045448303\n",
      "Critic Loss: 2.8887650966644287\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 1.446584701538086\n",
      "Critic Loss: 1.8731745481491089\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -2.1717774868011475\n",
      "Critic Loss: 0.7666764259338379\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 4.599855422973633\n",
      "Critic Loss: 4.036524295806885\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.6670483350753784\n",
      "Critic Loss: 0.8468727469444275\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.7391437292098999\n",
      "Critic Loss: 2.0050501823425293\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -1.2240524291992188\n",
      "Critic Loss: 1.5156821012496948\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 2.887298583984375\n",
      "Critic Loss: 1.5347727537155151\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 2.6448512077331543\n",
      "Critic Loss: 3.0210909843444824\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -1.7961432933807373\n",
      "Critic Loss: 1.0544567108154297\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -1.945626974105835\n",
      "Critic Loss: 1.3860918283462524\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.0006952285766601562\n",
      "Critic Loss: 1.2614620923995972\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.1659870743751526\n",
      "Critic Loss: 1.3954041004180908\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.7829113006591797\n",
      "Critic Loss: 2.4494147300720215\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -2.26165771484375\n",
      "Critic Loss: 1.3980435132980347\n",
      "\n",
      "New best validation reward reached in update [58/200]\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 1.4334369897842407\n",
      "Critic Loss: 1.8947222232818604\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.9594066143035889\n",
      "Critic Loss: 3.2557530403137207\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -1.3480031490325928\n",
      "Critic Loss: 1.5307899713516235\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -1.9124608039855957\n",
      "Critic Loss: 2.068948745727539\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 1.1665899753570557\n",
      "Critic Loss: 1.6467654705047607\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.5199018120765686\n",
      "Critic Loss: 2.2152137756347656\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 4.574899196624756\n",
      "Critic Loss: 3.8668789863586426\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 1.9535350799560547\n",
      "Critic Loss: 2.2938334941864014\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -2.4327213764190674\n",
      "Critic Loss: 0.903376042842865\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -2.963683605194092\n",
      "Critic Loss: 1.0260611772537231\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 5.53371524810791\n",
      "Critic Loss: 3.9331130981445312\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.7007691860198975\n",
      "Critic Loss: 2.9013876914978027\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 1.4498906135559082\n",
      "Critic Loss: 2.4217822551727295\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.10900288820266724\n",
      "Critic Loss: 1.8423768281936646\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 2.4683797359466553\n",
      "Critic Loss: 1.5877302885055542\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.8182201385498047\n",
      "Critic Loss: 2.9507391452789307\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.19202888011932373\n",
      "Critic Loss: 1.2905535697937012\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 1.9989185333251953\n",
      "Critic Loss: 4.001285552978516\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 3.606288433074951\n",
      "Critic Loss: 3.545278310775757\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 2.4581377506256104\n",
      "Critic Loss: 1.991983413696289\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.6492864489555359\n",
      "Critic Loss: 2.1031620502471924\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 2.1475744247436523\n",
      "Critic Loss: 2.5744848251342773\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 5.8322649002075195\n",
      "Critic Loss: 3.757763147354126\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -3.449944019317627\n",
      "Critic Loss: 1.6582882404327393\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 2.023603677749634\n",
      "Critic Loss: 3.312580108642578\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 2.165132522583008\n",
      "Critic Loss: 2.3773632049560547\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.9802367687225342\n",
      "Critic Loss: 3.218689441680908\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.43891477584838867\n",
      "Critic Loss: 2.023054838180542\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.39458179473876953\n",
      "Critic Loss: 2.084459066390991\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 1.2152971029281616\n",
      "Critic Loss: 3.0599281787872314\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 2.042398452758789\n",
      "Critic Loss: 3.367567539215088\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 2.201308012008667\n",
      "Critic Loss: 2.891693353652954\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 2.577704668045044\n",
      "Critic Loss: 2.0793492794036865\n",
      "\n",
      "New best validation reward reached in update [91/200]\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.9389018416404724\n",
      "Critic Loss: 1.0609413385391235\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 4.960055351257324\n",
      "Critic Loss: 3.693716049194336\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 4.017005443572998\n",
      "Critic Loss: 2.535949230194092\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.3848956823348999\n",
      "Critic Loss: 2.0768256187438965\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.5554691553115845\n",
      "Critic Loss: 1.5455867052078247\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.5497545003890991\n",
      "Critic Loss: 1.3377150297164917\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.6619513034820557\n",
      "Critic Loss: 1.7611641883850098\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 2.286907196044922\n",
      "Critic Loss: 2.4522855281829834\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 5.21073579788208\n",
      "Critic Loss: 3.521326780319214\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.8863002061843872\n",
      "Critic Loss: 3.0235507488250732\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -2.933501720428467\n",
      "Critic Loss: 1.7245601415634155\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 6.729923725128174\n",
      "Critic Loss: 5.282585144042969\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.5937870144844055\n",
      "Critic Loss: 1.3761324882507324\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -0.8695059418678284\n",
      "Critic Loss: 1.7224406003952026\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.7826147079467773\n",
      "Critic Loss: 1.681837797164917\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.531223475933075\n",
      "Critic Loss: 1.1701133251190186\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 1.5860021114349365\n",
      "Critic Loss: 2.2770237922668457\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -2.848043918609619\n",
      "Critic Loss: 1.5517948865890503\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -1.3390532732009888\n",
      "Critic Loss: 1.6701374053955078\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 1.8715150356292725\n",
      "Critic Loss: 2.2202491760253906\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 3.3424978256225586\n",
      "Critic Loss: 1.988277554512024\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.7605530619621277\n",
      "Critic Loss: 2.1550240516662598\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -2.8580405712127686\n",
      "Critic Loss: 1.6081665754318237\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 1.6375916004180908\n",
      "Critic Loss: 2.333977222442627\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56be1ffb0bf142ea9bcc1bda749bd18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>112.16666</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>116.9</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.96783</td></tr><tr><td>Loss/Critic_loss</td><td>2.33398</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.9012</td></tr><tr><td>Loss/KL_divergence</td><td>-0.02939</td></tr><tr><td>Loss/Policy_loss</td><td>0.99336</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.63759</td></tr><tr><td>Metric/Explained_variance</td><td>0.5667</td></tr><tr><td>Reward/Mean_train_reward</td><td>-8.50217</td></tr><tr><td>Reward/Mean_val_reward</td><td>5.5719</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.87416</td></tr><tr><td>global_step</td><td>115</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-7</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/e5y7lb6m' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/e5y7lb6m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_134838-e5y7lb6m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h23sj46y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0001376294072645268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.006174120243348213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0158383897681048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9374344812660268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.0393560820023642e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.979923562484843e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_140453-h23sj46y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/h23sj46y' target=\"_blank\">vocal-sweep-8</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/h23sj46y' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/h23sj46y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0001376294072645268, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.006174120243348213, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0158383897681048, 'epochs': 10, 'exponential_factor': 0.9374344812660268, 'gamma': 0.99, 'hidden_sizes': [250, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 1.0393560820023642e-06, 'l2_factor': 6.979923562484843e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0001376294072645268, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.006174120243348213, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0158383897681048, 'epochs': 10, 'exponential_factor': 0.9374344812660268, 'gamma': 0.99, 'l1_factor': 1.0393560820023642e-06, 'l2_factor': 6.979923562484843e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0001376294072645268, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.006174120243348213, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0158383897681048, 'epochs': 10, 'exponential_factor': 0.9374344812660268, 'gamma': 0.99, 'l1_factor': 1.0393560820023642e-06, 'l2_factor': 6.979923562484843e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0001376294072645268, 'critic_lr': 0.006174120243348213, 'decay_method': 'exponential', 'exponential_factor': 0.9374344812660268, 'value_loss_factor': 1, 'entropy': 0.0158383897681048, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.0393560820023642e-06, 'l2_factor': 6.979923562484843e-06, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [250, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 35.14127731323242\n",
      "Critic Loss: 22.175600051879883\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 51.13108825683594\n",
      "Critic Loss: 13.471996307373047\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 31.879758834838867\n",
      "Critic Loss: 19.763967514038086\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 10.797277450561523\n",
      "Critic Loss: 21.74558448791504\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 7.84083890914917\n",
      "Critic Loss: 15.691286087036133\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 3.5601298809051514\n",
      "Critic Loss: 11.361804962158203\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 25.087209701538086\n",
      "Critic Loss: 18.89989471435547\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 10.02575969696045\n",
      "Critic Loss: 9.659255027770996\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 12.549029350280762\n",
      "Critic Loss: 10.285408973693848\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 9.733102798461914\n",
      "Critic Loss: 7.415834426879883\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 13.744240760803223\n",
      "Critic Loss: 16.002553939819336\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 24.35485076904297\n",
      "Critic Loss: 13.273487091064453\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 31.648361206054688\n",
      "Critic Loss: 8.170433044433594\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 4.878623008728027\n",
      "Critic Loss: 9.415614128112793\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 13.161110877990723\n",
      "Critic Loss: 9.033660888671875\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -1.674849033355713\n",
      "Critic Loss: 7.343220233917236\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 3.3232336044311523\n",
      "Critic Loss: 9.346170425415039\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 4.576842308044434\n",
      "Critic Loss: 7.6668243408203125\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -1.4050699472427368\n",
      "Critic Loss: 6.802311897277832\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 2.8746213912963867\n",
      "Critic Loss: 9.034053802490234\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -3.0568089485168457\n",
      "Critic Loss: 4.132965087890625\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 1.3531322479248047\n",
      "Critic Loss: 7.265019416809082\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -2.8282036781311035\n",
      "Critic Loss: 5.598391532897949\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 3.9627463817596436\n",
      "Critic Loss: 7.768237113952637\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 8.747001647949219\n",
      "Critic Loss: 6.4332990646362305\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 6.265427589416504\n",
      "Critic Loss: 6.705662727355957\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 9.446206092834473\n",
      "Critic Loss: 6.51379919052124\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 2.21000599861145\n",
      "Critic Loss: 5.411418914794922\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 4.326409816741943\n",
      "Critic Loss: 4.547819137573242\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.448022484779358\n",
      "Critic Loss: 7.082432746887207\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 2.530418872833252\n",
      "Critic Loss: 7.127367973327637\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.9203916788101196\n",
      "Critic Loss: 5.492246150970459\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -2.3295042514801025\n",
      "Critic Loss: 7.831709861755371\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 1.1937235593795776\n",
      "Critic Loss: 4.222606658935547\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 7.5954790115356445\n",
      "Critic Loss: 8.418825149536133\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 8.614439964294434\n",
      "Critic Loss: 8.116755485534668\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.5056346654891968\n",
      "Critic Loss: 9.754480361938477\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 2.439309597015381\n",
      "Critic Loss: 8.003728866577148\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.7345359921455383\n",
      "Critic Loss: 7.973677158355713\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -3.512800693511963\n",
      "Critic Loss: 5.57429838180542\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 2.4220988750457764\n",
      "Critic Loss: 4.794147491455078\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 1.564009428024292\n",
      "Critic Loss: 6.027763843536377\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.7976580262184143\n",
      "Critic Loss: 6.678389549255371\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 1.1574708223342896\n",
      "Critic Loss: 5.505435943603516\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -4.456453800201416\n",
      "Critic Loss: 2.738866090774536\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.13204382359981537\n",
      "Critic Loss: 5.080253601074219\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -2.936976909637451\n",
      "Critic Loss: 7.004460334777832\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.553705632686615\n",
      "Critic Loss: 4.396204471588135\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 6.544098854064941\n",
      "Critic Loss: 5.368132591247559\n",
      "\n",
      "New best validation reward reached in update [49/200]\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 5.057888507843018\n",
      "Critic Loss: 9.81972599029541\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -3.9351160526275635\n",
      "Critic Loss: 2.802520275115967\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -1.1911828517913818\n",
      "Critic Loss: 2.3687496185302734\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.5146324038505554\n",
      "Critic Loss: 5.039923667907715\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 2.1014580726623535\n",
      "Critic Loss: 7.037865161895752\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 6.440944671630859\n",
      "Critic Loss: 8.491976737976074\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.24012500047683716\n",
      "Critic Loss: 5.874640464782715\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.017201194539666176\n",
      "Critic Loss: 4.641177177429199\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 1.5129728317260742\n",
      "Critic Loss: 6.2948198318481445\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -7.7823872566223145\n",
      "Critic Loss: 5.551030158996582\n",
      "\n",
      "New best validation reward reached in update [59/200]\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 2.4788293838500977\n",
      "Critic Loss: 4.288415908813477\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.3849114775657654\n",
      "Critic Loss: 4.113218307495117\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.47409170866012573\n",
      "Critic Loss: 4.962257385253906\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 2.077493667602539\n",
      "Critic Loss: 8.146160125732422\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 6.708206653594971\n",
      "Critic Loss: 11.064613342285156\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -3.013126850128174\n",
      "Critic Loss: 1.776512622833252\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 2.134939193725586\n",
      "Critic Loss: 7.409268379211426\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.06581802666187286\n",
      "Critic Loss: 8.547236442565918\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -1.6283130645751953\n",
      "Critic Loss: 7.1978349685668945\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -4.720892906188965\n",
      "Critic Loss: 2.1806907653808594\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -1.3699113130569458\n",
      "Critic Loss: 4.730378150939941\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -2.0206215381622314\n",
      "Critic Loss: 4.064607620239258\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -4.839537620544434\n",
      "Critic Loss: 3.298635482788086\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.9801710247993469\n",
      "Critic Loss: 6.379867076873779\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 5.31417989730835\n",
      "Critic Loss: 10.305047988891602\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -2.554920196533203\n",
      "Critic Loss: 4.600996017456055\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 2.7566871643066406\n",
      "Critic Loss: 6.8088178634643555\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.9722994565963745\n",
      "Critic Loss: 6.218329429626465\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -3.9250478744506836\n",
      "Critic Loss: 3.940098524093628\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -2.552582263946533\n",
      "Critic Loss: 6.191136837005615\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.468793660402298\n",
      "Critic Loss: 5.027476787567139\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -2.218759059906006\n",
      "Critic Loss: 5.441397666931152\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.4640902578830719\n",
      "Critic Loss: 1.9151182174682617\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 1.1127252578735352\n",
      "Critic Loss: 9.292570114135742\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -5.681560516357422\n",
      "Critic Loss: 4.892743110656738\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.36663803458213806\n",
      "Critic Loss: 8.016101837158203\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.9793953895568848\n",
      "Critic Loss: 3.1787350177764893\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -1.7272058725357056\n",
      "Critic Loss: 5.040840148925781\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 2.0445194244384766\n",
      "Critic Loss: 6.577078342437744\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -4.365017414093018\n",
      "Critic Loss: 4.680760860443115\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -5.983377933502197\n",
      "Critic Loss: 5.709847450256348\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.3523349165916443\n",
      "Critic Loss: 8.795099258422852\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -4.091527938842773\n",
      "Critic Loss: 4.672237873077393\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa011b7461f4154ac216bdeb18ea5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>128.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>139.60001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>2e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-4.1071</td></tr><tr><td>Loss/Critic_loss</td><td>4.67224</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.14499</td></tr><tr><td>Loss/KL_divergence</td><td>0.008</td></tr><tr><td>Loss/Policy_loss</td><td>-4.08897</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-4.09153</td></tr><tr><td>Metric/Explained_variance</td><td>0.54637</td></tr><tr><td>Reward/Mean_train_reward</td><td>-5.1525</td></tr><tr><td>Reward/Mean_val_reward</td><td>0.9906</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-3.55489</td></tr><tr><td>global_step</td><td>92</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-sweep-8</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/h23sj46y' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/h23sj46y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_140453-h23sj46y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sjbw0pa3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0020942885165254714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00020285666319313592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.025547631458773035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9568289807278793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.6634105316797389e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0004606514402925785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_141535-sjbw0pa3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/sjbw0pa3' target=\"_blank\">glorious-sweep-9</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/sjbw0pa3' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/sjbw0pa3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.0020942885165254714, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020285666319313592, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.025547631458773035, 'epochs': 10, 'exponential_factor': 0.9568289807278793, 'gamma': 0.99, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.6634105316797389e-06, 'l2_factor': 0.0004606514402925785, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0020942885165254714, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020285666319313592, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.025547631458773035, 'epochs': 10, 'exponential_factor': 0.9568289807278793, 'gamma': 0.99, 'l1_factor': 1.6634105316797389e-06, 'l2_factor': 0.0004606514402925785, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0020942885165254714, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020285666319313592, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.025547631458773035, 'epochs': 10, 'exponential_factor': 0.9568289807278793, 'gamma': 0.99, 'l1_factor': 1.6634105316797389e-06, 'l2_factor': 0.0004606514402925785, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0020942885165254714, 'critic_lr': 0.00020285666319313592, 'decay_method': 'exponential', 'exponential_factor': 0.9568289807278793, 'value_loss_factor': 1, 'entropy': 0.025547631458773035, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.6634105316797389e-06, 'l2_factor': 0.0004606514402925785, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.1469242572784424\n",
      "Critic Loss: 41.96369552612305\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.13989700376987457\n",
      "Critic Loss: 9.217179298400879\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.059172362089157104\n",
      "Critic Loss: 7.397335052490234\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.0632653683423996\n",
      "Critic Loss: 4.572931289672852\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.10138443112373352\n",
      "Critic Loss: 6.193671703338623\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.0011304672807455063\n",
      "Critic Loss: 8.207046508789062\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.025798838585615158\n",
      "Critic Loss: 11.151042938232422\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.030589833855628967\n",
      "Critic Loss: 8.57968807220459\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.050489138811826706\n",
      "Critic Loss: 14.607194900512695\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -3.5735778510570526e-05\n",
      "Critic Loss: 15.49687385559082\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.0352664515376091\n",
      "Critic Loss: 9.755049705505371\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.5794034004211426\n",
      "Critic Loss: 10.62185287475586\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.09321347624063492\n",
      "Critic Loss: 10.922466278076172\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.0060071442276239395\n",
      "Critic Loss: 10.442203521728516\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.01471160352230072\n",
      "Critic Loss: 10.980093955993652\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.026130177080631256\n",
      "Critic Loss: 10.008962631225586\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.065472811460495\n",
      "Critic Loss: 14.370495796203613\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.012246808037161827\n",
      "Critic Loss: 8.216913223266602\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.03298673778772354\n",
      "Critic Loss: 7.1125102043151855\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.0191204771399498\n",
      "Critic Loss: 10.268585205078125\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.04546770453453064\n",
      "Critic Loss: 4.984831809997559\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.02472783625125885\n",
      "Critic Loss: 5.031548976898193\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.059376634657382965\n",
      "Critic Loss: 4.538448810577393\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.04227220267057419\n",
      "Critic Loss: 4.988557815551758\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.0037045106291770935\n",
      "Critic Loss: 8.181953430175781\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.017327111214399338\n",
      "Critic Loss: 6.763542175292969\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.006295609287917614\n",
      "Critic Loss: 5.963150978088379\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.021366819739341736\n",
      "Critic Loss: 6.494603157043457\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.0165338646620512\n",
      "Critic Loss: 6.340340614318848\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.020324692130088806\n",
      "Critic Loss: 4.433001518249512\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.006072681397199631\n",
      "Critic Loss: 7.771801948547363\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.012301343493163586\n",
      "Critic Loss: 6.119015693664551\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.017822112888097763\n",
      "Critic Loss: 11.530634880065918\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.01824980601668358\n",
      "Critic Loss: 7.8326802253723145\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.03239614889025688\n",
      "Critic Loss: 6.909079074859619\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.05276354029774666\n",
      "Critic Loss: 4.634751319885254\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.0191941037774086\n",
      "Critic Loss: 3.900637149810791\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.023428577929735184\n",
      "Critic Loss: 5.806070327758789\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.004359088838100433\n",
      "Critic Loss: 10.966509819030762\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.00984229613095522\n",
      "Critic Loss: 4.301393508911133\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.03961717709898949\n",
      "Critic Loss: 2.9367618560791016\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.027113668620586395\n",
      "Critic Loss: 6.639035224914551\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.024954359978437424\n",
      "Critic Loss: 8.636093139648438\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.0414055697619915\n",
      "Critic Loss: 5.652187347412109\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.023984592407941818\n",
      "Critic Loss: 4.3301191329956055\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.025928102433681488\n",
      "Critic Loss: 9.254801750183105\n",
      "\n",
      "New best validation reward reached in update [46/200]\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.04784759134054184\n",
      "Critic Loss: 8.401226997375488\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.0025542238727211952\n",
      "Critic Loss: 7.004919528961182\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.031161367893218994\n",
      "Critic Loss: 5.033514976501465\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.02226848155260086\n",
      "Critic Loss: 8.797085762023926\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.011865143664181232\n",
      "Critic Loss: 9.015766143798828\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.17847295105457306\n",
      "Critic Loss: 5.574041366577148\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.022689014673233032\n",
      "Critic Loss: 6.940642833709717\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.017995070666074753\n",
      "Critic Loss: 4.41546106338501\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.00470361951738596\n",
      "Critic Loss: 5.319576740264893\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.021598313003778458\n",
      "Critic Loss: 5.04051399230957\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.019244831055402756\n",
      "Critic Loss: 6.881319999694824\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.001243635080754757\n",
      "Critic Loss: 4.058292865753174\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.023739583790302277\n",
      "Critic Loss: 4.254974365234375\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.022405941039323807\n",
      "Critic Loss: 3.0945839881896973\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.038045234978199005\n",
      "Critic Loss: 3.0914382934570312\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.016091693192720413\n",
      "Critic Loss: 4.68497371673584\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.006231397390365601\n",
      "Critic Loss: 6.028527736663818\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.008258342742919922\n",
      "Critic Loss: 7.66929817199707\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.008046453818678856\n",
      "Critic Loss: 5.762279987335205\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.012928813695907593\n",
      "Critic Loss: 5.76963472366333\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.04094214364886284\n",
      "Critic Loss: 4.667674541473389\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.010102885775268078\n",
      "Critic Loss: 4.1553053855896\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.018223434686660767\n",
      "Critic Loss: 11.683037757873535\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.02513069473206997\n",
      "Critic Loss: 3.644573211669922\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.030788253992795944\n",
      "Critic Loss: 8.239352226257324\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.021807044744491577\n",
      "Critic Loss: 4.211205959320068\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.01248728297650814\n",
      "Critic Loss: 3.843308925628662\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.04543136805295944\n",
      "Critic Loss: 6.858868598937988\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.02235158532857895\n",
      "Critic Loss: 7.007636070251465\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.025073792785406113\n",
      "Critic Loss: 7.811228275299072\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.01624166965484619\n",
      "Critic Loss: 4.275508880615234\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.0046936338767409325\n",
      "Critic Loss: 3.35752272605896\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9773886cba3148539861b9730b12d477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>157.33333</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>137.5</td></tr><tr><td>Learning_rate/Actor</td><td>7e-05</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.01754</td></tr><tr><td>Loss/Critic_loss</td><td>3.35752</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.83468</td></tr><tr><td>Loss/KL_divergence</td><td>0.00153</td></tr><tr><td>Loss/Policy_loss</td><td>0.00378</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.00469</td></tr><tr><td>Metric/Explained_variance</td><td>0.73239</td></tr><tr><td>Reward/Mean_train_reward</td><td>7.543</td></tr><tr><td>Reward/Mean_val_reward</td><td>-1.9115</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>2.77044</td></tr><tr><td>global_step</td><td>78</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-sweep-9</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/sjbw0pa3' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/sjbw0pa3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_141535-sjbw0pa3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vxs1o6u8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0006994883482315607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0011522613403651585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03870003682400877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9277244387698328\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.9068537515180694e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.2661674277837051e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_142739-vxs1o6u8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/vxs1o6u8' target=\"_blank\">quiet-sweep-10</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vxs1o6u8' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vxs1o6u8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.0006994883482315607, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011522613403651585, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03870003682400877, 'epochs': 10, 'exponential_factor': 0.9277244387698328, 'gamma': 0.99, 'hidden_sizes': [350, 250, 250, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.9068537515180694e-05, 'l2_factor': 1.2661674277837051e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 250, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0006994883482315607, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011522613403651585, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03870003682400877, 'epochs': 10, 'exponential_factor': 0.9277244387698328, 'gamma': 0.99, 'l1_factor': 2.9068537515180694e-05, 'l2_factor': 1.2661674277837051e-06, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 250, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0006994883482315607, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011522613403651585, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03870003682400877, 'epochs': 10, 'exponential_factor': 0.9277244387698328, 'gamma': 0.99, 'l1_factor': 2.9068537515180694e-05, 'l2_factor': 1.2661674277837051e-06, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0006994883482315607, 'critic_lr': 0.0011522613403651585, 'decay_method': 'exponential', 'exponential_factor': 0.9277244387698328, 'value_loss_factor': 1, 'entropy': 0.03870003682400877, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.9068537515180694e-05, 'l2_factor': 1.2661674277837051e-06, 'T': 768, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 250, 250, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.36921581625938416\n",
      "Critic Loss: 23.06926918029785\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.16053396463394165\n",
      "Critic Loss: 9.942325592041016\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.1821637749671936\n",
      "Critic Loss: 9.374334335327148\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.14918261766433716\n",
      "Critic Loss: 9.424233436584473\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.1459970772266388\n",
      "Critic Loss: 10.386150360107422\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.11202044785022736\n",
      "Critic Loss: 7.868710517883301\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.15471090376377106\n",
      "Critic Loss: 6.954244136810303\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.12830117344856262\n",
      "Critic Loss: 6.165003299713135\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.1448288857936859\n",
      "Critic Loss: 10.878171920776367\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.11384713649749756\n",
      "Critic Loss: 9.651434898376465\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.061395276337862015\n",
      "Critic Loss: 7.981898784637451\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.06737879663705826\n",
      "Critic Loss: 5.733450412750244\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.08681276440620422\n",
      "Critic Loss: 7.318926811218262\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.055752698332071304\n",
      "Critic Loss: 3.4481048583984375\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.0930604413151741\n",
      "Critic Loss: 3.6248021125793457\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.09018097817897797\n",
      "Critic Loss: 4.508702278137207\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.04654235765337944\n",
      "Critic Loss: 3.860714912414551\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.0578320138156414\n",
      "Critic Loss: 6.2804412841796875\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.05625170096755028\n",
      "Critic Loss: 6.733800411224365\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.08497840911149979\n",
      "Critic Loss: 7.933305740356445\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.055404309183359146\n",
      "Critic Loss: 7.762851715087891\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.03826494514942169\n",
      "Critic Loss: 8.730012893676758\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.07144704461097717\n",
      "Critic Loss: 3.1472315788269043\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.08401129394769669\n",
      "Critic Loss: 8.438343048095703\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.023851150646805763\n",
      "Critic Loss: 6.7908430099487305\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.04034503549337387\n",
      "Critic Loss: 9.248544692993164\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.04640824720263481\n",
      "Critic Loss: 9.137292861938477\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.04615359380841255\n",
      "Critic Loss: 4.393858432769775\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.04150734469294548\n",
      "Critic Loss: 6.428162574768066\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.06689881533384323\n",
      "Critic Loss: 7.741458892822266\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.08671105653047562\n",
      "Critic Loss: 4.675780296325684\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.04166917875409126\n",
      "Critic Loss: 5.163699150085449\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.053774479776620865\n",
      "Critic Loss: 7.398526191711426\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.027621909976005554\n",
      "Critic Loss: 2.2585978507995605\n",
      "\n",
      "New best validation reward reached in update [34/200]\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.0828690454363823\n",
      "Critic Loss: 6.096135139465332\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.02337399497628212\n",
      "Critic Loss: 3.4853155612945557\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.024809198454022408\n",
      "Critic Loss: 7.531977653503418\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.04101279005408287\n",
      "Critic Loss: 4.3349528312683105\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.0659564957022667\n",
      "Critic Loss: 5.621419429779053\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.06425242125988007\n",
      "Critic Loss: 6.768549919128418\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.0394071489572525\n",
      "Critic Loss: 5.698861598968506\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.06926867365837097\n",
      "Critic Loss: 4.374843597412109\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.06613889336585999\n",
      "Critic Loss: 10.361466407775879\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.04222933202981949\n",
      "Critic Loss: 5.491588115692139\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.04810912907123566\n",
      "Critic Loss: 7.720130443572998\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.03937302529811859\n",
      "Critic Loss: 5.804106712341309\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.0455702468752861\n",
      "Critic Loss: 5.678416728973389\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.02670673280954361\n",
      "Critic Loss: 5.0234832763671875\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.025287853553891182\n",
      "Critic Loss: 3.909552574157715\n",
      "\n",
      "New best validation reward reached in update [49/200]\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.05535997450351715\n",
      "Critic Loss: 4.781426429748535\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.07200027257204056\n",
      "Critic Loss: 5.220293045043945\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.0618356354534626\n",
      "Critic Loss: 3.387083053588867\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.03950868546962738\n",
      "Critic Loss: 2.98476505279541\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.035488229244947433\n",
      "Critic Loss: 3.5345053672790527\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.05552499741315842\n",
      "Critic Loss: 5.554014205932617\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.05044345185160637\n",
      "Critic Loss: 8.507692337036133\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.04167928546667099\n",
      "Critic Loss: 3.32206392288208\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.05356718972325325\n",
      "Critic Loss: 7.893810749053955\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.040924422442913055\n",
      "Critic Loss: 5.971611022949219\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.062159471213817596\n",
      "Critic Loss: 4.654216766357422\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.05474354326725006\n",
      "Critic Loss: 6.830872535705566\n",
      "\n",
      "New best validation reward reached in update [61/200]\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.032812535762786865\n",
      "Critic Loss: 6.21182107925415\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.07039368152618408\n",
      "Critic Loss: 1.8731977939605713\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.07635974138975143\n",
      "Critic Loss: 5.026500701904297\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.051095765084028244\n",
      "Critic Loss: 3.2008469104766846\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.05859309434890747\n",
      "Critic Loss: 2.443570613861084\n",
      "\n",
      "New best validation reward reached in update [66/200]\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.056316573172807693\n",
      "Critic Loss: 2.3328094482421875\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.0578014999628067\n",
      "Critic Loss: 7.515496253967285\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.06590604782104492\n",
      "Critic Loss: 5.273988246917725\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.07899700105190277\n",
      "Critic Loss: 2.673081874847412\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.0599406436085701\n",
      "Critic Loss: 6.147002220153809\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.04977366328239441\n",
      "Critic Loss: 3.2309327125549316\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.052350763231515884\n",
      "Critic Loss: 2.5438601970672607\n",
      "\n",
      "New best validation reward reached in update [73/200]\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.04738309979438782\n",
      "Critic Loss: 5.121922016143799\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.06787413358688354\n",
      "Critic Loss: 3.604551315307617\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.050429943948984146\n",
      "Critic Loss: 3.0414388179779053\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.07983085513114929\n",
      "Critic Loss: 5.17218542098999\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.05225769057869911\n",
      "Critic Loss: 5.303803443908691\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.05653749778866768\n",
      "Critic Loss: 5.680512428283691\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.06709196418523788\n",
      "Critic Loss: 8.270800590515137\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.06253392994403839\n",
      "Critic Loss: 6.114104747772217\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.055599845945835114\n",
      "Critic Loss: 6.070435047149658\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.05500278249382973\n",
      "Critic Loss: 5.436728000640869\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.0582645945250988\n",
      "Critic Loss: 5.001340389251709\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.029350973665714264\n",
      "Critic Loss: 4.303119659423828\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.054579269140958786\n",
      "Critic Loss: 7.132389068603516\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.05734012648463249\n",
      "Critic Loss: 5.511078834533691\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.04071902856230736\n",
      "Critic Loss: 4.113568305969238\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.07231175154447556\n",
      "Critic Loss: 2.951083183288574\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.0621061846613884\n",
      "Critic Loss: 4.228405952453613\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.05288355052471161\n",
      "Critic Loss: 3.212374687194824\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.03790481761097908\n",
      "Critic Loss: 5.491203308105469\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.13983218371868134\n",
      "Critic Loss: 6.676423072814941\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.05264957621693611\n",
      "Critic Loss: 5.971669673919678\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.05418557673692703\n",
      "Critic Loss: 2.9316165447235107\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.052445728331804276\n",
      "Critic Loss: 3.4631080627441406\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.0479714460670948\n",
      "Critic Loss: 2.6438417434692383\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.05822482332587242\n",
      "Critic Loss: 3.565650463104248\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.06557074934244156\n",
      "Critic Loss: 2.806474208831787\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.03620343655347824\n",
      "Critic Loss: 3.6803410053253174\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.02761698141694069\n",
      "Critic Loss: 4.066182613372803\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.049536947160959244\n",
      "Critic Loss: 5.641546726226807\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.0734122171998024\n",
      "Critic Loss: 3.1633286476135254\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.06760533899068832\n",
      "Critic Loss: 2.5316038131713867\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.036945976316928864\n",
      "Critic Loss: 2.5254600048065186\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.05361345037817955\n",
      "Critic Loss: 3.2140965461730957\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.050517547875642776\n",
      "Critic Loss: 8.783398628234863\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.07280664145946503\n",
      "Critic Loss: 3.638312816619873\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.06027893349528313\n",
      "Critic Loss: 4.3029704093933105\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.04653586074709892\n",
      "Critic Loss: 3.9696993827819824\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.07254433631896973\n",
      "Critic Loss: 6.645044326782227\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.08595425635576248\n",
      "Critic Loss: 5.0113983154296875\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.05223865807056427\n",
      "Critic Loss: 4.145654678344727\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.09164270758628845\n",
      "Critic Loss: 1.9197626113891602\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.049500562250614166\n",
      "Critic Loss: 3.0183701515197754\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.07289788872003555\n",
      "Critic Loss: 5.2121686935424805\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.04789545759558678\n",
      "Critic Loss: 3.9301605224609375\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.05213643237948418\n",
      "Critic Loss: 3.3345155715942383\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.07340651005506516\n",
      "Critic Loss: 3.5825653076171875\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.06115772947669029\n",
      "Critic Loss: 5.130431175231934\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.06609506160020828\n",
      "Critic Loss: 5.74169921875\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.08768747746944427\n",
      "Critic Loss: 5.7871904373168945\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.044621918350458145\n",
      "Critic Loss: 8.927994728088379\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.06600380688905716\n",
      "Critic Loss: 5.69010591506958\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.06838488578796387\n",
      "Critic Loss: 4.372107028961182\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.050533227622509\n",
      "Critic Loss: 5.471839904785156\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.06772555410861969\n",
      "Critic Loss: 6.14393424987793\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.0464768260717392\n",
      "Critic Loss: 5.757984161376953\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.08361039310693741\n",
      "Critic Loss: 3.8716495037078857\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.04825101047754288\n",
      "Critic Loss: 4.768714427947998\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.05853448808193207\n",
      "Critic Loss: 9.153409957885742\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.06168268620967865\n",
      "Critic Loss: 4.082913398742676\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.07183708250522614\n",
      "Critic Loss: 5.0887603759765625\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.07210942357778549\n",
      "Critic Loss: 2.759263515472412\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.04726804047822952\n",
      "Critic Loss: 6.171445369720459\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.07331905514001846\n",
      "Critic Loss: 2.5058443546295166\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.05193455517292023\n",
      "Critic Loss: 4.040462970733643\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.06228923425078392\n",
      "Critic Loss: 4.023442268371582\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.06196910887956619\n",
      "Critic Loss: 2.4312567710876465\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.05676169693470001\n",
      "Critic Loss: 3.688206434249878\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.05025305226445198\n",
      "Critic Loss: 8.792008399963379\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.06141384690999985\n",
      "Critic Loss: 4.009112358093262\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 0.053685855120420456\n",
      "Critic Loss: 2.7036795616149902\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.04318520426750183\n",
      "Critic Loss: 6.60748291015625\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.04326946288347244\n",
      "Critic Loss: 2.023756980895996\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 0.04765595868229866\n",
      "Critic Loss: 6.210806369781494\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.05340147763490677\n",
      "Critic Loss: 6.116506576538086\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.06295137107372284\n",
      "Critic Loss: 3.4231483936309814\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.08106043934822083\n",
      "Critic Loss: 3.8646435737609863\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.03098391182720661\n",
      "Critic Loss: 6.153341293334961\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e658858e81fa40e985ace8f3251b6507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>150.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>131.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.07412</td></tr><tr><td>Loss/Critic_loss</td><td>6.15334</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.30448</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00325</td></tr><tr><td>Loss/Policy_loss</td><td>-0.02363</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.03098</td></tr><tr><td>Metric/Explained_variance</td><td>0.34853</td></tr><tr><td>Reward/Mean_train_reward</td><td>-1.411</td></tr><tr><td>Reward/Mean_val_reward</td><td>-9.3173</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>1.13779</td></tr><tr><td>global_step</td><td>150</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-10</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vxs1o6u8' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vxs1o6u8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_142739-vxs1o6u8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0l52eqp5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0008256405505095168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.008172994437793124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.040982293675815976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8800705677263317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00010693167898945396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.186701203809096e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_144902-0l52eqp5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/0l52eqp5' target=\"_blank\">golden-sweep-11</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0l52eqp5' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0l52eqp5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0008256405505095168, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.008172994437793124, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.040982293675815976, 'epochs': 10, 'exponential_factor': 0.8800705677263317, 'gamma': 0.95, 'hidden_sizes': [350, 150, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.00010693167898945396, 'l2_factor': 6.186701203809096e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0008256405505095168, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.008172994437793124, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.040982293675815976, 'epochs': 10, 'exponential_factor': 0.8800705677263317, 'gamma': 0.95, 'l1_factor': 0.00010693167898945396, 'l2_factor': 6.186701203809096e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0008256405505095168, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.008172994437793124, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.040982293675815976, 'epochs': 10, 'exponential_factor': 0.8800705677263317, 'gamma': 0.95, 'l1_factor': 0.00010693167898945396, 'l2_factor': 6.186701203809096e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0008256405505095168, 'critic_lr': 0.008172994437793124, 'decay_method': 'exponential', 'exponential_factor': 0.8800705677263317, 'value_loss_factor': 1, 'entropy': 0.040982293675815976, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00010693167898945396, 'l2_factor': 6.186701203809096e-06, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 150, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 6.757972717285156\n",
      "Critic Loss: 80.08817291259766\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 26.784151077270508\n",
      "Critic Loss: 19.86797332763672\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 38.362178802490234\n",
      "Critic Loss: 20.398536682128906\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 47.73308563232422\n",
      "Critic Loss: 18.325298309326172\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 38.54721450805664\n",
      "Critic Loss: 5.296791076660156\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 33.541202545166016\n",
      "Critic Loss: 8.504853248596191\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 32.25952911376953\n",
      "Critic Loss: 7.1537299156188965\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 39.64338684082031\n",
      "Critic Loss: 7.743521690368652\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 43.27653884887695\n",
      "Critic Loss: 7.707472324371338\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 35.62195587158203\n",
      "Critic Loss: 6.242108345031738\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 29.07975196838379\n",
      "Critic Loss: 3.988332509994507\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 37.37567901611328\n",
      "Critic Loss: 4.354456901550293\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 33.28862380981445\n",
      "Critic Loss: 4.521305561065674\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 38.13493728637695\n",
      "Critic Loss: 4.465392112731934\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 31.976516723632812\n",
      "Critic Loss: 3.0977325439453125\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 37.85047149658203\n",
      "Critic Loss: 3.940697193145752\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 27.141462326049805\n",
      "Critic Loss: 3.835434913635254\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 27.095460891723633\n",
      "Critic Loss: 5.733606815338135\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 22.249746322631836\n",
      "Critic Loss: 3.539336681365967\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 34.737125396728516\n",
      "Critic Loss: 4.472488880157471\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 23.274555206298828\n",
      "Critic Loss: 3.1585195064544678\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 34.691158294677734\n",
      "Critic Loss: 4.954948425292969\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 46.06134033203125\n",
      "Critic Loss: 4.207523345947266\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 34.898738861083984\n",
      "Critic Loss: 3.11777925491333\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 45.431583404541016\n",
      "Critic Loss: 4.752066135406494\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 27.98046875\n",
      "Critic Loss: 4.309746265411377\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 33.298301696777344\n",
      "Critic Loss: 3.392552137374878\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 52.31724166870117\n",
      "Critic Loss: 4.231113910675049\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 31.749677658081055\n",
      "Critic Loss: 3.569847583770752\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 45.33404541015625\n",
      "Critic Loss: 3.195220708847046\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 22.88298797607422\n",
      "Critic Loss: 3.0188941955566406\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 27.89598274230957\n",
      "Critic Loss: 4.005403518676758\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 31.64674949645996\n",
      "Critic Loss: 3.9110190868377686\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 25.56464385986328\n",
      "Critic Loss: 2.7300586700439453\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 29.67896842956543\n",
      "Critic Loss: 3.9787983894348145\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 25.624889373779297\n",
      "Critic Loss: 2.2121424674987793\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 27.470182418823242\n",
      "Critic Loss: 3.0121567249298096\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 26.837017059326172\n",
      "Critic Loss: 4.5237202644348145\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 31.253070831298828\n",
      "Critic Loss: 3.6812989711761475\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 29.582242965698242\n",
      "Critic Loss: 2.9620018005371094\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 81.88452911376953\n",
      "Critic Loss: 2.910662889480591\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 28.569252014160156\n",
      "Critic Loss: 3.742108106613159\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 25.541017532348633\n",
      "Critic Loss: 2.7729878425598145\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 24.485595703125\n",
      "Critic Loss: 2.7921881675720215\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 21.337678909301758\n",
      "Critic Loss: 2.293419361114502\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 25.713552474975586\n",
      "Critic Loss: 3.1006247997283936\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 22.846887588500977\n",
      "Critic Loss: 2.6484341621398926\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 22.660675048828125\n",
      "Critic Loss: 2.15680193901062\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 23.64105987548828\n",
      "Critic Loss: 3.7376277446746826\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 23.267807006835938\n",
      "Critic Loss: 2.5559751987457275\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 26.676576614379883\n",
      "Critic Loss: 2.6164867877960205\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 57.18271255493164\n",
      "Critic Loss: 3.0110585689544678\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665a531c72a14799a2113dc176f3d8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>35.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>34.9</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>55.7067</td></tr><tr><td>Loss/Critic_loss</td><td>3.01106</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.14717</td></tr><tr><td>Loss/KL_divergence</td><td>0.0042</td></tr><tr><td>Loss/Policy_loss</td><td>55.71273</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>57.18271</td></tr><tr><td>Metric/Explained_variance</td><td>0.84551</td></tr><tr><td>Reward/Mean_train_reward</td><td>-76.166</td></tr><tr><td>Reward/Mean_val_reward</td><td>-76.3021</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-76.35405</td></tr><tr><td>global_step</td><td>52</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-11</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0l52eqp5' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0l52eqp5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_144902-0l52eqp5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 888ig7z0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.006429814583048769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0008533310564093102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.010441801207681848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8933222335516829\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.952362284990052e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.912956921632254e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_145135-888ig7z0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/888ig7z0' target=\"_blank\">smooth-sweep-12</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/888ig7z0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/888ig7z0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.006429814583048769, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0008533310564093102, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.010441801207681848, 'epochs': 10, 'exponential_factor': 0.8933222335516829, 'gamma': 0.9, 'hidden_sizes': [150, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.952362284990052e-06, 'l2_factor': 1.912956921632254e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.006429814583048769, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0008533310564093102, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.010441801207681848, 'epochs': 10, 'exponential_factor': 0.8933222335516829, 'gamma': 0.9, 'l1_factor': 2.952362284990052e-06, 'l2_factor': 1.912956921632254e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.006429814583048769, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0008533310564093102, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.010441801207681848, 'epochs': 10, 'exponential_factor': 0.8933222335516829, 'gamma': 0.9, 'l1_factor': 2.952362284990052e-06, 'l2_factor': 1.912956921632254e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.006429814583048769, 'critic_lr': 0.0008533310564093102, 'decay_method': 'exponential', 'exponential_factor': 0.8933222335516829, 'value_loss_factor': 1, 'entropy': 0.010441801207681848, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.952362284990052e-06, 'l2_factor': 1.912956921632254e-05, 'T': 512, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [150, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 15.836479187011719\n",
      "Critic Loss: 17.29606819152832\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 14.599824905395508\n",
      "Critic Loss: 2.2880921363830566\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.6012494564056396\n",
      "Critic Loss: 2.6385810375213623\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 3.4790220260620117\n",
      "Critic Loss: 6.774185657501221\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 15.842264175415039\n",
      "Critic Loss: 18.426685333251953\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 11.467536926269531\n",
      "Critic Loss: 11.110939979553223\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.09077923744916916\n",
      "Critic Loss: 2.2016348838806152\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 5.9792280197143555\n",
      "Critic Loss: 5.799717903137207\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 9.941658020019531\n",
      "Critic Loss: 12.649621963500977\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 5.385116100311279\n",
      "Critic Loss: 6.102347373962402\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 5.827989101409912\n",
      "Critic Loss: 5.2816314697265625\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 7.119287490844727\n",
      "Critic Loss: 5.3533830642700195\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 9.6378812789917\n",
      "Critic Loss: 7.890606880187988\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 15.911578178405762\n",
      "Critic Loss: 13.164867401123047\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 61.83897399902344\n",
      "Critic Loss: 65.09797668457031\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 9.922279357910156\n",
      "Critic Loss: 9.845396995544434\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 17.779319763183594\n",
      "Critic Loss: 17.447547912597656\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 8.933831214904785\n",
      "Critic Loss: 7.119680404663086\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 8.044939041137695\n",
      "Critic Loss: 6.386000633239746\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 5.283682823181152\n",
      "Critic Loss: 4.3543853759765625\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 8.87960433959961\n",
      "Critic Loss: 8.946702003479004\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 3.584763288497925\n",
      "Critic Loss: 8.99930191040039\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 6.934328079223633\n",
      "Critic Loss: 16.188472747802734\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 4.888535976409912\n",
      "Critic Loss: 13.227832794189453\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 4.277804374694824\n",
      "Critic Loss: 8.689875602722168\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 4.880447864532471\n",
      "Critic Loss: 8.976766586303711\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 5.742410659790039\n",
      "Critic Loss: 7.435851097106934\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 5.051436424255371\n",
      "Critic Loss: 7.8917951583862305\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.7082300186157227\n",
      "Critic Loss: 5.273928642272949\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 7.407794952392578\n",
      "Critic Loss: 7.6578521728515625\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 6.377636432647705\n",
      "Critic Loss: 9.151884078979492\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 8.731396675109863\n",
      "Critic Loss: 10.097925186157227\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 2.646050214767456\n",
      "Critic Loss: 7.42822790145874\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 9.004340171813965\n",
      "Critic Loss: 8.717634201049805\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.16733959317207336\n",
      "Critic Loss: 4.742631435394287\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 5.302395343780518\n",
      "Critic Loss: 7.279229164123535\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 10.126175880432129\n",
      "Critic Loss: 7.086438179016113\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 4.766043663024902\n",
      "Critic Loss: 5.894477844238281\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 7.520385265350342\n",
      "Critic Loss: 8.217026710510254\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 2.796126365661621\n",
      "Critic Loss: 3.8973045349121094\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 8.019305229187012\n",
      "Critic Loss: 9.590606689453125\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 3.0248565673828125\n",
      "Critic Loss: 5.796970367431641\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 7.093231201171875\n",
      "Critic Loss: 10.968300819396973\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 7.991429805755615\n",
      "Critic Loss: 7.629510402679443\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 3.050906181335449\n",
      "Critic Loss: 5.336729526519775\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 6.540490627288818\n",
      "Critic Loss: 9.311747550964355\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 2.4991745948791504\n",
      "Critic Loss: 6.3135986328125\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 3.1480557918548584\n",
      "Critic Loss: 4.501919746398926\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 5.689352512359619\n",
      "Critic Loss: 7.7960100173950195\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 8.602635383605957\n",
      "Critic Loss: 8.711313247680664\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 7.1706929206848145\n",
      "Critic Loss: 6.726463794708252\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 3.391315221786499\n",
      "Critic Loss: 8.224968910217285\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 4.788529396057129\n",
      "Critic Loss: 6.6629109382629395\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 6.244630813598633\n",
      "Critic Loss: 6.874388694763184\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -1.675462245941162\n",
      "Critic Loss: 3.9304842948913574\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 6.051516532897949\n",
      "Critic Loss: 8.055660247802734\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.13580460846424103\n",
      "Critic Loss: 3.486581325531006\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 2.583585739135742\n",
      "Critic Loss: 6.865387439727783\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 3.6220240592956543\n",
      "Critic Loss: 4.966534614562988\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.6835192441940308\n",
      "Critic Loss: 4.4563446044921875\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 4.1436638832092285\n",
      "Critic Loss: 6.6362199783325195\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 9.417126655578613\n",
      "Critic Loss: 9.010700225830078\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 5.8969879150390625\n",
      "Critic Loss: 9.564911842346191\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 2.9587907791137695\n",
      "Critic Loss: 5.644982814788818\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 4.823618412017822\n",
      "Critic Loss: 8.588836669921875\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 5.341864109039307\n",
      "Critic Loss: 6.676496982574463\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 5.473724842071533\n",
      "Critic Loss: 6.844585418701172\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 6.928578853607178\n",
      "Critic Loss: 5.751142501831055\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 7.101260662078857\n",
      "Critic Loss: 7.476563930511475\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 1.2540256977081299\n",
      "Critic Loss: 4.068106651306152\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 1.7440216541290283\n",
      "Critic Loss: 4.369719982147217\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 3.4537785053253174\n",
      "Critic Loss: 4.705565452575684\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 2.7147858142852783\n",
      "Critic Loss: 7.38700532913208\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 4.811269283294678\n",
      "Critic Loss: 6.175948143005371\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 9.86225414276123\n",
      "Critic Loss: 10.79777717590332\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 5.701343059539795\n",
      "Critic Loss: 6.5270867347717285\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.13634079694747925\n",
      "Critic Loss: 3.9629616737365723\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 2.416262626647949\n",
      "Critic Loss: 6.7134294509887695\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 6.576681613922119\n",
      "Critic Loss: 7.085293769836426\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 2.0460240840911865\n",
      "Critic Loss: 4.644684314727783\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 4.46543025970459\n",
      "Critic Loss: 7.6133503913879395\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 4.765244483947754\n",
      "Critic Loss: 5.8970441818237305\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.6053629517555237\n",
      "Critic Loss: 3.6314268112182617\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 6.667092323303223\n",
      "Critic Loss: 9.072011947631836\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 1.5878559350967407\n",
      "Critic Loss: 5.61204719543457\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.09324643015861511\n",
      "Critic Loss: 2.839860439300537\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.2850152850151062\n",
      "Critic Loss: 4.640792369842529\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 5.423583030700684\n",
      "Critic Loss: 8.669429779052734\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 8.761940002441406\n",
      "Critic Loss: 9.711000442504883\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 4.972287654876709\n",
      "Critic Loss: 8.326868057250977\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 3.802067756652832\n",
      "Critic Loss: 6.882752895355225\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 7.0180158615112305\n",
      "Critic Loss: 8.933534622192383\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 11.22592544555664\n",
      "Critic Loss: 10.29731559753418\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 14.905238151550293\n",
      "Critic Loss: 7.756730079650879\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 4.456127166748047\n",
      "Critic Loss: 5.902062892913818\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 2.8828647136688232\n",
      "Critic Loss: 6.102310657501221\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 3.959885358810425\n",
      "Critic Loss: 8.210610389709473\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 3.311289072036743\n",
      "Critic Loss: 8.668636322021484\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 2.5275537967681885\n",
      "Critic Loss: 5.811214447021484\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 2.9675111770629883\n",
      "Critic Loss: 7.535557746887207\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 4.9816975593566895\n",
      "Critic Loss: 8.791425704956055\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 4.460907459259033\n",
      "Critic Loss: 7.7989678382873535\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.275100439786911\n",
      "Critic Loss: 3.7354042530059814\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -1.6135743856430054\n",
      "Critic Loss: 5.7684431076049805\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 7.989326000213623\n",
      "Critic Loss: 10.947070121765137\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 7.011950492858887\n",
      "Critic Loss: 9.346661567687988\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 5.507678508758545\n",
      "Critic Loss: 6.6601033210754395\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 2.8719325065612793\n",
      "Critic Loss: 5.393743991851807\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 1.3360517024993896\n",
      "Critic Loss: 7.583631992340088\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.25052863359451294\n",
      "Critic Loss: 4.685671806335449\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 4.878549575805664\n",
      "Critic Loss: 8.858781814575195\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 2.6182119846343994\n",
      "Critic Loss: 6.817612171173096\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 9.039168357849121\n",
      "Critic Loss: 9.409071922302246\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 1.5315710306167603\n",
      "Critic Loss: 4.158501148223877\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 5.227855205535889\n",
      "Critic Loss: 7.48414945602417\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 3.173300266265869\n",
      "Critic Loss: 6.06410551071167\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 6.903286933898926\n",
      "Critic Loss: 8.943472862243652\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 5.432311058044434\n",
      "Critic Loss: 8.502915382385254\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 5.236130237579346\n",
      "Critic Loss: 9.124194145202637\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 2.152378559112549\n",
      "Critic Loss: 6.309123516082764\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 7.730388641357422\n",
      "Critic Loss: 8.291842460632324\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 2.587092399597168\n",
      "Critic Loss: 5.413419246673584\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 8.902352333068848\n",
      "Critic Loss: 10.258896827697754\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 1.837699294090271\n",
      "Critic Loss: 5.269108295440674\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 2.153590440750122\n",
      "Critic Loss: 5.3390212059021\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 4.45551872253418\n",
      "Critic Loss: 6.710782051086426\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 7.639214992523193\n",
      "Critic Loss: 9.07554817199707\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 2.287076234817505\n",
      "Critic Loss: 4.776653289794922\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 2.9352469444274902\n",
      "Critic Loss: 5.98747444152832\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 6.7310099601745605\n",
      "Critic Loss: 7.695139408111572\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -0.9175809025764465\n",
      "Critic Loss: 6.205014705657959\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.7083656191825867\n",
      "Critic Loss: 7.231736183166504\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 4.398064613342285\n",
      "Critic Loss: 7.202210903167725\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 2.3026318550109863\n",
      "Critic Loss: 6.970775604248047\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 7.075872421264648\n",
      "Critic Loss: 5.7759270668029785\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 6.366814613342285\n",
      "Critic Loss: 7.839263439178467\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 4.870756149291992\n",
      "Critic Loss: 5.3217854499816895\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 14.512191772460938\n",
      "Critic Loss: 8.847835540771484\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f851e652d9604f118c3e42473c37c4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>65.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>65.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>14.44627</td></tr><tr><td>Loss/Critic_loss</td><td>8.84784</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.49195</td></tr><tr><td>Loss/KL_divergence</td><td>0.03941</td></tr><tr><td>Loss/Policy_loss</td><td>14.45141</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>14.51219</td></tr><tr><td>Metric/Explained_variance</td><td>0.24917</td></tr><tr><td>Reward/Mean_train_reward</td><td>-34.9355</td></tr><tr><td>Reward/Mean_val_reward</td><td>-36.3596</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-35.92725</td></tr><tr><td>global_step</td><td>138</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smooth-sweep-12</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/888ig7z0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/888ig7z0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_145135-888ig7z0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d5fvt26y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00021015886374918795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0006674442257353529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.030437637850713264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9293287859460988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.000701728362533609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.95868537917224e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_150055-d5fvt26y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/d5fvt26y' target=\"_blank\">scarlet-sweep-13</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/d5fvt26y' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/d5fvt26y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.00021015886374918795, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0006674442257353529, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.030437637850713264, 'epochs': 10, 'exponential_factor': 0.9293287859460988, 'gamma': 0.99, 'hidden_sizes': [150, 350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.000701728362533609, 'l2_factor': 4.95868537917224e-06, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00021015886374918795, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0006674442257353529, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.030437637850713264, 'epochs': 10, 'exponential_factor': 0.9293287859460988, 'gamma': 0.99, 'l1_factor': 0.000701728362533609, 'l2_factor': 4.95868537917224e-06, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00021015886374918795, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0006674442257353529, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.030437637850713264, 'epochs': 10, 'exponential_factor': 0.9293287859460988, 'gamma': 0.99, 'l1_factor': 0.000701728362533609, 'l2_factor': 4.95868537917224e-06, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00021015886374918795, 'critic_lr': 0.0006674442257353529, 'decay_method': 'exponential', 'exponential_factor': 0.9293287859460988, 'value_loss_factor': 1, 'entropy': 0.030437637850713264, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.000701728362533609, 'l2_factor': 4.95868537917224e-06, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [150, 350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 38.62334442138672\n",
      "Critic Loss: 14.292976379394531\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 39.46354675292969\n",
      "Critic Loss: 32.536800384521484\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 22.686031341552734\n",
      "Critic Loss: 19.42334747314453\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 38.318321228027344\n",
      "Critic Loss: 36.40000915527344\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 33.4261474609375\n",
      "Critic Loss: 26.90094757080078\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 33.92445373535156\n",
      "Critic Loss: 25.224645614624023\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 24.731725692749023\n",
      "Critic Loss: 15.461614608764648\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 36.510101318359375\n",
      "Critic Loss: 27.85068130493164\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 33.693458557128906\n",
      "Critic Loss: 19.05889129638672\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 30.334415435791016\n",
      "Critic Loss: 20.799318313598633\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 22.071399688720703\n",
      "Critic Loss: 16.656496047973633\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 27.377424240112305\n",
      "Critic Loss: 16.042081832885742\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 37.457969665527344\n",
      "Critic Loss: 25.38547706604004\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 23.226144790649414\n",
      "Critic Loss: 14.096467018127441\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 23.21152114868164\n",
      "Critic Loss: 13.648839950561523\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 32.90692901611328\n",
      "Critic Loss: 21.452106475830078\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 23.682443618774414\n",
      "Critic Loss: 15.122182846069336\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 22.88041114807129\n",
      "Critic Loss: 11.308443069458008\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 20.259174346923828\n",
      "Critic Loss: 10.483509063720703\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 28.564884185791016\n",
      "Critic Loss: 16.23076057434082\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 22.786020278930664\n",
      "Critic Loss: 12.513803482055664\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 22.176029205322266\n",
      "Critic Loss: 12.779743194580078\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 25.209997177124023\n",
      "Critic Loss: 11.930020332336426\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 28.25163459777832\n",
      "Critic Loss: 14.272704124450684\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 17.469528198242188\n",
      "Critic Loss: 8.517644882202148\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 25.133642196655273\n",
      "Critic Loss: 13.067755699157715\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 27.939428329467773\n",
      "Critic Loss: 17.078311920166016\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 22.370227813720703\n",
      "Critic Loss: 10.530810356140137\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 19.068897247314453\n",
      "Critic Loss: 10.611604690551758\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 21.91781234741211\n",
      "Critic Loss: 11.622965812683105\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 26.352636337280273\n",
      "Critic Loss: 14.187435150146484\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 29.296234130859375\n",
      "Critic Loss: 15.430774688720703\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 27.2208309173584\n",
      "Critic Loss: 16.329029083251953\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 22.81249237060547\n",
      "Critic Loss: 9.349483489990234\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 29.04843521118164\n",
      "Critic Loss: 14.760705947875977\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 24.656620025634766\n",
      "Critic Loss: 12.973030090332031\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 27.07855224609375\n",
      "Critic Loss: 13.11383056640625\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 27.11376953125\n",
      "Critic Loss: 16.139076232910156\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 22.049983978271484\n",
      "Critic Loss: 10.326953887939453\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 35.834716796875\n",
      "Critic Loss: 21.233449935913086\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 25.803796768188477\n",
      "Critic Loss: 9.801243782043457\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 18.35311508178711\n",
      "Critic Loss: 10.283745765686035\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 23.163156509399414\n",
      "Critic Loss: 13.787307739257812\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 29.997501373291016\n",
      "Critic Loss: 17.16803550720215\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 25.512008666992188\n",
      "Critic Loss: 12.628562927246094\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 24.1116886138916\n",
      "Critic Loss: 11.008855819702148\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 23.859603881835938\n",
      "Critic Loss: 9.361394882202148\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 23.807024002075195\n",
      "Critic Loss: 10.822147369384766\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 30.02179527282715\n",
      "Critic Loss: 14.049757957458496\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 26.610754013061523\n",
      "Critic Loss: 12.881048202514648\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 24.020431518554688\n",
      "Critic Loss: 10.242993354797363\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 32.757171630859375\n",
      "Critic Loss: 19.47370719909668\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 23.0302734375\n",
      "Critic Loss: 8.861922264099121\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 18.58262825012207\n",
      "Critic Loss: 11.910499572753906\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 31.677230834960938\n",
      "Critic Loss: 14.303384780883789\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 19.9126033782959\n",
      "Critic Loss: 7.013682842254639\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 18.983680725097656\n",
      "Critic Loss: 8.903526306152344\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 27.993621826171875\n",
      "Critic Loss: 14.357744216918945\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 30.745037078857422\n",
      "Critic Loss: 17.53852653503418\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 31.171010971069336\n",
      "Critic Loss: 16.246105194091797\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 30.818199157714844\n",
      "Critic Loss: 13.446873664855957\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 28.29404067993164\n",
      "Critic Loss: 14.701818466186523\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 31.245283126831055\n",
      "Critic Loss: 14.532570838928223\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 31.634925842285156\n",
      "Critic Loss: 16.068397521972656\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 22.80404281616211\n",
      "Critic Loss: 9.64007568359375\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531d836af0bc42a49c7b7a4b94a839bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>85.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>49.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>15.74786</td></tr><tr><td>Loss/Critic_loss</td><td>9.64008</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.71515</td></tr><tr><td>Loss/KL_divergence</td><td>0.00032</td></tr><tr><td>Loss/Policy_loss</td><td>15.80007</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>22.80404</td></tr><tr><td>Metric/Explained_variance</td><td>0.53172</td></tr><tr><td>Reward/Mean_train_reward</td><td>-66.036</td></tr><tr><td>Reward/Mean_val_reward</td><td>-78.664</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-77.5097</td></tr><tr><td>global_step</td><td>65</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-13</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/d5fvt26y' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/d5fvt26y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_150055-d5fvt26y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u9yo6ju0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.003934005060273262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0015451733208604029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.044706776844353834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9852998069454576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 9.018529341172836e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.524715820736802e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_150411-u9yo6ju0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/u9yo6ju0' target=\"_blank\">splendid-sweep-14</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/u9yo6ju0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/u9yo6ju0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.003934005060273262, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0015451733208604029, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.044706776844353834, 'epochs': 10, 'exponential_factor': 0.9852998069454576, 'gamma': 0.95, 'hidden_sizes': [150, 350, 350, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 9.018529341172836e-05, 'l2_factor': 3.524715820736802e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 350, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.003934005060273262, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0015451733208604029, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.044706776844353834, 'epochs': 10, 'exponential_factor': 0.9852998069454576, 'gamma': 0.95, 'l1_factor': 9.018529341172836e-05, 'l2_factor': 3.524715820736802e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 350, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.003934005060273262, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0015451733208604029, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.044706776844353834, 'epochs': 10, 'exponential_factor': 0.9852998069454576, 'gamma': 0.95, 'l1_factor': 9.018529341172836e-05, 'l2_factor': 3.524715820736802e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.003934005060273262, 'critic_lr': 0.0015451733208604029, 'decay_method': 'exponential', 'exponential_factor': 0.9852998069454576, 'value_loss_factor': 1, 'entropy': 0.044706776844353834, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 9.018529341172836e-05, 'l2_factor': 3.524715820736802e-05, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [150, 350, 350, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.107470989227295\n",
      "Critic Loss: 28.12630844116211\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 1.09971022605896\n",
      "Critic Loss: 11.774114608764648\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.8482169508934021\n",
      "Critic Loss: 14.8196439743042\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.7889568209648132\n",
      "Critic Loss: 9.831037521362305\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.5521068572998047\n",
      "Critic Loss: 16.840879440307617\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.4204714894294739\n",
      "Critic Loss: 7.621338367462158\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.3941040337085724\n",
      "Critic Loss: 6.430542469024658\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.5031372904777527\n",
      "Critic Loss: 5.851953983306885\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.35130414366722107\n",
      "Critic Loss: 9.006664276123047\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.3133920729160309\n",
      "Critic Loss: 10.4027738571167\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.348267525434494\n",
      "Critic Loss: 10.064692497253418\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.3362751603126526\n",
      "Critic Loss: 14.085121154785156\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.342358261346817\n",
      "Critic Loss: 10.168346405029297\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.46850499510765076\n",
      "Critic Loss: 13.164321899414062\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.41838911175727844\n",
      "Critic Loss: 9.105354309082031\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.47043734788894653\n",
      "Critic Loss: 7.705082893371582\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.6852208971977234\n",
      "Critic Loss: 8.9243803024292\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.5419765114784241\n",
      "Critic Loss: 7.801747798919678\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.4125957787036896\n",
      "Critic Loss: 8.07046890258789\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.3798045516014099\n",
      "Critic Loss: 5.291738033294678\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.4120972752571106\n",
      "Critic Loss: 6.8563408851623535\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.3052960932254791\n",
      "Critic Loss: 11.820274353027344\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.30017656087875366\n",
      "Critic Loss: 6.650615692138672\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.3349006175994873\n",
      "Critic Loss: 5.113349437713623\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.13198791444301605\n",
      "Critic Loss: 5.183827877044678\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.2788308560848236\n",
      "Critic Loss: 6.397698402404785\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.25004979968070984\n",
      "Critic Loss: 5.2568488121032715\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.38870030641555786\n",
      "Critic Loss: 6.810936450958252\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.08037323504686356\n",
      "Critic Loss: 4.969969749450684\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.15544767677783966\n",
      "Critic Loss: 14.860177993774414\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.2628786265850067\n",
      "Critic Loss: 14.707021713256836\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.24752387404441833\n",
      "Critic Loss: 7.148788928985596\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.10639453679323196\n",
      "Critic Loss: 3.175297498703003\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.16548475623130798\n",
      "Critic Loss: 10.265741348266602\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.22428178787231445\n",
      "Critic Loss: 10.090350151062012\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.1747661679983139\n",
      "Critic Loss: 7.42173957824707\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.17699763178825378\n",
      "Critic Loss: 5.021456241607666\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.018847253173589706\n",
      "Critic Loss: 4.870969772338867\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.12797516584396362\n",
      "Critic Loss: 13.580259323120117\n",
      "\n",
      "New best validation reward reached in update [39/200]\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.11452911049127579\n",
      "Critic Loss: 6.072203159332275\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.03752538561820984\n",
      "Critic Loss: 10.493979454040527\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.02340012416243553\n",
      "Critic Loss: 8.112003326416016\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.0035121517721563578\n",
      "Critic Loss: 8.810029983520508\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.011805521324276924\n",
      "Critic Loss: 11.268604278564453\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.016046980395913124\n",
      "Critic Loss: 9.535890579223633\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.010870406404137611\n",
      "Critic Loss: 6.954370021820068\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.2798200845718384\n",
      "Critic Loss: 4.2070770263671875\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.012076147831976414\n",
      "Critic Loss: 5.711956024169922\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.08560116589069366\n",
      "Critic Loss: 8.258478164672852\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.02708667516708374\n",
      "Critic Loss: 4.455519199371338\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.04695863649249077\n",
      "Critic Loss: 5.392691612243652\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.012124446220695972\n",
      "Critic Loss: 6.528548240661621\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.0451851412653923\n",
      "Critic Loss: 2.975752353668213\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.0242621973156929\n",
      "Critic Loss: 3.198392868041992\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.004928144626319408\n",
      "Critic Loss: 5.746231555938721\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.0792052298784256\n",
      "Critic Loss: 2.336822509765625\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.0319531187415123\n",
      "Critic Loss: 3.709853410720825\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.03669200837612152\n",
      "Critic Loss: 9.0611572265625\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.037692416459321976\n",
      "Critic Loss: 5.747658729553223\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.052852556109428406\n",
      "Critic Loss: 5.460319995880127\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.006940371356904507\n",
      "Critic Loss: 5.120818614959717\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.029291555285453796\n",
      "Critic Loss: 5.0928168296813965\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.007348297629505396\n",
      "Critic Loss: 8.910815238952637\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.05139785632491112\n",
      "Critic Loss: 3.543868064880371\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.019282594323158264\n",
      "Critic Loss: 3.868699073791504\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.07300186157226562\n",
      "Critic Loss: 8.218135833740234\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.06974472105503082\n",
      "Critic Loss: 4.887702941894531\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.0060336533933877945\n",
      "Critic Loss: 2.655097723007202\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.05056509003043175\n",
      "Critic Loss: 5.077877521514893\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.07095439732074738\n",
      "Critic Loss: 2.2443699836730957\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.06311151385307312\n",
      "Critic Loss: 9.20343017578125\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.008201628923416138\n",
      "Critic Loss: 10.006092071533203\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.047350820153951645\n",
      "Critic Loss: 4.5487260818481445\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.034636758267879486\n",
      "Critic Loss: 5.423442840576172\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.07639443129301071\n",
      "Critic Loss: 5.2663187980651855\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.03400082141160965\n",
      "Critic Loss: 5.590684413909912\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.011932102963328362\n",
      "Critic Loss: 5.369309902191162\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.037989888340234756\n",
      "Critic Loss: 3.485173225402832\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.0035092183388769627\n",
      "Critic Loss: 3.9573452472686768\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.1111539974808693\n",
      "Critic Loss: 2.563579559326172\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.01362366322427988\n",
      "Critic Loss: 3.4509267807006836\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.052568916231393814\n",
      "Critic Loss: 7.078700065612793\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.016870219260454178\n",
      "Critic Loss: 2.8356614112854004\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.058258429169654846\n",
      "Critic Loss: 3.5291693210601807\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.0469636507332325\n",
      "Critic Loss: 3.0846259593963623\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.011874561198055744\n",
      "Critic Loss: 4.587249755859375\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.013334503397345543\n",
      "Critic Loss: 6.306824684143066\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.0238967128098011\n",
      "Critic Loss: 3.7754597663879395\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.03753441199660301\n",
      "Critic Loss: 5.491613388061523\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.0012447991175577044\n",
      "Critic Loss: 5.058618545532227\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.04593917727470398\n",
      "Critic Loss: 4.464479446411133\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.043399691581726074\n",
      "Critic Loss: 5.415810585021973\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.0463251993060112\n",
      "Critic Loss: 5.846569061279297\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.035026561468839645\n",
      "Critic Loss: 6.462728977203369\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.0004233107902109623\n",
      "Critic Loss: 4.882723808288574\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.05811229720711708\n",
      "Critic Loss: 8.773941040039062\n",
      "\n",
      "New best validation reward reached in update [96/200]\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.04281384125351906\n",
      "Critic Loss: 4.327708721160889\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.01427348144352436\n",
      "Critic Loss: 2.5287258625030518\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.04718697443604469\n",
      "Critic Loss: 4.405149459838867\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.0396905355155468\n",
      "Critic Loss: 6.761526107788086\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.07623384147882462\n",
      "Critic Loss: 2.837348461151123\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.04202096164226532\n",
      "Critic Loss: 8.916435241699219\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.0038848151452839375\n",
      "Critic Loss: 4.15399694442749\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.044587090611457825\n",
      "Critic Loss: 2.2325119972229004\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.011423186399042606\n",
      "Critic Loss: 5.190229415893555\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.0382147878408432\n",
      "Critic Loss: 7.218989372253418\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.009539642371237278\n",
      "Critic Loss: 8.84217357635498\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.027677129954099655\n",
      "Critic Loss: 4.422499179840088\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -0.05344047024846077\n",
      "Critic Loss: 2.1797213554382324\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -0.08153186738491058\n",
      "Critic Loss: 4.106675624847412\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -0.010793439112603664\n",
      "Critic Loss: 8.155885696411133\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.06166599690914154\n",
      "Critic Loss: 5.076341152191162\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.062431976199150085\n",
      "Critic Loss: 7.236423492431641\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -0.000626590452156961\n",
      "Critic Loss: 6.34542179107666\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.020032919943332672\n",
      "Critic Loss: 4.220837116241455\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -0.05556856840848923\n",
      "Critic Loss: 4.803796291351318\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -0.013886974193155766\n",
      "Critic Loss: 6.939199447631836\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -0.05788639932870865\n",
      "Critic Loss: 4.714842796325684\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.03215356916189194\n",
      "Critic Loss: 4.97061824798584\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.008645509369671345\n",
      "Critic Loss: 11.59619140625\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.06731895357370377\n",
      "Critic Loss: 3.559221029281616\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -0.06477657705545425\n",
      "Critic Loss: 4.656023979187012\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.04307685047388077\n",
      "Critic Loss: 3.8700718879699707\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -0.017945967614650726\n",
      "Critic Loss: 3.401899576187134\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -0.0753428265452385\n",
      "Critic Loss: 3.9217967987060547\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.013894611038267612\n",
      "Critic Loss: 5.479104518890381\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -0.00430129561573267\n",
      "Critic Loss: 4.6634321212768555\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.01619829051196575\n",
      "Critic Loss: 5.584038734436035\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -0.05079531669616699\n",
      "Critic Loss: 5.1503214836120605\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.028292395174503326\n",
      "Critic Loss: 9.615379333496094\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -0.0019402556354179978\n",
      "Critic Loss: 3.264249086380005\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -0.030555814504623413\n",
      "Critic Loss: 2.4405627250671387\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.04124946519732475\n",
      "Critic Loss: 5.662347316741943\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -0.023940635845065117\n",
      "Critic Loss: 5.797627925872803\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: -0.01042099203914404\n",
      "Critic Loss: 3.523247003555298\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.041515618562698364\n",
      "Critic Loss: 4.7032599449157715\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -0.04945402592420578\n",
      "Critic Loss: 3.967341184616089\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -0.03692718967795372\n",
      "Critic Loss: 3.9166107177734375\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.02817465551197529\n",
      "Critic Loss: 3.1210200786590576\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -0.035225819796323776\n",
      "Critic Loss: 2.8772289752960205\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -0.07148532569408417\n",
      "Critic Loss: 4.493523597717285\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: -0.016156716272234917\n",
      "Critic Loss: 3.6105217933654785\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.05201449245214462\n",
      "Critic Loss: 5.103533744812012\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -0.007958667352795601\n",
      "Critic Loss: 3.5001344680786133\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -0.0028936932794749737\n",
      "Critic Loss: 3.2412874698638916\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a2dd392db64822a3ec5008a4f631ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>129.42857</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>75.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.00047</td></tr><tr><td>Learning_rate/Critic</td><td>0.00018</td></tr><tr><td>Loss/Actor_loss</td><td>-0.0254</td></tr><tr><td>Loss/Critic_loss</td><td>3.24129</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.40171</td></tr><tr><td>Loss/KL_divergence</td><td>0.01437</td></tr><tr><td>Loss/Policy_loss</td><td>0.03727</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.00289</td></tr><tr><td>Metric/Explained_variance</td><td>0.36273</td></tr><tr><td>Reward/Mean_train_reward</td><td>4.37986</td></tr><tr><td>Reward/Mean_val_reward</td><td>-33.8253</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-22.63382</td></tr><tr><td>global_step</td><td>145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-14</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/u9yo6ju0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/u9yo6ju0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_150411-u9yo6ju0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lzcf9f0t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0009336196748325956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0008705695480191021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.036162752327663354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8567893872355051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.954866391921722e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.909268383712707e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_152428-lzcf9f0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/lzcf9f0t' target=\"_blank\">polar-sweep-15</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/lzcf9f0t' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/lzcf9f0t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0009336196748325956, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0008705695480191021, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.036162752327663354, 'epochs': 10, 'exponential_factor': 0.8567893872355051, 'gamma': 0.9, 'hidden_sizes': [250, 350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 1.954866391921722e-05, 'l2_factor': 4.909268383712707e-06, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0009336196748325956, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0008705695480191021, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.036162752327663354, 'epochs': 10, 'exponential_factor': 0.8567893872355051, 'gamma': 0.9, 'l1_factor': 1.954866391921722e-05, 'l2_factor': 4.909268383712707e-06, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0009336196748325956, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0008705695480191021, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.036162752327663354, 'epochs': 10, 'exponential_factor': 0.8567893872355051, 'gamma': 0.9, 'l1_factor': 1.954866391921722e-05, 'l2_factor': 4.909268383712707e-06, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0009336196748325956, 'critic_lr': 0.0008705695480191021, 'decay_method': 'exponential', 'exponential_factor': 0.8567893872355051, 'value_loss_factor': 1, 'entropy': 0.036162752327663354, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.954866391921722e-05, 'l2_factor': 4.909268383712707e-06, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [250, 350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 36.755027770996094\n",
      "Critic Loss: 39.20021057128906\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 8.284791946411133\n",
      "Critic Loss: 9.868556022644043\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 9.400221824645996\n",
      "Critic Loss: 9.523343086242676\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 13.796553611755371\n",
      "Critic Loss: 14.527851104736328\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 12.765399932861328\n",
      "Critic Loss: 14.41914176940918\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 6.178566932678223\n",
      "Critic Loss: 9.031344413757324\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 15.090470314025879\n",
      "Critic Loss: 17.7559814453125\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 10.222808837890625\n",
      "Critic Loss: 12.229533195495605\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 4.13623571395874\n",
      "Critic Loss: 5.852097988128662\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 5.905747413635254\n",
      "Critic Loss: 8.292243957519531\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 4.969512939453125\n",
      "Critic Loss: 7.758326053619385\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 8.04773998260498\n",
      "Critic Loss: 9.323302268981934\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 23.864694595336914\n",
      "Critic Loss: 26.54273796081543\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 6.623348236083984\n",
      "Critic Loss: 8.59237289428711\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 19.423595428466797\n",
      "Critic Loss: 21.598766326904297\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 14.082087516784668\n",
      "Critic Loss: 17.2648983001709\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 3.5502917766571045\n",
      "Critic Loss: 6.4438629150390625\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 13.087018013000488\n",
      "Critic Loss: 15.603752136230469\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 16.44884490966797\n",
      "Critic Loss: 18.693408966064453\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 12.12338924407959\n",
      "Critic Loss: 13.86103343963623\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 14.360447883605957\n",
      "Critic Loss: 15.195760726928711\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 2.5390875339508057\n",
      "Critic Loss: 4.635238170623779\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 10.525440216064453\n",
      "Critic Loss: 13.182613372802734\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 10.88569164276123\n",
      "Critic Loss: 12.984064102172852\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 13.549660682678223\n",
      "Critic Loss: 14.546648025512695\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 11.478554725646973\n",
      "Critic Loss: 14.637332916259766\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 27.47710418701172\n",
      "Critic Loss: 29.411901473999023\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 5.57656717300415\n",
      "Critic Loss: 8.1848726272583\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 14.415679931640625\n",
      "Critic Loss: 16.446636199951172\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 11.136495590209961\n",
      "Critic Loss: 13.143501281738281\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 16.829317092895508\n",
      "Critic Loss: 19.235658645629883\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 15.564735412597656\n",
      "Critic Loss: 17.31157112121582\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652fd542af37499996e685a4b7f8aa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>âââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>âââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>19.2</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>26.8</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>15.30535</td></tr><tr><td>Loss/Critic_loss</td><td>17.31157</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.59618</td></tr><tr><td>Loss/KL_divergence</td><td>0.01963</td></tr><tr><td>Loss/Policy_loss</td><td>15.36307</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>15.56474</td></tr><tr><td>Metric/Explained_variance</td><td>0.00431</td></tr><tr><td>Reward/Mean_train_reward</td><td>-96.7458</td></tr><tr><td>Reward/Mean_val_reward</td><td>-90.6502</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-91.19601</td></tr><tr><td>global_step</td><td>32</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-15</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/lzcf9f0t' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/lzcf9f0t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_152428-lzcf9f0t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ob4fi55n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0006981809486659926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0006518018015069512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.015714466721123286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9417909361686218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.0537797963198855e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00012439713588152478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_152556-ob4fi55n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/ob4fi55n' target=\"_blank\">grateful-sweep-16</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ob4fi55n' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ob4fi55n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0006981809486659926, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0006518018015069512, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015714466721123286, 'epochs': 10, 'exponential_factor': 0.9417909361686218, 'gamma': 0.95, 'hidden_sizes': [250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.0537797963198855e-06, 'l2_factor': 0.00012439713588152478, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0006981809486659926, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0006518018015069512, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015714466721123286, 'epochs': 10, 'exponential_factor': 0.9417909361686218, 'gamma': 0.95, 'l1_factor': 2.0537797963198855e-06, 'l2_factor': 0.00012439713588152478, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0006981809486659926, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0006518018015069512, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015714466721123286, 'epochs': 10, 'exponential_factor': 0.9417909361686218, 'gamma': 0.95, 'l1_factor': 2.0537797963198855e-06, 'l2_factor': 0.00012439713588152478, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0006981809486659926, 'critic_lr': 0.0006518018015069512, 'decay_method': 'exponential', 'exponential_factor': 0.9417909361686218, 'value_loss_factor': 1, 'entropy': 0.015714466721123286, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.0537797963198855e-06, 'l2_factor': 0.00012439713588152478, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: -0.022551946341991425\n",
      "Critic Loss: 30.912199020385742\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.003871917724609375\n",
      "Critic Loss: 17.493623733520508\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.00748492032289505\n",
      "Critic Loss: 20.55735969543457\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.028198979794979095\n",
      "Critic Loss: 16.85284423828125\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.04573557525873184\n",
      "Critic Loss: 14.005708694458008\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.0211656354367733\n",
      "Critic Loss: 10.476490020751953\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.06205923855304718\n",
      "Critic Loss: 8.866209983825684\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.03244342654943466\n",
      "Critic Loss: 12.052108764648438\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.04020651802420616\n",
      "Critic Loss: 13.649080276489258\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.033096976578235626\n",
      "Critic Loss: 10.36252498626709\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.01870298758149147\n",
      "Critic Loss: 5.766279220581055\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.02516971156001091\n",
      "Critic Loss: 5.580306053161621\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.04401534050703049\n",
      "Critic Loss: 15.427000045776367\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.022423040121793747\n",
      "Critic Loss: 11.590448379516602\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.015420254319906235\n",
      "Critic Loss: 12.144876480102539\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.021398015320301056\n",
      "Critic Loss: 10.77392864227295\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.01641261950135231\n",
      "Critic Loss: 14.631681442260742\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.06726984679698944\n",
      "Critic Loss: 10.718913078308105\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.04248291254043579\n",
      "Critic Loss: 8.352087020874023\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.0784299224615097\n",
      "Critic Loss: 14.067368507385254\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.04928595572710037\n",
      "Critic Loss: 8.309565544128418\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.04297782853245735\n",
      "Critic Loss: 10.012920379638672\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.08005493879318237\n",
      "Critic Loss: 7.530179023742676\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.0715135782957077\n",
      "Critic Loss: 12.903816223144531\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.047966018319129944\n",
      "Critic Loss: 15.773426055908203\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.07366586476564407\n",
      "Critic Loss: 9.534371376037598\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.038728777319192886\n",
      "Critic Loss: 15.83810806274414\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.05205022543668747\n",
      "Critic Loss: 9.474716186523438\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.04614415019750595\n",
      "Critic Loss: 12.30215835571289\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.054095879197120667\n",
      "Critic Loss: 9.80614948272705\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.038433272391557693\n",
      "Critic Loss: 7.337697505950928\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.061279281973838806\n",
      "Critic Loss: 13.146780967712402\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.0614294707775116\n",
      "Critic Loss: 11.924827575683594\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.051450032740831375\n",
      "Critic Loss: 8.870864868164062\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.0357179157435894\n",
      "Critic Loss: 12.658199310302734\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.15523318946361542\n",
      "Critic Loss: 9.838984489440918\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.05724993348121643\n",
      "Critic Loss: 10.22592544555664\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.05733960494399071\n",
      "Critic Loss: 7.117596626281738\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.030299298465251923\n",
      "Critic Loss: 8.62598705291748\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.050953857600688934\n",
      "Critic Loss: 9.819190979003906\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.05015719309449196\n",
      "Critic Loss: 8.843280792236328\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.073647640645504\n",
      "Critic Loss: 12.072559356689453\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.06959298998117447\n",
      "Critic Loss: 12.115907669067383\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.06912270188331604\n",
      "Critic Loss: 7.664330959320068\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.041822876781225204\n",
      "Critic Loss: 7.297348976135254\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.09837587922811508\n",
      "Critic Loss: 10.500594139099121\n",
      "\n",
      "New best validation reward reached in update [46/200]\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.019515223801136017\n",
      "Critic Loss: 7.007366180419922\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.05789867416024208\n",
      "Critic Loss: 7.273425102233887\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.05556941032409668\n",
      "Critic Loss: 6.101738929748535\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.05543573573231697\n",
      "Critic Loss: 9.99162483215332\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.04557548090815544\n",
      "Critic Loss: 7.411496639251709\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.033858634531497955\n",
      "Critic Loss: 6.27264928817749\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.059843383729457855\n",
      "Critic Loss: 6.639180660247803\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.048146069049835205\n",
      "Critic Loss: 6.909397125244141\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.058261938393116\n",
      "Critic Loss: 6.859670639038086\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.08169685304164886\n",
      "Critic Loss: 7.059432506561279\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.08360053598880768\n",
      "Critic Loss: 7.329687118530273\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.05905402824282646\n",
      "Critic Loss: 6.183241844177246\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.037567585706710815\n",
      "Critic Loss: 6.8086838722229\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.053543850779533386\n",
      "Critic Loss: 9.265475273132324\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.04425309598445892\n",
      "Critic Loss: 6.449172019958496\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.06950102001428604\n",
      "Critic Loss: 7.242438793182373\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.06207393854856491\n",
      "Critic Loss: 5.006450653076172\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.07526934146881104\n",
      "Critic Loss: 7.03119421005249\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.07060446590185165\n",
      "Critic Loss: 4.7854838371276855\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.05569262057542801\n",
      "Critic Loss: 6.68860387802124\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.06910217553377151\n",
      "Critic Loss: 6.29837703704834\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.035962287336587906\n",
      "Critic Loss: 7.790058135986328\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.060736529529094696\n",
      "Critic Loss: 5.580295562744141\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.05976003408432007\n",
      "Critic Loss: 5.629395484924316\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.07091108709573746\n",
      "Critic Loss: 5.0471367835998535\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.0504060760140419\n",
      "Critic Loss: 5.200577259063721\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.07492434233427048\n",
      "Critic Loss: 5.145086288452148\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.049670372158288956\n",
      "Critic Loss: 5.260154724121094\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.06335395574569702\n",
      "Critic Loss: 8.370895385742188\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.04245154932141304\n",
      "Critic Loss: 6.335614204406738\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.06797925382852554\n",
      "Critic Loss: 7.473925590515137\n",
      "\n",
      "New best validation reward reached in update [77/200]\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.05540592595934868\n",
      "Critic Loss: 7.426851749420166\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.08199453353881836\n",
      "Critic Loss: 7.177213191986084\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.04758606106042862\n",
      "Critic Loss: 5.964304447174072\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.044401757419109344\n",
      "Critic Loss: 6.134087562561035\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.08014879375696182\n",
      "Critic Loss: 4.975436687469482\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.09294839203357697\n",
      "Critic Loss: 7.367591381072998\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.08219341933727264\n",
      "Critic Loss: 5.2288312911987305\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.053245265036821365\n",
      "Critic Loss: 4.812930583953857\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.06431660056114197\n",
      "Critic Loss: 5.5380144119262695\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.06483842432498932\n",
      "Critic Loss: 4.816094398498535\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.043453752994537354\n",
      "Critic Loss: 5.197417259216309\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.0868687778711319\n",
      "Critic Loss: 9.579567909240723\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.07670392841100693\n",
      "Critic Loss: 7.429988861083984\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.06525962799787521\n",
      "Critic Loss: 5.770528793334961\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.05449332296848297\n",
      "Critic Loss: 5.724906921386719\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.06121009960770607\n",
      "Critic Loss: 6.102967739105225\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.08595649898052216\n",
      "Critic Loss: 4.245803356170654\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.02816040813922882\n",
      "Critic Loss: 5.002893447875977\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.06429911404848099\n",
      "Critic Loss: 5.859882354736328\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.06323277205228806\n",
      "Critic Loss: 6.971933364868164\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.06152915209531784\n",
      "Critic Loss: 5.460764408111572\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.05458000674843788\n",
      "Critic Loss: 12.126388549804688\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.13124814629554749\n",
      "Critic Loss: 7.1112060546875\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.0555727481842041\n",
      "Critic Loss: 4.726531028747559\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.06441187858581543\n",
      "Critic Loss: 7.132279872894287\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.08005748689174652\n",
      "Critic Loss: 5.62005090713501\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.053868263959884644\n",
      "Critic Loss: 5.354144096374512\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.073262058198452\n",
      "Critic Loss: 7.668938159942627\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.055105917155742645\n",
      "Critic Loss: 9.505377769470215\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.08395382761955261\n",
      "Critic Loss: 7.821811676025391\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.05160683020949364\n",
      "Critic Loss: 7.045916557312012\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.048990607261657715\n",
      "Critic Loss: 9.265632629394531\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.07752884924411774\n",
      "Critic Loss: 11.251625061035156\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.07632827013731003\n",
      "Critic Loss: 5.841320514678955\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.06220794469118118\n",
      "Critic Loss: 6.099935054779053\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.031119611114263535\n",
      "Critic Loss: 6.387915134429932\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4eb002af1942438e6524d317337a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>114.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>112.6</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.043</td></tr><tr><td>Loss/Critic_loss</td><td>6.38792</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.0601</td></tr><tr><td>Loss/KL_divergence</td><td>-0.02632</td></tr><tr><td>Loss/Policy_loss</td><td>-0.02634</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.03112</td></tr><tr><td>Metric/Explained_variance</td><td>0.29847</td></tr><tr><td>Reward/Mean_train_reward</td><td>11.59299</td></tr><tr><td>Reward/Mean_val_reward</td><td>4.2796</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.15216</td></tr><tr><td>global_step</td><td>113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-16</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ob4fi55n' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ob4fi55n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_152556-ob4fi55n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ndeduizn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0005587974441550501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0017736436086005407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.011866306267991716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9186584113056208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 8.110965714136781e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 5.354898250252507e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_153306-ndeduizn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/ndeduizn' target=\"_blank\">true-sweep-17</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ndeduizn' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ndeduizn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.0005587974441550501, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017736436086005407, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.011866306267991716, 'epochs': 10, 'exponential_factor': 0.9186584113056208, 'gamma': 0.99, 'hidden_sizes': [150, 350, 250, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 8.110965714136781e-05, 'l2_factor': 5.354898250252507e-05, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0005587974441550501, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017736436086005407, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.011866306267991716, 'epochs': 10, 'exponential_factor': 0.9186584113056208, 'gamma': 0.99, 'l1_factor': 8.110965714136781e-05, 'l2_factor': 5.354898250252507e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0005587974441550501, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017736436086005407, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.011866306267991716, 'epochs': 10, 'exponential_factor': 0.9186584113056208, 'gamma': 0.99, 'l1_factor': 8.110965714136781e-05, 'l2_factor': 5.354898250252507e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0005587974441550501, 'critic_lr': 0.0017736436086005407, 'decay_method': 'exponential', 'exponential_factor': 0.9186584113056208, 'value_loss_factor': 1, 'entropy': 0.011866306267991716, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 8.110965714136781e-05, 'l2_factor': 5.354898250252507e-05, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [150, 350, 250, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 23.713775634765625\n",
      "Critic Loss: 22.988239288330078\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 41.629615783691406\n",
      "Critic Loss: 38.09483337402344\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 27.2183837890625\n",
      "Critic Loss: 22.922109603881836\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 21.154306411743164\n",
      "Critic Loss: 16.96356201171875\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 22.424530029296875\n",
      "Critic Loss: 13.8781156539917\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 20.546550750732422\n",
      "Critic Loss: 11.946199417114258\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 8.710604667663574\n",
      "Critic Loss: 11.331709861755371\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 11.720682144165039\n",
      "Critic Loss: 9.39015007019043\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 18.265888214111328\n",
      "Critic Loss: 8.402205467224121\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 20.145305633544922\n",
      "Critic Loss: 8.194405555725098\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 18.9876708984375\n",
      "Critic Loss: 9.42947006225586\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 20.225587844848633\n",
      "Critic Loss: 7.559664249420166\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 23.426332473754883\n",
      "Critic Loss: 7.474431991577148\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 19.680034637451172\n",
      "Critic Loss: 6.31467866897583\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 18.527294158935547\n",
      "Critic Loss: 11.249798774719238\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 22.937726974487305\n",
      "Critic Loss: 7.019282817840576\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 18.936134338378906\n",
      "Critic Loss: 6.040038108825684\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 20.694377899169922\n",
      "Critic Loss: 9.974721908569336\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 18.762012481689453\n",
      "Critic Loss: 9.197425842285156\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 20.804244995117188\n",
      "Critic Loss: 8.660269737243652\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 19.86001205444336\n",
      "Critic Loss: 8.580633163452148\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 20.99439239501953\n",
      "Critic Loss: 8.038410186767578\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 19.691312789916992\n",
      "Critic Loss: 8.501969337463379\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 18.539838790893555\n",
      "Critic Loss: 11.343241691589355\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 20.070478439331055\n",
      "Critic Loss: 9.282670974731445\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 18.1546688079834\n",
      "Critic Loss: 8.295197486877441\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 18.29720115661621\n",
      "Critic Loss: 6.5451979637146\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 23.265146255493164\n",
      "Critic Loss: 7.015260696411133\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 20.66678237915039\n",
      "Critic Loss: 6.879786014556885\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 16.697723388671875\n",
      "Critic Loss: 10.003135681152344\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 22.722339630126953\n",
      "Critic Loss: 6.500266075134277\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 17.841798782348633\n",
      "Critic Loss: 4.136002540588379\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 20.128402709960938\n",
      "Critic Loss: 8.263278007507324\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 15.402631759643555\n",
      "Critic Loss: 9.037492752075195\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 18.54808235168457\n",
      "Critic Loss: 6.7618489265441895\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 16.405208587646484\n",
      "Critic Loss: 11.107772827148438\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 18.7811279296875\n",
      "Critic Loss: 6.982900142669678\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 17.63620948791504\n",
      "Critic Loss: 8.688309669494629\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 17.624713897705078\n",
      "Critic Loss: 6.824212074279785\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 19.053335189819336\n",
      "Critic Loss: 5.6811933517456055\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 12.397456169128418\n",
      "Critic Loss: 10.722414016723633\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 18.372817993164062\n",
      "Critic Loss: 6.5772881507873535\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 15.856938362121582\n",
      "Critic Loss: 9.436047554016113\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 15.54041576385498\n",
      "Critic Loss: 6.790710926055908\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 17.72613525390625\n",
      "Critic Loss: 5.659774303436279\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 13.101129531860352\n",
      "Critic Loss: 10.658422470092773\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 18.199003219604492\n",
      "Critic Loss: 8.935158729553223\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 20.45079231262207\n",
      "Critic Loss: 6.5689496994018555\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 14.604169845581055\n",
      "Critic Loss: 14.210247039794922\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 18.287246704101562\n",
      "Critic Loss: 8.163118362426758\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 15.329606056213379\n",
      "Critic Loss: 10.317414283752441\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 16.060056686401367\n",
      "Critic Loss: 10.183125495910645\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 18.617341995239258\n",
      "Critic Loss: 5.101702690124512\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 16.5257511138916\n",
      "Critic Loss: 10.549309730529785\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 18.54266929626465\n",
      "Critic Loss: 11.640938758850098\n",
      "\n",
      "New best validation reward reached in update [55/200]\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 16.564207077026367\n",
      "Critic Loss: 6.744779109954834\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 18.51068687438965\n",
      "Critic Loss: 7.230268955230713\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 11.246519088745117\n",
      "Critic Loss: 13.797609329223633\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 19.418819427490234\n",
      "Critic Loss: 9.90761661529541\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 13.106192588806152\n",
      "Critic Loss: 10.59118366241455\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 17.945579528808594\n",
      "Critic Loss: 6.68107795715332\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 21.29983139038086\n",
      "Critic Loss: 7.657111167907715\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 11.644104957580566\n",
      "Critic Loss: 13.524576187133789\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 16.072784423828125\n",
      "Critic Loss: 9.940364837646484\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 12.684303283691406\n",
      "Critic Loss: 10.821434020996094\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 19.432971954345703\n",
      "Critic Loss: 7.542633533477783\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 18.052745819091797\n",
      "Critic Loss: 10.808436393737793\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 9.186774253845215\n",
      "Critic Loss: 11.40658187866211\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 15.023322105407715\n",
      "Critic Loss: 9.915619850158691\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 15.80817699432373\n",
      "Critic Loss: 10.993711471557617\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 12.002054214477539\n",
      "Critic Loss: 14.468809127807617\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 13.279668807983398\n",
      "Critic Loss: 13.240909576416016\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 18.915189743041992\n",
      "Critic Loss: 10.29837417602539\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 19.53197479248047\n",
      "Critic Loss: 7.8821635246276855\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 18.389902114868164\n",
      "Critic Loss: 8.698400497436523\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 14.74409008026123\n",
      "Critic Loss: 11.666570663452148\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 16.81895637512207\n",
      "Critic Loss: 10.794109344482422\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 19.541189193725586\n",
      "Critic Loss: 7.054591178894043\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 18.3004150390625\n",
      "Critic Loss: 9.521722793579102\n",
      "\n",
      "New best validation reward reached in update [79/200]\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 16.61748504638672\n",
      "Critic Loss: 11.980539321899414\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 18.071054458618164\n",
      "Critic Loss: 9.691158294677734\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 12.526670455932617\n",
      "Critic Loss: 13.425074577331543\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 7.6019721031188965\n",
      "Critic Loss: 12.614559173583984\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 16.589120864868164\n",
      "Critic Loss: 8.787942886352539\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 10.996674537658691\n",
      "Critic Loss: 14.662052154541016\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 6.4360551834106445\n",
      "Critic Loss: 13.690241813659668\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 16.102962493896484\n",
      "Critic Loss: 8.940594673156738\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 17.937501907348633\n",
      "Critic Loss: 12.596596717834473\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 16.077402114868164\n",
      "Critic Loss: 10.100709915161133\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 15.787270545959473\n",
      "Critic Loss: 10.46358871459961\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 17.374040603637695\n",
      "Critic Loss: 6.825070858001709\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 15.404457092285156\n",
      "Critic Loss: 9.980566024780273\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 12.044662475585938\n",
      "Critic Loss: 11.955734252929688\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 17.089828491210938\n",
      "Critic Loss: 10.732147216796875\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 13.337940216064453\n",
      "Critic Loss: 8.28823471069336\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 14.001886367797852\n",
      "Critic Loss: 12.415489196777344\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 11.2353515625\n",
      "Critic Loss: 8.879247665405273\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 16.353567123413086\n",
      "Critic Loss: 11.198002815246582\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 18.796770095825195\n",
      "Critic Loss: 6.183013439178467\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 14.711790084838867\n",
      "Critic Loss: 9.661454200744629\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 9.537381172180176\n",
      "Critic Loss: 14.287367820739746\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 20.832015991210938\n",
      "Critic Loss: 6.646273612976074\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 13.372380256652832\n",
      "Critic Loss: 11.231171607971191\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 20.244163513183594\n",
      "Critic Loss: 11.239025115966797\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 19.926395416259766\n",
      "Critic Loss: 7.432662010192871\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 16.582977294921875\n",
      "Critic Loss: 9.458307266235352\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 14.896328926086426\n",
      "Critic Loss: 9.04110336303711\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 13.908540725708008\n",
      "Critic Loss: 10.289239883422852\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 13.073177337646484\n",
      "Critic Loss: 9.132408142089844\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 15.045711517333984\n",
      "Critic Loss: 9.082307815551758\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 17.107952117919922\n",
      "Critic Loss: 10.028877258300781\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 9.286186218261719\n",
      "Critic Loss: 12.397211074829102\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 15.933162689208984\n",
      "Critic Loss: 10.162160873413086\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 15.528070449829102\n",
      "Critic Loss: 11.4120512008667\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 10.29896354675293\n",
      "Critic Loss: 11.793062210083008\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 18.603759765625\n",
      "Critic Loss: 7.372613906860352\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 16.652482986450195\n",
      "Critic Loss: 9.02003288269043\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 15.654640197753906\n",
      "Critic Loss: 12.777888298034668\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 13.95457649230957\n",
      "Critic Loss: 11.430234909057617\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 13.69421672821045\n",
      "Critic Loss: 9.585368156433105\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 20.453651428222656\n",
      "Critic Loss: 7.195464611053467\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 15.010358810424805\n",
      "Critic Loss: 11.131729125976562\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 12.945965766906738\n",
      "Critic Loss: 9.216045379638672\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 18.77199935913086\n",
      "Critic Loss: 4.945650577545166\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 11.212726593017578\n",
      "Critic Loss: 14.866854667663574\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 17.544801712036133\n",
      "Critic Loss: 9.235760688781738\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 15.723701477050781\n",
      "Critic Loss: 9.271025657653809\n",
      "\n",
      "New best validation reward reached in update [127/200]\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 15.311843872070312\n",
      "Critic Loss: 11.727161407470703\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 18.08009910583496\n",
      "Critic Loss: 10.835184097290039\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 16.384286880493164\n",
      "Critic Loss: 5.930351257324219\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 12.761800765991211\n",
      "Critic Loss: 9.731764793395996\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 9.147724151611328\n",
      "Critic Loss: 16.695743560791016\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 10.685572624206543\n",
      "Critic Loss: 10.364409446716309\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 8.388580322265625\n",
      "Critic Loss: 16.085037231445312\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 14.880280494689941\n",
      "Critic Loss: 13.266681671142578\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 14.8266019821167\n",
      "Critic Loss: 10.346381187438965\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 19.239147186279297\n",
      "Critic Loss: 11.024301528930664\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 16.842451095581055\n",
      "Critic Loss: 7.356135845184326\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 11.885598182678223\n",
      "Critic Loss: 12.194709777832031\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 18.07323455810547\n",
      "Critic Loss: 8.845940589904785\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 16.171855926513672\n",
      "Critic Loss: 8.973871231079102\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 13.561063766479492\n",
      "Critic Loss: 8.623114585876465\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 16.944393157958984\n",
      "Critic Loss: 13.104144096374512\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 14.515954971313477\n",
      "Critic Loss: 10.039374351501465\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 17.46601104736328\n",
      "Critic Loss: 10.982210159301758\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 15.108697891235352\n",
      "Critic Loss: 10.275955200195312\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 13.460572242736816\n",
      "Critic Loss: 7.851048469543457\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 13.404675483703613\n",
      "Critic Loss: 9.805994033813477\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 15.161761283874512\n",
      "Critic Loss: 10.97482967376709\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 14.444196701049805\n",
      "Critic Loss: 11.690301895141602\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 11.437318801879883\n",
      "Critic Loss: 13.425797462463379\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: 15.224796295166016\n",
      "Critic Loss: 12.623763084411621\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: 18.497455596923828\n",
      "Critic Loss: 8.171459197998047\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: 18.240644454956055\n",
      "Critic Loss: 10.671258926391602\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: 11.767269134521484\n",
      "Critic Loss: 12.122966766357422\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 14.39753246307373\n",
      "Critic Loss: 12.13762092590332\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: 11.897765159606934\n",
      "Critic Loss: 9.68232536315918\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 17.210813522338867\n",
      "Critic Loss: 9.577098846435547\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d3c2f4bff24860b8bee2273cb59028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>80.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>75.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>15.88011</td></tr><tr><td>Loss/Critic_loss</td><td>9.5771</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.22843</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0071</td></tr><tr><td>Loss/Policy_loss</td><td>15.89468</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>17.21081</td></tr><tr><td>Metric/Explained_variance</td><td>0.33037</td></tr><tr><td>Reward/Mean_train_reward</td><td>-46.465</td></tr><tr><td>Reward/Mean_val_reward</td><td>-52.4256</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-40.92336</td></tr><tr><td>global_step</td><td>158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-17</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ndeduizn' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ndeduizn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_153306-ndeduizn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: io70i6ce with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00012809112872037663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.003575056040506533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.015013566685078274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9132641855358214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00013389786062526236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.133265095881513e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_154612-io70i6ce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/io70i6ce' target=\"_blank\">silver-sweep-18</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/io70i6ce' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/io70i6ce</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.00012809112872037663, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003575056040506533, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015013566685078274, 'epochs': 10, 'exponential_factor': 0.9132641855358214, 'gamma': 0.9, 'hidden_sizes': [350, 250, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.00013389786062526236, 'l2_factor': 6.133265095881513e-06, 'lrelu': 0.001, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00012809112872037663, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003575056040506533, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015013566685078274, 'epochs': 10, 'exponential_factor': 0.9132641855358214, 'gamma': 0.9, 'l1_factor': 0.00013389786062526236, 'l2_factor': 6.133265095881513e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00012809112872037663, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003575056040506533, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015013566685078274, 'epochs': 10, 'exponential_factor': 0.9132641855358214, 'gamma': 0.9, 'l1_factor': 0.00013389786062526236, 'l2_factor': 6.133265095881513e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00012809112872037663, 'critic_lr': 0.003575056040506533, 'decay_method': 'exponential', 'exponential_factor': 0.9132641855358214, 'value_loss_factor': 1, 'entropy': 0.015013566685078274, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00013389786062526236, 'l2_factor': 6.133265095881513e-06, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 250, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.7656818628311157\n",
      "Critic Loss: 31.293264389038086\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 1.7817773818969727\n",
      "Critic Loss: 10.610023498535156\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 1.7089149951934814\n",
      "Critic Loss: 24.965473175048828\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 1.6810356378555298\n",
      "Critic Loss: 12.471231460571289\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 1.665990948677063\n",
      "Critic Loss: 18.806936264038086\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 1.6641204357147217\n",
      "Critic Loss: 4.435317039489746\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.626283049583435\n",
      "Critic Loss: 10.351262092590332\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 1.6024224758148193\n",
      "Critic Loss: 9.575329780578613\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 1.608855962753296\n",
      "Critic Loss: 11.984676361083984\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 1.6023095846176147\n",
      "Critic Loss: 5.64273738861084\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.5593664646148682\n",
      "Critic Loss: 9.208045959472656\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.578431487083435\n",
      "Critic Loss: 9.908112525939941\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.553733229637146\n",
      "Critic Loss: 12.10395622253418\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.5512386560440063\n",
      "Critic Loss: 7.260784149169922\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.5278117656707764\n",
      "Critic Loss: 7.852921485900879\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.5289007425308228\n",
      "Critic Loss: 10.448866844177246\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 1.5316678285598755\n",
      "Critic Loss: 12.196085929870605\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.4955726861953735\n",
      "Critic Loss: 6.312938213348389\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 1.5225993394851685\n",
      "Critic Loss: 9.486474990844727\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 1.5415705442428589\n",
      "Critic Loss: 4.831014156341553\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 1.5025742053985596\n",
      "Critic Loss: 6.701735496520996\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 1.5226194858551025\n",
      "Critic Loss: 11.055368423461914\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 1.468052625656128\n",
      "Critic Loss: 8.26205062866211\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 1.4822802543640137\n",
      "Critic Loss: 5.836154937744141\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 1.4738668203353882\n",
      "Critic Loss: 9.890822410583496\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.4857624769210815\n",
      "Critic Loss: 9.362356185913086\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.5286047458648682\n",
      "Critic Loss: 12.714632034301758\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 1.4691418409347534\n",
      "Critic Loss: 8.224647521972656\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.4884597063064575\n",
      "Critic Loss: 4.700900077819824\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.4958274364471436\n",
      "Critic Loss: 8.004344940185547\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 1.478459358215332\n",
      "Critic Loss: 6.763566493988037\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.4769648313522339\n",
      "Critic Loss: 8.942742347717285\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 1.4507088661193848\n",
      "Critic Loss: 9.019647598266602\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 1.479035496711731\n",
      "Critic Loss: 11.105186462402344\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 1.5022048950195312\n",
      "Critic Loss: 7.236882209777832\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 1.4709341526031494\n",
      "Critic Loss: 7.934909343719482\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 1.4994330406188965\n",
      "Critic Loss: 10.889610290527344\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 1.485276699066162\n",
      "Critic Loss: 5.662544250488281\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 1.459167718887329\n",
      "Critic Loss: 7.844311237335205\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 1.4474204778671265\n",
      "Critic Loss: 10.594993591308594\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 1.448684573173523\n",
      "Critic Loss: 8.993475914001465\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 1.4500467777252197\n",
      "Critic Loss: 10.824355125427246\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 1.4736794233322144\n",
      "Critic Loss: 10.112781524658203\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 1.5270246267318726\n",
      "Critic Loss: 8.160995483398438\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 1.461035132408142\n",
      "Critic Loss: 6.117264747619629\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 1.462982177734375\n",
      "Critic Loss: 7.304314613342285\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 1.4646427631378174\n",
      "Critic Loss: 5.552846908569336\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 1.4464706182479858\n",
      "Critic Loss: 7.0872321128845215\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.4795376062393188\n",
      "Critic Loss: 7.980584621429443\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 1.4779701232910156\n",
      "Critic Loss: 6.809358596801758\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 1.4849722385406494\n",
      "Critic Loss: 7.875420570373535\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 1.4378955364227295\n",
      "Critic Loss: 8.342475891113281\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 1.4685498476028442\n",
      "Critic Loss: 7.820598602294922\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 1.505205750465393\n",
      "Critic Loss: 6.369503974914551\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 1.4915753602981567\n",
      "Critic Loss: 8.611309051513672\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 1.501197338104248\n",
      "Critic Loss: 7.222326278686523\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 1.4437470436096191\n",
      "Critic Loss: 6.280447006225586\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 1.4830564260482788\n",
      "Critic Loss: 8.480091094970703\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 1.5168102979660034\n",
      "Critic Loss: 8.712930679321289\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 1.4678969383239746\n",
      "Critic Loss: 6.92533540725708\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 1.4691392183303833\n",
      "Critic Loss: 5.3622236251831055\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 1.4691383838653564\n",
      "Critic Loss: 11.333320617675781\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 1.4423191547393799\n",
      "Critic Loss: 7.871191024780273\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 1.4638081789016724\n",
      "Critic Loss: 7.3379740715026855\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 1.4725477695465088\n",
      "Critic Loss: 6.509504318237305\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 1.4831624031066895\n",
      "Critic Loss: 8.267488479614258\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 1.4491766691207886\n",
      "Critic Loss: 8.934383392333984\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 1.4378055334091187\n",
      "Critic Loss: 10.000078201293945\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 1.4538496732711792\n",
      "Critic Loss: 5.698733806610107\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 1.4692641496658325\n",
      "Critic Loss: 8.175256729125977\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 1.4835400581359863\n",
      "Critic Loss: 7.790289402008057\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 1.471897006034851\n",
      "Critic Loss: 9.81938362121582\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 1.4575022459030151\n",
      "Critic Loss: 6.510334014892578\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 1.463732361793518\n",
      "Critic Loss: 5.817078113555908\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 1.5764179229736328\n",
      "Critic Loss: 8.428779602050781\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 1.4638166427612305\n",
      "Critic Loss: 5.9294657707214355\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 1.482072353363037\n",
      "Critic Loss: 5.783705234527588\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 1.4442517757415771\n",
      "Critic Loss: 7.607806205749512\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 1.4876821041107178\n",
      "Critic Loss: 11.065505027770996\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40927e1e8ca242bf9de11c7529d4cf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>45.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>40.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.00248</td></tr><tr><td>Loss/Critic_loss</td><td>11.06551</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.62145</td></tr><tr><td>Loss/KL_divergence</td><td>0.00184</td></tr><tr><td>Loss/Policy_loss</td><td>0.02682</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.48768</td></tr><tr><td>Metric/Explained_variance</td><td>-0.33601</td></tr><tr><td>Reward/Mean_train_reward</td><td>-73.556</td></tr><tr><td>Reward/Mean_val_reward</td><td>-77.8403</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-73.18913</td></tr><tr><td>global_step</td><td>79</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-18</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/io70i6ce' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/io70i6ce</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_154612-io70i6ce\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0veddcwe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.002853767532136351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00017635712455395084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.00971167478621916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8716858916887438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.1056687735888173e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 5.051633332215996e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_155009-0veddcwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/0veddcwe' target=\"_blank\">trim-sweep-19</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0veddcwe' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0veddcwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.002853767532136351, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017635712455395084, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00971167478621916, 'epochs': 10, 'exponential_factor': 0.8716858916887438, 'gamma': 0.95, 'hidden_sizes': [350, 150, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.1056687735888173e-05, 'l2_factor': 5.051633332215996e-06, 'lrelu': 0.1, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.002853767532136351, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017635712455395084, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00971167478621916, 'epochs': 10, 'exponential_factor': 0.8716858916887438, 'gamma': 0.95, 'l1_factor': 2.1056687735888173e-05, 'l2_factor': 5.051633332215996e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.002853767532136351, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017635712455395084, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00971167478621916, 'epochs': 10, 'exponential_factor': 0.8716858916887438, 'gamma': 0.95, 'l1_factor': 2.1056687735888173e-05, 'l2_factor': 5.051633332215996e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.002853767532136351, 'critic_lr': 0.00017635712455395084, 'decay_method': 'exponential', 'exponential_factor': 0.8716858916887438, 'value_loss_factor': 1, 'entropy': 0.00971167478621916, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.1056687735888173e-05, 'l2_factor': 5.051633332215996e-06, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [350, 150, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.2328459471464157\n",
      "Critic Loss: 31.936800003051758\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.2979523837566376\n",
      "Critic Loss: 26.14014434814453\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.14499467611312866\n",
      "Critic Loss: 21.66274070739746\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.1764192283153534\n",
      "Critic Loss: 10.107913970947266\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.06252634525299072\n",
      "Critic Loss: 7.496216297149658\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.0027799687813967466\n",
      "Critic Loss: 10.407666206359863\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.1029421016573906\n",
      "Critic Loss: 8.476542472839355\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.006562002934515476\n",
      "Critic Loss: 7.816343307495117\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.025789478793740273\n",
      "Critic Loss: 9.065190315246582\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.09141121804714203\n",
      "Critic Loss: 12.412574768066406\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.07575710862874985\n",
      "Critic Loss: 12.796525955200195\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.04040127992630005\n",
      "Critic Loss: 11.63907527923584\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.03124113753437996\n",
      "Critic Loss: 12.117232322692871\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.022101569920778275\n",
      "Critic Loss: 12.001045227050781\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.014271755702793598\n",
      "Critic Loss: 14.343331336975098\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.0332508347928524\n",
      "Critic Loss: 9.695034980773926\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.03754418343305588\n",
      "Critic Loss: 12.004447937011719\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.06267015635967255\n",
      "Critic Loss: 10.600696563720703\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.07504180073738098\n",
      "Critic Loss: 8.50749397277832\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.00774021539837122\n",
      "Critic Loss: 9.58552360534668\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.011935543268918991\n",
      "Critic Loss: 9.279190063476562\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.04092710465192795\n",
      "Critic Loss: 6.579563140869141\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.03598542883992195\n",
      "Critic Loss: 8.959064483642578\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.034036897122859955\n",
      "Critic Loss: 4.874019145965576\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.023535678163170815\n",
      "Critic Loss: 6.397695541381836\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.056344930082559586\n",
      "Critic Loss: 4.939736366271973\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.05264251306653023\n",
      "Critic Loss: 3.316669225692749\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.030124962329864502\n",
      "Critic Loss: 3.8321003913879395\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.02994748391211033\n",
      "Critic Loss: 2.2467496395111084\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.0256241075694561\n",
      "Critic Loss: 8.687140464782715\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.04629157483577728\n",
      "Critic Loss: 6.191183090209961\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.04189589247107506\n",
      "Critic Loss: 5.370838165283203\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.039090439677238464\n",
      "Critic Loss: 3.381767988204956\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.04935155808925629\n",
      "Critic Loss: 4.915948390960693\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.05010838806629181\n",
      "Critic Loss: 5.016637325286865\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.04420178011059761\n",
      "Critic Loss: 7.484626293182373\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.06379339843988419\n",
      "Critic Loss: 4.06045389175415\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.03957043215632439\n",
      "Critic Loss: 7.022176265716553\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.0553487092256546\n",
      "Critic Loss: 3.589830160140991\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.03353872522711754\n",
      "Critic Loss: 4.914841651916504\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.06125311180949211\n",
      "Critic Loss: 5.785374641418457\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.04327459633350372\n",
      "Critic Loss: 3.02591609954834\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.04362701624631882\n",
      "Critic Loss: 3.656839370727539\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.04289858788251877\n",
      "Critic Loss: 4.04857063293457\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.0344487801194191\n",
      "Critic Loss: 4.139379501342773\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.04925808310508728\n",
      "Critic Loss: 4.469862461090088\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.04804788902401924\n",
      "Critic Loss: 2.61527419090271\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.050577253103256226\n",
      "Critic Loss: 2.1284611225128174\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.05132749304175377\n",
      "Critic Loss: 4.931928634643555\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.045923810452222824\n",
      "Critic Loss: 5.843430042266846\n",
      "\n",
      "New best validation reward reached in update [50/200]\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.05506926029920578\n",
      "Critic Loss: 4.617271423339844\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.055680323392152786\n",
      "Critic Loss: 3.2030909061431885\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.05876262113451958\n",
      "Critic Loss: 1.3411540985107422\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.05762782692909241\n",
      "Critic Loss: 7.2685041427612305\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.05599871650338173\n",
      "Critic Loss: 5.517856121063232\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.04760781675577164\n",
      "Critic Loss: 7.489293098449707\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.05520288273692131\n",
      "Critic Loss: 5.183887004852295\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.06055538356304169\n",
      "Critic Loss: 0.6549530625343323\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.05549211800098419\n",
      "Critic Loss: 5.755053520202637\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.055513713508844376\n",
      "Critic Loss: 5.908046722412109\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.056246671825647354\n",
      "Critic Loss: 3.6609013080596924\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.056106265634298325\n",
      "Critic Loss: 7.204617977142334\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.05622846260666847\n",
      "Critic Loss: 4.926168441772461\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.05996060371398926\n",
      "Critic Loss: 3.9012012481689453\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.06132172793149948\n",
      "Critic Loss: 0.9325676560401917\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.05600419640541077\n",
      "Critic Loss: 5.179931640625\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.0555543527007103\n",
      "Critic Loss: 5.395179271697998\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.055589813739061356\n",
      "Critic Loss: 3.967275381088257\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.056973520666360855\n",
      "Critic Loss: 4.84684944152832\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.0562116764485836\n",
      "Critic Loss: 4.80209493637085\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.05850701406598091\n",
      "Critic Loss: 2.87937593460083\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.05429642274975777\n",
      "Critic Loss: 5.9209980964660645\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.05907841771841049\n",
      "Critic Loss: 5.349578380584717\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.05889757350087166\n",
      "Critic Loss: 5.687861919403076\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef860af4b9aa48f6944a7db86555f8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>99.25</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>150.8</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.0051</td></tr><tr><td>Loss/Critic_loss</td><td>5.68786</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.53521</td></tr><tr><td>Loss/KL_divergence</td><td>8e-05</td></tr><tr><td>Loss/Policy_loss</td><td>0.0001</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.0589</td></tr><tr><td>Metric/Explained_variance</td><td>0.28847</td></tr><tr><td>Reward/Mean_train_reward</td><td>-68.89174</td></tr><tr><td>Reward/Mean_val_reward</td><td>-61.5582</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-59.70646</td></tr><tr><td>global_step</td><td>74</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-19</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0veddcwe' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0veddcwe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_155009-0veddcwe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: quzgahaa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0002764543275882708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00016048265292976295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0013071406050925148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9373557153924592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.637148708139512e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0001265984072527381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_155747-quzgahaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/quzgahaa' target=\"_blank\">solar-sweep-20</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/quzgahaa' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/quzgahaa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0002764543275882708, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00016048265292976295, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0013071406050925148, 'epochs': 10, 'exponential_factor': 0.9373557153924592, 'gamma': 0.99, 'hidden_sizes': [350, 350, 150, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.637148708139512e-05, 'l2_factor': 0.0001265984072527381, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0002764543275882708, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00016048265292976295, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0013071406050925148, 'epochs': 10, 'exponential_factor': 0.9373557153924592, 'gamma': 0.99, 'l1_factor': 2.637148708139512e-05, 'l2_factor': 0.0001265984072527381, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0002764543275882708, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00016048265292976295, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0013071406050925148, 'epochs': 10, 'exponential_factor': 0.9373557153924592, 'gamma': 0.99, 'l1_factor': 2.637148708139512e-05, 'l2_factor': 0.0001265984072527381, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0002764543275882708, 'critic_lr': 0.00016048265292976295, 'decay_method': 'exponential', 'exponential_factor': 0.9373557153924592, 'value_loss_factor': 1, 'entropy': 0.0013071406050925148, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.637148708139512e-05, 'l2_factor': 0.0001265984072527381, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [350, 350, 150, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.46005046367645264\n",
      "Critic Loss: 23.80811882019043\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.4662523865699768\n",
      "Critic Loss: 20.212072372436523\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.44316285848617554\n",
      "Critic Loss: 18.256847381591797\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.42430731654167175\n",
      "Critic Loss: 19.01952362060547\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.43268218636512756\n",
      "Critic Loss: 14.498347282409668\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.4222193658351898\n",
      "Critic Loss: 22.990156173706055\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.41496312618255615\n",
      "Critic Loss: 16.707462310791016\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.41701540350914\n",
      "Critic Loss: 17.69643211364746\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.39920568466186523\n",
      "Critic Loss: 18.628156661987305\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.40364933013916016\n",
      "Critic Loss: 13.074939727783203\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.40366441011428833\n",
      "Critic Loss: 14.59775447845459\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.39946433901786804\n",
      "Critic Loss: 15.60879898071289\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.3858107626438141\n",
      "Critic Loss: 17.290742874145508\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.3980942964553833\n",
      "Critic Loss: 11.881057739257812\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.3773305416107178\n",
      "Critic Loss: 19.262664794921875\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.37576809525489807\n",
      "Critic Loss: 18.25737953186035\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.38093090057373047\n",
      "Critic Loss: 15.880990028381348\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.3675459921360016\n",
      "Critic Loss: 18.60702133178711\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.3896927833557129\n",
      "Critic Loss: 13.373550415039062\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.3911769986152649\n",
      "Critic Loss: 14.103375434875488\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.37815648317337036\n",
      "Critic Loss: 10.483027458190918\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.38090193271636963\n",
      "Critic Loss: 11.868310928344727\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.3821425437927246\n",
      "Critic Loss: 18.79756736755371\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.3724786043167114\n",
      "Critic Loss: 12.898759841918945\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.37344637513160706\n",
      "Critic Loss: 10.066368103027344\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.37980836629867554\n",
      "Critic Loss: 9.973128318786621\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.3722376227378845\n",
      "Critic Loss: 14.045251846313477\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.38530969619750977\n",
      "Critic Loss: 11.797901153564453\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.38089966773986816\n",
      "Critic Loss: 9.92778491973877\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.37661677598953247\n",
      "Critic Loss: 9.815126419067383\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.3669157028198242\n",
      "Critic Loss: 17.347875595092773\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.38177958130836487\n",
      "Critic Loss: 11.213668823242188\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.384575217962265\n",
      "Critic Loss: 13.62852954864502\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.3762100338935852\n",
      "Critic Loss: 10.880180358886719\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.374464750289917\n",
      "Critic Loss: 10.951179504394531\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.3776104748249054\n",
      "Critic Loss: 10.48926830291748\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.3794345557689667\n",
      "Critic Loss: 11.993637084960938\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.3802371621131897\n",
      "Critic Loss: 9.625141143798828\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.374461829662323\n",
      "Critic Loss: 9.546693801879883\n",
      "\n",
      "New best validation reward reached in update [39/200]\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.36009207367897034\n",
      "Critic Loss: 17.264545440673828\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.3705148696899414\n",
      "Critic Loss: 14.091135025024414\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.375029981136322\n",
      "Critic Loss: 12.849189758300781\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.3682287931442261\n",
      "Critic Loss: 12.416181564331055\n",
      "\n",
      "New best validation reward reached in update [43/200]\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.37751662731170654\n",
      "Critic Loss: 14.048371315002441\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.3714011609554291\n",
      "Critic Loss: 13.430732727050781\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.3803408443927765\n",
      "Critic Loss: 12.402953147888184\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.3752403259277344\n",
      "Critic Loss: 12.301155090332031\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.37969326972961426\n",
      "Critic Loss: 13.276559829711914\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.3778913915157318\n",
      "Critic Loss: 11.145112991333008\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.37720584869384766\n",
      "Critic Loss: 13.388935089111328\n",
      "\n",
      "New best validation reward reached in update [50/200]\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.37396347522735596\n",
      "Critic Loss: 10.857908248901367\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.36862319707870483\n",
      "Critic Loss: 9.954479217529297\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.37796705961227417\n",
      "Critic Loss: 12.492596626281738\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.3731592297554016\n",
      "Critic Loss: 11.965983390808105\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.37210050225257874\n",
      "Critic Loss: 15.00914478302002\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.37471526861190796\n",
      "Critic Loss: 12.15464973449707\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.381014883518219\n",
      "Critic Loss: 11.487846374511719\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.3780820965766907\n",
      "Critic Loss: 12.907428741455078\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.3794969916343689\n",
      "Critic Loss: 14.718805313110352\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.38033950328826904\n",
      "Critic Loss: 14.480164527893066\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.3793313205242157\n",
      "Critic Loss: 12.164647102355957\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.3809133470058441\n",
      "Critic Loss: 11.897457122802734\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.3795974552631378\n",
      "Critic Loss: 11.51668643951416\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.3805745542049408\n",
      "Critic Loss: 11.58109188079834\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.3786858916282654\n",
      "Critic Loss: 12.422014236450195\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.3778330385684967\n",
      "Critic Loss: 14.353872299194336\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.38090696930885315\n",
      "Critic Loss: 13.0594482421875\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.3806212246417999\n",
      "Critic Loss: 13.85267448425293\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.37967199087142944\n",
      "Critic Loss: 13.413297653198242\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.3789408206939697\n",
      "Critic Loss: 14.421998977661133\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.3801780045032501\n",
      "Critic Loss: 14.474089622497559\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.37932488322257996\n",
      "Critic Loss: 12.627118110656738\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.38038623332977295\n",
      "Critic Loss: 17.260828018188477\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.3782631754875183\n",
      "Critic Loss: 16.05699348449707\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.3802875876426697\n",
      "Critic Loss: 13.724930763244629\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.37969547510147095\n",
      "Critic Loss: 13.630867004394531\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.3804072141647339\n",
      "Critic Loss: 15.11732006072998\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.3804780840873718\n",
      "Critic Loss: 13.316024780273438\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.37951743602752686\n",
      "Critic Loss: 13.762772560119629\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.38099902868270874\n",
      "Critic Loss: 12.524896621704102\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.38062071800231934\n",
      "Critic Loss: 14.025647163391113\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.3806484639644623\n",
      "Critic Loss: 14.289559364318848\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.3805027902126312\n",
      "Critic Loss: 15.726753234863281\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.38042667508125305\n",
      "Critic Loss: 12.350193977355957\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.38095027208328247\n",
      "Critic Loss: 13.412606239318848\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.38078004121780396\n",
      "Critic Loss: 12.397602081298828\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.38072431087493896\n",
      "Critic Loss: 12.220318794250488\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.3804739713668823\n",
      "Critic Loss: 11.931253433227539\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.3805943429470062\n",
      "Critic Loss: 11.85660171508789\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.3805842399597168\n",
      "Critic Loss: 12.837660789489746\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.3806416690349579\n",
      "Critic Loss: 13.60926628112793\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.3806968927383423\n",
      "Critic Loss: 14.50193977355957\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.38083183765411377\n",
      "Critic Loss: 13.19111442565918\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.3807915151119232\n",
      "Critic Loss: 13.750359535217285\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.38082531094551086\n",
      "Critic Loss: 13.790426254272461\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.3803735077381134\n",
      "Critic Loss: 12.461777687072754\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.3803699016571045\n",
      "Critic Loss: 16.6287841796875\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.3808642327785492\n",
      "Critic Loss: 15.905625343322754\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.38074302673339844\n",
      "Critic Loss: 12.465999603271484\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.38071632385253906\n",
      "Critic Loss: 11.988862991333008\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.3805893659591675\n",
      "Critic Loss: 14.23646354675293\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.3808054029941559\n",
      "Critic Loss: 14.606040000915527\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.38092607259750366\n",
      "Critic Loss: 11.739095687866211\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.38095900416374207\n",
      "Critic Loss: 12.963044166564941\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccc496ed17444ef8b37623d90d9f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>48.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>67.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00168</td></tr><tr><td>Loss/Critic_loss</td><td>12.96304</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.23171</td></tr><tr><td>Loss/KL_divergence</td><td>-2e-05</td></tr><tr><td>Loss/Policy_loss</td><td>-7e-05</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.38096</td></tr><tr><td>Metric/Explained_variance</td><td>0.34194</td></tr><tr><td>Reward/Mean_train_reward</td><td>-60.143</td></tr><tr><td>Reward/Mean_val_reward</td><td>-44.326</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-25.6125</td></tr><tr><td>global_step</td><td>104</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-20</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/quzgahaa' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/quzgahaa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_155747-quzgahaa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jgzgp0eb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.007593290564047245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.000585812330053055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.02955210171667238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8696843120194657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00020274076099870337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0007922702192707737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_160341-jgzgp0eb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/jgzgp0eb' target=\"_blank\">smart-sweep-21</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/jgzgp0eb' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/jgzgp0eb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.007593290564047245, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.000585812330053055, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02955210171667238, 'epochs': 10, 'exponential_factor': 0.8696843120194657, 'gamma': 0.95, 'hidden_sizes': [250, 150, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.00020274076099870337, 'l2_factor': 0.0007922702192707737, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.007593290564047245, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.000585812330053055, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02955210171667238, 'epochs': 10, 'exponential_factor': 0.8696843120194657, 'gamma': 0.95, 'l1_factor': 0.00020274076099870337, 'l2_factor': 0.0007922702192707737, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.007593290564047245, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.000585812330053055, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02955210171667238, 'epochs': 10, 'exponential_factor': 0.8696843120194657, 'gamma': 0.95, 'l1_factor': 0.00020274076099870337, 'l2_factor': 0.0007922702192707737, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.007593290564047245, 'critic_lr': 0.000585812330053055, 'decay_method': 'exponential', 'exponential_factor': 0.8696843120194657, 'value_loss_factor': 1, 'entropy': 0.02955210171667238, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00020274076099870337, 'l2_factor': 0.0007922702192707737, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [250, 150, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 2.734175205230713\n",
      "Critic Loss: 21.972333908081055\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 1.4053077697753906\n",
      "Critic Loss: 37.71129608154297\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.8515052795410156\n",
      "Critic Loss: 22.128816604614258\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.6041672229766846\n",
      "Critic Loss: 19.64756202697754\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.47248736023902893\n",
      "Critic Loss: 14.400936126708984\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.3769567012786865\n",
      "Critic Loss: 11.224040985107422\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.319378137588501\n",
      "Critic Loss: 13.287616729736328\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.2586299777030945\n",
      "Critic Loss: 14.291847229003906\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.2444562017917633\n",
      "Critic Loss: 8.480118751525879\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.20087489485740662\n",
      "Critic Loss: 13.364123344421387\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.17063957452774048\n",
      "Critic Loss: 8.28087329864502\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.14631962776184082\n",
      "Critic Loss: 10.10696029663086\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.15641531348228455\n",
      "Critic Loss: 10.399893760681152\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.13519398868083954\n",
      "Critic Loss: 10.857117652893066\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.08477991819381714\n",
      "Critic Loss: 11.8978853225708\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.09152945876121521\n",
      "Critic Loss: 8.517724990844727\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.084443099796772\n",
      "Critic Loss: 7.487013339996338\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.08227992057800293\n",
      "Critic Loss: 7.013399124145508\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.0802159532904625\n",
      "Critic Loss: 8.78874397277832\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.07636215537786484\n",
      "Critic Loss: 8.521596908569336\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.07486888766288757\n",
      "Critic Loss: 7.588987350463867\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.06451167166233063\n",
      "Critic Loss: 13.4042329788208\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.06096504256129265\n",
      "Critic Loss: 6.876771926879883\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.060888249427080154\n",
      "Critic Loss: 10.656622886657715\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.056098829954862595\n",
      "Critic Loss: 8.833353996276855\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.04083193466067314\n",
      "Critic Loss: 8.984979629516602\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.04968683049082756\n",
      "Critic Loss: 6.0173444747924805\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.047316983342170715\n",
      "Critic Loss: 4.202459812164307\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.04884420335292816\n",
      "Critic Loss: 7.70769739151001\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.04560238867998123\n",
      "Critic Loss: 6.756624221801758\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.054524775594472885\n",
      "Critic Loss: 7.208128929138184\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.05258927494287491\n",
      "Critic Loss: 12.29417896270752\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.05412271246314049\n",
      "Critic Loss: 7.044203281402588\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.07547895610332489\n",
      "Critic Loss: 11.709651947021484\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.06346482038497925\n",
      "Critic Loss: 8.883306503295898\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.054285671561956406\n",
      "Critic Loss: 10.664548873901367\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.06349005550146103\n",
      "Critic Loss: 7.4875311851501465\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.055597081780433655\n",
      "Critic Loss: 8.709290504455566\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.059262193739414215\n",
      "Critic Loss: 9.978998184204102\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.05440619960427284\n",
      "Critic Loss: 7.465682029724121\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.06308606266975403\n",
      "Critic Loss: 9.089736938476562\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.06612420827150345\n",
      "Critic Loss: 7.878020286560059\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.07290778309106827\n",
      "Critic Loss: 6.873627662658691\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.07239320874214172\n",
      "Critic Loss: 8.081572532653809\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.07529059797525406\n",
      "Critic Loss: 7.679992198944092\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.060897424817085266\n",
      "Critic Loss: 8.369072914123535\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.08632750809192657\n",
      "Critic Loss: 10.615805625915527\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.07367480546236038\n",
      "Critic Loss: 8.873985290527344\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.08987731486558914\n",
      "Critic Loss: 11.388091087341309\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.08757075667381287\n",
      "Critic Loss: 8.958199501037598\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.08376482129096985\n",
      "Critic Loss: 8.803045272827148\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.09346388280391693\n",
      "Critic Loss: 10.57468032836914\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.07408489286899567\n",
      "Critic Loss: 9.816511154174805\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.0877937600016594\n",
      "Critic Loss: 9.636839866638184\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.09398503601551056\n",
      "Critic Loss: 10.811553955078125\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.08596242964267731\n",
      "Critic Loss: 10.74372673034668\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.07686848938465118\n",
      "Critic Loss: 7.756804943084717\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.06508897989988327\n",
      "Critic Loss: 13.206745147705078\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.0789269432425499\n",
      "Critic Loss: 9.562878608703613\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.07867841422557831\n",
      "Critic Loss: 8.777019500732422\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.1585196852684021\n",
      "Critic Loss: 8.445442199707031\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.08155268430709839\n",
      "Critic Loss: 7.480393409729004\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.08712559938430786\n",
      "Critic Loss: 10.378031730651855\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.12059777975082397\n",
      "Critic Loss: 9.1255464553833\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.09027820825576782\n",
      "Critic Loss: 8.847909927368164\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.09679228067398071\n",
      "Critic Loss: 11.778672218322754\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.08991619944572449\n",
      "Critic Loss: 6.938998222351074\n",
      "\n",
      "New best validation reward reached in update [67/200]\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.10041770339012146\n",
      "Critic Loss: 9.703733444213867\n",
      "\n",
      "New best validation reward reached in update [68/200]\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.09347398579120636\n",
      "Critic Loss: 10.808688163757324\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.06786605715751648\n",
      "Critic Loss: 7.7632155418396\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.10566642135381699\n",
      "Critic Loss: 8.549637794494629\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.07918834686279297\n",
      "Critic Loss: 7.8408942222595215\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.10995505750179291\n",
      "Critic Loss: 9.376978874206543\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.08029823005199432\n",
      "Critic Loss: 7.882106304168701\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.12916402518749237\n",
      "Critic Loss: 10.800192832946777\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.09131376445293427\n",
      "Critic Loss: 7.47590970993042\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.1243039071559906\n",
      "Critic Loss: 14.0538330078125\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.0925958901643753\n",
      "Critic Loss: 8.095154762268066\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.09297769516706467\n",
      "Critic Loss: 10.65554428100586\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.07957112789154053\n",
      "Critic Loss: 8.305006980895996\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.08922522515058517\n",
      "Critic Loss: 9.212543487548828\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.11332256346940994\n",
      "Critic Loss: 10.214033126831055\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.07637953013181686\n",
      "Critic Loss: 8.697025299072266\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.09364534169435501\n",
      "Critic Loss: 8.197410583496094\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.08484865725040436\n",
      "Critic Loss: 8.423858642578125\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.09901164472103119\n",
      "Critic Loss: 7.799223899841309\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.09259980171918869\n",
      "Critic Loss: 11.19383430480957\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.08923664689064026\n",
      "Critic Loss: 10.243741989135742\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.11295828223228455\n",
      "Critic Loss: 8.304965019226074\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.10152623057365417\n",
      "Critic Loss: 9.928168296813965\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.0985613465309143\n",
      "Critic Loss: 8.18039608001709\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.09049093723297119\n",
      "Critic Loss: 6.498188018798828\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.08979564905166626\n",
      "Critic Loss: 10.135309219360352\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.08803936094045639\n",
      "Critic Loss: 11.217170715332031\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.11458896845579147\n",
      "Critic Loss: 7.019230365753174\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.07976555824279785\n",
      "Critic Loss: 8.18671989440918\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.09499522298574448\n",
      "Critic Loss: 9.725869178771973\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.07312509417533875\n",
      "Critic Loss: 8.755120277404785\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f7bacc61894b5c95e9e55dd615701b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>74.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>135.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.06378</td></tr><tr><td>Loss/Critic_loss</td><td>8.75512</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.56875</td></tr><tr><td>Loss/KL_divergence</td><td>0.00277</td></tr><tr><td>Loss/Policy_loss</td><td>-0.01742</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.07313</td></tr><tr><td>Metric/Explained_variance</td><td>-0.16151</td></tr><tr><td>Reward/Mean_train_reward</td><td>-43.34034</td></tr><tr><td>Reward/Mean_val_reward</td><td>-6.8735</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-4.69575</td></tr><tr><td>global_step</td><td>98</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-sweep-21</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/jgzgp0eb' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/jgzgp0eb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_160341-jgzgp0eb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8d899l89 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.000773587896793357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0001857073176170235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.004503858073374783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8915724430608235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0003356633894007055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00023942858396834625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_161230-8d899l89</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/8d899l89' target=\"_blank\">noble-sweep-22</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8d899l89' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8d899l89</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.000773587896793357, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0001857073176170235, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004503858073374783, 'epochs': 10, 'exponential_factor': 0.8915724430608235, 'gamma': 0.95, 'hidden_sizes': [350, 250, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0003356633894007055, 'l2_factor': 0.00023942858396834625, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.000773587896793357, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0001857073176170235, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004503858073374783, 'epochs': 10, 'exponential_factor': 0.8915724430608235, 'gamma': 0.95, 'l1_factor': 0.0003356633894007055, 'l2_factor': 0.00023942858396834625, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.000773587896793357, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0001857073176170235, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004503858073374783, 'epochs': 10, 'exponential_factor': 0.8915724430608235, 'gamma': 0.95, 'l1_factor': 0.0003356633894007055, 'l2_factor': 0.00023942858396834625, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.000773587896793357, 'critic_lr': 0.0001857073176170235, 'decay_method': 'exponential', 'exponential_factor': 0.8915724430608235, 'value_loss_factor': 1, 'entropy': 0.004503858073374783, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0003356633894007055, 'l2_factor': 0.00023942858396834625, 'T': 1024, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 250, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 17.78163719177246\n",
      "Critic Loss: 13.547457695007324\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 17.694507598876953\n",
      "Critic Loss: 12.835866928100586\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 17.189029693603516\n",
      "Critic Loss: 9.301555633544922\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 11.255313873291016\n",
      "Critic Loss: 10.269434928894043\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 6.9659552574157715\n",
      "Critic Loss: 8.30180549621582\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 7.1611738204956055\n",
      "Critic Loss: 6.585522651672363\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 4.731017112731934\n",
      "Critic Loss: 3.5221736431121826\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 5.160711765289307\n",
      "Critic Loss: 4.467236042022705\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 4.019032955169678\n",
      "Critic Loss: 3.401015043258667\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 3.4652299880981445\n",
      "Critic Loss: 2.461362361907959\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 5.706595420837402\n",
      "Critic Loss: 3.1364634037017822\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 4.579500675201416\n",
      "Critic Loss: 2.410266876220703\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 8.550690650939941\n",
      "Critic Loss: 3.097888946533203\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 5.739902019500732\n",
      "Critic Loss: 3.3067004680633545\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 4.399168968200684\n",
      "Critic Loss: 1.5637552738189697\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 4.781752586364746\n",
      "Critic Loss: 3.1291377544403076\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 4.991385459899902\n",
      "Critic Loss: 3.2145447731018066\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 4.966493606567383\n",
      "Critic Loss: 2.316171407699585\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 4.682328224182129\n",
      "Critic Loss: 2.864044666290283\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 6.347846031188965\n",
      "Critic Loss: 3.1079816818237305\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 3.490952730178833\n",
      "Critic Loss: 3.0261037349700928\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 2.0601534843444824\n",
      "Critic Loss: 2.4175713062286377\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 4.434312343597412\n",
      "Critic Loss: 4.3744120597839355\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 3.239833354949951\n",
      "Critic Loss: 4.257233142852783\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 3.6239428520202637\n",
      "Critic Loss: 3.527390956878662\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 6.46872615814209\n",
      "Critic Loss: 4.200587749481201\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.919525384902954\n",
      "Critic Loss: 1.9387304782867432\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 4.704636573791504\n",
      "Critic Loss: 5.6064348220825195\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 7.058370113372803\n",
      "Critic Loss: 6.825948238372803\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 2.77068829536438\n",
      "Critic Loss: 5.247334957122803\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 4.530763149261475\n",
      "Critic Loss: 3.6168129444122314\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 5.926353454589844\n",
      "Critic Loss: 4.652957439422607\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 1.0708425045013428\n",
      "Critic Loss: 4.437225341796875\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -1.0416258573532104\n",
      "Critic Loss: 3.3385653495788574\n",
      "\n",
      "New best validation reward reached in update [34/200]\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 3.3183071613311768\n",
      "Critic Loss: 6.372838020324707\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 4.58751106262207\n",
      "Critic Loss: 8.058985710144043\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 3.9941890239715576\n",
      "Critic Loss: 5.505852222442627\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 4.257673740386963\n",
      "Critic Loss: 5.680896759033203\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -3.0986123085021973\n",
      "Critic Loss: 3.8572471141815186\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.44784000515937805\n",
      "Critic Loss: 4.071962833404541\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 2.5987563133239746\n",
      "Critic Loss: 6.320369720458984\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -1.6694155931472778\n",
      "Critic Loss: 6.04148530960083\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -2.59885311126709\n",
      "Critic Loss: 4.230640888214111\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -2.842938184738159\n",
      "Critic Loss: 3.805741786956787\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -2.401801109313965\n",
      "Critic Loss: 4.109274864196777\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -3.2208540439605713\n",
      "Critic Loss: 3.790665626525879\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -9.448343276977539\n",
      "Critic Loss: 5.76059627532959\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -3.9085676670074463\n",
      "Critic Loss: 2.779195547103882\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -3.7047181129455566\n",
      "Critic Loss: 3.843895196914673\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 4.952558994293213\n",
      "Critic Loss: 7.147336959838867\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.48910093307495117\n",
      "Critic Loss: 4.0395355224609375\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -2.8480584621429443\n",
      "Critic Loss: 4.218934059143066\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -4.074645519256592\n",
      "Critic Loss: 3.8101015090942383\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.475913405418396\n",
      "Critic Loss: 4.347512245178223\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -5.209784507751465\n",
      "Critic Loss: 3.2655036449432373\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -3.805452346801758\n",
      "Critic Loss: 3.4761710166931152\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -3.366644859313965\n",
      "Critic Loss: 2.509989023208618\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.62554532289505\n",
      "Critic Loss: 5.816692352294922\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -6.186975479125977\n",
      "Critic Loss: 3.076118230819702\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.3989157974720001\n",
      "Critic Loss: 7.777315139770508\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -2.0757064819335938\n",
      "Critic Loss: 4.931421279907227\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -2.28428053855896\n",
      "Critic Loss: 4.281830310821533\n",
      "\n",
      "New best validation reward reached in update [62/200]\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.2882961630821228\n",
      "Critic Loss: 5.67648983001709\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -1.1381078958511353\n",
      "Critic Loss: 5.966582298278809\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.5991504192352295\n",
      "Critic Loss: 5.1339006423950195\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -1.150180697441101\n",
      "Critic Loss: 5.719510555267334\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -1.3494690656661987\n",
      "Critic Loss: 4.515171051025391\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -1.4832595586776733\n",
      "Critic Loss: 4.997029781341553\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -2.617141008377075\n",
      "Critic Loss: 4.634493350982666\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 1.0298835039138794\n",
      "Critic Loss: 6.858503818511963\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.48307669162750244\n",
      "Critic Loss: 6.004549026489258\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -3.1427907943725586\n",
      "Critic Loss: 3.583315849304199\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.9073389768600464\n",
      "Critic Loss: 4.6159563064575195\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -2.252039909362793\n",
      "Critic Loss: 2.9530229568481445\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -1.9808800220489502\n",
      "Critic Loss: 5.277799129486084\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -4.254040241241455\n",
      "Critic Loss: 3.719501495361328\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -4.096944808959961\n",
      "Critic Loss: 4.139604568481445\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.011638343334197998\n",
      "Critic Loss: 6.414994239807129\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -2.18109393119812\n",
      "Critic Loss: 4.251656532287598\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -2.476985216140747\n",
      "Critic Loss: 4.648012638092041\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -4.222411632537842\n",
      "Critic Loss: 2.9886388778686523\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -1.4984841346740723\n",
      "Critic Loss: 5.3540449142456055\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -4.016998291015625\n",
      "Critic Loss: 3.3682169914245605\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -5.824459552764893\n",
      "Critic Loss: 2.406710624694824\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.9763737320899963\n",
      "Critic Loss: 5.555506229400635\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -2.0522243976593018\n",
      "Critic Loss: 4.657034397125244\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -1.053501009941101\n",
      "Critic Loss: 5.22546911239624\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -2.9461212158203125\n",
      "Critic Loss: 4.261099338531494\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -1.9144396781921387\n",
      "Critic Loss: 5.060142517089844\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -3.5938806533813477\n",
      "Critic Loss: 3.9447295665740967\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -2.170262098312378\n",
      "Critic Loss: 5.272899627685547\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -2.9209067821502686\n",
      "Critic Loss: 4.402719020843506\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.040935516357421875\n",
      "Critic Loss: 6.069058418273926\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.11424469947814941\n",
      "Critic Loss: 7.014617443084717\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -3.4771862030029297\n",
      "Critic Loss: 4.633101463317871\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be3725f92fd4175ab448b25c71d1fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>429.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>341.70001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-8.75909</td></tr><tr><td>Loss/Critic_loss</td><td>4.6331</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.24992</td></tr><tr><td>Loss/KL_divergence</td><td>0.00036</td></tr><tr><td>Loss/Policy_loss</td><td>-8.75797</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-3.47719</td></tr><tr><td>Metric/Explained_variance</td><td>0.0063</td></tr><tr><td>Reward/Mean_train_reward</td><td>310.06848</td></tr><tr><td>Reward/Mean_val_reward</td><td>212.02071</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>145.83098</td></tr><tr><td>global_step</td><td>95</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-sweep-22</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8d899l89' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8d899l89</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_161230-8d899l89\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zc1440ux with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0028143823525120857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00832217380126745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.005120707977174764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9384941383346692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 4.826149665716156e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00022692453063343488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_162920-zc1440ux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/zc1440ux' target=\"_blank\">genial-sweep-23</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/zc1440ux' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/zc1440ux</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0028143823525120857, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00832217380126745, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005120707977174764, 'epochs': 10, 'exponential_factor': 0.9384941383346692, 'gamma': 0.9, 'hidden_sizes': [150, 250, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 4.826149665716156e-06, 'l2_factor': 0.00022692453063343488, 'lrelu': 0.1, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0028143823525120857, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00832217380126745, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005120707977174764, 'epochs': 10, 'exponential_factor': 0.9384941383346692, 'gamma': 0.9, 'l1_factor': 4.826149665716156e-06, 'l2_factor': 0.00022692453063343488, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0028143823525120857, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00832217380126745, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005120707977174764, 'epochs': 10, 'exponential_factor': 0.9384941383346692, 'gamma': 0.9, 'l1_factor': 4.826149665716156e-06, 'l2_factor': 0.00022692453063343488, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0028143823525120857, 'critic_lr': 0.00832217380126745, 'decay_method': 'exponential', 'exponential_factor': 0.9384941383346692, 'value_loss_factor': 1, 'entropy': 0.005120707977174764, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 4.826149665716156e-06, 'l2_factor': 0.00022692453063343488, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [150, 250, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.36833104491233826\n",
      "Critic Loss: 38.31184768676758\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.35007479786872864\n",
      "Critic Loss: 12.490570068359375\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.3230777382850647\n",
      "Critic Loss: 11.354485511779785\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.30370843410491943\n",
      "Critic Loss: 10.191718101501465\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.3035587668418884\n",
      "Critic Loss: 5.962981700897217\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.2833608388900757\n",
      "Critic Loss: 9.001679420471191\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.24288108944892883\n",
      "Critic Loss: 8.206900596618652\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.23388369381427765\n",
      "Critic Loss: 8.81155776977539\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.219417542219162\n",
      "Critic Loss: 8.8652982711792\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.23455816507339478\n",
      "Critic Loss: 8.446958541870117\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.2147282212972641\n",
      "Critic Loss: 7.417337417602539\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.21546117961406708\n",
      "Critic Loss: 7.468957901000977\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.20853494107723236\n",
      "Critic Loss: 9.14835262298584\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.19046643376350403\n",
      "Critic Loss: 8.267181396484375\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.20067280530929565\n",
      "Critic Loss: 7.194828510284424\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.18660587072372437\n",
      "Critic Loss: 5.977360725402832\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.17231015861034393\n",
      "Critic Loss: 6.148151397705078\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.17751923203468323\n",
      "Critic Loss: 4.9177727699279785\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.171675905585289\n",
      "Critic Loss: 6.377747058868408\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.17793656885623932\n",
      "Critic Loss: 3.7875423431396484\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.1924929916858673\n",
      "Critic Loss: 5.433469772338867\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.15438330173492432\n",
      "Critic Loss: 3.2382307052612305\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.16163396835327148\n",
      "Critic Loss: 5.946092128753662\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.17324815690517426\n",
      "Critic Loss: 3.733825206756592\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.24189847707748413\n",
      "Critic Loss: 4.679638385772705\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.1611657738685608\n",
      "Critic Loss: 3.186187744140625\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.18831264972686768\n",
      "Critic Loss: 3.2246344089508057\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.156895712018013\n",
      "Critic Loss: 2.748286247253418\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.1635400652885437\n",
      "Critic Loss: 3.1405506134033203\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.1401335597038269\n",
      "Critic Loss: 2.6816954612731934\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.15346094965934753\n",
      "Critic Loss: 3.6905927658081055\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.18163874745368958\n",
      "Critic Loss: 4.279658794403076\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.1793261617422104\n",
      "Critic Loss: 3.40051531791687\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.14785455167293549\n",
      "Critic Loss: 2.9839861392974854\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.1676899939775467\n",
      "Critic Loss: 2.7095255851745605\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.14865392446517944\n",
      "Critic Loss: 5.157414436340332\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.14840459823608398\n",
      "Critic Loss: 4.244446277618408\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.17386476695537567\n",
      "Critic Loss: 3.023526906967163\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.1578923463821411\n",
      "Critic Loss: 5.766958236694336\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.24936409294605255\n",
      "Critic Loss: 5.638313293457031\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.1395164430141449\n",
      "Critic Loss: 2.810452699661255\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.1293950080871582\n",
      "Critic Loss: 2.7266242504119873\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.15366661548614502\n",
      "Critic Loss: 3.2505104541778564\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.14843162894248962\n",
      "Critic Loss: 3.0018012523651123\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.13128158450126648\n",
      "Critic Loss: 2.7947258949279785\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.1572476178407669\n",
      "Critic Loss: 2.778517961502075\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.1343911588191986\n",
      "Critic Loss: 3.6631979942321777\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.1466706395149231\n",
      "Critic Loss: 3.177837371826172\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.16074547171592712\n",
      "Critic Loss: 3.4909000396728516\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.17979753017425537\n",
      "Critic Loss: 8.644232749938965\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.29843470454216003\n",
      "Critic Loss: 9.891803741455078\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.1569567322731018\n",
      "Critic Loss: 8.7144775390625\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.1473022997379303\n",
      "Critic Loss: 6.056164264678955\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.19060203433036804\n",
      "Critic Loss: 10.695207595825195\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.1836993396282196\n",
      "Critic Loss: 6.029303550720215\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.2304316610097885\n",
      "Critic Loss: 8.868780136108398\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.1378812938928604\n",
      "Critic Loss: 9.017250061035156\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.13798588514328003\n",
      "Critic Loss: 7.918940544128418\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7b61ba8a1247c19647d0d0b477434c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>94.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>80.6</td></tr><tr><td>Learning_rate/Actor</td><td>8e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.00022</td></tr><tr><td>Loss/Actor_loss</td><td>-0.01305</td></tr><tr><td>Loss/Critic_loss</td><td>7.91894</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.03445</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01141</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00775</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.13799</td></tr><tr><td>Metric/Explained_variance</td><td>0.01816</td></tr><tr><td>Reward/Mean_train_reward</td><td>-23.7065</td></tr><tr><td>Reward/Mean_val_reward</td><td>-45.4644</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-43.66997</td></tr><tr><td>global_step</td><td>58</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sweep-23</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/zc1440ux' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/zc1440ux</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_162920-zc1440ux\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s3hecz7k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.000681082990242636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.003009925162185662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.014326645469037773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9146549861710976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.1992561129112308e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.0053934446129956e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_163337-s3hecz7k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/s3hecz7k' target=\"_blank\">deft-sweep-24</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/s3hecz7k' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/s3hecz7k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.000681082990242636, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003009925162185662, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.014326645469037773, 'epochs': 10, 'exponential_factor': 0.9146549861710976, 'gamma': 0.9, 'hidden_sizes': [250, 350, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.1992561129112308e-06, 'l2_factor': 3.0053934446129956e-06, 'lrelu': 0.1, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.000681082990242636, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003009925162185662, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.014326645469037773, 'epochs': 10, 'exponential_factor': 0.9146549861710976, 'gamma': 0.9, 'l1_factor': 1.1992561129112308e-06, 'l2_factor': 3.0053934446129956e-06, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.000681082990242636, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003009925162185662, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.014326645469037773, 'epochs': 10, 'exponential_factor': 0.9146549861710976, 'gamma': 0.9, 'l1_factor': 1.1992561129112308e-06, 'l2_factor': 3.0053934446129956e-06, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.000681082990242636, 'critic_lr': 0.003009925162185662, 'decay_method': 'exponential', 'exponential_factor': 0.9146549861710976, 'value_loss_factor': 1, 'entropy': 0.014326645469037773, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.1992561129112308e-06, 'l2_factor': 3.0053934446129956e-06, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [250, 350, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 13.3236665725708\n",
      "Critic Loss: 15.602500915527344\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 14.021488189697266\n",
      "Critic Loss: 15.771903991699219\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 6.639095306396484\n",
      "Critic Loss: 7.864502429962158\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 13.70369815826416\n",
      "Critic Loss: 14.057268142700195\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 12.46825122833252\n",
      "Critic Loss: 9.830148696899414\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 9.231226921081543\n",
      "Critic Loss: 8.789056777954102\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 9.702836036682129\n",
      "Critic Loss: 7.836622714996338\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 8.72608470916748\n",
      "Critic Loss: 10.56635856628418\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 6.775391578674316\n",
      "Critic Loss: 7.962571620941162\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 5.742562770843506\n",
      "Critic Loss: 7.169952869415283\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 5.3773651123046875\n",
      "Critic Loss: 5.996217250823975\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 6.000738143920898\n",
      "Critic Loss: 6.430307865142822\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 6.892712116241455\n",
      "Critic Loss: 7.130425930023193\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 8.33407974243164\n",
      "Critic Loss: 7.241787910461426\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 6.875305652618408\n",
      "Critic Loss: 5.7828369140625\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 5.136168956756592\n",
      "Critic Loss: 5.793110370635986\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 4.785393714904785\n",
      "Critic Loss: 5.740116119384766\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 5.175771713256836\n",
      "Critic Loss: 5.187631130218506\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 5.204848289489746\n",
      "Critic Loss: 6.503115653991699\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 6.171013832092285\n",
      "Critic Loss: 6.913058280944824\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 3.7603113651275635\n",
      "Critic Loss: 5.191898822784424\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 6.6530866622924805\n",
      "Critic Loss: 5.690596580505371\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 5.657000541687012\n",
      "Critic Loss: 4.9342942237854\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 3.3127357959747314\n",
      "Critic Loss: 3.5791213512420654\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 6.551094055175781\n",
      "Critic Loss: 4.527482509613037\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 6.653635025024414\n",
      "Critic Loss: 4.7124762535095215\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 4.173338890075684\n",
      "Critic Loss: 4.222524166107178\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 7.361574172973633\n",
      "Critic Loss: 5.689739227294922\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 4.909017086029053\n",
      "Critic Loss: 4.059985637664795\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 6.4837164878845215\n",
      "Critic Loss: 5.195188522338867\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 4.458626747131348\n",
      "Critic Loss: 3.913585662841797\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 2.630812406539917\n",
      "Critic Loss: 3.631140947341919\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 3.3559398651123047\n",
      "Critic Loss: 3.8993616104125977\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 4.670171737670898\n",
      "Critic Loss: 5.7710676193237305\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 4.546164035797119\n",
      "Critic Loss: 3.2415313720703125\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 5.584793567657471\n",
      "Critic Loss: 5.438525676727295\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 3.8965296745300293\n",
      "Critic Loss: 4.401200771331787\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 5.984537601470947\n",
      "Critic Loss: 5.024615287780762\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 5.094498157501221\n",
      "Critic Loss: 3.4924449920654297\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 4.797397136688232\n",
      "Critic Loss: 3.79848051071167\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 6.626413345336914\n",
      "Critic Loss: 3.6416194438934326\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 4.707437515258789\n",
      "Critic Loss: 3.884277582168579\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 3.0214245319366455\n",
      "Critic Loss: 3.229835033416748\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 4.614675998687744\n",
      "Critic Loss: 4.531863689422607\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 4.211629390716553\n",
      "Critic Loss: 4.183469772338867\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 6.251460075378418\n",
      "Critic Loss: 6.374090194702148\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.08829715847969055\n",
      "Critic Loss: 3.0533645153045654\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 3.430819272994995\n",
      "Critic Loss: 4.96012544631958\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 2.2020490169525146\n",
      "Critic Loss: 4.281566143035889\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 2.615586757659912\n",
      "Critic Loss: 3.949422836303711\n",
      "\n",
      "New best validation reward reached in update [50/200]\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 2.1420679092407227\n",
      "Critic Loss: 4.200838565826416\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 2.229975938796997\n",
      "Critic Loss: 3.433727264404297\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 3.9872899055480957\n",
      "Critic Loss: 5.113385200500488\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.5725527405738831\n",
      "Critic Loss: 3.472447633743286\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 3.6773409843444824\n",
      "Critic Loss: 5.068100929260254\n",
      "\n",
      "New best validation reward reached in update [55/200]\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 1.0811710357666016\n",
      "Critic Loss: 3.8561933040618896\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 2.598627805709839\n",
      "Critic Loss: 3.405592918395996\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 3.150535821914673\n",
      "Critic Loss: 4.683797359466553\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.6944073438644409\n",
      "Critic Loss: 4.0895233154296875\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 3.1843791007995605\n",
      "Critic Loss: 5.98295783996582\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 4.137508392333984\n",
      "Critic Loss: 5.549900054931641\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.9981356263160706\n",
      "Critic Loss: 2.5711264610290527\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 2.607529878616333\n",
      "Critic Loss: 4.810754776000977\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 5.032283782958984\n",
      "Critic Loss: 6.562638759613037\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 1.4383158683776855\n",
      "Critic Loss: 4.055286884307861\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 2.3782408237457275\n",
      "Critic Loss: 3.7260003089904785\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 4.148456573486328\n",
      "Critic Loss: 6.206675052642822\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 2.520594835281372\n",
      "Critic Loss: 3.420750856399536\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 1.1755176782608032\n",
      "Critic Loss: 2.5165421962738037\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 2.3193202018737793\n",
      "Critic Loss: 5.236169338226318\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 3.1366827487945557\n",
      "Critic Loss: 3.584226608276367\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 1.9318733215332031\n",
      "Critic Loss: 4.767108917236328\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 2.9398810863494873\n",
      "Critic Loss: 6.170238971710205\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 3.430974245071411\n",
      "Critic Loss: 4.652340888977051\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 1.219702959060669\n",
      "Critic Loss: 2.558854103088379\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 3.5562360286712646\n",
      "Critic Loss: 6.502682209014893\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 1.2934094667434692\n",
      "Critic Loss: 4.368844032287598\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 2.405532121658325\n",
      "Critic Loss: 4.3945417404174805\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 1.2812913656234741\n",
      "Critic Loss: 3.6990132331848145\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.8050926327705383\n",
      "Critic Loss: 2.637748956680298\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 3.023409843444824\n",
      "Critic Loss: 6.128542423248291\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 2.5148208141326904\n",
      "Critic Loss: 3.524322986602783\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 2.098238229751587\n",
      "Critic Loss: 4.889092445373535\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 2.765920877456665\n",
      "Critic Loss: 3.8633737564086914\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 3.475828170776367\n",
      "Critic Loss: 6.292097568511963\n",
      "\n",
      "New best validation reward reached in update [85/200]\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 2.362462282180786\n",
      "Critic Loss: 6.132113933563232\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 3.7104883193969727\n",
      "Critic Loss: 5.0956807136535645\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 1.8163892030715942\n",
      "Critic Loss: 4.903398513793945\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 1.15185546875\n",
      "Critic Loss: 3.4161930084228516\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 4.173764228820801\n",
      "Critic Loss: 5.902841567993164\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.7785236239433289\n",
      "Critic Loss: 3.369373321533203\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 1.2810431718826294\n",
      "Critic Loss: 2.7933897972106934\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.46370217204093933\n",
      "Critic Loss: 3.321085214614868\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.9624941945075989\n",
      "Critic Loss: 3.989964485168457\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.28062763810157776\n",
      "Critic Loss: 3.17612361907959\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 3.250713348388672\n",
      "Critic Loss: 6.611889362335205\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 3.962409734725952\n",
      "Critic Loss: 6.903855323791504\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 3.105468273162842\n",
      "Critic Loss: 3.455718994140625\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 1.2603129148483276\n",
      "Critic Loss: 3.916177749633789\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 2.0966880321502686\n",
      "Critic Loss: 3.5373141765594482\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 6.5853962898254395\n",
      "Critic Loss: 5.247307777404785\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 1.00956392288208\n",
      "Critic Loss: 4.280447959899902\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 2.8800973892211914\n",
      "Critic Loss: 3.304941177368164\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.7612441778182983\n",
      "Critic Loss: 4.083388328552246\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 3.4364864826202393\n",
      "Critic Loss: 4.408701419830322\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 2.8265178203582764\n",
      "Critic Loss: 4.722621440887451\n",
      "\n",
      "New best validation reward reached in update [106/200]\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 1.9580366611480713\n",
      "Critic Loss: 3.5689258575439453\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 4.463479995727539\n",
      "Critic Loss: 5.544869899749756\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.607897162437439\n",
      "Critic Loss: 3.938690662384033\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -1.060027837753296\n",
      "Critic Loss: 3.0347023010253906\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 1.8210089206695557\n",
      "Critic Loss: 2.7896125316619873\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 1.7772561311721802\n",
      "Critic Loss: 2.8268606662750244\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 1.2790313959121704\n",
      "Critic Loss: 2.975348472595215\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 1.6434977054595947\n",
      "Critic Loss: 3.178973913192749\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 4.541839599609375\n",
      "Critic Loss: 7.354466915130615\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 2.550773859024048\n",
      "Critic Loss: 3.952319383621216\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 2.9270503520965576\n",
      "Critic Loss: 5.892894268035889\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 1.6271064281463623\n",
      "Critic Loss: 3.5101239681243896\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 2.7197799682617188\n",
      "Critic Loss: 6.339881896972656\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 2.1094470024108887\n",
      "Critic Loss: 4.189517498016357\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 1.4582712650299072\n",
      "Critic Loss: 4.312864780426025\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 4.686952590942383\n",
      "Critic Loss: 6.970176696777344\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.9183810949325562\n",
      "Critic Loss: 2.702143907546997\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 2.5301284790039062\n",
      "Critic Loss: 3.1367008686065674\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 3.64052152633667\n",
      "Critic Loss: 6.278011322021484\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2056d61373554a38a1348603372f8bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>69.16666</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>83.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>3.61424</td></tr><tr><td>Loss/Critic_loss</td><td>6.27801</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.10262</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0</td></tr><tr><td>Loss/Policy_loss</td><td>3.63003</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>3.64052</td></tr><tr><td>Metric/Explained_variance</td><td>0.25548</td></tr><tr><td>Reward/Mean_train_reward</td><td>-36.81183</td></tr><tr><td>Reward/Mean_val_reward</td><td>-24.442</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-28.33029</td></tr><tr><td>global_step</td><td>125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-sweep-24</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/s3hecz7k' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/s3hecz7k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_163337-s3hecz7k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mvk8r5w8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0020952538744408483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00026850623748804345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.018740638770199724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9664345870680864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.939769615978174e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.962177113467285e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_164157-mvk8r5w8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/mvk8r5w8' target=\"_blank\">cosmic-sweep-25</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/mvk8r5w8' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/mvk8r5w8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.0020952538744408483, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00026850623748804345, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018740638770199724, 'epochs': 10, 'exponential_factor': 0.9664345870680864, 'gamma': 0.95, 'hidden_sizes': [250, 350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 1.939769615978174e-06, 'l2_factor': 4.962177113467285e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0020952538744408483, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00026850623748804345, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018740638770199724, 'epochs': 10, 'exponential_factor': 0.9664345870680864, 'gamma': 0.95, 'l1_factor': 1.939769615978174e-06, 'l2_factor': 4.962177113467285e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0020952538744408483, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00026850623748804345, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018740638770199724, 'epochs': 10, 'exponential_factor': 0.9664345870680864, 'gamma': 0.95, 'l1_factor': 1.939769615978174e-06, 'l2_factor': 4.962177113467285e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0020952538744408483, 'critic_lr': 0.00026850623748804345, 'decay_method': 'exponential', 'exponential_factor': 0.9664345870680864, 'value_loss_factor': 1, 'entropy': 0.018740638770199724, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.939769615978174e-06, 'l2_factor': 4.962177113467285e-05, 'T': 768, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [250, 350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.06288754940032959\n",
      "Critic Loss: 33.48910140991211\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.04525499790906906\n",
      "Critic Loss: 18.295827865600586\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.06326426565647125\n",
      "Critic Loss: 13.470117568969727\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.027511492371559143\n",
      "Critic Loss: 13.530780792236328\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.055257853120565414\n",
      "Critic Loss: 13.443169593811035\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.0138358473777771\n",
      "Critic Loss: 13.72395133972168\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.014903321862220764\n",
      "Critic Loss: 9.492653846740723\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.013468142598867416\n",
      "Critic Loss: 7.864986419677734\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.0019061639904975891\n",
      "Critic Loss: 7.910904884338379\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.01000426709651947\n",
      "Critic Loss: 7.407382488250732\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.06239640712738037\n",
      "Critic Loss: 8.996273040771484\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.04855647683143616\n",
      "Critic Loss: 5.06344747543335\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.024216409772634506\n",
      "Critic Loss: 7.097613334655762\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.006944883614778519\n",
      "Critic Loss: 5.91050386428833\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.04484989121556282\n",
      "Critic Loss: 6.591263294219971\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.03286533057689667\n",
      "Critic Loss: 5.5133562088012695\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.01347670704126358\n",
      "Critic Loss: 5.9505815505981445\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.0399899035692215\n",
      "Critic Loss: 3.752500057220459\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.019791461527347565\n",
      "Critic Loss: 6.738954067230225\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.0355922132730484\n",
      "Critic Loss: 7.085318565368652\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.028159914538264275\n",
      "Critic Loss: 5.562022686004639\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.004608394578099251\n",
      "Critic Loss: 4.5198869705200195\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.029348555952310562\n",
      "Critic Loss: 2.409532308578491\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.02332570031285286\n",
      "Critic Loss: 4.342055320739746\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.004298094660043716\n",
      "Critic Loss: 4.068413257598877\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.008114099502563477\n",
      "Critic Loss: 2.5641942024230957\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.013330793008208275\n",
      "Critic Loss: 2.0773396492004395\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.016850806772708893\n",
      "Critic Loss: 4.515069007873535\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.024847041815519333\n",
      "Critic Loss: 1.6985304355621338\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.014359846711158752\n",
      "Critic Loss: 4.883334159851074\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.00881119817495346\n",
      "Critic Loss: 3.123789072036743\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.011321866884827614\n",
      "Critic Loss: 3.394458055496216\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.002859698608517647\n",
      "Critic Loss: 7.729403018951416\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.036512259393930435\n",
      "Critic Loss: 5.161393165588379\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.0020900126546621323\n",
      "Critic Loss: 4.873047828674316\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.01674458384513855\n",
      "Critic Loss: 9.277670860290527\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.03252711147069931\n",
      "Critic Loss: 4.403565883636475\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.0009153466671705246\n",
      "Critic Loss: 5.675729751586914\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.027234774082899094\n",
      "Critic Loss: 4.853420257568359\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.0020373668521642685\n",
      "Critic Loss: 5.6934380531311035\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.023022176697850227\n",
      "Critic Loss: 4.712834358215332\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.005599416792392731\n",
      "Critic Loss: 6.084803581237793\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.02259678766131401\n",
      "Critic Loss: 2.071033239364624\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.005507826805114746\n",
      "Critic Loss: 1.5232130289077759\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.007318899035453796\n",
      "Critic Loss: 3.4386091232299805\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.006538968533277512\n",
      "Critic Loss: 2.5681376457214355\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.016154777258634567\n",
      "Critic Loss: 1.6163750886917114\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.005915381014347076\n",
      "Critic Loss: 2.0976810455322266\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.00832335650920868\n",
      "Critic Loss: 1.915953278541565\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.02642986923456192\n",
      "Critic Loss: 2.990532159805298\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.024983486160635948\n",
      "Critic Loss: 2.9219088554382324\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.0239842738956213\n",
      "Critic Loss: 3.9449048042297363\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.07031937688589096\n",
      "Critic Loss: 6.617945194244385\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.023007534444332123\n",
      "Critic Loss: 5.197500705718994\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.03195459395647049\n",
      "Critic Loss: 5.0174479484558105\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.03746259957551956\n",
      "Critic Loss: 7.069310188293457\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.012985480949282646\n",
      "Critic Loss: 3.8330912590026855\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.012787972576916218\n",
      "Critic Loss: 6.401859760284424\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.01931995153427124\n",
      "Critic Loss: 5.6466240882873535\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.004303313791751862\n",
      "Critic Loss: 6.54049015045166\n",
      "\n",
      "New best validation reward reached in update [60/200]\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.028755486011505127\n",
      "Critic Loss: 3.834477186203003\n",
      "\n",
      "New best validation reward reached in update [61/200]\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.010031405836343765\n",
      "Critic Loss: 2.114522695541382\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.003154497593641281\n",
      "Critic Loss: 1.7608709335327148\n",
      "\n",
      "New best validation reward reached in update [63/200]\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.014508900232613087\n",
      "Critic Loss: 2.101224422454834\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.005524549633264542\n",
      "Critic Loss: 4.507368564605713\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.02050972171127796\n",
      "Critic Loss: 1.4562125205993652\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.015290532261133194\n",
      "Critic Loss: 3.1600606441497803\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.0334683433175087\n",
      "Critic Loss: 1.9403592348098755\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.030561503022909164\n",
      "Critic Loss: 2.645456075668335\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.00884800124913454\n",
      "Critic Loss: 3.626715898513794\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.014758739620447159\n",
      "Critic Loss: 3.336371421813965\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.01986880972981453\n",
      "Critic Loss: 1.5804699659347534\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.08935090154409409\n",
      "Critic Loss: 3.328075408935547\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.028590699657797813\n",
      "Critic Loss: 1.2509708404541016\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.03919433057308197\n",
      "Critic Loss: 1.2713158130645752\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.033049020916223526\n",
      "Critic Loss: 2.5717358589172363\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.01893257349729538\n",
      "Critic Loss: 2.9968581199645996\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.014372923411428928\n",
      "Critic Loss: 1.6052056550979614\n",
      "\n",
      "New best validation reward reached in update [78/200]\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.024078913033008575\n",
      "Critic Loss: 2.938851833343506\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.027310892939567566\n",
      "Critic Loss: 1.1623120307922363\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.015271490439772606\n",
      "Critic Loss: 2.692866325378418\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.07473911345005035\n",
      "Critic Loss: 1.6010174751281738\n",
      "\n",
      "New best validation reward reached in update [82/200]\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.003305116668343544\n",
      "Critic Loss: 2.3299598693847656\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.016324851661920547\n",
      "Critic Loss: 1.837430477142334\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.01677606999874115\n",
      "Critic Loss: 1.821761131286621\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.0222851000726223\n",
      "Critic Loss: 1.5640143156051636\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.015550019219517708\n",
      "Critic Loss: 2.868513584136963\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -0.015451602637767792\n",
      "Critic Loss: 2.9325954914093018\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.013597745448350906\n",
      "Critic Loss: 1.2198257446289062\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.025290418416261673\n",
      "Critic Loss: 3.478689193725586\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.00688360258936882\n",
      "Critic Loss: 1.202095627784729\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.034879349172115326\n",
      "Critic Loss: 2.185863733291626\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.01784106343984604\n",
      "Critic Loss: 2.578382730484009\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.0042291004210710526\n",
      "Critic Loss: 4.29629373550415\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.00955219380557537\n",
      "Critic Loss: 2.7720203399658203\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.03891850635409355\n",
      "Critic Loss: 2.111818552017212\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.0025733299553394318\n",
      "Critic Loss: 2.9197068214416504\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.00946574006229639\n",
      "Critic Loss: 2.0828771591186523\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.024913780391216278\n",
      "Critic Loss: 2.3527252674102783\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.008675618097186089\n",
      "Critic Loss: 1.8837825059890747\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.012780296616256237\n",
      "Critic Loss: 1.939597249031067\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.024997971951961517\n",
      "Critic Loss: 2.3162035942077637\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.008305734023451805\n",
      "Critic Loss: 1.1604857444763184\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.010422059334814548\n",
      "Critic Loss: 1.5937873125076294\n",
      "\n",
      "New best validation reward reached in update [104/200]\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.010845900513231754\n",
      "Critic Loss: 4.607719421386719\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.02804022654891014\n",
      "Critic Loss: 3.2960190773010254\n",
      "\n",
      "New best validation reward reached in update [106/200]\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.04743928834795952\n",
      "Critic Loss: 1.5698091983795166\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.017533723264932632\n",
      "Critic Loss: 1.7511098384857178\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.03062782622873783\n",
      "Critic Loss: 1.9082289934158325\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -0.014195030555129051\n",
      "Critic Loss: 2.1812174320220947\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.005872899666428566\n",
      "Critic Loss: 2.5596964359283447\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.037670765072107315\n",
      "Critic Loss: 1.770125150680542\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.013548167422413826\n",
      "Critic Loss: 2.0976929664611816\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.01726064644753933\n",
      "Critic Loss: 1.7125526666641235\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.033353179693222046\n",
      "Critic Loss: 1.5888116359710693\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.05148518085479736\n",
      "Critic Loss: 3.749361991882324\n",
      "\n",
      "New best validation reward reached in update [116/200]\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.002760753035545349\n",
      "Critic Loss: 4.092390060424805\n",
      "\n",
      "New best validation reward reached in update [117/200]\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.02800847217440605\n",
      "Critic Loss: 4.932031631469727\n",
      "\n",
      "New best validation reward reached in update [118/200]\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.0072628166526556015\n",
      "Critic Loss: 1.375671625137329\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.05301080644130707\n",
      "Critic Loss: 1.4594467878341675\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.046675339341163635\n",
      "Critic Loss: 2.258359909057617\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.05101170390844345\n",
      "Critic Loss: 3.9445486068725586\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.0055575864389538765\n",
      "Critic Loss: 2.252129554748535\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -0.003000415861606598\n",
      "Critic Loss: 1.66373610496521\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.0205316711217165\n",
      "Critic Loss: 1.982305884361267\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.006999543868005276\n",
      "Critic Loss: 9.125877380371094\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.0005279108881950378\n",
      "Critic Loss: 2.041071653366089\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.016701053828001022\n",
      "Critic Loss: 1.1511479616165161\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.010061386972665787\n",
      "Critic Loss: 1.7530136108398438\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.025360673666000366\n",
      "Critic Loss: 2.943725824356079\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.01854560896754265\n",
      "Critic Loss: 2.753274917602539\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.01787836104631424\n",
      "Critic Loss: 1.9765704870224\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.0366971530020237\n",
      "Critic Loss: 4.0122199058532715\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.02144596353173256\n",
      "Critic Loss: 1.9378148317337036\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.028102558106184006\n",
      "Critic Loss: 2.4408388137817383\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.010236063972115517\n",
      "Critic Loss: 3.1462512016296387\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.023287788033485413\n",
      "Critic Loss: 1.3551805019378662\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.008392971940338612\n",
      "Critic Loss: 1.7098844051361084\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.008904332295060158\n",
      "Critic Loss: 2.8100273609161377\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.02252884954214096\n",
      "Critic Loss: 1.7787446975708008\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.021278666332364082\n",
      "Critic Loss: 2.2552740573883057\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.007145269773900509\n",
      "Critic Loss: 1.6024128198623657\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 0.01741238497197628\n",
      "Critic Loss: 2.9857876300811768\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.035227712243795395\n",
      "Critic Loss: 6.3780927658081055\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -0.004182688891887665\n",
      "Critic Loss: 1.339126706123352\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 0.025795573368668556\n",
      "Critic Loss: 1.3518550395965576\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.03100442700088024\n",
      "Critic Loss: 3.056459426879883\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.03728964552283287\n",
      "Critic Loss: 2.421287775039673\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.031095581129193306\n",
      "Critic Loss: 5.758667945861816\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.02897496335208416\n",
      "Critic Loss: 2.831819534301758\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfb9f3881474f868f8793552f6ce5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>109.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>106.9</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.00259</td></tr><tr><td>Loss/Critic_loss</td><td>2.83182</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.65084</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00489</td></tr><tr><td>Loss/Policy_loss</td><td>0.01479</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.02897</td></tr><tr><td>Metric/Explained_variance</td><td>0.64309</td></tr><tr><td>Reward/Mean_train_reward</td><td>5.648</td></tr><tr><td>Reward/Mean_val_reward</td><td>2.7899</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.76891</td></tr><tr><td>global_step</td><td>150</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-25</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/mvk8r5w8' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/mvk8r5w8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_164157-mvk8r5w8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q1x3t79p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0007536588516135134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00011416866183023788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0023705323273667737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9481002044596172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0002908570561182219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.821425929056515e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_170353-q1x3t79p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/q1x3t79p' target=\"_blank\">graceful-sweep-26</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/q1x3t79p' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/q1x3t79p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0007536588516135134, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00011416866183023788, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0023705323273667737, 'epochs': 10, 'exponential_factor': 0.9481002044596172, 'gamma': 0.95, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0002908570561182219, 'l2_factor': 2.821425929056515e-05, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0007536588516135134, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00011416866183023788, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0023705323273667737, 'epochs': 10, 'exponential_factor': 0.9481002044596172, 'gamma': 0.95, 'l1_factor': 0.0002908570561182219, 'l2_factor': 2.821425929056515e-05, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0007536588516135134, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00011416866183023788, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0023705323273667737, 'epochs': 10, 'exponential_factor': 0.9481002044596172, 'gamma': 0.95, 'l1_factor': 0.0002908570561182219, 'l2_factor': 2.821425929056515e-05, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0007536588516135134, 'critic_lr': 0.00011416866183023788, 'decay_method': 'exponential', 'exponential_factor': 0.9481002044596172, 'value_loss_factor': 1, 'entropy': 0.0023705323273667737, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0002908570561182219, 'l2_factor': 2.821425929056515e-05, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 27.16650390625\n",
      "Critic Loss: 27.58231544494629\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 17.67449378967285\n",
      "Critic Loss: 10.670726776123047\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 8.761909484863281\n",
      "Critic Loss: 10.258060455322266\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 14.103462219238281\n",
      "Critic Loss: 9.985956192016602\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 10.504281997680664\n",
      "Critic Loss: 5.795576572418213\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 14.25091552734375\n",
      "Critic Loss: 8.92451286315918\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 8.560759544372559\n",
      "Critic Loss: 5.569655895233154\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 8.951844215393066\n",
      "Critic Loss: 5.660369873046875\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 8.628296852111816\n",
      "Critic Loss: 5.89036750793457\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 8.14286994934082\n",
      "Critic Loss: 7.266417026519775\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 12.721822738647461\n",
      "Critic Loss: 7.047233581542969\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 10.57931137084961\n",
      "Critic Loss: 7.212654113769531\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 10.649471282958984\n",
      "Critic Loss: 5.046930313110352\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 12.63398551940918\n",
      "Critic Loss: 6.326735973358154\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 6.5786943435668945\n",
      "Critic Loss: 5.140018939971924\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 14.545860290527344\n",
      "Critic Loss: 10.215373992919922\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 8.716165542602539\n",
      "Critic Loss: 6.229311466217041\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 10.50335693359375\n",
      "Critic Loss: 8.762947082519531\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 7.384096145629883\n",
      "Critic Loss: 5.178854465484619\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 7.907171726226807\n",
      "Critic Loss: 5.711167335510254\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 7.136247158050537\n",
      "Critic Loss: 6.6966447830200195\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 3.65114426612854\n",
      "Critic Loss: 4.918025493621826\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -1.2861889600753784\n",
      "Critic Loss: 4.477592468261719\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 6.205748081207275\n",
      "Critic Loss: 5.299273490905762\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 8.440862655639648\n",
      "Critic Loss: 5.747016906738281\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 3.235795736312866\n",
      "Critic Loss: 4.438470363616943\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.5049448013305664\n",
      "Critic Loss: 6.0579023361206055\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 4.364498615264893\n",
      "Critic Loss: 4.77021598815918\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 2.309715509414673\n",
      "Critic Loss: 3.085847854614258\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.4388092756271362\n",
      "Critic Loss: 3.889970302581787\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 2.94559383392334\n",
      "Critic Loss: 4.210944175720215\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 3.4637417793273926\n",
      "Critic Loss: 3.3705813884735107\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 1.0360993146896362\n",
      "Critic Loss: 2.151120185852051\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 3.3358042240142822\n",
      "Critic Loss: 3.1398332118988037\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.2962981164455414\n",
      "Critic Loss: 3.451827049255371\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.5829262137413025\n",
      "Critic Loss: 1.6290282011032104\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 1.7393337488174438\n",
      "Critic Loss: 4.396851539611816\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 3.8122572898864746\n",
      "Critic Loss: 3.3683371543884277\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 7.931640148162842\n",
      "Critic Loss: 4.530127048492432\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 3.637547492980957\n",
      "Critic Loss: 3.3785932064056396\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 2.9750802516937256\n",
      "Critic Loss: 2.641242027282715\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 2.411940813064575\n",
      "Critic Loss: 4.452551364898682\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.6511123776435852\n",
      "Critic Loss: 2.0804903507232666\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 2.2134997844696045\n",
      "Critic Loss: 1.752910852432251\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 3.3243861198425293\n",
      "Critic Loss: 2.2517690658569336\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 2.9966869354248047\n",
      "Critic Loss: 2.7321181297302246\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 5.237026214599609\n",
      "Critic Loss: 3.1205196380615234\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 1.2347286939620972\n",
      "Critic Loss: 1.706588864326477\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.3644284009933472\n",
      "Critic Loss: 2.0098562240600586\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 3.2639524936676025\n",
      "Critic Loss: 1.8218761682510376\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 3.730196237564087\n",
      "Critic Loss: 2.155155897140503\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.05970313027501106\n",
      "Critic Loss: 1.3374546766281128\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 1.6332521438598633\n",
      "Critic Loss: 2.335993766784668\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 1.673749327659607\n",
      "Critic Loss: 1.828373908996582\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.634694516658783\n",
      "Critic Loss: 2.0719313621520996\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 3.0238754749298096\n",
      "Critic Loss: 2.8969225883483887\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 3.6132612228393555\n",
      "Critic Loss: 2.262389898300171\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.6778804659843445\n",
      "Critic Loss: 1.2067521810531616\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 3.3133373260498047\n",
      "Critic Loss: 3.952913284301758\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.5355073809623718\n",
      "Critic Loss: 1.0846258401870728\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 4.404315948486328\n",
      "Critic Loss: 4.177549839019775\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 3.2505240440368652\n",
      "Critic Loss: 2.4884023666381836\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 2.0199930667877197\n",
      "Critic Loss: 4.220350742340088\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 5.6764349937438965\n",
      "Critic Loss: 4.891983509063721\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 2.141166925430298\n",
      "Critic Loss: 2.34197735786438\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 4.4616522789001465\n",
      "Critic Loss: 3.6261749267578125\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 3.463484764099121\n",
      "Critic Loss: 1.6756503582000732\n",
      "\n",
      "New best validation reward reached in update [67/200]\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 3.0993709564208984\n",
      "Critic Loss: 4.349306106567383\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 4.758397102355957\n",
      "Critic Loss: 2.5895609855651855\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 3.7516419887542725\n",
      "Critic Loss: 3.645426034927368\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 4.395627975463867\n",
      "Critic Loss: 2.636923313140869\n",
      "\n",
      "New best validation reward reached in update [71/200]\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 2.5743026733398438\n",
      "Critic Loss: 3.585805654525757\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 1.6573724746704102\n",
      "Critic Loss: 2.9079596996307373\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 3.9715864658355713\n",
      "Critic Loss: 2.7777647972106934\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 3.2384181022644043\n",
      "Critic Loss: 3.1438701152801514\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 2.9718985557556152\n",
      "Critic Loss: 2.7147748470306396\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.338512122631073\n",
      "Critic Loss: 0.7713068723678589\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.575410008430481\n",
      "Critic Loss: 1.5223766565322876\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.5859570503234863\n",
      "Critic Loss: 1.899627923965454\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 3.646648645401001\n",
      "Critic Loss: 2.525503158569336\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 3.588775396347046\n",
      "Critic Loss: 3.3433282375335693\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 1.2570606470108032\n",
      "Critic Loss: 2.5945091247558594\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 7.937767505645752\n",
      "Critic Loss: 3.443484306335449\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.0049477629363536835\n",
      "Critic Loss: 1.1917014122009277\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 3.0909628868103027\n",
      "Critic Loss: 2.5340535640716553\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.10251100361347198\n",
      "Critic Loss: 1.2079499959945679\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 1.0087436437606812\n",
      "Critic Loss: 1.6070888042449951\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 7.182859420776367\n",
      "Critic Loss: 2.524332046508789\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 1.0732526779174805\n",
      "Critic Loss: 1.565793514251709\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 1.6128596067428589\n",
      "Critic Loss: 2.2694976329803467\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.1035095751285553\n",
      "Critic Loss: 1.1660430431365967\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 2.0747745037078857\n",
      "Critic Loss: 2.1437339782714844\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.1251443326473236\n",
      "Critic Loss: 1.4944716691970825\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 2.7263667583465576\n",
      "Critic Loss: 2.0651564598083496\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 3.850895404815674\n",
      "Critic Loss: 3.041837453842163\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 3.3031444549560547\n",
      "Critic Loss: 1.9104368686676025\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 2.692068099975586\n",
      "Critic Loss: 2.1334402561187744\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 2.317908525466919\n",
      "Critic Loss: 1.7317184209823608\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 2.8804216384887695\n",
      "Critic Loss: 3.4957516193389893\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 4.144057273864746\n",
      "Critic Loss: 2.0530812740325928\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 1.1985149383544922\n",
      "Critic Loss: 1.6832973957061768\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 4.363729476928711\n",
      "Critic Loss: 2.109522819519043\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34883bac8fa46f295dcfe8d5550d96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>97.33334</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>89.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>1.67226</td></tr><tr><td>Loss/Critic_loss</td><td>2.10952</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.37453</td></tr><tr><td>Loss/KL_divergence</td><td>0.00095</td></tr><tr><td>Loss/Policy_loss</td><td>1.67315</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>4.36373</td></tr><tr><td>Metric/Explained_variance</td><td>0.8536</td></tr><tr><td>Reward/Mean_train_reward</td><td>-1.37033</td></tr><tr><td>Reward/Mean_val_reward</td><td>-11.048</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-7.94879</td></tr><tr><td>global_step</td><td>102</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-sweep-26</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/q1x3t79p' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/q1x3t79p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_170353-q1x3t79p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s088ykix with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0002342203571672758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0007911408378897133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0038653135491394943\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8541893023523218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00020194282927196984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00013826434174276167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_171450-s088ykix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/s088ykix' target=\"_blank\">faithful-sweep-27</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/s088ykix' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/s088ykix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.0002342203571672758, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007911408378897133, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0038653135491394943, 'epochs': 10, 'exponential_factor': 0.8541893023523218, 'gamma': 0.95, 'hidden_sizes': [250, 150, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.00020194282927196984, 'l2_factor': 0.00013826434174276167, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0002342203571672758, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007911408378897133, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0038653135491394943, 'epochs': 10, 'exponential_factor': 0.8541893023523218, 'gamma': 0.95, 'l1_factor': 0.00020194282927196984, 'l2_factor': 0.00013826434174276167, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0002342203571672758, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007911408378897133, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0038653135491394943, 'epochs': 10, 'exponential_factor': 0.8541893023523218, 'gamma': 0.95, 'l1_factor': 0.00020194282927196984, 'l2_factor': 0.00013826434174276167, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0002342203571672758, 'critic_lr': 0.0007911408378897133, 'decay_method': 'exponential', 'exponential_factor': 0.8541893023523218, 'value_loss_factor': 1, 'entropy': 0.0038653135491394943, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00020194282927196984, 'l2_factor': 0.00013826434174276167, 'T': 768, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [250, 150, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 33.26591110229492\n",
      "Critic Loss: 28.131410598754883\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 32.921817779541016\n",
      "Critic Loss: 16.030712127685547\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 27.83853530883789\n",
      "Critic Loss: 16.931821823120117\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 17.983749389648438\n",
      "Critic Loss: 9.383195877075195\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 20.46047019958496\n",
      "Critic Loss: 11.322553634643555\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 18.909332275390625\n",
      "Critic Loss: 16.233102798461914\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 8.731208801269531\n",
      "Critic Loss: 7.012673377990723\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 18.58173942565918\n",
      "Critic Loss: 13.112039566040039\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 15.063824653625488\n",
      "Critic Loss: 6.672536849975586\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 10.085201263427734\n",
      "Critic Loss: 5.586056232452393\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 12.098461151123047\n",
      "Critic Loss: 7.7419328689575195\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 15.270818710327148\n",
      "Critic Loss: 8.436324119567871\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 7.99293327331543\n",
      "Critic Loss: 8.045475006103516\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 9.864721298217773\n",
      "Critic Loss: 9.895073890686035\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 11.256952285766602\n",
      "Critic Loss: 12.403247833251953\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 10.106925010681152\n",
      "Critic Loss: 6.930130958557129\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 12.367866516113281\n",
      "Critic Loss: 12.800090789794922\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 5.98906946182251\n",
      "Critic Loss: 8.028108596801758\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 6.99515438079834\n",
      "Critic Loss: 6.44309139251709\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 4.8089470863342285\n",
      "Critic Loss: 6.569075584411621\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 2.567329168319702\n",
      "Critic Loss: 7.422455787658691\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 8.480466842651367\n",
      "Critic Loss: 7.348013401031494\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 9.760710716247559\n",
      "Critic Loss: 11.830306053161621\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 3.6043038368225098\n",
      "Critic Loss: 8.07539176940918\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 6.508552551269531\n",
      "Critic Loss: 7.992464065551758\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 4.223927974700928\n",
      "Critic Loss: 6.486294746398926\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 5.097240924835205\n",
      "Critic Loss: 5.523397922515869\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 4.266211032867432\n",
      "Critic Loss: 6.063368320465088\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 6.916999816894531\n",
      "Critic Loss: 7.425152778625488\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 3.423704147338867\n",
      "Critic Loss: 7.173396587371826\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 7.0747456550598145\n",
      "Critic Loss: 6.412873268127441\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 6.927917957305908\n",
      "Critic Loss: 9.226251602172852\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 14.010223388671875\n",
      "Critic Loss: 7.4084062576293945\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.40237417817115784\n",
      "Critic Loss: 5.115977764129639\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 4.6860575675964355\n",
      "Critic Loss: 6.388200759887695\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 6.0553669929504395\n",
      "Critic Loss: 6.749388217926025\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.42285048961639404\n",
      "Critic Loss: 3.0325911045074463\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 7.336654186248779\n",
      "Critic Loss: 5.188730239868164\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 2.800980567932129\n",
      "Critic Loss: 4.022845268249512\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 1.2005528211593628\n",
      "Critic Loss: 4.449265956878662\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 7.309298038482666\n",
      "Critic Loss: 6.947977066040039\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 1.3628684282302856\n",
      "Critic Loss: 3.803633689880371\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 3.5257084369659424\n",
      "Critic Loss: 4.935725688934326\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 8.324931144714355\n",
      "Critic Loss: 9.558576583862305\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 8.704276084899902\n",
      "Critic Loss: 4.914816856384277\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 9.122577667236328\n",
      "Critic Loss: 7.537849426269531\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 13.868593215942383\n",
      "Critic Loss: 8.528793334960938\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 1.5020514726638794\n",
      "Critic Loss: 4.439436912536621\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 5.56635856628418\n",
      "Critic Loss: 5.3554182052612305\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 7.6517415046691895\n",
      "Critic Loss: 10.699319839477539\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 6.45451545715332\n",
      "Critic Loss: 4.94310998916626\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 8.507579803466797\n",
      "Critic Loss: 9.996137619018555\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 3.473060369491577\n",
      "Critic Loss: 4.581132888793945\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 1.3437294960021973\n",
      "Critic Loss: 4.24365758895874\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 6.0157575607299805\n",
      "Critic Loss: 8.588780403137207\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 6.331418991088867\n",
      "Critic Loss: 4.798924922943115\n",
      "\n",
      "New best validation reward reached in update [56/200]\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 8.547637939453125\n",
      "Critic Loss: 4.771312713623047\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 8.40121841430664\n",
      "Critic Loss: 9.415103912353516\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 3.474562168121338\n",
      "Critic Loss: 8.039743423461914\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 3.891136646270752\n",
      "Critic Loss: 6.4871039390563965\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 5.245005130767822\n",
      "Critic Loss: 8.952227592468262\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 5.073246479034424\n",
      "Critic Loss: 7.270220756530762\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 4.694398403167725\n",
      "Critic Loss: 7.762268543243408\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 6.983320713043213\n",
      "Critic Loss: 6.533989429473877\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 6.315826416015625\n",
      "Critic Loss: 8.327275276184082\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 7.035029888153076\n",
      "Critic Loss: 4.679299831390381\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 6.270079612731934\n",
      "Critic Loss: 7.26798152923584\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 1.071467399597168\n",
      "Critic Loss: 5.184868335723877\n",
      "\n",
      "New best validation reward reached in update [68/200]\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 3.6577377319335938\n",
      "Critic Loss: 5.796432971954346\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 7.343351364135742\n",
      "Critic Loss: 9.860859870910645\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 4.868470191955566\n",
      "Critic Loss: 6.877057075500488\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 3.9285101890563965\n",
      "Critic Loss: 4.167029857635498\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 4.41736364364624\n",
      "Critic Loss: 4.792850971221924\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 9.140883445739746\n",
      "Critic Loss: 10.084769248962402\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 12.187456130981445\n",
      "Critic Loss: 7.451719284057617\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.497964471578598\n",
      "Critic Loss: 3.86798357963562\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 9.862466812133789\n",
      "Critic Loss: 7.955314636230469\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 6.15014123916626\n",
      "Critic Loss: 3.922243595123291\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.2523195445537567\n",
      "Critic Loss: 3.420193910598755\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 5.202459335327148\n",
      "Critic Loss: 8.972475051879883\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 2.675020694732666\n",
      "Critic Loss: 5.952486515045166\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 6.948451995849609\n",
      "Critic Loss: 9.613409042358398\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 12.326169967651367\n",
      "Critic Loss: 13.650422096252441\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 2.8360342979431152\n",
      "Critic Loss: 6.357598304748535\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 4.616815567016602\n",
      "Critic Loss: 5.964824199676514\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.5098800659179688\n",
      "Critic Loss: 2.461635112762451\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 4.7098188400268555\n",
      "Critic Loss: 10.179096221923828\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 6.6234354972839355\n",
      "Critic Loss: 6.2101569175720215\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 2.6589856147766113\n",
      "Critic Loss: 7.440500259399414\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.18535390496253967\n",
      "Critic Loss: 3.325438976287842\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 9.32771110534668\n",
      "Critic Loss: 7.750929832458496\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 6.65105676651001\n",
      "Critic Loss: 8.04920482635498\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 4.735090255737305\n",
      "Critic Loss: 4.769656181335449\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 7.382328510284424\n",
      "Critic Loss: 9.639739036560059\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 5.5180864334106445\n",
      "Critic Loss: 4.6336493492126465\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 5.5505290031433105\n",
      "Critic Loss: 6.267507076263428\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 2.4520647525787354\n",
      "Critic Loss: 7.1973700523376465\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 6.209936618804932\n",
      "Critic Loss: 6.135593891143799\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 4.81812858581543\n",
      "Critic Loss: 7.339650630950928\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 7.254644393920898\n",
      "Critic Loss: 6.9633355140686035\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6457d976a76b43678d5dc1d42fbd5d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>101.33334</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>141.60001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>5.67672</td></tr><tr><td>Loss/Critic_loss</td><td>6.96334</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.54523</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01396</td></tr><tr><td>Loss/Policy_loss</td><td>5.68269</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>7.25464</td></tr><tr><td>Metric/Explained_variance</td><td>0.4799</td></tr><tr><td>Reward/Mean_train_reward</td><td>-43.61301</td></tr><tr><td>Reward/Mean_val_reward</td><td>-23.7394</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-38.21948</td></tr><tr><td>global_step</td><td>100</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-27</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/s088ykix' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/s088ykix</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_171450-s088ykix\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lz3ykfiw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.007558301798269005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00011720762159629845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0474153757740874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9531290576125508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.6811209941228222e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.444968840334554e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_172757-lz3ykfiw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/lz3ykfiw' target=\"_blank\">drawn-sweep-28</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/lz3ykfiw' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/lz3ykfiw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.007558301798269005, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00011720762159629845, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0474153757740874, 'epochs': 10, 'exponential_factor': 0.9531290576125508, 'gamma': 0.99, 'hidden_sizes': [350, 150, 350, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 1.6811209941228222e-05, 'l2_factor': 3.444968840334554e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.007558301798269005, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00011720762159629845, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0474153757740874, 'epochs': 10, 'exponential_factor': 0.9531290576125508, 'gamma': 0.99, 'l1_factor': 1.6811209941228222e-05, 'l2_factor': 3.444968840334554e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.007558301798269005, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00011720762159629845, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0474153757740874, 'epochs': 10, 'exponential_factor': 0.9531290576125508, 'gamma': 0.99, 'l1_factor': 1.6811209941228222e-05, 'l2_factor': 3.444968840334554e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.007558301798269005, 'critic_lr': 0.00011720762159629845, 'decay_method': 'exponential', 'exponential_factor': 0.9531290576125508, 'value_loss_factor': 1, 'entropy': 0.0474153757740874, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.6811209941228222e-05, 'l2_factor': 3.444968840334554e-05, 'T': 768, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [350, 150, 350, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.22603416442871094\n",
      "Critic Loss: 40.021827697753906\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.060661811381578445\n",
      "Critic Loss: 19.700056076049805\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.21920330822467804\n",
      "Critic Loss: 21.531909942626953\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.1805836409330368\n",
      "Critic Loss: 23.1977481842041\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.2941131889820099\n",
      "Critic Loss: 16.02035140991211\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.05130777135491371\n",
      "Critic Loss: 14.608695983886719\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.09671737998723984\n",
      "Critic Loss: 14.591492652893066\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.13717325031757355\n",
      "Critic Loss: 12.068806648254395\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.06200512498617172\n",
      "Critic Loss: 13.545140266418457\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.09233196824789047\n",
      "Critic Loss: 12.6699857711792\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.2701576352119446\n",
      "Critic Loss: 11.678466796875\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.0559137687087059\n",
      "Critic Loss: 12.8932466506958\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.03314903378486633\n",
      "Critic Loss: 8.86678695678711\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.06872877478599548\n",
      "Critic Loss: 21.25092887878418\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.4024791121482849\n",
      "Critic Loss: 6.713130474090576\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.7690296173095703\n",
      "Critic Loss: 12.210124015808105\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.0957072526216507\n",
      "Critic Loss: 12.835203170776367\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.09879261255264282\n",
      "Critic Loss: 8.215046882629395\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.3803699016571045\n",
      "Critic Loss: 6.341596603393555\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.040998902171850204\n",
      "Critic Loss: 8.043246269226074\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.14696140587329865\n",
      "Critic Loss: 7.499704837799072\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.06689020246267319\n",
      "Critic Loss: 5.6337199211120605\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.021898221224546432\n",
      "Critic Loss: 7.524365425109863\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.07898584008216858\n",
      "Critic Loss: 6.261462688446045\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.06918013095855713\n",
      "Critic Loss: 6.955739498138428\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.049240995198488235\n",
      "Critic Loss: 11.881009101867676\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.09130142629146576\n",
      "Critic Loss: 5.956521987915039\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.1210058331489563\n",
      "Critic Loss: 5.635201930999756\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.06488825380802155\n",
      "Critic Loss: 5.25923490524292\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.077090322971344\n",
      "Critic Loss: 7.9834418296813965\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.08118011057376862\n",
      "Critic Loss: 4.371864318847656\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.052674196660518646\n",
      "Critic Loss: 5.429709434509277\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.03288950026035309\n",
      "Critic Loss: 5.522585868835449\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.0742286965250969\n",
      "Critic Loss: 7.114373207092285\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.05425906181335449\n",
      "Critic Loss: 5.102569580078125\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.07393792271614075\n",
      "Critic Loss: 5.149036407470703\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.0599435530602932\n",
      "Critic Loss: 6.739546775817871\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.09078730642795563\n",
      "Critic Loss: 5.09250020980835\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.07977056503295898\n",
      "Critic Loss: 6.5032854080200195\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.05519106239080429\n",
      "Critic Loss: 4.244537353515625\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.04118308424949646\n",
      "Critic Loss: 4.465511322021484\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.08934634178876877\n",
      "Critic Loss: 5.949181079864502\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.0613081231713295\n",
      "Critic Loss: 4.890369892120361\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.01886420138180256\n",
      "Critic Loss: 4.181999206542969\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.04017791152000427\n",
      "Critic Loss: 4.918738842010498\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.0559968501329422\n",
      "Critic Loss: 5.738317489624023\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.06904642283916473\n",
      "Critic Loss: 4.818052768707275\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.013237090781331062\n",
      "Critic Loss: 4.156547546386719\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.05201143026351929\n",
      "Critic Loss: 6.714066028594971\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.059409067034721375\n",
      "Critic Loss: 10.770073890686035\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.02124428004026413\n",
      "Critic Loss: 6.635763645172119\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.01138606108725071\n",
      "Critic Loss: 9.600774765014648\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.0248806681483984\n",
      "Critic Loss: 4.962608337402344\n",
      "\n",
      "New best validation reward reached in update [53/200]\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.0594063326716423\n",
      "Critic Loss: 5.840571403503418\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.002182425931096077\n",
      "Critic Loss: 4.459655284881592\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.007907502353191376\n",
      "Critic Loss: 6.5952911376953125\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.032807253301143646\n",
      "Critic Loss: 6.222818374633789\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.00407753512263298\n",
      "Critic Loss: 6.230867862701416\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.09851786494255066\n",
      "Critic Loss: 5.66567850112915\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.039230264723300934\n",
      "Critic Loss: 4.223201274871826\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.010488452389836311\n",
      "Critic Loss: 7.770814895629883\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.025320807471871376\n",
      "Critic Loss: 7.567258834838867\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.022634323686361313\n",
      "Critic Loss: 11.725706100463867\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.014715636149048805\n",
      "Critic Loss: 4.616025447845459\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.015265978872776031\n",
      "Critic Loss: 4.87789249420166\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.013999288901686668\n",
      "Critic Loss: 5.798656463623047\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.04165642708539963\n",
      "Critic Loss: 4.744970321655273\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.07439034432172775\n",
      "Critic Loss: 7.978210926055908\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.011486899107694626\n",
      "Critic Loss: 6.215424537658691\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.010794507339596748\n",
      "Critic Loss: 3.229374408721924\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.005659479647874832\n",
      "Critic Loss: 6.311120986938477\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.012371547520160675\n",
      "Critic Loss: 8.489007949829102\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.01622936688363552\n",
      "Critic Loss: 4.164201736450195\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.009474825114011765\n",
      "Critic Loss: 6.9304962158203125\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804f7d859ae24ff49dfb24b5bf62bfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>141.60001</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>136.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.00023</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.0596</td></tr><tr><td>Loss/Critic_loss</td><td>6.9305</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.33119</td></tr><tr><td>Loss/KL_divergence</td><td>0.03692</td></tr><tr><td>Loss/Policy_loss</td><td>0.00352</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.00947</td></tr><tr><td>Metric/Explained_variance</td><td>0.54733</td></tr><tr><td>Reward/Mean_train_reward</td><td>-1.09941</td></tr><tr><td>Reward/Mean_val_reward</td><td>-9.2845</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-0.09938</td></tr><tr><td>global_step</td><td>74</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-28</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/lz3ykfiw' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/lz3ykfiw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_172757-lz3ykfiw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9zbkshi1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0029818242878904564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.001691971447829929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.009824024358290466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.939008268962999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 7.2048078655732085e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.6795609093063923e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_173945-9zbkshi1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/9zbkshi1' target=\"_blank\">glorious-sweep-29</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/9zbkshi1' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/9zbkshi1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.0029818242878904564, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001691971447829929, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009824024358290466, 'epochs': 10, 'exponential_factor': 0.939008268962999, 'gamma': 0.99, 'hidden_sizes': [350, 250, 150, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 7.2048078655732085e-06, 'l2_factor': 1.6795609093063923e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0029818242878904564, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001691971447829929, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009824024358290466, 'epochs': 10, 'exponential_factor': 0.939008268962999, 'gamma': 0.99, 'l1_factor': 7.2048078655732085e-06, 'l2_factor': 1.6795609093063923e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0029818242878904564, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001691971447829929, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009824024358290466, 'epochs': 10, 'exponential_factor': 0.939008268962999, 'gamma': 0.99, 'l1_factor': 7.2048078655732085e-06, 'l2_factor': 1.6795609093063923e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0029818242878904564, 'critic_lr': 0.001691971447829929, 'decay_method': 'exponential', 'exponential_factor': 0.939008268962999, 'value_loss_factor': 1, 'entropy': 0.009824024358290466, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 7.2048078655732085e-06, 'l2_factor': 1.6795609093063923e-06, 'T': 512, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [350, 250, 150, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.026104286313056946\n",
      "Critic Loss: 23.9669132232666\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.03328802064061165\n",
      "Critic Loss: 18.35931396484375\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.06721582263708115\n",
      "Critic Loss: 10.743797302246094\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.02481899969279766\n",
      "Critic Loss: 15.032410621643066\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.06576517969369888\n",
      "Critic Loss: 17.97088623046875\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.17217285931110382\n",
      "Critic Loss: 16.146411895751953\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.02779630944132805\n",
      "Critic Loss: 7.937356472015381\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.02688385359942913\n",
      "Critic Loss: 8.913308143615723\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.022527461871504784\n",
      "Critic Loss: 11.408992767333984\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.019568270072340965\n",
      "Critic Loss: 6.501641273498535\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.017940083518624306\n",
      "Critic Loss: 5.024947166442871\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.02018861286342144\n",
      "Critic Loss: 5.342985153198242\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.001324044307693839\n",
      "Critic Loss: 8.335320472717285\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.014981069602072239\n",
      "Critic Loss: 7.244617462158203\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.002190906787291169\n",
      "Critic Loss: 7.599282264709473\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.020661938935518265\n",
      "Critic Loss: 8.111373901367188\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.018404383212327957\n",
      "Critic Loss: 5.246546745300293\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.008938188664615154\n",
      "Critic Loss: 6.264278411865234\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.08369340747594833\n",
      "Critic Loss: 6.784454345703125\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.008142524398863316\n",
      "Critic Loss: 6.206984043121338\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.02045034058392048\n",
      "Critic Loss: 10.33159351348877\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.045853473246097565\n",
      "Critic Loss: 9.98794937133789\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.06920116394758224\n",
      "Critic Loss: 6.361520767211914\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.03104379028081894\n",
      "Critic Loss: 6.6954851150512695\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.0030799072701483965\n",
      "Critic Loss: 8.075058937072754\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.053437501192092896\n",
      "Critic Loss: 9.082998275756836\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.052766427397727966\n",
      "Critic Loss: 7.803592681884766\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.037346817553043365\n",
      "Critic Loss: 3.4994442462921143\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.030374789610505104\n",
      "Critic Loss: 5.921488285064697\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.10124149918556213\n",
      "Critic Loss: 5.812607765197754\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.016288476064801216\n",
      "Critic Loss: 2.317103385925293\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.04708532243967056\n",
      "Critic Loss: 5.392369747161865\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.027281632646918297\n",
      "Critic Loss: 11.270612716674805\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.02978109009563923\n",
      "Critic Loss: 4.519362926483154\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.012088623829185963\n",
      "Critic Loss: 5.777822494506836\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.005022992379963398\n",
      "Critic Loss: 6.652289390563965\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.01689533144235611\n",
      "Critic Loss: 5.010655879974365\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.04152583330869675\n",
      "Critic Loss: 4.149869441986084\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.06216440722346306\n",
      "Critic Loss: 10.921247482299805\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.0012895320542156696\n",
      "Critic Loss: 2.9345579147338867\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.035861048847436905\n",
      "Critic Loss: 6.877721786499023\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.0014113490469753742\n",
      "Critic Loss: 1.7762163877487183\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.0005155887920409441\n",
      "Critic Loss: 2.171344757080078\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.014701450243592262\n",
      "Critic Loss: 7.05599308013916\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.05143412575125694\n",
      "Critic Loss: 2.920238733291626\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.00928498525172472\n",
      "Critic Loss: 2.557586431503296\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 6.290595047175884e-05\n",
      "Critic Loss: 2.8023953437805176\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.0060104248113930225\n",
      "Critic Loss: 9.020895004272461\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.0078278174623847\n",
      "Critic Loss: 4.2573161125183105\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -5.89471310377121e-05\n",
      "Critic Loss: 6.553431987762451\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.005276670679450035\n",
      "Critic Loss: 4.951437473297119\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.011468954384326935\n",
      "Critic Loss: 3.2150940895080566\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.0513102225959301\n",
      "Critic Loss: 2.298031806945801\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.046533335000276566\n",
      "Critic Loss: 5.6467204093933105\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.010396476835012436\n",
      "Critic Loss: 4.329416751861572\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.011988365091383457\n",
      "Critic Loss: 6.856456279754639\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.01832709088921547\n",
      "Critic Loss: 5.1345062255859375\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.04569714888930321\n",
      "Critic Loss: 4.658307075500488\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.019604776054620743\n",
      "Critic Loss: 3.4945311546325684\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.016719955950975418\n",
      "Critic Loss: 6.017103672027588\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.02778678573668003\n",
      "Critic Loss: 3.467606782913208\n",
      "\n",
      "New best validation reward reached in update [61/200]\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.016694217920303345\n",
      "Critic Loss: 6.1909894943237305\n",
      "\n",
      "New best validation reward reached in update [62/200]\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.0031516754534095526\n",
      "Critic Loss: 2.719862699508667\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.002359778620302677\n",
      "Critic Loss: 2.200711250305176\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.024086933583021164\n",
      "Critic Loss: 2.1373071670532227\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.03325884789228439\n",
      "Critic Loss: 2.079447031021118\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.013366411440074444\n",
      "Critic Loss: 2.7650198936462402\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.034841448068618774\n",
      "Critic Loss: 1.7179378271102905\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.02985755167901516\n",
      "Critic Loss: 1.9706237316131592\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.06740336120128632\n",
      "Critic Loss: 4.601877689361572\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.005795898847281933\n",
      "Critic Loss: 2.335892677307129\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.0733293667435646\n",
      "Critic Loss: 3.009645700454712\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.037354666739702225\n",
      "Critic Loss: 2.6044681072235107\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.006491391453891993\n",
      "Critic Loss: 4.097845077514648\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.0189620703458786\n",
      "Critic Loss: 2.644216299057007\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.027288515120744705\n",
      "Critic Loss: 4.329075336456299\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.02825489267706871\n",
      "Critic Loss: 3.1033730506896973\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.0496818982064724\n",
      "Critic Loss: 1.202409267425537\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.012053032405674458\n",
      "Critic Loss: 6.289201259613037\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.031088707968592644\n",
      "Critic Loss: 4.045161724090576\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.05158248543739319\n",
      "Critic Loss: 5.361393451690674\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.023071929812431335\n",
      "Critic Loss: 2.9258882999420166\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.05507829412817955\n",
      "Critic Loss: 4.893469333648682\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.04259946569800377\n",
      "Critic Loss: 6.031702518463135\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.042220473289489746\n",
      "Critic Loss: 3.453834056854248\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.04138795658946037\n",
      "Critic Loss: 3.747281074523926\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.038514308631420135\n",
      "Critic Loss: 3.1854894161224365\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.0572555810213089\n",
      "Critic Loss: 3.824223279953003\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.017750076949596405\n",
      "Critic Loss: 1.5604326725006104\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.0022070868872106075\n",
      "Critic Loss: 5.656617641448975\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.02459726110100746\n",
      "Critic Loss: 2.127683162689209\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.013394942507147789\n",
      "Critic Loss: 3.7180233001708984\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.013305718079209328\n",
      "Critic Loss: 4.694334983825684\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.042767856270074844\n",
      "Critic Loss: 3.751192092895508\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.0013576277997344732\n",
      "Critic Loss: 3.0528111457824707\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.04115121439099312\n",
      "Critic Loss: 2.216181755065918\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.05096329376101494\n",
      "Critic Loss: 4.40291690826416\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.04667250066995621\n",
      "Critic Loss: 2.338693380355835\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa3ab271c5f451d8584383f38c3b2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>122.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>114.6</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.00379</td></tr><tr><td>Loss/Critic_loss</td><td>2.33869</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.79358</td></tr><tr><td>Loss/KL_divergence</td><td>0.02165</td></tr><tr><td>Loss/Policy_loss</td><td>0.01159</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.04667</td></tr><tr><td>Metric/Explained_variance</td><td>0.88307</td></tr><tr><td>Reward/Mean_train_reward</td><td>2.49433</td></tr><tr><td>Reward/Mean_val_reward</td><td>3.3176</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>0.87367</td></tr><tr><td>global_step</td><td>98</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-sweep-29</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/9zbkshi1' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/9zbkshi1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_173945-9zbkshi1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r7rznh59 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.001196962607264042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00198745920284241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.024886959094987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8634911459470309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00044071834483726166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.69646074087783e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_175205-r7rznh59</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/r7rznh59' target=\"_blank\">rare-sweep-30</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/r7rznh59' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/r7rznh59</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.001196962607264042, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00198745920284241, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024886959094987, 'epochs': 10, 'exponential_factor': 0.8634911459470309, 'gamma': 0.99, 'hidden_sizes': [250, 150, 150, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.00044071834483726166, 'l2_factor': 2.69646074087783e-06, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.001196962607264042, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00198745920284241, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024886959094987, 'epochs': 10, 'exponential_factor': 0.8634911459470309, 'gamma': 0.99, 'l1_factor': 0.00044071834483726166, 'l2_factor': 2.69646074087783e-06, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.001196962607264042, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00198745920284241, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024886959094987, 'epochs': 10, 'exponential_factor': 0.8634911459470309, 'gamma': 0.99, 'l1_factor': 0.00044071834483726166, 'l2_factor': 2.69646074087783e-06, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.001196962607264042, 'critic_lr': 0.00198745920284241, 'decay_method': 'exponential', 'exponential_factor': 0.8634911459470309, 'value_loss_factor': 1, 'entropy': 0.024886959094987, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00044071834483726166, 'l2_factor': 2.69646074087783e-06, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [250, 150, 150, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 4.268927574157715\n",
      "Critic Loss: 34.64858627319336\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 3.7024312019348145\n",
      "Critic Loss: 28.58808135986328\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 2.5892438888549805\n",
      "Critic Loss: 8.631519317626953\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 2.611734390258789\n",
      "Critic Loss: 8.226313591003418\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 2.495406150817871\n",
      "Critic Loss: 9.083295822143555\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 5.020418167114258\n",
      "Critic Loss: 11.231165885925293\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 2.1382505893707275\n",
      "Critic Loss: 9.92751693725586\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 1.9086887836456299\n",
      "Critic Loss: 9.354351997375488\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 2.0025603771209717\n",
      "Critic Loss: 15.207236289978027\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 2.429607629776001\n",
      "Critic Loss: 10.693535804748535\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.786086916923523\n",
      "Critic Loss: 7.957032203674316\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.798471212387085\n",
      "Critic Loss: 6.249181747436523\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.9774667024612427\n",
      "Critic Loss: 5.79970645904541\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.6308937072753906\n",
      "Critic Loss: 6.442037105560303\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.8768115043640137\n",
      "Critic Loss: 4.230664253234863\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.7622853517532349\n",
      "Critic Loss: 8.577523231506348\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 1.783742904663086\n",
      "Critic Loss: 6.867769241333008\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.642357587814331\n",
      "Critic Loss: 6.929083824157715\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 1.6401801109313965\n",
      "Critic Loss: 10.335135459899902\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 1.6646132469177246\n",
      "Critic Loss: 6.654538631439209\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 1.5562094449996948\n",
      "Critic Loss: 6.688484191894531\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 1.8487515449523926\n",
      "Critic Loss: 5.902153491973877\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 3.3885793685913086\n",
      "Critic Loss: 6.106351375579834\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 1.5559226274490356\n",
      "Critic Loss: 5.451669692993164\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 1.688146948814392\n",
      "Critic Loss: 6.30272102355957\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.548576831817627\n",
      "Critic Loss: 7.583910942077637\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 2.060882806777954\n",
      "Critic Loss: 8.22966480255127\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 1.6445884704589844\n",
      "Critic Loss: 4.723452091217041\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.5968748331069946\n",
      "Critic Loss: 6.3173394203186035\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.6714609861373901\n",
      "Critic Loss: 6.458756923675537\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 1.80584716796875\n",
      "Critic Loss: 6.863433837890625\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.6427867412567139\n",
      "Critic Loss: 5.300269603729248\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 2.0876176357269287\n",
      "Critic Loss: 2.7287018299102783\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 1.6113191843032837\n",
      "Critic Loss: 6.256820201873779\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 1.5104100704193115\n",
      "Critic Loss: 5.0089263916015625\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 1.5174736976623535\n",
      "Critic Loss: 5.329462051391602\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 1.616592288017273\n",
      "Critic Loss: 5.146239280700684\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 2.029299259185791\n",
      "Critic Loss: 5.139529228210449\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 1.5514124631881714\n",
      "Critic Loss: 6.820091724395752\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 1.6917959451675415\n",
      "Critic Loss: 4.51494026184082\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 1.677658200263977\n",
      "Critic Loss: 5.730138301849365\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 2.5186548233032227\n",
      "Critic Loss: 5.297291278839111\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 1.5476547479629517\n",
      "Critic Loss: 6.550774574279785\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 1.651989221572876\n",
      "Critic Loss: 5.5437517166137695\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 1.5697686672210693\n",
      "Critic Loss: 4.276741981506348\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 1.5988755226135254\n",
      "Critic Loss: 5.214541435241699\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 1.5726534128189087\n",
      "Critic Loss: 6.30095911026001\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 1.5361641645431519\n",
      "Critic Loss: 5.845468997955322\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.7165249586105347\n",
      "Critic Loss: 7.147790908813477\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 1.6171563863754272\n",
      "Critic Loss: 6.6707587242126465\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 1.6043334007263184\n",
      "Critic Loss: 5.5230512619018555\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 1.5322678089141846\n",
      "Critic Loss: 6.888976573944092\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 1.564388394355774\n",
      "Critic Loss: 6.190280914306641\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 1.5281177759170532\n",
      "Critic Loss: 5.456079006195068\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 1.7954766750335693\n",
      "Critic Loss: 4.2949442863464355\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 2.104755401611328\n",
      "Critic Loss: 4.1637043952941895\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 1.6533448696136475\n",
      "Critic Loss: 4.980719089508057\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 2.2811877727508545\n",
      "Critic Loss: 5.479240417480469\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 1.7692904472351074\n",
      "Critic Loss: 5.62186336517334\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 1.5036059617996216\n",
      "Critic Loss: 4.62448787689209\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 1.691261887550354\n",
      "Critic Loss: 4.960973739624023\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 1.7787376642227173\n",
      "Critic Loss: 5.535446643829346\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 1.6463849544525146\n",
      "Critic Loss: 6.643556594848633\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 1.715983271598816\n",
      "Critic Loss: 5.727344989776611\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 1.558172583580017\n",
      "Critic Loss: 4.974111080169678\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 1.8127444982528687\n",
      "Critic Loss: 5.678574562072754\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 1.6335296630859375\n",
      "Critic Loss: 5.238552093505859\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 1.5395952463150024\n",
      "Critic Loss: 7.458056449890137\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 1.5848251581192017\n",
      "Critic Loss: 4.6177978515625\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 1.5831794738769531\n",
      "Critic Loss: 3.095872402191162\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 1.6057811975479126\n",
      "Critic Loss: 4.362095832824707\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 1.8312523365020752\n",
      "Critic Loss: 3.1432249546051025\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 1.7876362800598145\n",
      "Critic Loss: 6.485311508178711\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 1.6029523611068726\n",
      "Critic Loss: 7.422346591949463\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 1.6217602491378784\n",
      "Critic Loss: 6.637172698974609\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 1.8085931539535522\n",
      "Critic Loss: 5.289974212646484\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 1.8751423358917236\n",
      "Critic Loss: 5.223855018615723\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 2.046096086502075\n",
      "Critic Loss: 6.690083980560303\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 1.5444086790084839\n",
      "Critic Loss: 4.523747444152832\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 1.7346948385238647\n",
      "Critic Loss: 4.451081275939941\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 1.788774847984314\n",
      "Critic Loss: 3.5599682331085205\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 1.5689842700958252\n",
      "Critic Loss: 4.618508338928223\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 2.523878574371338\n",
      "Critic Loss: 3.6782174110412598\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 1.8054426908493042\n",
      "Critic Loss: 4.371500492095947\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 1.7698966264724731\n",
      "Critic Loss: 5.865540027618408\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 1.534925937652588\n",
      "Critic Loss: 4.20238733291626\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 3.3810787200927734\n",
      "Critic Loss: 7.815633773803711\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 1.7370301485061646\n",
      "Critic Loss: 5.160795211791992\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 1.6454781293869019\n",
      "Critic Loss: 4.730971813201904\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 1.5280290842056274\n",
      "Critic Loss: 4.921998977661133\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 1.4978982210159302\n",
      "Critic Loss: 5.751066207885742\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 1.6214755773544312\n",
      "Critic Loss: 5.982515335083008\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 1.6273967027664185\n",
      "Critic Loss: 6.507399082183838\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 1.5372282266616821\n",
      "Critic Loss: 4.161830425262451\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 1.5064244270324707\n",
      "Critic Loss: 6.487701416015625\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 1.6894718408584595\n",
      "Critic Loss: 4.952587604522705\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 1.6479233503341675\n",
      "Critic Loss: 5.0239667892456055\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 1.5141782760620117\n",
      "Critic Loss: 6.7328338623046875\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 1.8895198106765747\n",
      "Critic Loss: 4.954616546630859\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 1.7554230690002441\n",
      "Critic Loss: 5.353652000427246\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 1.776128888130188\n",
      "Critic Loss: 3.585766315460205\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 1.4997597932815552\n",
      "Critic Loss: 5.524900436401367\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 1.6161246299743652\n",
      "Critic Loss: 5.256902694702148\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 1.867997646331787\n",
      "Critic Loss: 4.485036373138428\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 1.4859797954559326\n",
      "Critic Loss: 4.979881763458252\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 1.5064667463302612\n",
      "Critic Loss: 7.769481182098389\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93bba8a513442f19fe353b47c5ff28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>127.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>125.6</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.02427</td></tr><tr><td>Loss/Critic_loss</td><td>7.76948</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.14022</td></tr><tr><td>Loss/KL_divergence</td><td>0.05537</td></tr><tr><td>Loss/Policy_loss</td><td>-0.02078</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.50647</td></tr><tr><td>Metric/Explained_variance</td><td>0.86734</td></tr><tr><td>Reward/Mean_train_reward</td><td>3.126</td></tr><tr><td>Reward/Mean_val_reward</td><td>3.8206</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.71972</td></tr><tr><td>global_step</td><td>106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-sweep-30</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/r7rznh59' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/r7rznh59</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_175205-r7rznh59\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: egg2fsuq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.009088186882336351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0017531204231651775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.007284770146609111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.969499150142167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 8.277916768734815e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 5.378107398897753e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_180210-egg2fsuq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/egg2fsuq' target=\"_blank\">comfy-sweep-31</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/egg2fsuq' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/egg2fsuq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.009088186882336351, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017531204231651775, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.007284770146609111, 'epochs': 10, 'exponential_factor': 0.969499150142167, 'gamma': 0.9, 'hidden_sizes': [150, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 8.277916768734815e-05, 'l2_factor': 5.378107398897753e-05, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.009088186882336351, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017531204231651775, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.007284770146609111, 'epochs': 10, 'exponential_factor': 0.969499150142167, 'gamma': 0.9, 'l1_factor': 8.277916768734815e-05, 'l2_factor': 5.378107398897753e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.009088186882336351, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017531204231651775, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.007284770146609111, 'epochs': 10, 'exponential_factor': 0.969499150142167, 'gamma': 0.9, 'l1_factor': 8.277916768734815e-05, 'l2_factor': 5.378107398897753e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.009088186882336351, 'critic_lr': 0.0017531204231651775, 'decay_method': 'exponential', 'exponential_factor': 0.969499150142167, 'value_loss_factor': 1, 'entropy': 0.007284770146609111, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 8.277916768734815e-05, 'l2_factor': 5.378107398897753e-05, 'T': 512, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [150, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.46213531494140625\n",
      "Critic Loss: 27.507081985473633\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.8249083161354065\n",
      "Critic Loss: 9.793845176696777\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.42889437079429626\n",
      "Critic Loss: 20.14373016357422\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.2936687767505646\n",
      "Critic Loss: 8.435946464538574\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.12712189555168152\n",
      "Critic Loss: 4.232399940490723\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.12108306586742401\n",
      "Critic Loss: 1.7877274751663208\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.13732700049877167\n",
      "Critic Loss: 4.166186809539795\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.10180612653493881\n",
      "Critic Loss: 2.527333974838257\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.15892648696899414\n",
      "Critic Loss: 6.731123924255371\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.060462262481451035\n",
      "Critic Loss: 1.7110947370529175\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.12843851745128632\n",
      "Critic Loss: 1.7061048746109009\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.1425960659980774\n",
      "Critic Loss: 1.5994702577590942\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.09102337062358856\n",
      "Critic Loss: 1.0411537885665894\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.042954400181770325\n",
      "Critic Loss: 1.4949697256088257\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.049705620855093\n",
      "Critic Loss: 1.4980535507202148\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.1236618384718895\n",
      "Critic Loss: 1.498568058013916\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.053414374589920044\n",
      "Critic Loss: 2.5030667781829834\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.12140943109989166\n",
      "Critic Loss: 6.0715155601501465\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.08368859440088272\n",
      "Critic Loss: 2.151236057281494\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.06035890430212021\n",
      "Critic Loss: 1.3069813251495361\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.23247233033180237\n",
      "Critic Loss: 1.0135561227798462\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.048966459929943085\n",
      "Critic Loss: 0.8279544115066528\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.20508238673210144\n",
      "Critic Loss: 3.891420364379883\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.015499680303037167\n",
      "Critic Loss: 0.3816536068916321\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.005170031450688839\n",
      "Critic Loss: 2.8099632263183594\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.05080997943878174\n",
      "Critic Loss: 3.2420904636383057\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.013096892274916172\n",
      "Critic Loss: 3.346642017364502\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.06493635475635529\n",
      "Critic Loss: 8.284817695617676\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.045755427330732346\n",
      "Critic Loss: 3.2685322761535645\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.10222999006509781\n",
      "Critic Loss: 0.594989538192749\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.06368083506822586\n",
      "Critic Loss: 0.5079688429832458\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.18665921688079834\n",
      "Critic Loss: 2.260043144226074\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.02084837667644024\n",
      "Critic Loss: 0.9003681540489197\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.06237567588686943\n",
      "Critic Loss: 1.62827730178833\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.007358466740697622\n",
      "Critic Loss: 0.5338113307952881\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.074781134724617\n",
      "Critic Loss: 0.5569355487823486\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.0071604298427701\n",
      "Critic Loss: 1.8083608150482178\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.01679682731628418\n",
      "Critic Loss: 0.6722695827484131\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.06024545058608055\n",
      "Critic Loss: 1.6078437566757202\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.33246174454689026\n",
      "Critic Loss: 1.1701990365982056\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.05548781901597977\n",
      "Critic Loss: 0.7442691326141357\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.0002917647361755371\n",
      "Critic Loss: 2.096872091293335\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.023088665679097176\n",
      "Critic Loss: 0.7317272424697876\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.010801834054291248\n",
      "Critic Loss: 0.6890881061553955\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.03623490780591965\n",
      "Critic Loss: 0.721603512763977\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.00901598297059536\n",
      "Critic Loss: 1.6541752815246582\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.03391022980213165\n",
      "Critic Loss: 2.8086178302764893\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.007631533779203892\n",
      "Critic Loss: 1.648877739906311\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.03423529118299484\n",
      "Critic Loss: 0.8886070847511292\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.029766511172056198\n",
      "Critic Loss: 1.0254849195480347\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.0009709815494716167\n",
      "Critic Loss: 0.4244665801525116\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.008995781652629375\n",
      "Critic Loss: 0.5803570747375488\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.00934658758342266\n",
      "Critic Loss: 1.3003398180007935\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.01554806623607874\n",
      "Critic Loss: 0.31737756729125977\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.14789825677871704\n",
      "Critic Loss: 1.2283488512039185\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.007211833726614714\n",
      "Critic Loss: 0.31687554717063904\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.020328830927610397\n",
      "Critic Loss: 2.607973575592041\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.02768450416624546\n",
      "Critic Loss: 1.1209193468093872\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.12845319509506226\n",
      "Critic Loss: 4.156424522399902\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.06639973074197769\n",
      "Critic Loss: 1.542402982711792\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.06351562589406967\n",
      "Critic Loss: 2.9410359859466553\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.018392179161310196\n",
      "Critic Loss: 2.4705679416656494\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.10002023726701736\n",
      "Critic Loss: 5.499258041381836\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.06619344651699066\n",
      "Critic Loss: 1.1302461624145508\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.1753489375114441\n",
      "Critic Loss: 0.715618371963501\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.033151041716337204\n",
      "Critic Loss: 3.838904857635498\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.03610026463866234\n",
      "Critic Loss: 0.9061295390129089\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.013828696683049202\n",
      "Critic Loss: 1.0812615156173706\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.2128240317106247\n",
      "Critic Loss: 1.5379512310028076\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.016491496935486794\n",
      "Critic Loss: 0.929498016834259\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.0276663675904274\n",
      "Critic Loss: 0.33521103858947754\n",
      "\n",
      "New best validation reward reached in update [71/200]\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.05190665274858475\n",
      "Critic Loss: 2.85540509223938\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.0004132981412112713\n",
      "Critic Loss: 1.2688074111938477\n",
      "\n",
      "New best validation reward reached in update [73/200]\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.0063849641010165215\n",
      "Critic Loss: 1.0250493288040161\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.03147336468100548\n",
      "Critic Loss: 0.956266462802887\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.012628359720110893\n",
      "Critic Loss: 2.8209588527679443\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.0011772592552006245\n",
      "Critic Loss: 3.087480306625366\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.07879751175642014\n",
      "Critic Loss: 2.681535005569458\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.05585654452443123\n",
      "Critic Loss: 6.389713287353516\n",
      "\n",
      "New best validation reward reached in update [79/200]\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.029520805925130844\n",
      "Critic Loss: 0.9854074716567993\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.05479699745774269\n",
      "Critic Loss: 0.433879017829895\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.0032632295042276382\n",
      "Critic Loss: 4.440374851226807\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.007658322807401419\n",
      "Critic Loss: 0.3118746876716614\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.01396179385483265\n",
      "Critic Loss: 0.7466422319412231\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.04319656640291214\n",
      "Critic Loss: 1.4076335430145264\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.006856707856059074\n",
      "Critic Loss: 0.3227827548980713\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.023163367062807083\n",
      "Critic Loss: 2.0604097843170166\n",
      "\n",
      "New best validation reward reached in update [87/200]\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.024061165750026703\n",
      "Critic Loss: 1.7560536861419678\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.032351475208997726\n",
      "Critic Loss: 5.237876892089844\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.02447497844696045\n",
      "Critic Loss: 2.411470651626587\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.02866997756063938\n",
      "Critic Loss: 2.4574365615844727\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.013649259693920612\n",
      "Critic Loss: 4.259541034698486\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.04543757438659668\n",
      "Critic Loss: 5.669464111328125\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.01410222053527832\n",
      "Critic Loss: 1.0302963256835938\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.003066520905122161\n",
      "Critic Loss: 1.6945120096206665\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.045396432280540466\n",
      "Critic Loss: 0.5125154852867126\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.0177898108959198\n",
      "Critic Loss: 5.019131183624268\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.017586076632142067\n",
      "Critic Loss: 0.8413124084472656\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.026980213820934296\n",
      "Critic Loss: 2.5974676609039307\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.01664593257009983\n",
      "Critic Loss: 1.1533141136169434\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.014046703465282917\n",
      "Critic Loss: 0.8705349564552307\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.004422793164849281\n",
      "Critic Loss: 1.9863628149032593\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.0193586777895689\n",
      "Critic Loss: 1.8852099180221558\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.008287244476377964\n",
      "Critic Loss: 1.3934937715530396\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.0360233299434185\n",
      "Critic Loss: 1.2248823642730713\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.015934336930513382\n",
      "Critic Loss: 0.6539007425308228\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.0630030557513237\n",
      "Critic Loss: 0.8049305081367493\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.05061793699860573\n",
      "Critic Loss: 0.5225845575332642\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.024625785648822784\n",
      "Critic Loss: 0.8017047047615051\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.08789079636335373\n",
      "Critic Loss: 3.123786449432373\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.05720950663089752\n",
      "Critic Loss: 0.5018523335456848\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.05517181381583214\n",
      "Critic Loss: 3.4268622398376465\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.006964638829231262\n",
      "Critic Loss: 0.5003265738487244\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.02112937718629837\n",
      "Critic Loss: 0.8213595151901245\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.06646891683340073\n",
      "Critic Loss: 2.9415318965911865\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.030706847086548805\n",
      "Critic Loss: 1.5956271886825562\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.03941882774233818\n",
      "Critic Loss: 2.117992401123047\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbb2b8643794c87a171e0fec23d9bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>129.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>169.89999</td></tr><tr><td>Learning_rate/Actor</td><td>0.00025</td></tr><tr><td>Learning_rate/Critic</td><td>5e-05</td></tr><tr><td>Loss/Actor_loss</td><td>0.01223</td></tr><tr><td>Loss/Critic_loss</td><td>2.11799</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.32314</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01129</td></tr><tr><td>Loss/Policy_loss</td><td>0.01459</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.03942</td></tr><tr><td>Metric/Explained_variance</td><td>0.39198</td></tr><tr><td>Reward/Mean_train_reward</td><td>4.5085</td></tr><tr><td>Reward/Mean_val_reward</td><td>13.2689</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>19.57736</td></tr><tr><td>global_step</td><td>117</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-31</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/egg2fsuq' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/egg2fsuq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_180210-egg2fsuq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: badcdinu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.007930857175333586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004150315798785521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.004563162421066501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9264410540692616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0001845535175972598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.056654905232913e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_181928-badcdinu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/badcdinu' target=\"_blank\">celestial-sweep-32</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/badcdinu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/badcdinu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.007930857175333586, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004150315798785521, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004563162421066501, 'epochs': 10, 'exponential_factor': 0.9264410540692616, 'gamma': 0.95, 'hidden_sizes': [150, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0001845535175972598, 'l2_factor': 2.056654905232913e-06, 'lrelu': 0.1, 'minibatch_size': 128, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.007930857175333586, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004150315798785521, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004563162421066501, 'epochs': 10, 'exponential_factor': 0.9264410540692616, 'gamma': 0.95, 'l1_factor': 0.0001845535175972598, 'l2_factor': 2.056654905232913e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.007930857175333586, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004150315798785521, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004563162421066501, 'epochs': 10, 'exponential_factor': 0.9264410540692616, 'gamma': 0.95, 'l1_factor': 0.0001845535175972598, 'l2_factor': 2.056654905232913e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.007930857175333586, 'critic_lr': 0.0004150315798785521, 'decay_method': 'exponential', 'exponential_factor': 0.9264410540692616, 'value_loss_factor': 1, 'entropy': 0.004563162421066501, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0001845535175972598, 'l2_factor': 2.056654905232913e-06, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [150, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 23.52582359313965\n",
      "Critic Loss: 31.55440330505371\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 36.875587463378906\n",
      "Critic Loss: 3.004180669784546\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 23.334108352661133\n",
      "Critic Loss: 2.0123331546783447\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 33.68889236450195\n",
      "Critic Loss: 0.5653306841850281\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 25.891864776611328\n",
      "Critic Loss: 0.7986883521080017\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 32.60377502441406\n",
      "Critic Loss: 0.13864243030548096\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 28.72058868408203\n",
      "Critic Loss: 0.194750115275383\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 26.049882888793945\n",
      "Critic Loss: 0.11348507553339005\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 26.447317123413086\n",
      "Critic Loss: 0.12027451395988464\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 28.376203536987305\n",
      "Critic Loss: 0.09038416296243668\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 26.055246353149414\n",
      "Critic Loss: 0.07640840858221054\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 26.106796264648438\n",
      "Critic Loss: 0.08036687225103378\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 27.519271850585938\n",
      "Critic Loss: 0.09426354616880417\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 26.915437698364258\n",
      "Critic Loss: 0.1288238763809204\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 25.554428100585938\n",
      "Critic Loss: 0.08935216069221497\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 26.059741973876953\n",
      "Critic Loss: 0.08826806396245956\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 30.768863677978516\n",
      "Critic Loss: 0.09852979332208633\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 26.495256423950195\n",
      "Critic Loss: 0.08070621639490128\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 27.69361114501953\n",
      "Critic Loss: 0.05183465778827667\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 34.46723175048828\n",
      "Critic Loss: 0.05156233534216881\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 24.073261260986328\n",
      "Critic Loss: 0.04392422363162041\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 27.143686294555664\n",
      "Critic Loss: 0.06602387130260468\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 27.390464782714844\n",
      "Critic Loss: 0.07511404901742935\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 32.974693298339844\n",
      "Critic Loss: 0.12078418582677841\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 25.949676513671875\n",
      "Critic Loss: 0.06009504571557045\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 20.794456481933594\n",
      "Critic Loss: 0.1088084951043129\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 100.19173431396484\n",
      "Critic Loss: 0.4826662838459015\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 100.11007690429688\n",
      "Critic Loss: 1.6726664304733276\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 100.10140228271484\n",
      "Critic Loss: 9.137443542480469\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 100.09564208984375\n",
      "Critic Loss: 22.196701049804688\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 100.09130096435547\n",
      "Critic Loss: 2.4146957397460938\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 100.08782196044922\n",
      "Critic Loss: 0.40388113260269165\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 100.08491516113281\n",
      "Critic Loss: 8.806270599365234\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 100.08244323730469\n",
      "Critic Loss: 1.1102371215820312\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 100.08031463623047\n",
      "Critic Loss: 0.6303787231445312\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 100.07845306396484\n",
      "Critic Loss: 4.201335906982422\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 100.07681274414062\n",
      "Critic Loss: 2.3049964904785156\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 100.07535552978516\n",
      "Critic Loss: 0.3368319272994995\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 100.07404327392578\n",
      "Critic Loss: 0.38086897134780884\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 100.0728530883789\n",
      "Critic Loss: 1.6665267944335938\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 100.07177734375\n",
      "Critic Loss: 0.13916845619678497\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 100.0707778930664\n",
      "Critic Loss: 0.10454864054918289\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 100.06986999511719\n",
      "Critic Loss: 0.9366455078125\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 100.06903076171875\n",
      "Critic Loss: 0.011954435147345066\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 100.06825256347656\n",
      "Critic Loss: 0.21141467988491058\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 100.0675277709961\n",
      "Critic Loss: 0.26910170912742615\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 100.06686401367188\n",
      "Critic Loss: 0.15907765924930573\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 100.06624603271484\n",
      "Critic Loss: 0.011371864937245846\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 80.06915283203125\n",
      "Critic Loss: 0.10985255241394043\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 50.681175231933594\n",
      "Critic Loss: 33.779911041259766\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 36.077110290527344\n",
      "Critic Loss: 44.490692138671875\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 29.860809326171875\n",
      "Critic Loss: 44.45392608642578\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 30.745012283325195\n",
      "Critic Loss: 37.32838821411133\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 29.973724365234375\n",
      "Critic Loss: 32.77969741821289\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 29.93960952758789\n",
      "Critic Loss: 23.048656463623047\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7dd99f2893487487743c7d4421701e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>36.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>36.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00013</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>29.86222</td></tr><tr><td>Loss/Critic_loss</td><td>23.04866</td></tr><tr><td>Loss/Entropy_bonus</td><td>2e-05</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0</td></tr><tr><td>Loss/Policy_loss</td><td>29.86222</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>29.93961</td></tr><tr><td>Metric/Explained_variance</td><td>0.05449</td></tr><tr><td>Reward/Mean_train_reward</td><td>-74.76499</td></tr><tr><td>Reward/Mean_val_reward</td><td>-74.765</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-81.02721</td></tr><tr><td>global_step</td><td>55</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-32</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/badcdinu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/badcdinu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_181928-badcdinu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: afg97tih with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00042233164420571456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00015680527449756009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.00385734538425536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8947396766648134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0001825763949892606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.7592011607222075e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_182452-afg97tih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/afg97tih' target=\"_blank\">hardy-sweep-33</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/afg97tih' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/afg97tih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.00042233164420571456, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00015680527449756009, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00385734538425536, 'epochs': 10, 'exponential_factor': 0.8947396766648134, 'gamma': 0.9, 'hidden_sizes': [150, 250, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0001825763949892606, 'l2_factor': 4.7592011607222075e-05, 'lrelu': 0.1, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.00042233164420571456, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00015680527449756009, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00385734538425536, 'epochs': 10, 'exponential_factor': 0.8947396766648134, 'gamma': 0.9, 'l1_factor': 0.0001825763949892606, 'l2_factor': 4.7592011607222075e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.00042233164420571456, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00015680527449756009, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00385734538425536, 'epochs': 10, 'exponential_factor': 0.8947396766648134, 'gamma': 0.9, 'l1_factor': 0.0001825763949892606, 'l2_factor': 4.7592011607222075e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00042233164420571456, 'critic_lr': 0.00015680527449756009, 'decay_method': 'exponential', 'exponential_factor': 0.8947396766648134, 'value_loss_factor': 1, 'entropy': 0.00385734538425536, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0001825763949892606, 'l2_factor': 4.7592011607222075e-05, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [150, 250, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.766859769821167\n",
      "Critic Loss: 81.53388977050781\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 1.7229745388031006\n",
      "Critic Loss: 64.61351013183594\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 1.76546049118042\n",
      "Critic Loss: 51.90440368652344\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 1.7051928043365479\n",
      "Critic Loss: 48.66551971435547\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 1.7347149848937988\n",
      "Critic Loss: 33.46794509887695\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 1.699989676475525\n",
      "Critic Loss: 29.674230575561523\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.7628580331802368\n",
      "Critic Loss: 33.01631164550781\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 1.7252198457717896\n",
      "Critic Loss: 32.974422454833984\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 1.692676067352295\n",
      "Critic Loss: 37.64495086669922\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 1.6911410093307495\n",
      "Critic Loss: 34.28447341918945\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.697139024734497\n",
      "Critic Loss: 33.340858459472656\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.7119911909103394\n",
      "Critic Loss: 31.120349884033203\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.6735897064208984\n",
      "Critic Loss: 31.983802795410156\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.7136257886886597\n",
      "Critic Loss: 32.714576721191406\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.6809046268463135\n",
      "Critic Loss: 28.56957244873047\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.695265293121338\n",
      "Critic Loss: 31.342540740966797\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 1.7022483348846436\n",
      "Critic Loss: 30.4536190032959\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.6583932638168335\n",
      "Critic Loss: 30.425365447998047\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 1.655373454093933\n",
      "Critic Loss: 28.624427795410156\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 1.701926350593567\n",
      "Critic Loss: 25.5877742767334\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 1.6675758361816406\n",
      "Critic Loss: 25.578258514404297\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 1.6701985597610474\n",
      "Critic Loss: 29.80025863647461\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 1.6562345027923584\n",
      "Critic Loss: 26.883277893066406\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 1.6609547138214111\n",
      "Critic Loss: 24.93741798400879\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 1.6527230739593506\n",
      "Critic Loss: 31.72711181640625\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.675557017326355\n",
      "Critic Loss: 29.54427146911621\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.674579381942749\n",
      "Critic Loss: 26.87114906311035\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 1.6704864501953125\n",
      "Critic Loss: 27.390995025634766\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.6527221202850342\n",
      "Critic Loss: 28.11301612854004\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.689427137374878\n",
      "Critic Loss: 29.498506546020508\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 1.6634260416030884\n",
      "Critic Loss: 30.818828582763672\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.68099844455719\n",
      "Critic Loss: 27.80396270751953\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 1.6579115390777588\n",
      "Critic Loss: 25.856853485107422\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 1.6592750549316406\n",
      "Critic Loss: 27.188980102539062\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 1.6760053634643555\n",
      "Critic Loss: 26.345491409301758\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 1.6768282651901245\n",
      "Critic Loss: 28.50141143798828\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 1.6692718267440796\n",
      "Critic Loss: 30.49477195739746\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5834173062964f3d8e61a01dee7c2348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>âââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>70.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>38.5</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.02616</td></tr><tr><td>Loss/Critic_loss</td><td>30.49477</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.62987</td></tr><tr><td>Loss/KL_divergence</td><td>0.01645</td></tr><tr><td>Loss/Policy_loss</td><td>0.03245</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.66927</td></tr><tr><td>Metric/Explained_variance</td><td>-0.00272</td></tr><tr><td>Reward/Mean_train_reward</td><td>-64.267</td></tr><tr><td>Reward/Mean_val_reward</td><td>-82.8385</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-80.75156</td></tr><tr><td>global_step</td><td>37</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-33</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/afg97tih' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/afg97tih</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_182452-afg97tih\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cidh2ccc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0006644086270589773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.007553606477719556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0316569146656629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8529997061380378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 7.500663420912767e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0004437218844894752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_182735-cidh2ccc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/cidh2ccc' target=\"_blank\">super-sweep-34</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/cidh2ccc' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/cidh2ccc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0006644086270589773, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.007553606477719556, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0316569146656629, 'epochs': 10, 'exponential_factor': 0.8529997061380378, 'gamma': 0.95, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 7.500663420912767e-05, 'l2_factor': 0.0004437218844894752, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0006644086270589773, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007553606477719556, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0316569146656629, 'epochs': 10, 'exponential_factor': 0.8529997061380378, 'gamma': 0.95, 'l1_factor': 7.500663420912767e-05, 'l2_factor': 0.0004437218844894752, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0006644086270589773, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007553606477719556, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0316569146656629, 'epochs': 10, 'exponential_factor': 0.8529997061380378, 'gamma': 0.95, 'l1_factor': 7.500663420912767e-05, 'l2_factor': 0.0004437218844894752, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0006644086270589773, 'critic_lr': 0.007553606477719556, 'decay_method': 'exponential', 'exponential_factor': 0.8529997061380378, 'value_loss_factor': 1, 'entropy': 0.0316569146656629, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 7.500663420912767e-05, 'l2_factor': 0.0004437218844894752, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 49.110252380371094\n",
      "Critic Loss: 29.038541793823242\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 21.48404312133789\n",
      "Critic Loss: 8.850013732910156\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 5.0654520988464355\n",
      "Critic Loss: 7.788677215576172\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 26.510984420776367\n",
      "Critic Loss: 18.062288284301758\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 10.850151062011719\n",
      "Critic Loss: 11.119124412536621\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 23.54829216003418\n",
      "Critic Loss: 12.830659866333008\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 9.1912841796875\n",
      "Critic Loss: 5.812150478363037\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 11.151535987854004\n",
      "Critic Loss: 7.487577438354492\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 16.835657119750977\n",
      "Critic Loss: 4.855345726013184\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 13.604156494140625\n",
      "Critic Loss: 12.480810165405273\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 13.541455268859863\n",
      "Critic Loss: 11.693784713745117\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 25.186527252197266\n",
      "Critic Loss: 5.639434337615967\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 7.387458801269531\n",
      "Critic Loss: 3.1752336025238037\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 18.29010581970215\n",
      "Critic Loss: 5.780885696411133\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 10.297969818115234\n",
      "Critic Loss: 3.9551351070404053\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 17.102371215820312\n",
      "Critic Loss: 7.0043721199035645\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 17.731595993041992\n",
      "Critic Loss: 5.123378276824951\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 11.79948616027832\n",
      "Critic Loss: 6.737940788269043\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 15.808154106140137\n",
      "Critic Loss: 10.662331581115723\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 9.163558006286621\n",
      "Critic Loss: 6.435578346252441\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 10.531614303588867\n",
      "Critic Loss: 12.928003311157227\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 10.742271423339844\n",
      "Critic Loss: 5.178654670715332\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 10.940417289733887\n",
      "Critic Loss: 3.868570327758789\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 12.765802383422852\n",
      "Critic Loss: 6.110785484313965\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 12.663347244262695\n",
      "Critic Loss: 7.7637763023376465\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 11.45340633392334\n",
      "Critic Loss: 9.605506896972656\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 13.075607299804688\n",
      "Critic Loss: 4.343488693237305\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 9.085466384887695\n",
      "Critic Loss: 4.841193675994873\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 5.848068714141846\n",
      "Critic Loss: 3.151045560836792\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 8.22701644897461\n",
      "Critic Loss: 3.290245294570923\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 13.490824699401855\n",
      "Critic Loss: 3.2916557788848877\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 6.247737407684326\n",
      "Critic Loss: 4.413728713989258\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 13.341897010803223\n",
      "Critic Loss: 5.591407299041748\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 12.613804817199707\n",
      "Critic Loss: 3.278749465942383\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 18.088531494140625\n",
      "Critic Loss: 5.554892063140869\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 8.31917953491211\n",
      "Critic Loss: 8.512874603271484\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 14.716973304748535\n",
      "Critic Loss: 5.228105545043945\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 6.776165962219238\n",
      "Critic Loss: 14.425362586975098\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 14.048680305480957\n",
      "Critic Loss: 4.556393623352051\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 16.020301818847656\n",
      "Critic Loss: 10.52109146118164\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 9.185811996459961\n",
      "Critic Loss: 7.860522747039795\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 14.596494674682617\n",
      "Critic Loss: 5.782773017883301\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 11.326095581054688\n",
      "Critic Loss: 7.880577564239502\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 17.165363311767578\n",
      "Critic Loss: 4.69096565246582\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 8.178619384765625\n",
      "Critic Loss: 7.558953762054443\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 14.292954444885254\n",
      "Critic Loss: 8.375776290893555\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 12.41285514831543\n",
      "Critic Loss: 5.328570365905762\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 12.76182746887207\n",
      "Critic Loss: 3.3271257877349854\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 7.425239086151123\n",
      "Critic Loss: 11.697793006896973\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 17.58574867248535\n",
      "Critic Loss: 11.60749340057373\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 22.017728805541992\n",
      "Critic Loss: 9.294840812683105\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 15.564906120300293\n",
      "Critic Loss: 9.215566635131836\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 8.793431282043457\n",
      "Critic Loss: 13.462363243103027\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 10.478283882141113\n",
      "Critic Loss: 4.495014667510986\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 7.465762138366699\n",
      "Critic Loss: 3.755136489868164\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 12.964357376098633\n",
      "Critic Loss: 5.021400451660156\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 9.681026458740234\n",
      "Critic Loss: 11.105417251586914\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 17.137441635131836\n",
      "Critic Loss: 7.854499816894531\n",
      "\n",
      "New best validation reward reached in update [58/200]\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 14.52266788482666\n",
      "Critic Loss: 2.663322687149048\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 11.216217041015625\n",
      "Critic Loss: 3.9804482460021973\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 11.068408012390137\n",
      "Critic Loss: 10.642044067382812\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 13.066226959228516\n",
      "Critic Loss: 6.817922592163086\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 10.68592643737793\n",
      "Critic Loss: 4.809323310852051\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 20.38561248779297\n",
      "Critic Loss: 7.27732515335083\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 15.634601593017578\n",
      "Critic Loss: 11.768596649169922\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 5.802035331726074\n",
      "Critic Loss: 2.8756797313690186\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 8.910467147827148\n",
      "Critic Loss: 7.442080020904541\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 11.058675765991211\n",
      "Critic Loss: 9.186799049377441\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 13.348549842834473\n",
      "Critic Loss: 2.604604721069336\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 7.89284610748291\n",
      "Critic Loss: 12.599248886108398\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 11.128541946411133\n",
      "Critic Loss: 3.3554253578186035\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 8.470682144165039\n",
      "Critic Loss: 4.731954574584961\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 23.011768341064453\n",
      "Critic Loss: 4.969040393829346\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 14.584470748901367\n",
      "Critic Loss: 5.058471202850342\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 9.260600090026855\n",
      "Critic Loss: 3.2115917205810547\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 1.0955803394317627\n",
      "Critic Loss: 12.743569374084473\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 15.630731582641602\n",
      "Critic Loss: 8.143245697021484\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 11.041056632995605\n",
      "Critic Loss: 14.85336685180664\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 20.624149322509766\n",
      "Critic Loss: 8.349959373474121\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 13.799348831176758\n",
      "Critic Loss: 4.6019086837768555\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 10.468133926391602\n",
      "Critic Loss: 9.965583801269531\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 5.793230056762695\n",
      "Critic Loss: 8.959341049194336\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 16.197593688964844\n",
      "Critic Loss: 3.1769180297851562\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 15.80234432220459\n",
      "Critic Loss: 8.715206146240234\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 8.476137161254883\n",
      "Critic Loss: 4.865506172180176\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 5.495450973510742\n",
      "Critic Loss: 9.100285530090332\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 15.901884078979492\n",
      "Critic Loss: 11.509786605834961\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 16.75244903564453\n",
      "Critic Loss: 6.484772205352783\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 7.839886665344238\n",
      "Critic Loss: 3.7366995811462402\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca25fb4096c443b299b5d3fe1c1e2f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>80.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>65.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>5.62489</td></tr><tr><td>Loss/Critic_loss</td><td>3.7367</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.52482</td></tr><tr><td>Loss/KL_divergence</td><td>0.00215</td></tr><tr><td>Loss/Policy_loss</td><td>5.67317</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>7.83989</td></tr><tr><td>Metric/Explained_variance</td><td>0.80248</td></tr><tr><td>Reward/Mean_train_reward</td><td>-46.88049</td></tr><tr><td>Reward/Mean_val_reward</td><td>-58.156</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-57.56691</td></tr><tr><td>global_step</td><td>89</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-34</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/cidh2ccc' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/cidh2ccc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_182735-cidh2ccc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: shxgbxpq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.001092251356510318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.003349115256717329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.02976599424830743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8779820387389247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.4447741988652544e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00019134493791455492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_183448-shxgbxpq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/shxgbxpq' target=\"_blank\">sleek-sweep-35</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/shxgbxpq' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/shxgbxpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.001092251356510318, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003349115256717329, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02976599424830743, 'epochs': 10, 'exponential_factor': 0.8779820387389247, 'gamma': 0.99, 'hidden_sizes': [350, 350, 250, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 3.4447741988652544e-05, 'l2_factor': 0.00019134493791455492, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.001092251356510318, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003349115256717329, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02976599424830743, 'epochs': 10, 'exponential_factor': 0.8779820387389247, 'gamma': 0.99, 'l1_factor': 3.4447741988652544e-05, 'l2_factor': 0.00019134493791455492, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.001092251356510318, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.003349115256717329, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02976599424830743, 'epochs': 10, 'exponential_factor': 0.8779820387389247, 'gamma': 0.99, 'l1_factor': 3.4447741988652544e-05, 'l2_factor': 0.00019134493791455492, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.001092251356510318, 'critic_lr': 0.003349115256717329, 'decay_method': 'exponential', 'exponential_factor': 0.8779820387389247, 'value_loss_factor': 1, 'entropy': 0.02976599424830743, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.4447741988652544e-05, 'l2_factor': 0.00019134493791455492, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [350, 350, 250, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 15.223298072814941\n",
      "Critic Loss: 16.172481536865234\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 2.841553211212158\n",
      "Critic Loss: 11.640646934509277\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 9.430996894836426\n",
      "Critic Loss: 9.1591215133667\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 13.237311363220215\n",
      "Critic Loss: 9.413887023925781\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 24.546680450439453\n",
      "Critic Loss: 4.017158031463623\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 25.803037643432617\n",
      "Critic Loss: 9.809956550598145\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 20.016244888305664\n",
      "Critic Loss: 14.127754211425781\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 24.525310516357422\n",
      "Critic Loss: 15.87646484375\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 19.638628005981445\n",
      "Critic Loss: 11.883905410766602\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 26.241933822631836\n",
      "Critic Loss: 9.894064903259277\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 19.8916015625\n",
      "Critic Loss: 9.259773254394531\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 38.54311752319336\n",
      "Critic Loss: 7.3771162033081055\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 49.0352668762207\n",
      "Critic Loss: 19.78463363647461\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 23.288558959960938\n",
      "Critic Loss: 10.592690467834473\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 24.411226272583008\n",
      "Critic Loss: 11.365610122680664\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 22.089632034301758\n",
      "Critic Loss: 8.330571174621582\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 26.282485961914062\n",
      "Critic Loss: 8.632984161376953\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 28.441112518310547\n",
      "Critic Loss: 5.237909317016602\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 22.497940063476562\n",
      "Critic Loss: 8.050614356994629\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 16.983854293823242\n",
      "Critic Loss: 4.440469741821289\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 31.20509147644043\n",
      "Critic Loss: 5.149467468261719\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 22.841899871826172\n",
      "Critic Loss: 6.96025276184082\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 37.17998123168945\n",
      "Critic Loss: 12.750587463378906\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 20.204387664794922\n",
      "Critic Loss: 7.734521865844727\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 24.86817741394043\n",
      "Critic Loss: 5.449095249176025\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 28.357025146484375\n",
      "Critic Loss: 8.522825241088867\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 22.47187042236328\n",
      "Critic Loss: 7.641324520111084\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 27.39836883544922\n",
      "Critic Loss: 4.551814556121826\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 24.58742332458496\n",
      "Critic Loss: 6.235048770904541\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 28.74917221069336\n",
      "Critic Loss: 7.321786880493164\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 22.910985946655273\n",
      "Critic Loss: 6.928053855895996\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 23.110309600830078\n",
      "Critic Loss: 4.437128067016602\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 25.014320373535156\n",
      "Critic Loss: 7.135025978088379\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 29.128896713256836\n",
      "Critic Loss: 12.290807723999023\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 26.109079360961914\n",
      "Critic Loss: 8.333671569824219\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 15.574438095092773\n",
      "Critic Loss: 7.547120571136475\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 19.83171272277832\n",
      "Critic Loss: 11.783084869384766\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 16.477134704589844\n",
      "Critic Loss: 4.38408088684082\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 16.141530990600586\n",
      "Critic Loss: 10.255306243896484\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 28.839555740356445\n",
      "Critic Loss: 7.521190166473389\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 23.404300689697266\n",
      "Critic Loss: 5.704875469207764\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 19.029890060424805\n",
      "Critic Loss: 7.966433525085449\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 22.1558837890625\n",
      "Critic Loss: 5.770079135894775\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 27.79767608642578\n",
      "Critic Loss: 9.619234085083008\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 24.913576126098633\n",
      "Critic Loss: 7.0813727378845215\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 12.641593933105469\n",
      "Critic Loss: 6.406630516052246\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 17.01601219177246\n",
      "Critic Loss: 12.462127685546875\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 17.296194076538086\n",
      "Critic Loss: 5.489007949829102\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 27.941118240356445\n",
      "Critic Loss: 13.790925025939941\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 18.0085506439209\n",
      "Critic Loss: 10.24798583984375\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 13.059066772460938\n",
      "Critic Loss: 7.735710144042969\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 35.45115280151367\n",
      "Critic Loss: 8.518190383911133\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 24.09232521057129\n",
      "Critic Loss: 6.329996585845947\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 22.090269088745117\n",
      "Critic Loss: 5.552361488342285\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 24.032936096191406\n",
      "Critic Loss: 9.500980377197266\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 28.00796890258789\n",
      "Critic Loss: 5.188883304595947\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 18.763118743896484\n",
      "Critic Loss: 4.791253089904785\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 20.272327423095703\n",
      "Critic Loss: 8.762453079223633\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 25.053586959838867\n",
      "Critic Loss: 3.7521934509277344\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 22.649946212768555\n",
      "Critic Loss: 6.250769138336182\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 24.718605041503906\n",
      "Critic Loss: 8.943117141723633\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 20.011943817138672\n",
      "Critic Loss: 5.689330101013184\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 21.4570255279541\n",
      "Critic Loss: 3.0800318717956543\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 21.567758560180664\n",
      "Critic Loss: 8.044146537780762\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 18.749666213989258\n",
      "Critic Loss: 8.286839485168457\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 28.592790603637695\n",
      "Critic Loss: 4.2052130699157715\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 20.67615509033203\n",
      "Critic Loss: 4.711112976074219\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 20.836585998535156\n",
      "Critic Loss: 5.919451713562012\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 18.274648666381836\n",
      "Critic Loss: 8.51789665222168\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 28.022838592529297\n",
      "Critic Loss: 6.200728416442871\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 13.101430892944336\n",
      "Critic Loss: 6.720708847045898\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 30.576658248901367\n",
      "Critic Loss: 9.153532981872559\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 23.561504364013672\n",
      "Critic Loss: 9.407180786132812\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 25.70433807373047\n",
      "Critic Loss: 6.860178470611572\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 26.1310977935791\n",
      "Critic Loss: 8.510876655578613\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 14.057853698730469\n",
      "Critic Loss: 2.8908281326293945\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 37.43596267700195\n",
      "Critic Loss: 5.074619293212891\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 20.074642181396484\n",
      "Critic Loss: 6.512049674987793\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 12.8836088180542\n",
      "Critic Loss: 9.092536926269531\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 23.35010528564453\n",
      "Critic Loss: 12.206722259521484\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 31.817121505737305\n",
      "Critic Loss: 12.02220630645752\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 27.121826171875\n",
      "Critic Loss: 11.707266807556152\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a97d2954874096abe3215ff8fb6ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>80.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>59.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>25.75761</td></tr><tr><td>Loss/Critic_loss</td><td>11.70727</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.23926</td></tr><tr><td>Loss/KL_divergence</td><td>0.03376</td></tr><tr><td>Loss/Policy_loss</td><td>25.79449</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>27.12183</td></tr><tr><td>Metric/Explained_variance</td><td>0.37309</td></tr><tr><td>Reward/Mean_train_reward</td><td>-49.461</td></tr><tr><td>Reward/Mean_val_reward</td><td>-58.4216</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-55.57093</td></tr><tr><td>global_step</td><td>82</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-35</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/shxgbxpq' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/shxgbxpq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_183448-shxgbxpq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vcqkp026 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0030913991713651533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0009607361440878124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.023202226276275342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9183952723226634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 5.092305459543365e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.173114148384762e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_184234-vcqkp026</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/vcqkp026' target=\"_blank\">unique-sweep-36</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vcqkp026' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vcqkp026</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0030913991713651533, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009607361440878124, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.023202226276275342, 'epochs': 10, 'exponential_factor': 0.9183952723226634, 'gamma': 0.99, 'hidden_sizes': [150, 350, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 5.092305459543365e-05, 'l2_factor': 6.173114148384762e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0030913991713651533, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009607361440878124, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.023202226276275342, 'epochs': 10, 'exponential_factor': 0.9183952723226634, 'gamma': 0.99, 'l1_factor': 5.092305459543365e-05, 'l2_factor': 6.173114148384762e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0030913991713651533, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009607361440878124, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.023202226276275342, 'epochs': 10, 'exponential_factor': 0.9183952723226634, 'gamma': 0.99, 'l1_factor': 5.092305459543365e-05, 'l2_factor': 6.173114148384762e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0030913991713651533, 'critic_lr': 0.0009607361440878124, 'decay_method': 'exponential', 'exponential_factor': 0.9183952723226634, 'value_loss_factor': 1, 'entropy': 0.023202226276275342, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 5.092305459543365e-05, 'l2_factor': 6.173114148384762e-06, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [150, 350, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 13.357367515563965\n",
      "Critic Loss: 15.707079887390137\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 56.6252326965332\n",
      "Critic Loss: 56.14033508300781\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 8.31497859954834\n",
      "Critic Loss: 12.655654907226562\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 30.871835708618164\n",
      "Critic Loss: 30.10149574279785\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 16.218599319458008\n",
      "Critic Loss: 20.544788360595703\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 4.030882835388184\n",
      "Critic Loss: 11.443833351135254\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 9.13636302947998\n",
      "Critic Loss: 13.273639678955078\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 18.331138610839844\n",
      "Critic Loss: 22.37316131591797\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 2.9422500133514404\n",
      "Critic Loss: 9.193721771240234\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 5.021598815917969\n",
      "Critic Loss: 13.169934272766113\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 11.312767028808594\n",
      "Critic Loss: 15.835650444030762\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 11.813614845275879\n",
      "Critic Loss: 15.88258171081543\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 15.646806716918945\n",
      "Critic Loss: 16.546403884887695\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 15.911066055297852\n",
      "Critic Loss: 15.636431694030762\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 7.062016487121582\n",
      "Critic Loss: 11.024393081665039\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 7.353155612945557\n",
      "Critic Loss: 12.665352821350098\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 9.875775337219238\n",
      "Critic Loss: 14.611614227294922\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 10.485858917236328\n",
      "Critic Loss: 11.61146354675293\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 14.940675735473633\n",
      "Critic Loss: 16.280479431152344\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 8.880105972290039\n",
      "Critic Loss: 11.723231315612793\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 14.06666088104248\n",
      "Critic Loss: 18.10293960571289\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 13.02107048034668\n",
      "Critic Loss: 14.469449996948242\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 14.410015106201172\n",
      "Critic Loss: 13.559098243713379\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 18.45106315612793\n",
      "Critic Loss: 17.651674270629883\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 14.175264358520508\n",
      "Critic Loss: 16.027225494384766\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.9887627363204956\n",
      "Critic Loss: 10.593599319458008\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 16.054405212402344\n",
      "Critic Loss: 17.66971206665039\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 15.35137939453125\n",
      "Critic Loss: 15.65482234954834\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 13.696767807006836\n",
      "Critic Loss: 11.611594200134277\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 23.064983367919922\n",
      "Critic Loss: 18.103300094604492\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 14.129725456237793\n",
      "Critic Loss: 13.829790115356445\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 13.996538162231445\n",
      "Critic Loss: 10.712722778320312\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 15.754973411560059\n",
      "Critic Loss: 11.094915390014648\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 19.88833236694336\n",
      "Critic Loss: 15.132078170776367\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 16.250356674194336\n",
      "Critic Loss: 12.298227310180664\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 12.868633270263672\n",
      "Critic Loss: 9.660561561584473\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 13.867959022521973\n",
      "Critic Loss: 11.695878982543945\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 26.565271377563477\n",
      "Critic Loss: 18.19550132751465\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 17.750442504882812\n",
      "Critic Loss: 13.617337226867676\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 24.00662612915039\n",
      "Critic Loss: 16.19049072265625\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 14.754883766174316\n",
      "Critic Loss: 10.693148612976074\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 15.0913724899292\n",
      "Critic Loss: 13.530451774597168\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 13.455467224121094\n",
      "Critic Loss: 8.54522705078125\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 20.058828353881836\n",
      "Critic Loss: 13.205816268920898\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 19.627866744995117\n",
      "Critic Loss: 14.03381633758545\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 17.92790412902832\n",
      "Critic Loss: 11.745877265930176\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 16.022642135620117\n",
      "Critic Loss: 14.048294067382812\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 11.536627769470215\n",
      "Critic Loss: 10.952890396118164\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 17.69461441040039\n",
      "Critic Loss: 12.140044212341309\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 13.581254959106445\n",
      "Critic Loss: 10.306031227111816\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 15.880330085754395\n",
      "Critic Loss: 13.938949584960938\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 19.538631439208984\n",
      "Critic Loss: 13.300285339355469\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 15.920743942260742\n",
      "Critic Loss: 13.190258026123047\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 17.238679885864258\n",
      "Critic Loss: 13.091073036193848\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 17.61030387878418\n",
      "Critic Loss: 12.646086692810059\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 14.450287818908691\n",
      "Critic Loss: 10.807109832763672\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 14.188435554504395\n",
      "Critic Loss: 9.890459060668945\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 20.33897590637207\n",
      "Critic Loss: 13.571269035339355\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 19.603246688842773\n",
      "Critic Loss: 14.686190605163574\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 18.65553855895996\n",
      "Critic Loss: 12.06955623626709\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 21.59029769897461\n",
      "Critic Loss: 12.859474182128906\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 17.208332061767578\n",
      "Critic Loss: 10.592764854431152\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 14.026713371276855\n",
      "Critic Loss: 11.087484359741211\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 15.350220680236816\n",
      "Critic Loss: 12.600839614868164\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 14.835660934448242\n",
      "Critic Loss: 9.20993423461914\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 18.450864791870117\n",
      "Critic Loss: 13.674052238464355\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 29.08955192565918\n",
      "Critic Loss: 18.23407554626465\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 20.723119735717773\n",
      "Critic Loss: 14.002948760986328\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 12.195361137390137\n",
      "Critic Loss: 13.217472076416016\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 19.43682289123535\n",
      "Critic Loss: 13.849888801574707\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 27.180192947387695\n",
      "Critic Loss: 18.509151458740234\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 25.381072998046875\n",
      "Critic Loss: 17.5059871673584\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 14.430683135986328\n",
      "Critic Loss: 10.321613311767578\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 20.47806167602539\n",
      "Critic Loss: 14.753454208374023\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 25.239097595214844\n",
      "Critic Loss: 16.993568420410156\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 12.00385856628418\n",
      "Critic Loss: 9.900338172912598\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 15.751956939697266\n",
      "Critic Loss: 10.9849214553833\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 13.857220649719238\n",
      "Critic Loss: 10.179878234863281\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 21.284618377685547\n",
      "Critic Loss: 14.26654052734375\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 14.095498085021973\n",
      "Critic Loss: 9.380026817321777\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 16.230379104614258\n",
      "Critic Loss: 13.771699905395508\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 17.73223304748535\n",
      "Critic Loss: 12.061429023742676\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 17.66969108581543\n",
      "Critic Loss: 13.602474212646484\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 21.84123420715332\n",
      "Critic Loss: 13.55438232421875\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 24.736961364746094\n",
      "Critic Loss: 16.34151268005371\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 21.939760208129883\n",
      "Critic Loss: 15.143416404724121\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 19.85672950744629\n",
      "Critic Loss: 13.481610298156738\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 16.861923217773438\n",
      "Critic Loss: 13.094991683959961\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 14.588290214538574\n",
      "Critic Loss: 12.80280590057373\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588aa21c41074f22b8cf689919e89f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>54.33333</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>51.9</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>13.93889</td></tr><tr><td>Loss/Critic_loss</td><td>12.80281</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.60491</td></tr><tr><td>Loss/KL_divergence</td><td>-0.04137</td></tr><tr><td>Loss/Policy_loss</td><td>13.95292</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>14.58829</td></tr><tr><td>Metric/Explained_variance</td><td>0.35009</td></tr><tr><td>Reward/Mean_train_reward</td><td>-49.78666</td></tr><tr><td>Reward/Mean_val_reward</td><td>-53.1251</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-54.54227</td></tr><tr><td>global_step</td><td>89</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-36</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vcqkp026' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vcqkp026</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_184234-vcqkp026\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t578xlj3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0008504388110560009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0017274736131631004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.009630122685964766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8615059698247903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 6.595268777844997e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.583700308588196e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_184930-t578xlj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/t578xlj3' target=\"_blank\">good-sweep-37</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/t578xlj3' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/t578xlj3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0008504388110560009, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017274736131631004, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009630122685964766, 'epochs': 10, 'exponential_factor': 0.8615059698247903, 'gamma': 0.95, 'hidden_sizes': [150, 250, 250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 6.595268777844997e-06, 'l2_factor': 7.583700308588196e-05, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0008504388110560009, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017274736131631004, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009630122685964766, 'epochs': 10, 'exponential_factor': 0.8615059698247903, 'gamma': 0.95, 'l1_factor': 6.595268777844997e-06, 'l2_factor': 7.583700308588196e-05, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0008504388110560009, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0017274736131631004, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009630122685964766, 'epochs': 10, 'exponential_factor': 0.8615059698247903, 'gamma': 0.95, 'l1_factor': 6.595268777844997e-06, 'l2_factor': 7.583700308588196e-05, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0008504388110560009, 'critic_lr': 0.0017274736131631004, 'decay_method': 'exponential', 'exponential_factor': 0.8615059698247903, 'value_loss_factor': 1, 'entropy': 0.009630122685964766, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 6.595268777844997e-06, 'l2_factor': 7.583700308588196e-05, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [150, 250, 250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 14.219182014465332\n",
      "Critic Loss: 17.18879508972168\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 15.006900787353516\n",
      "Critic Loss: 14.914060592651367\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 10.988784790039062\n",
      "Critic Loss: 13.997772216796875\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 13.691996574401855\n",
      "Critic Loss: 12.834246635437012\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 17.056461334228516\n",
      "Critic Loss: 14.191290855407715\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 14.387660026550293\n",
      "Critic Loss: 12.562419891357422\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 17.2954044342041\n",
      "Critic Loss: 12.31859302520752\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 14.798853874206543\n",
      "Critic Loss: 12.203035354614258\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 15.224699974060059\n",
      "Critic Loss: 12.929624557495117\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 11.498030662536621\n",
      "Critic Loss: 10.441908836364746\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 15.163289070129395\n",
      "Critic Loss: 12.931427001953125\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 10.591845512390137\n",
      "Critic Loss: 8.88940715789795\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 10.89717960357666\n",
      "Critic Loss: 11.908370971679688\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 7.515870571136475\n",
      "Critic Loss: 7.566836833953857\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 9.627242088317871\n",
      "Critic Loss: 8.895952224731445\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 2.773822069168091\n",
      "Critic Loss: 7.4150390625\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 2.9611496925354004\n",
      "Critic Loss: 6.704260349273682\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 8.251444816589355\n",
      "Critic Loss: 8.097986221313477\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 8.070967674255371\n",
      "Critic Loss: 8.933965682983398\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 6.735777378082275\n",
      "Critic Loss: 9.074920654296875\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 8.682099342346191\n",
      "Critic Loss: 8.396196365356445\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 5.872915744781494\n",
      "Critic Loss: 8.825618743896484\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 8.362545013427734\n",
      "Critic Loss: 9.629463195800781\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 6.39085578918457\n",
      "Critic Loss: 7.354404926300049\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 7.608026504516602\n",
      "Critic Loss: 8.883816719055176\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 10.193997383117676\n",
      "Critic Loss: 7.954958438873291\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 6.382064342498779\n",
      "Critic Loss: 7.362624645233154\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 6.8637847900390625\n",
      "Critic Loss: 7.380244731903076\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 7.186012268066406\n",
      "Critic Loss: 7.312687397003174\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 10.234509468078613\n",
      "Critic Loss: 8.803862571716309\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 6.0280914306640625\n",
      "Critic Loss: 4.421693325042725\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 4.186452865600586\n",
      "Critic Loss: 6.031702041625977\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 6.088042736053467\n",
      "Critic Loss: 7.147801399230957\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 7.877065181732178\n",
      "Critic Loss: 9.337906837463379\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 6.827794075012207\n",
      "Critic Loss: 7.153883457183838\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 11.034280776977539\n",
      "Critic Loss: 8.930949211120605\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 5.9963698387146\n",
      "Critic Loss: 7.421738624572754\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 10.049705505371094\n",
      "Critic Loss: 8.098642349243164\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 5.135323524475098\n",
      "Critic Loss: 7.06815242767334\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 11.117864608764648\n",
      "Critic Loss: 9.292397499084473\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 4.901670932769775\n",
      "Critic Loss: 6.651869297027588\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 3.417391061782837\n",
      "Critic Loss: 7.778936386108398\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 9.527210235595703\n",
      "Critic Loss: 8.600275039672852\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 10.380735397338867\n",
      "Critic Loss: 8.74464225769043\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 5.151674270629883\n",
      "Critic Loss: 8.641623497009277\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 5.549538612365723\n",
      "Critic Loss: 7.725306034088135\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 10.35175609588623\n",
      "Critic Loss: 7.741297721862793\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 8.896970748901367\n",
      "Critic Loss: 7.54564094543457\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 7.5395827293396\n",
      "Critic Loss: 7.2920050621032715\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 3.7545855045318604\n",
      "Critic Loss: 6.717465400695801\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 10.13073444366455\n",
      "Critic Loss: 9.746826171875\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 9.387063980102539\n",
      "Critic Loss: 6.942193031311035\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 3.9004909992218018\n",
      "Critic Loss: 6.509172439575195\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 8.573896408081055\n",
      "Critic Loss: 6.355267524719238\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 9.54676628112793\n",
      "Critic Loss: 8.98397159576416\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 8.530667304992676\n",
      "Critic Loss: 7.332991123199463\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 4.646048069000244\n",
      "Critic Loss: 5.218461036682129\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 7.7732086181640625\n",
      "Critic Loss: 7.403589725494385\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 8.388752937316895\n",
      "Critic Loss: 6.734043121337891\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 8.836421966552734\n",
      "Critic Loss: 9.012414932250977\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 6.981134414672852\n",
      "Critic Loss: 7.108086585998535\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 8.49963092803955\n",
      "Critic Loss: 8.138154029846191\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 3.3302013874053955\n",
      "Critic Loss: 6.330721855163574\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 10.54859733581543\n",
      "Critic Loss: 7.436483860015869\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 10.59620189666748\n",
      "Critic Loss: 8.73117446899414\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 9.667159080505371\n",
      "Critic Loss: 7.78891134262085\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 8.619454383850098\n",
      "Critic Loss: 8.324994087219238\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 3.1693832874298096\n",
      "Critic Loss: 5.738785266876221\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 8.719318389892578\n",
      "Critic Loss: 7.524694442749023\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 10.456506729125977\n",
      "Critic Loss: 8.333897590637207\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 7.396158695220947\n",
      "Critic Loss: 7.627789497375488\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 8.715606689453125\n",
      "Critic Loss: 6.996737003326416\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 6.17227029800415\n",
      "Critic Loss: 6.654258728027344\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 6.523681163787842\n",
      "Critic Loss: 7.0744099617004395\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 7.9937543869018555\n",
      "Critic Loss: 8.667953491210938\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 3.8794329166412354\n",
      "Critic Loss: 6.689849853515625\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 8.875186920166016\n",
      "Critic Loss: 7.12493371963501\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 7.608404636383057\n",
      "Critic Loss: 6.887447357177734\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 10.910537719726562\n",
      "Critic Loss: 9.682083129882812\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 5.611997127532959\n",
      "Critic Loss: 8.957313537597656\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 9.471855163574219\n",
      "Critic Loss: 8.400606155395508\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 7.901479721069336\n",
      "Critic Loss: 7.7519354820251465\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5e0a9c5377422c9a346f06824020f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>63.33333</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>66.9</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>7.75061</td></tr><tr><td>Loss/Critic_loss</td><td>7.75194</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.109</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0101</td></tr><tr><td>Loss/Policy_loss</td><td>7.76129</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>7.90148</td></tr><tr><td>Metric/Explained_variance</td><td>0.49538</td></tr><tr><td>Reward/Mean_train_reward</td><td>-45.67101</td></tr><tr><td>Reward/Mean_val_reward</td><td>-43.3181</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-44.55441</td></tr><tr><td>global_step</td><td>82</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-sweep-37</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/t578xlj3' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/t578xlj3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_184930-t578xlj3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8vfoy2ai with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0006364036308445669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00038795282076171126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.00026168117600784815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9242611684482492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.0649529336677958e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.4858877217694717e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_185445-8vfoy2ai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/8vfoy2ai' target=\"_blank\">icy-sweep-38</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8vfoy2ai' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8vfoy2ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.0006364036308445669, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00038795282076171126, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00026168117600784815, 'epochs': 10, 'exponential_factor': 0.9242611684482492, 'gamma': 0.9, 'hidden_sizes': [350, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.0649529336677958e-05, 'l2_factor': 1.4858877217694717e-06, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0006364036308445669, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00038795282076171126, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00026168117600784815, 'epochs': 10, 'exponential_factor': 0.9242611684482492, 'gamma': 0.9, 'l1_factor': 1.0649529336677958e-05, 'l2_factor': 1.4858877217694717e-06, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0006364036308445669, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00038795282076171126, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.00026168117600784815, 'epochs': 10, 'exponential_factor': 0.9242611684482492, 'gamma': 0.9, 'l1_factor': 1.0649529336677958e-05, 'l2_factor': 1.4858877217694717e-06, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0006364036308445669, 'critic_lr': 0.00038795282076171126, 'decay_method': 'exponential', 'exponential_factor': 0.9242611684482492, 'value_loss_factor': 1, 'entropy': 0.00026168117600784815, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.0649529336677958e-05, 'l2_factor': 1.4858877217694717e-06, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.08516397327184677\n",
      "Critic Loss: 23.853633880615234\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.10959239304065704\n",
      "Critic Loss: 10.143474578857422\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.10208181291818619\n",
      "Critic Loss: 7.808505535125732\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.10750090330839157\n",
      "Critic Loss: 11.720061302185059\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.10890413820743561\n",
      "Critic Loss: 7.238044261932373\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.08548495173454285\n",
      "Critic Loss: 6.9574666023254395\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.11882740259170532\n",
      "Critic Loss: 5.726682662963867\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.09740027040243149\n",
      "Critic Loss: 5.829296112060547\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.09458751231431961\n",
      "Critic Loss: 5.046892166137695\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.09153062105178833\n",
      "Critic Loss: 3.4427130222320557\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.09064459800720215\n",
      "Critic Loss: 4.105648040771484\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.10993809998035431\n",
      "Critic Loss: 2.8138551712036133\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.09744831919670105\n",
      "Critic Loss: 2.453880786895752\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.11120196431875229\n",
      "Critic Loss: 3.0713961124420166\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.12205514311790466\n",
      "Critic Loss: 2.4416050910949707\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.10625313967466354\n",
      "Critic Loss: 3.0452563762664795\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.09551095217466354\n",
      "Critic Loss: 3.1827049255371094\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.09673801064491272\n",
      "Critic Loss: 4.242793083190918\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.10413474589586258\n",
      "Critic Loss: 2.9685349464416504\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.10364110767841339\n",
      "Critic Loss: 3.385676860809326\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.09427982568740845\n",
      "Critic Loss: 2.995375871658325\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.12064793705940247\n",
      "Critic Loss: 3.0177698135375977\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.09974630922079086\n",
      "Critic Loss: 2.6319258213043213\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.11613473296165466\n",
      "Critic Loss: 2.4355127811431885\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.1253850907087326\n",
      "Critic Loss: 2.091057062149048\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.10122303664684296\n",
      "Critic Loss: 2.6897764205932617\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.10287225246429443\n",
      "Critic Loss: 3.359365224838257\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.10919685661792755\n",
      "Critic Loss: 1.6563042402267456\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.10474545508623123\n",
      "Critic Loss: 2.6130027770996094\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.11929991841316223\n",
      "Critic Loss: 2.3487038612365723\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.11811757832765579\n",
      "Critic Loss: 2.1623260974884033\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.11776027083396912\n",
      "Critic Loss: 1.2913638353347778\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.10467728227376938\n",
      "Critic Loss: 2.0742785930633545\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.10645721852779388\n",
      "Critic Loss: 3.4448812007904053\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.12722662091255188\n",
      "Critic Loss: 2.707592248916626\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.11961272358894348\n",
      "Critic Loss: 2.6097099781036377\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.1107860654592514\n",
      "Critic Loss: 2.049083948135376\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.11846628785133362\n",
      "Critic Loss: 1.898756504058838\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.10548295825719833\n",
      "Critic Loss: 2.734027862548828\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.12527455389499664\n",
      "Critic Loss: 2.7957615852355957\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.11449187994003296\n",
      "Critic Loss: 2.30224871635437\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.1141122356057167\n",
      "Critic Loss: 2.050084114074707\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.11989060789346695\n",
      "Critic Loss: 2.6137537956237793\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.11126011610031128\n",
      "Critic Loss: 2.5950632095336914\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.10959472507238388\n",
      "Critic Loss: 2.617858648300171\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.1256299763917923\n",
      "Critic Loss: 2.1928369998931885\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.12363026291131973\n",
      "Critic Loss: 2.922598361968994\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.12486830353736877\n",
      "Critic Loss: 1.9495776891708374\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.11374031752347946\n",
      "Critic Loss: 2.610116720199585\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.11879906803369522\n",
      "Critic Loss: 2.876068592071533\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.11167451739311218\n",
      "Critic Loss: 3.7760009765625\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.12506107985973358\n",
      "Critic Loss: 2.081885814666748\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.14098651707172394\n",
      "Critic Loss: 2.7266345024108887\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.1083337739109993\n",
      "Critic Loss: 2.520415782928467\n",
      "\n",
      "New best validation reward reached in update [54/200]\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.12806333601474762\n",
      "Critic Loss: 2.2871198654174805\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.12368873506784439\n",
      "Critic Loss: 2.5877881050109863\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.11357889324426651\n",
      "Critic Loss: 2.551384687423706\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.11480319499969482\n",
      "Critic Loss: 2.733010768890381\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.1128489300608635\n",
      "Critic Loss: 3.068641424179077\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.12289509177207947\n",
      "Critic Loss: 1.5066865682601929\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.11004374921321869\n",
      "Critic Loss: 1.9513448476791382\n",
      "\n",
      "New best validation reward reached in update [61/200]\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.1323893517255783\n",
      "Critic Loss: 2.6008646488189697\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.12647613883018494\n",
      "Critic Loss: 2.7693536281585693\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.11598320305347443\n",
      "Critic Loss: 2.928313970565796\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.130963996052742\n",
      "Critic Loss: 2.1794910430908203\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.1336347907781601\n",
      "Critic Loss: 2.495929479598999\n",
      "\n",
      "New best validation reward reached in update [66/200]\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.11793707311153412\n",
      "Critic Loss: 2.0011327266693115\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.09897743165493011\n",
      "Critic Loss: 3.580310106277466\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.11472346633672714\n",
      "Critic Loss: 2.2347285747528076\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.15155825018882751\n",
      "Critic Loss: 2.7454822063446045\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.1639573872089386\n",
      "Critic Loss: 1.667215347290039\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.1171010360121727\n",
      "Critic Loss: 2.8997762203216553\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.12220653891563416\n",
      "Critic Loss: 1.6975961923599243\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.11922422051429749\n",
      "Critic Loss: 3.0226523876190186\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.12697231769561768\n",
      "Critic Loss: 2.3723535537719727\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.13492366671562195\n",
      "Critic Loss: 1.838391900062561\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.12493565678596497\n",
      "Critic Loss: 2.017167568206787\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.1370391696691513\n",
      "Critic Loss: 1.9755302667617798\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.12918932735919952\n",
      "Critic Loss: 2.1339011192321777\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.1330772489309311\n",
      "Critic Loss: 2.9378607273101807\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.12383798509836197\n",
      "Critic Loss: 2.454221248626709\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.13463260233402252\n",
      "Critic Loss: 2.2495696544647217\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.12668952345848083\n",
      "Critic Loss: 1.3262622356414795\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.12758493423461914\n",
      "Critic Loss: 2.671565055847168\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.13170745968818665\n",
      "Critic Loss: 1.5481719970703125\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.12913818657398224\n",
      "Critic Loss: 2.369873285293579\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.13149815797805786\n",
      "Critic Loss: 2.3048746585845947\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.12693417072296143\n",
      "Critic Loss: 3.0490148067474365\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.1294766217470169\n",
      "Critic Loss: 2.1648712158203125\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.1371896117925644\n",
      "Critic Loss: 2.1323869228363037\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.1341489553451538\n",
      "Critic Loss: 2.1127724647521973\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.1334122270345688\n",
      "Critic Loss: 2.4947237968444824\n",
      "\n",
      "New best validation reward reached in update [92/200]\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.1471947431564331\n",
      "Critic Loss: 2.3003525733947754\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.12929780781269073\n",
      "Critic Loss: 2.947261095046997\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.1218847706913948\n",
      "Critic Loss: 2.1937978267669678\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.13458193838596344\n",
      "Critic Loss: 2.4883790016174316\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.1281013935804367\n",
      "Critic Loss: 2.385737180709839\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.11744861304759979\n",
      "Critic Loss: 1.68617844581604\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374a2da0782f40d38b0c93fbe1c5f4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>137.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>128.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00833</td></tr><tr><td>Loss/Critic_loss</td><td>1.68618</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.42922</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00862</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00821</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.11745</td></tr><tr><td>Metric/Explained_variance</td><td>0.44196</td></tr><tr><td>Reward/Mean_train_reward</td><td>12.416</td></tr><tr><td>Reward/Mean_val_reward</td><td>8.955</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>6.35275</td></tr><tr><td>global_step</td><td>98</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-38</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8vfoy2ai' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8vfoy2ai</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_185445-8vfoy2ai\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t2drmuwi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.004615122567006594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0010286915583778942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.015364899753243365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9892590384753888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0006194302505217875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0003090031218212567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_190449-t2drmuwi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/t2drmuwi' target=\"_blank\">northern-sweep-39</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/t2drmuwi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/t2drmuwi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.004615122567006594, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0010286915583778942, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015364899753243365, 'epochs': 10, 'exponential_factor': 0.9892590384753888, 'gamma': 0.95, 'hidden_sizes': [350, 350, 150, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0006194302505217875, 'l2_factor': 0.0003090031218212567, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.004615122567006594, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0010286915583778942, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015364899753243365, 'epochs': 10, 'exponential_factor': 0.9892590384753888, 'gamma': 0.95, 'l1_factor': 0.0006194302505217875, 'l2_factor': 0.0003090031218212567, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.004615122567006594, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0010286915583778942, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.015364899753243365, 'epochs': 10, 'exponential_factor': 0.9892590384753888, 'gamma': 0.95, 'l1_factor': 0.0006194302505217875, 'l2_factor': 0.0003090031218212567, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.004615122567006594, 'critic_lr': 0.0010286915583778942, 'decay_method': 'exponential', 'exponential_factor': 0.9892590384753888, 'value_loss_factor': 1, 'entropy': 0.015364899753243365, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0006194302505217875, 'l2_factor': 0.0003090031218212567, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [350, 350, 150, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 22.29546546936035\n",
      "Critic Loss: 14.70500659942627\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 20.805545806884766\n",
      "Critic Loss: 13.40176010131836\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 18.604001998901367\n",
      "Critic Loss: 13.631209373474121\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 21.47510528564453\n",
      "Critic Loss: 15.994564056396484\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 37.082305908203125\n",
      "Critic Loss: 29.432201385498047\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 44.8226318359375\n",
      "Critic Loss: 38.83297348022461\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 89.29562377929688\n",
      "Critic Loss: 87.17049407958984\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 82.00885009765625\n",
      "Critic Loss: 87.59524536132812\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 54.14320373535156\n",
      "Critic Loss: 43.936676025390625\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 96.21807861328125\n",
      "Critic Loss: 100.09851837158203\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 93.81644439697266\n",
      "Critic Loss: 94.81382751464844\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 93.36552429199219\n",
      "Critic Loss: 90.06201171875\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 91.23068237304688\n",
      "Critic Loss: 84.46473693847656\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 26.377193450927734\n",
      "Critic Loss: 35.927947998046875\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 48.845664978027344\n",
      "Critic Loss: 9.347088813781738\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 21.856948852539062\n",
      "Critic Loss: 27.12417984008789\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 46.178443908691406\n",
      "Critic Loss: 25.0584659576416\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 33.41036605834961\n",
      "Critic Loss: 23.589557647705078\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 26.834716796875\n",
      "Critic Loss: 20.542827606201172\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 24.182147979736328\n",
      "Critic Loss: 15.375450134277344\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 27.44590950012207\n",
      "Critic Loss: 11.675960540771484\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 42.66337585449219\n",
      "Critic Loss: 9.362565994262695\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 49.669334411621094\n",
      "Critic Loss: 8.300806045532227\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 38.701969146728516\n",
      "Critic Loss: 7.902381896972656\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 35.124996185302734\n",
      "Critic Loss: 8.137248992919922\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 29.017175674438477\n",
      "Critic Loss: 10.176607131958008\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 30.60401153564453\n",
      "Critic Loss: 5.678093433380127\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 25.43497657775879\n",
      "Critic Loss: 7.839328289031982\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 32.6417121887207\n",
      "Critic Loss: 7.352931499481201\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 30.385183334350586\n",
      "Critic Loss: 6.9041900634765625\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 27.294828414916992\n",
      "Critic Loss: 7.836218357086182\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 30.815128326416016\n",
      "Critic Loss: 8.582803726196289\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 30.628950119018555\n",
      "Critic Loss: 8.781869888305664\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 26.969572067260742\n",
      "Critic Loss: 8.498998641967773\n",
      "\n",
      "New best validation reward reached in update [34/200]\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 27.222797393798828\n",
      "Critic Loss: 8.067789077758789\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 24.47300910949707\n",
      "Critic Loss: 7.1403656005859375\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 24.21065902709961\n",
      "Critic Loss: 6.818192481994629\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 20.977163314819336\n",
      "Critic Loss: 11.860628128051758\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 13.377327919006348\n",
      "Critic Loss: 16.129924774169922\n",
      "\n",
      "New best validation reward reached in update [39/200]\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 12.649636268615723\n",
      "Critic Loss: 16.451955795288086\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 12.402791023254395\n",
      "Critic Loss: 15.94970989227295\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 12.332986831665039\n",
      "Critic Loss: 16.25069808959961\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 13.26503849029541\n",
      "Critic Loss: 15.83526611328125\n",
      "\n",
      "New best validation reward reached in update [43/200]\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 11.057794570922852\n",
      "Critic Loss: 13.780830383300781\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 16.405080795288086\n",
      "Critic Loss: 13.730901718139648\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 13.682538986206055\n",
      "Critic Loss: 13.578180313110352\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 11.674810409545898\n",
      "Critic Loss: 12.83721923828125\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 12.077199935913086\n",
      "Critic Loss: 14.155521392822266\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 12.796314239501953\n",
      "Critic Loss: 12.357799530029297\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 12.561366081237793\n",
      "Critic Loss: 11.465354919433594\n",
      "\n",
      "New best validation reward reached in update [50/200]\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 13.173519134521484\n",
      "Critic Loss: 12.692391395568848\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 13.737841606140137\n",
      "Critic Loss: 11.458803176879883\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 11.340136528015137\n",
      "Critic Loss: 11.263630867004395\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 10.157970428466797\n",
      "Critic Loss: 10.576708793640137\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 10.9957914352417\n",
      "Critic Loss: 12.030588150024414\n",
      "\n",
      "New best validation reward reached in update [55/200]\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 10.133437156677246\n",
      "Critic Loss: 9.218915939331055\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 9.760260581970215\n",
      "Critic Loss: 9.509206771850586\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 9.760953903198242\n",
      "Critic Loss: 9.360218048095703\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 9.604625701904297\n",
      "Critic Loss: 8.809122085571289\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 10.405430793762207\n",
      "Critic Loss: 8.369481086730957\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 10.809942245483398\n",
      "Critic Loss: 8.275300025939941\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 10.399852752685547\n",
      "Critic Loss: 9.548563003540039\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 12.145424842834473\n",
      "Critic Loss: 7.148200511932373\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 9.896589279174805\n",
      "Critic Loss: 8.702361106872559\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 11.008376121520996\n",
      "Critic Loss: 7.342958927154541\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 9.514681816101074\n",
      "Critic Loss: 6.936065673828125\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 9.309416770935059\n",
      "Critic Loss: 6.897704601287842\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 9.040031433105469\n",
      "Critic Loss: 6.4977641105651855\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 10.717418670654297\n",
      "Critic Loss: 7.632356643676758\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 10.16893196105957\n",
      "Critic Loss: 6.082175254821777\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 8.673408508300781\n",
      "Critic Loss: 6.35996675491333\n",
      "\n",
      "New best validation reward reached in update [71/200]\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 10.316633224487305\n",
      "Critic Loss: 5.7555646896362305\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 9.089055061340332\n",
      "Critic Loss: 6.574309825897217\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 9.064066886901855\n",
      "Critic Loss: 5.755665302276611\n",
      "\n",
      "New best validation reward reached in update [74/200]\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 10.678539276123047\n",
      "Critic Loss: 5.285788536071777\n",
      "\n",
      "New best validation reward reached in update [75/200]\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 8.61568832397461\n",
      "Critic Loss: 4.281564712524414\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 9.054545402526855\n",
      "Critic Loss: 3.9650051593780518\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 8.51165771484375\n",
      "Critic Loss: 4.556748390197754\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 7.532491207122803\n",
      "Critic Loss: 3.5931906700134277\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 8.141036987304688\n",
      "Critic Loss: 3.3195130825042725\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 8.161251068115234\n",
      "Critic Loss: 4.275387763977051\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 7.902791976928711\n",
      "Critic Loss: 3.601755142211914\n",
      "\n",
      "New best validation reward reached in update [82/200]\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 8.326847076416016\n",
      "Critic Loss: 3.634819507598877\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 6.239799499511719\n",
      "Critic Loss: 3.7564525604248047\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 8.3310546875\n",
      "Critic Loss: 6.181870460510254\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 6.3781867027282715\n",
      "Critic Loss: 3.5328433513641357\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 7.754455089569092\n",
      "Critic Loss: 3.698695182800293\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 7.704727649688721\n",
      "Critic Loss: 6.139512538909912\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 6.1576056480407715\n",
      "Critic Loss: 3.4031505584716797\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 5.245530605316162\n",
      "Critic Loss: 3.0014760494232178\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 7.238600730895996\n",
      "Critic Loss: 3.231147050857544\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 5.919833183288574\n",
      "Critic Loss: 3.0006277561187744\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 7.957685947418213\n",
      "Critic Loss: 3.867454767227173\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 6.345944404602051\n",
      "Critic Loss: 3.452953338623047\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 5.952830791473389\n",
      "Critic Loss: 8.115418434143066\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 7.869607925415039\n",
      "Critic Loss: 2.9372196197509766\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 4.968035697937012\n",
      "Critic Loss: 3.3486037254333496\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 6.858071804046631\n",
      "Critic Loss: 4.577526092529297\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 5.177987575531006\n",
      "Critic Loss: 2.769521951675415\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 6.451727390289307\n",
      "Critic Loss: 3.2236263751983643\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 4.683383464813232\n",
      "Critic Loss: 2.7850472927093506\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 3.5485036373138428\n",
      "Critic Loss: 2.8432366847991943\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 7.326292991638184\n",
      "Critic Loss: 3.403552770614624\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 2.519533634185791\n",
      "Critic Loss: 3.9699156284332275\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 5.655035495758057\n",
      "Critic Loss: 4.54685640335083\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 5.9923601150512695\n",
      "Critic Loss: 3.305314540863037\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 4.821430206298828\n",
      "Critic Loss: 3.185586929321289\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 4.490245342254639\n",
      "Critic Loss: 2.4557461738586426\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 6.73829984664917\n",
      "Critic Loss: 3.2585761547088623\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 6.345150947570801\n",
      "Critic Loss: 3.1616201400756836\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 3.5276784896850586\n",
      "Critic Loss: 2.5271944999694824\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 2.9929511547088623\n",
      "Critic Loss: 2.2925589084625244\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 3.6558358669281006\n",
      "Critic Loss: 2.4907212257385254\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092483f4b56d4c85854709f9383db828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>145.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>148.39999</td></tr><tr><td>Learning_rate/Actor</td><td>0.00138</td></tr><tr><td>Learning_rate/Critic</td><td>0.00031</td></tr><tr><td>Loss/Actor_loss</td><td>-2.51786</td></tr><tr><td>Loss/Critic_loss</td><td>2.49072</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.45368</td></tr><tr><td>Loss/KL_divergence</td><td>-0.02709</td></tr><tr><td>Loss/Policy_loss</td><td>-2.51089</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>3.65584</td></tr><tr><td>Metric/Explained_variance</td><td>0.802</td></tr><tr><td>Reward/Mean_train_reward</td><td>8.56451</td></tr><tr><td>Reward/Mean_val_reward</td><td>20.9194</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>15.66992</td></tr><tr><td>global_step</td><td>113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-39</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/t2drmuwi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/t2drmuwi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_190449-t2drmuwi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 72a9thc8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.001073992188263431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004644310990877041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04832774527898613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9364983238154204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0006296698509568597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.950330435768783e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81a23543e7f42f9bf29642a91ff4597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_191714-72a9thc8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/72a9thc8' target=\"_blank\">earnest-sweep-40</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/72a9thc8' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/72a9thc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.001073992188263431, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004644310990877041, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04832774527898613, 'epochs': 10, 'exponential_factor': 0.9364983238154204, 'gamma': 0.99, 'hidden_sizes': [150, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.0006296698509568597, 'l2_factor': 7.950330435768783e-05, 'lrelu': 0.001, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.001073992188263431, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004644310990877041, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04832774527898613, 'epochs': 10, 'exponential_factor': 0.9364983238154204, 'gamma': 0.99, 'l1_factor': 0.0006296698509568597, 'l2_factor': 7.950330435768783e-05, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.001073992188263431, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004644310990877041, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04832774527898613, 'epochs': 10, 'exponential_factor': 0.9364983238154204, 'gamma': 0.99, 'l1_factor': 0.0006296698509568597, 'l2_factor': 7.950330435768783e-05, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.001073992188263431, 'critic_lr': 0.0004644310990877041, 'decay_method': 'exponential', 'exponential_factor': 0.9364983238154204, 'value_loss_factor': 1, 'entropy': 0.04832774527898613, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0006296698509568597, 'l2_factor': 7.950330435768783e-05, 'T': 1024, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [150, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.1281543970108032\n",
      "Critic Loss: 43.90321350097656\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.535904049873352\n",
      "Critic Loss: 20.286882400512695\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.4004270136356354\n",
      "Critic Loss: 17.758066177368164\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.42812925577163696\n",
      "Critic Loss: 12.693489074707031\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.33775222301483154\n",
      "Critic Loss: 13.563688278198242\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.3222866654396057\n",
      "Critic Loss: 13.176027297973633\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.2977323830127716\n",
      "Critic Loss: 10.393269538879395\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.32244768738746643\n",
      "Critic Loss: 10.851934432983398\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.22966806590557098\n",
      "Critic Loss: 9.972123146057129\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.2525787651538849\n",
      "Critic Loss: 10.892854690551758\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.25560665130615234\n",
      "Critic Loss: 8.537243843078613\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.20302116870880127\n",
      "Critic Loss: 8.512565612792969\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.1693129539489746\n",
      "Critic Loss: 10.317843437194824\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.1878926306962967\n",
      "Critic Loss: 6.166449546813965\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.13807979226112366\n",
      "Critic Loss: 8.438002586364746\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.16991642117500305\n",
      "Critic Loss: 12.760872840881348\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.13646739721298218\n",
      "Critic Loss: 5.7892656326293945\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.10226377844810486\n",
      "Critic Loss: 7.924137115478516\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.1113557294011116\n",
      "Critic Loss: 11.361300468444824\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.10091502219438553\n",
      "Critic Loss: 12.944906234741211\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.10302877426147461\n",
      "Critic Loss: 10.227950096130371\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.10541575402021408\n",
      "Critic Loss: 14.658562660217285\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.056851208209991455\n",
      "Critic Loss: 8.34589672088623\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.06677769124507904\n",
      "Critic Loss: 8.73393440246582\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.0644490197300911\n",
      "Critic Loss: 9.693492889404297\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.04221335053443909\n",
      "Critic Loss: 8.82259750366211\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.06175883859395981\n",
      "Critic Loss: 8.067084312438965\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.027967866510152817\n",
      "Critic Loss: 9.097630500793457\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.05535373091697693\n",
      "Critic Loss: 8.504959106445312\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.04117884114384651\n",
      "Critic Loss: 10.34311580657959\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.023848094046115875\n",
      "Critic Loss: 9.689318656921387\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.017937015742063522\n",
      "Critic Loss: 6.763784408569336\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.04311677813529968\n",
      "Critic Loss: 7.269672870635986\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.011397315189242363\n",
      "Critic Loss: 11.23831558227539\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.04517030715942383\n",
      "Critic Loss: 7.007072448730469\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.033111218363046646\n",
      "Critic Loss: 6.873312950134277\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.015040285885334015\n",
      "Critic Loss: 6.633989334106445\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.027589667588472366\n",
      "Critic Loss: 8.925882339477539\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.0031716933008283377\n",
      "Critic Loss: 7.6048102378845215\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.0032776829320937395\n",
      "Critic Loss: 9.972505569458008\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.011879809200763702\n",
      "Critic Loss: 8.560270309448242\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.012943623587489128\n",
      "Critic Loss: 12.335455894470215\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.006114279385656118\n",
      "Critic Loss: 10.526032447814941\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.05051431059837341\n",
      "Critic Loss: 9.548035621643066\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.06305936723947525\n",
      "Critic Loss: 10.022345542907715\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.0337899848818779\n",
      "Critic Loss: 9.255951881408691\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.015598230063915253\n",
      "Critic Loss: 7.355287075042725\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.01868073269724846\n",
      "Critic Loss: 11.21539306640625\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.048081256449222565\n",
      "Critic Loss: 8.247570037841797\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.006966531276702881\n",
      "Critic Loss: 6.746355056762695\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.005637648515403271\n",
      "Critic Loss: 8.260719299316406\n",
      "\n",
      "New best validation reward reached in update [51/200]\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.012557067908346653\n",
      "Critic Loss: 7.330892562866211\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.022759919986128807\n",
      "Critic Loss: 5.71614933013916\n",
      "\n",
      "New best validation reward reached in update [53/200]\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.01999630220234394\n",
      "Critic Loss: 7.183241367340088\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.01935792714357376\n",
      "Critic Loss: 7.744217872619629\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.0002396076451987028\n",
      "Critic Loss: 7.019595146179199\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.019543897360563278\n",
      "Critic Loss: 11.993797302246094\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.021237561479210854\n",
      "Critic Loss: 13.512876510620117\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.014659949578344822\n",
      "Critic Loss: 10.362900733947754\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.006361199542880058\n",
      "Critic Loss: 5.747931480407715\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.02220900170505047\n",
      "Critic Loss: 8.890501976013184\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.016198275610804558\n",
      "Critic Loss: 15.588239669799805\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.0021031000651419163\n",
      "Critic Loss: 9.249181747436523\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.003784986212849617\n",
      "Critic Loss: 6.793337821960449\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.01866397261619568\n",
      "Critic Loss: 4.679357051849365\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.023406459018588066\n",
      "Critic Loss: 6.046566009521484\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.003310811473056674\n",
      "Critic Loss: 5.802493095397949\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.005563282407820225\n",
      "Critic Loss: 7.974388599395752\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.013275885954499245\n",
      "Critic Loss: 5.38645076751709\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.0004876670427620411\n",
      "Critic Loss: 8.040882110595703\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.015335243195295334\n",
      "Critic Loss: 11.663522720336914\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.007921857759356499\n",
      "Critic Loss: 3.4978487491607666\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.007623184937983751\n",
      "Critic Loss: 5.301590442657471\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.0015057283453643322\n",
      "Critic Loss: 4.474115371704102\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 3.6655692383646965e-05\n",
      "Critic Loss: 4.391217231750488\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.007281904108822346\n",
      "Critic Loss: 7.967860698699951\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.008889959193766117\n",
      "Critic Loss: 8.923051834106445\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.015891514718532562\n",
      "Critic Loss: 6.657519817352295\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.02820015139877796\n",
      "Critic Loss: 6.56004524230957\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.0013371168170124292\n",
      "Critic Loss: 6.128925323486328\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.017239907756447792\n",
      "Critic Loss: 6.9788618087768555\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.016697708517313004\n",
      "Critic Loss: 5.057404518127441\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.005424076225608587\n",
      "Critic Loss: 9.26152515411377\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.014576972462236881\n",
      "Critic Loss: 7.285385608673096\n",
      "\n",
      "New best validation reward reached in update [84/200]\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.026224445551633835\n",
      "Critic Loss: 6.345516681671143\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.0019312759395688772\n",
      "Critic Loss: 6.9896979331970215\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.007352778688073158\n",
      "Critic Loss: 9.495092391967773\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.006192397326231003\n",
      "Critic Loss: 6.606569290161133\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.004942762665450573\n",
      "Critic Loss: 6.029313087463379\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.006089584901928902\n",
      "Critic Loss: 6.191232681274414\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.078400619328022\n",
      "Critic Loss: 5.926505088806152\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.01516026258468628\n",
      "Critic Loss: 8.33835506439209\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.003870479529723525\n",
      "Critic Loss: 4.823178291320801\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.008012233301997185\n",
      "Critic Loss: 5.664676189422607\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.020972268655896187\n",
      "Critic Loss: 6.0455827713012695\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.015809403732419014\n",
      "Critic Loss: 4.8852715492248535\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.01110039371997118\n",
      "Critic Loss: 8.211984634399414\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.0004106331616640091\n",
      "Critic Loss: 6.499256134033203\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.005842244252562523\n",
      "Critic Loss: 6.497983932495117\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.00970697496086359\n",
      "Critic Loss: 5.975693702697754\n",
      "\n",
      "New best validation reward reached in update [100/200]\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.005198531784117222\n",
      "Critic Loss: 7.576059818267822\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -9.51387919485569e-05\n",
      "Critic Loss: 4.171353816986084\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.005252620205283165\n",
      "Critic Loss: 5.619189262390137\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.012156735174357891\n",
      "Critic Loss: 5.97503662109375\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.022554462775588036\n",
      "Critic Loss: 4.554718017578125\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.012146325781941414\n",
      "Critic Loss: 5.117134094238281\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.018331993371248245\n",
      "Critic Loss: 7.4557204246521\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.021021736785769463\n",
      "Critic Loss: 8.452787399291992\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.006538250483572483\n",
      "Critic Loss: 4.483740329742432\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.012681325897574425\n",
      "Critic Loss: 6.887207508087158\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.010265110060572624\n",
      "Critic Loss: 3.6896400451660156\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.016645226627588272\n",
      "Critic Loss: 8.142023086547852\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.0722411498427391\n",
      "Critic Loss: 8.859240531921387\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.014491943642497063\n",
      "Critic Loss: 4.09636926651001\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.014171665534377098\n",
      "Critic Loss: 5.7985148429870605\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.018845247104763985\n",
      "Critic Loss: 7.988945484161377\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.025929825380444527\n",
      "Critic Loss: 8.330724716186523\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.006355103105306625\n",
      "Critic Loss: 8.34278392791748\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.017884094268083572\n",
      "Critic Loss: 13.98211669921875\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.016174960881471634\n",
      "Critic Loss: 6.125777721405029\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.009229268878698349\n",
      "Critic Loss: 8.408018112182617\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.019970661029219627\n",
      "Critic Loss: 7.031579494476318\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.020873552188277245\n",
      "Critic Loss: 4.338428020477295\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.035651981830596924\n",
      "Critic Loss: 7.39103889465332\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.011389758437871933\n",
      "Critic Loss: 7.852007865905762\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.06157252937555313\n",
      "Critic Loss: 5.956347942352295\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.03187962993979454\n",
      "Critic Loss: 6.612121105194092\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.004215192515403032\n",
      "Critic Loss: 5.484777927398682\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.02585344947874546\n",
      "Critic Loss: 10.820136070251465\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.011016428470611572\n",
      "Critic Loss: 10.843232154846191\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.011876428499817848\n",
      "Critic Loss: 9.52930736541748\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660721f0802a420db23aa887f10e308b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>295.66666</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>233.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.07512</td></tr><tr><td>Loss/Critic_loss</td><td>9.52931</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.70513</td></tr><tr><td>Loss/KL_divergence</td><td>0.00062</td></tr><tr><td>Loss/Policy_loss</td><td>0.00729</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.01188</td></tr><tr><td>Metric/Explained_variance</td><td>-1.11204</td></tr><tr><td>Reward/Mean_train_reward</td><td>21.08133</td></tr><tr><td>Reward/Mean_val_reward</td><td>1.6127</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-11.66136</td></tr><tr><td>global_step</td><td>131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-40</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/72a9thc8' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/72a9thc8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_191714-72a9thc8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 19uogdlz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.004302443606632136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.003397302806480466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.004417164652072709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9473384380590676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 150, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.232689808248475e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.000836478146930121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_194219-19uogdlz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/19uogdlz' target=\"_blank\">lunar-sweep-41</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/19uogdlz' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/19uogdlz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.004302443606632136, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003397302806480466, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004417164652072709, 'epochs': 10, 'exponential_factor': 0.9473384380590676, 'gamma': 0.99, 'hidden_sizes': [150, 150, 350, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 1.232689808248475e-06, 'l2_factor': 0.000836478146930121, 'lrelu': 0.01, 'minibatch_size': 32, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 350, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.004302443606632136, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003397302806480466, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004417164652072709, 'epochs': 10, 'exponential_factor': 0.9473384380590676, 'gamma': 0.99, 'l1_factor': 1.232689808248475e-06, 'l2_factor': 0.000836478146930121, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 350, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.004302443606632136, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003397302806480466, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004417164652072709, 'epochs': 10, 'exponential_factor': 0.9473384380590676, 'gamma': 0.99, 'l1_factor': 1.232689808248475e-06, 'l2_factor': 0.000836478146930121, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.004302443606632136, 'critic_lr': 0.003397302806480466, 'decay_method': 'exponential', 'exponential_factor': 0.9473384380590676, 'value_loss_factor': 1, 'entropy': 0.004417164652072709, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.232689808248475e-06, 'l2_factor': 0.000836478146930121, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [150, 150, 350, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.9800174236297607\n",
      "Critic Loss: 30.164566040039062\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.03308005630970001\n",
      "Critic Loss: 13.473894119262695\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.02910575456917286\n",
      "Critic Loss: 10.231040000915527\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.03449881076812744\n",
      "Critic Loss: 15.863039016723633\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.0038947751745581627\n",
      "Critic Loss: 7.701430320739746\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.02494972012937069\n",
      "Critic Loss: 6.691135883331299\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.030087389051914215\n",
      "Critic Loss: 9.846406936645508\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.021977394819259644\n",
      "Critic Loss: 6.49139404296875\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.004128162749111652\n",
      "Critic Loss: 8.269855499267578\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.01676853373646736\n",
      "Critic Loss: 7.1027069091796875\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.08640330284833908\n",
      "Critic Loss: 4.230153560638428\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.09270630776882172\n",
      "Critic Loss: 6.177933692932129\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.03665447235107422\n",
      "Critic Loss: 6.193714618682861\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.0030045202001929283\n",
      "Critic Loss: 3.1292929649353027\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.02633814886212349\n",
      "Critic Loss: 6.565819263458252\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.022316452115774155\n",
      "Critic Loss: 8.075849533081055\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.016568833962082863\n",
      "Critic Loss: 10.161338806152344\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.017469724640250206\n",
      "Critic Loss: 7.56508207321167\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.011845782399177551\n",
      "Critic Loss: 4.295355319976807\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.011039653792977333\n",
      "Critic Loss: 4.5423760414123535\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.035394687205553055\n",
      "Critic Loss: 7.54883337020874\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.03937501832842827\n",
      "Critic Loss: 7.373591899871826\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.02323160320520401\n",
      "Critic Loss: 2.953792095184326\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.002493462525308132\n",
      "Critic Loss: 3.554908514022827\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.0995127260684967\n",
      "Critic Loss: 4.572693347930908\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.0018504858016967773\n",
      "Critic Loss: 6.067287921905518\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.09781356900930405\n",
      "Critic Loss: 4.4671735763549805\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.01909702643752098\n",
      "Critic Loss: 5.802324295043945\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.05986873060464859\n",
      "Critic Loss: 5.468682765960693\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.00417307298630476\n",
      "Critic Loss: 3.769425868988037\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.030843302607536316\n",
      "Critic Loss: 3.2950220108032227\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.04417628049850464\n",
      "Critic Loss: 3.8957886695861816\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.024200331419706345\n",
      "Critic Loss: 3.420534610748291\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.05935738980770111\n",
      "Critic Loss: 4.663514137268066\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.0018463218584656715\n",
      "Critic Loss: 3.4397029876708984\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.009773936122655869\n",
      "Critic Loss: 4.022543430328369\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.015568044036626816\n",
      "Critic Loss: 3.293337106704712\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.023901235312223434\n",
      "Critic Loss: 4.093390941619873\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.04398798197507858\n",
      "Critic Loss: 5.320909023284912\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.02329125627875328\n",
      "Critic Loss: 4.3640265464782715\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.0608174204826355\n",
      "Critic Loss: 3.640833854675293\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.0007375748828053474\n",
      "Critic Loss: 5.870253562927246\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.013406200334429741\n",
      "Critic Loss: 5.707474708557129\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.03031880408525467\n",
      "Critic Loss: 3.029221773147583\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.061055250465869904\n",
      "Critic Loss: 3.590827226638794\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.07080649584531784\n",
      "Critic Loss: 4.101980686187744\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.02928844466805458\n",
      "Critic Loss: 6.186065673828125\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.024323079735040665\n",
      "Critic Loss: 5.358794689178467\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.025940589606761932\n",
      "Critic Loss: 3.4773740768432617\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.00047955382615327835\n",
      "Critic Loss: 4.536131858825684\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.0026572691276669502\n",
      "Critic Loss: 3.916912078857422\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.00928109884262085\n",
      "Critic Loss: 4.820308685302734\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.04290539026260376\n",
      "Critic Loss: 4.938970565795898\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.0131952790543437\n",
      "Critic Loss: 2.3686983585357666\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.004340341780334711\n",
      "Critic Loss: 3.447084665298462\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.005251803435385227\n",
      "Critic Loss: 5.063233375549316\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.054080694913864136\n",
      "Critic Loss: 2.9881134033203125\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.05916817486286163\n",
      "Critic Loss: 3.3722426891326904\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.006636098027229309\n",
      "Critic Loss: 5.377023220062256\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.008667769841849804\n",
      "Critic Loss: 4.715012073516846\n",
      "\n",
      "New best validation reward reached in update [60/200]\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.0020413557067513466\n",
      "Critic Loss: 7.877558708190918\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.006648148410022259\n",
      "Critic Loss: 6.487689971923828\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.042816221714019775\n",
      "Critic Loss: 7.797720909118652\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.022385042160749435\n",
      "Critic Loss: 6.492100715637207\n",
      "\n",
      "New best validation reward reached in update [64/200]\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.03662595897912979\n",
      "Critic Loss: 10.91176986694336\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.078646220266819\n",
      "Critic Loss: 6.571751594543457\n",
      "\n",
      "New best validation reward reached in update [66/200]\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.05391822010278702\n",
      "Critic Loss: 13.455806732177734\n",
      "\n",
      "New best validation reward reached in update [67/200]\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.0035073040053248405\n",
      "Critic Loss: 8.676482200622559\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.006877543404698372\n",
      "Critic Loss: 5.174337863922119\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.017121564596891403\n",
      "Critic Loss: 6.582188606262207\n",
      "\n",
      "New best validation reward reached in update [70/200]\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.013323829509317875\n",
      "Critic Loss: 10.749838829040527\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.05166102200746536\n",
      "Critic Loss: 7.020309925079346\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.004280838184058666\n",
      "Critic Loss: 9.168523788452148\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.02063646726310253\n",
      "Critic Loss: 9.218639373779297\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.03161212429404259\n",
      "Critic Loss: 6.658406734466553\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.16760961711406708\n",
      "Critic Loss: 7.8986101150512695\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.0038610752671957016\n",
      "Critic Loss: 8.461122512817383\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.04451066255569458\n",
      "Critic Loss: 6.397526741027832\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.11012768745422363\n",
      "Critic Loss: 7.1762590408325195\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.039872217923402786\n",
      "Critic Loss: 11.296608924865723\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.0059282295405864716\n",
      "Critic Loss: 4.9532856941223145\n",
      "\n",
      "New best validation reward reached in update [81/200]\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.02975410968065262\n",
      "Critic Loss: 11.180994987487793\n",
      "\n",
      "New best validation reward reached in update [82/200]\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.029998941347002983\n",
      "Critic Loss: 7.445002555847168\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.019240431487560272\n",
      "Critic Loss: 10.187105178833008\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.002666907384991646\n",
      "Critic Loss: 8.57689094543457\n",
      "\n",
      "New best validation reward reached in update [85/200]\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.019931256771087646\n",
      "Critic Loss: 7.619030952453613\n",
      "\n",
      "New best validation reward reached in update [86/200]\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.043496016412973404\n",
      "Critic Loss: 4.611934185028076\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.05640031397342682\n",
      "Critic Loss: 5.764332294464111\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.0014533670619130135\n",
      "Critic Loss: 6.016984462738037\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.01658513955771923\n",
      "Critic Loss: 6.659453868865967\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.011323532089591026\n",
      "Critic Loss: 2.5443761348724365\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.026561055332422256\n",
      "Critic Loss: 4.176652908325195\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.009886818006634712\n",
      "Critic Loss: 3.19187068939209\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.03826853632926941\n",
      "Critic Loss: 5.098339080810547\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.022318022325634956\n",
      "Critic Loss: 4.721319675445557\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.10925014317035675\n",
      "Critic Loss: 3.411175489425659\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.018751095980405807\n",
      "Critic Loss: 5.3399658203125\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.02042127214372158\n",
      "Critic Loss: 6.0453996658325195\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.03375376760959625\n",
      "Critic Loss: 4.901057720184326\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.02305808663368225\n",
      "Critic Loss: 3.5638034343719482\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.030425647273659706\n",
      "Critic Loss: 4.426725387573242\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.0008693523705005646\n",
      "Critic Loss: 3.134368419647217\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.01911081373691559\n",
      "Critic Loss: 6.4449262619018555\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.023497717455029488\n",
      "Critic Loss: 6.566249847412109\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -0.0030964799225330353\n",
      "Critic Loss: 4.973548412322998\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.011352553963661194\n",
      "Critic Loss: 7.707229137420654\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.003412899561226368\n",
      "Critic Loss: 3.6174685955047607\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.003805401735007763\n",
      "Critic Loss: 2.860483169555664\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.01858564466238022\n",
      "Critic Loss: 3.7407066822052\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.051069699227809906\n",
      "Critic Loss: 3.361812114715576\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -0.008871877565979958\n",
      "Critic Loss: 2.4467175006866455\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.022827140986919403\n",
      "Critic Loss: 3.4777634143829346\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.08641830086708069\n",
      "Critic Loss: 4.488399028778076\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.049408987164497375\n",
      "Critic Loss: 3.3895771503448486\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.01657915487885475\n",
      "Critic Loss: 5.83076286315918\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.034142326563596725\n",
      "Critic Loss: 4.91646671295166\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.03266218304634094\n",
      "Critic Loss: 2.7550997734069824\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.004128090105950832\n",
      "Critic Loss: 2.963813304901123\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.01265623141080141\n",
      "Critic Loss: 6.163103103637695\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -0.0006143320351839066\n",
      "Critic Loss: 3.534973621368408\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.01864488050341606\n",
      "Critic Loss: 2.734499454498291\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.0058095273561775684\n",
      "Critic Loss: 1.8020210266113281\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.020368220284581184\n",
      "Critic Loss: 6.9392991065979\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.030652295798063278\n",
      "Critic Loss: 2.915391683578491\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.021271511912345886\n",
      "Critic Loss: 4.169534206390381\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.10238765180110931\n",
      "Critic Loss: 3.308472156524658\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.04217582568526268\n",
      "Critic Loss: 3.265937089920044\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.05077839642763138\n",
      "Critic Loss: 2.863295555114746\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.009795189835131168\n",
      "Critic Loss: 8.454697608947754\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.02652304619550705\n",
      "Critic Loss: 3.6983842849731445\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.1091219037771225\n",
      "Critic Loss: 3.131636381149292\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -0.009716296568512917\n",
      "Critic Loss: 3.375873327255249\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.032088108360767365\n",
      "Critic Loss: 7.213884353637695\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.019814830273389816\n",
      "Critic Loss: 3.3323817253112793\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.02387487329542637\n",
      "Critic Loss: 5.817962169647217\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.00721963495016098\n",
      "Critic Loss: 5.910486698150635\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.052934952080249786\n",
      "Critic Loss: 4.803029537200928\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.007827801629900932\n",
      "Critic Loss: 5.260892391204834\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.01860443688929081\n",
      "Critic Loss: 6.232821464538574\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.03275106102228165\n",
      "Critic Loss: 5.624718189239502\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.0544196180999279\n",
      "Critic Loss: 3.7779629230499268\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.10521005094051361\n",
      "Critic Loss: 2.7465221881866455\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.009161335416138172\n",
      "Critic Loss: 1.9608010053634644\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.0919606164097786\n",
      "Critic Loss: 2.937540054321289\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.02112390846014023\n",
      "Critic Loss: 5.150152206420898\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 0.05943628028035164\n",
      "Critic Loss: 3.5074357986450195\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.020542165264487267\n",
      "Critic Loss: 4.828451633453369\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.0725812092423439\n",
      "Critic Loss: 1.9378312826156616\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.023639272898435593\n",
      "Critic Loss: 4.275241851806641\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.02062780037522316\n",
      "Critic Loss: 2.643704891204834\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 0.02500147372484207\n",
      "Critic Loss: 5.285984516143799\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: 0.03541942313313484\n",
      "Critic Loss: 5.372799873352051\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: 0.00026888400316238403\n",
      "Critic Loss: 4.529775142669678\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: 0.01881592348217964\n",
      "Critic Loss: 4.781083583831787\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: 0.02093317359685898\n",
      "Critic Loss: 2.850233554840088\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 0.044809937477111816\n",
      "Critic Loss: 4.5117268562316895\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: 0.019483525305986404\n",
      "Critic Loss: 4.380619049072266\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 0.02399853989481926\n",
      "Critic Loss: 3.437208414077759\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 0.03721453249454498\n",
      "Critic Loss: 5.140636920928955\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: 0.060897067189216614\n",
      "Critic Loss: 7.066167831420898\n",
      "\n",
      "Update [161/200]\n",
      "Actor Loss: -0.023860977962613106\n",
      "Critic Loss: 3.17350435256958\n",
      "\n",
      "Update [162/200]\n",
      "Actor Loss: 0.10153542459011078\n",
      "Critic Loss: 3.8940885066986084\n",
      "\n",
      "Update [163/200]\n",
      "Actor Loss: 0.022530600428581238\n",
      "Critic Loss: 4.927652835845947\n",
      "\n",
      "Update [164/200]\n",
      "Actor Loss: -0.03753625601530075\n",
      "Critic Loss: 2.9784083366394043\n",
      "\n",
      "Update [165/200]\n",
      "Actor Loss: -0.010736491531133652\n",
      "Critic Loss: 6.1054182052612305\n",
      "\n",
      "Update [166/200]\n",
      "Actor Loss: 0.036079682409763336\n",
      "Critic Loss: 3.5334157943725586\n",
      "\n",
      "Update [167/200]\n",
      "Actor Loss: -0.016230281442403793\n",
      "Critic Loss: 1.991941213607788\n",
      "\n",
      "Update [168/200]\n",
      "Actor Loss: 0.009246475994586945\n",
      "Critic Loss: 3.0156643390655518\n",
      "\n",
      "Update [169/200]\n",
      "Actor Loss: -0.020604465156793594\n",
      "Critic Loss: 6.24293327331543\n",
      "\n",
      "Update [170/200]\n",
      "Actor Loss: 0.015919754281640053\n",
      "Critic Loss: 2.85709810256958\n",
      "\n",
      "Update [171/200]\n",
      "Actor Loss: 0.014783984050154686\n",
      "Critic Loss: 2.627931833267212\n",
      "\n",
      "Update [172/200]\n",
      "Actor Loss: 0.05546477437019348\n",
      "Critic Loss: 3.7093000411987305\n",
      "\n",
      "Update [173/200]\n",
      "Actor Loss: 0.02802407369017601\n",
      "Critic Loss: 3.612335443496704\n",
      "\n",
      "Update [174/200]\n",
      "Actor Loss: 0.06331022828817368\n",
      "Critic Loss: 3.907402992248535\n",
      "\n",
      "Update [175/200]\n",
      "Actor Loss: -0.015960654243826866\n",
      "Critic Loss: 3.3932247161865234\n",
      "\n",
      "Update [176/200]\n",
      "Actor Loss: 0.0035095149651169777\n",
      "Critic Loss: 3.6549715995788574\n",
      "\n",
      "Update [177/200]\n",
      "Actor Loss: 0.0699644535779953\n",
      "Critic Loss: 3.1277270317077637\n",
      "\n",
      "Update [178/200]\n",
      "Actor Loss: 0.06493297964334488\n",
      "Critic Loss: 3.5345563888549805\n",
      "\n",
      "Update [179/200]\n",
      "Actor Loss: 0.003388490527868271\n",
      "Critic Loss: 3.895453929901123\n",
      "\n",
      "Update [180/200]\n",
      "Actor Loss: 0.05532193183898926\n",
      "Critic Loss: 4.138625144958496\n",
      "\n",
      "Update [181/200]\n",
      "Actor Loss: 0.014205426909029484\n",
      "Critic Loss: 3.3573694229125977\n",
      "\n",
      "Update [182/200]\n",
      "Actor Loss: 0.014156656339764595\n",
      "Critic Loss: 7.7439045906066895\n",
      "\n",
      "Update [183/200]\n",
      "Actor Loss: 0.01405291073024273\n",
      "Critic Loss: 6.383914947509766\n",
      "\n",
      "Update [184/200]\n",
      "Actor Loss: 0.019751355051994324\n",
      "Critic Loss: 5.422330856323242\n",
      "\n",
      "Update [185/200]\n",
      "Actor Loss: 0.06681894510984421\n",
      "Critic Loss: 4.808375358581543\n",
      "\n",
      "Update [186/200]\n",
      "Actor Loss: -0.0036866245791316032\n",
      "Critic Loss: 3.184133529663086\n",
      "\n",
      "Update [187/200]\n",
      "Actor Loss: 0.04749547690153122\n",
      "Critic Loss: 2.727355480194092\n",
      "\n",
      "Update [188/200]\n",
      "Actor Loss: 0.005486439447849989\n",
      "Critic Loss: 5.847392559051514\n",
      "\n",
      "Update [189/200]\n",
      "Actor Loss: 0.016474101692438126\n",
      "Critic Loss: 7.3501081466674805\n",
      "\n",
      "Update [190/200]\n",
      "Actor Loss: -0.016063181683421135\n",
      "Critic Loss: 2.7802820205688477\n",
      "\n",
      "Update [191/200]\n",
      "Actor Loss: -0.02757948637008667\n",
      "Critic Loss: 3.513608455657959\n",
      "\n",
      "Update [192/200]\n",
      "Actor Loss: 0.03894335776567459\n",
      "Critic Loss: 2.7751567363739014\n",
      "\n",
      "Update [193/200]\n",
      "Actor Loss: 0.03389531746506691\n",
      "Critic Loss: 5.268260955810547\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5feab575b5421f9fab55e8c37e2a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>120.75</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>122.9</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.02042</td></tr><tr><td>Loss/Critic_loss</td><td>5.26826</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.71534</td></tr><tr><td>Loss/KL_divergence</td><td>0.05381</td></tr><tr><td>Loss/Policy_loss</td><td>0.02358</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.0339</td></tr><tr><td>Metric/Explained_variance</td><td>0.87299</td></tr><tr><td>Reward/Mean_train_reward</td><td>-1.27525</td></tr><tr><td>Reward/Mean_val_reward</td><td>-0.1541</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>0.99266</td></tr><tr><td>global_step</td><td>193</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-41</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/19uogdlz' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/19uogdlz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_194219-19uogdlz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rssqc96i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0002815214076083508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00026503208922109303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.02421363547792713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8869244139870407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.3193793347284496e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00034037292192767816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_202048-rssqc96i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/rssqc96i' target=\"_blank\">visionary-sweep-42</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/rssqc96i' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/rssqc96i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0002815214076083508, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00026503208922109303, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02421363547792713, 'epochs': 10, 'exponential_factor': 0.8869244139870407, 'gamma': 0.99, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 1.3193793347284496e-06, 'l2_factor': 0.00034037292192767816, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0002815214076083508, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00026503208922109303, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02421363547792713, 'epochs': 10, 'exponential_factor': 0.8869244139870407, 'gamma': 0.99, 'l1_factor': 1.3193793347284496e-06, 'l2_factor': 0.00034037292192767816, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0002815214076083508, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00026503208922109303, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02421363547792713, 'epochs': 10, 'exponential_factor': 0.8869244139870407, 'gamma': 0.99, 'l1_factor': 1.3193793347284496e-06, 'l2_factor': 0.00034037292192767816, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0002815214076083508, 'critic_lr': 0.00026503208922109303, 'decay_method': 'exponential', 'exponential_factor': 0.8869244139870407, 'value_loss_factor': 1, 'entropy': 0.02421363547792713, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.3193793347284496e-06, 'l2_factor': 0.00034037292192767816, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 32.7451057434082\n",
      "Critic Loss: 31.736242294311523\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 26.18798828125\n",
      "Critic Loss: 14.55820083618164\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 19.99990463256836\n",
      "Critic Loss: 21.322093963623047\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 19.190587997436523\n",
      "Critic Loss: 13.359804153442383\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 19.121095657348633\n",
      "Critic Loss: 10.615148544311523\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 20.70779037475586\n",
      "Critic Loss: 9.594369888305664\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 18.35291290283203\n",
      "Critic Loss: 8.583085060119629\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 17.22702980041504\n",
      "Critic Loss: 6.354081153869629\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 25.808420181274414\n",
      "Critic Loss: 8.536606788635254\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 16.77334976196289\n",
      "Critic Loss: 9.585396766662598\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 17.6375675201416\n",
      "Critic Loss: 6.552283763885498\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 20.144344329833984\n",
      "Critic Loss: 5.566186904907227\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 17.176353454589844\n",
      "Critic Loss: 5.934486389160156\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 10.600990295410156\n",
      "Critic Loss: 11.0179443359375\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 7.3073906898498535\n",
      "Critic Loss: 11.976009368896484\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 4.261010646820068\n",
      "Critic Loss: 11.219230651855469\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 4.392545223236084\n",
      "Critic Loss: 8.699295043945312\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 4.0718278884887695\n",
      "Critic Loss: 9.010052680969238\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 4.661491394042969\n",
      "Critic Loss: 6.668758869171143\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -3.730429172515869\n",
      "Critic Loss: 4.1832451820373535\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.3471328020095825\n",
      "Critic Loss: 3.7823894023895264\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.9650348424911499\n",
      "Critic Loss: 3.346997022628784\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.7562808394432068\n",
      "Critic Loss: 3.4096152782440186\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 5.30134391784668\n",
      "Critic Loss: 3.099259853363037\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -2.030566930770874\n",
      "Critic Loss: 2.9121851921081543\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.5670418739318848\n",
      "Critic Loss: 2.8379929065704346\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 4.870724678039551\n",
      "Critic Loss: 4.899140357971191\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.15360382199287415\n",
      "Critic Loss: 3.1487014293670654\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.1834633350372314\n",
      "Critic Loss: 4.236284255981445\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.9327021837234497\n",
      "Critic Loss: 5.036751747131348\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 1.2018084526062012\n",
      "Critic Loss: 2.878542900085449\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.49706974625587463\n",
      "Critic Loss: 2.6404712200164795\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 4.697360038757324\n",
      "Critic Loss: 6.488954544067383\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -2.0291600227355957\n",
      "Critic Loss: 2.342287063598633\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 4.028944969177246\n",
      "Critic Loss: 5.428040981292725\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.5898539423942566\n",
      "Critic Loss: 3.3729801177978516\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.8998838663101196\n",
      "Critic Loss: 2.792959213256836\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 3.7701432704925537\n",
      "Critic Loss: 7.663383960723877\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.024737805128097534\n",
      "Critic Loss: 5.499025821685791\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.7241716384887695\n",
      "Critic Loss: 2.577890157699585\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 4.875034809112549\n",
      "Critic Loss: 2.1817800998687744\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 4.297779560089111\n",
      "Critic Loss: 2.7650415897369385\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.7555646896362305\n",
      "Critic Loss: 2.6599297523498535\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 2.9250223636627197\n",
      "Critic Loss: 5.964563846588135\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 1.7425673007965088\n",
      "Critic Loss: 2.970425844192505\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 1.4921083450317383\n",
      "Critic Loss: 3.2002038955688477\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.7329866886138916\n",
      "Critic Loss: 4.096715450286865\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.290213018655777\n",
      "Critic Loss: 2.909595489501953\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.8191590309143066\n",
      "Critic Loss: 3.3416056632995605\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 3.036301612854004\n",
      "Critic Loss: 2.983102798461914\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.2833839952945709\n",
      "Critic Loss: 2.81748104095459\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 1.641369104385376\n",
      "Critic Loss: 3.359692096710205\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.7057403326034546\n",
      "Critic Loss: 3.290794610977173\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 3.363926410675049\n",
      "Critic Loss: 3.6101694107055664\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 1.4015611410140991\n",
      "Critic Loss: 2.887535810470581\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -1.6357309818267822\n",
      "Critic Loss: 2.846421957015991\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 5.309359073638916\n",
      "Critic Loss: 5.0001220703125\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.02923908829689026\n",
      "Critic Loss: 2.7778913974761963\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -1.5092501640319824\n",
      "Critic Loss: 4.78213357925415\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.2968863248825073\n",
      "Critic Loss: 2.517740488052368\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 4.825911045074463\n",
      "Critic Loss: 3.3375461101531982\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 1.146491527557373\n",
      "Critic Loss: 3.4360764026641846\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -3.909177541732788\n",
      "Critic Loss: 5.131989479064941\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 3.4239752292633057\n",
      "Critic Loss: 3.064423084259033\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -3.312425136566162\n",
      "Critic Loss: 2.714141845703125\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.7863537073135376\n",
      "Critic Loss: 4.3374199867248535\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 7.212034225463867\n",
      "Critic Loss: 8.644366264343262\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -1.0382665395736694\n",
      "Critic Loss: 2.324805498123169\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 3.315370798110962\n",
      "Critic Loss: 4.987591743469238\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.18644759058952332\n",
      "Critic Loss: 2.5873334407806396\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 1.6182893514633179\n",
      "Critic Loss: 2.181230068206787\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.8909163475036621\n",
      "Critic Loss: 5.897625923156738\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 5.088078498840332\n",
      "Critic Loss: 4.328629493713379\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -1.8128026723861694\n",
      "Critic Loss: 2.539412260055542\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.3325517177581787\n",
      "Critic Loss: 3.485910654067993\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 9.555625915527344\n",
      "Critic Loss: 4.897427558898926\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.6937718987464905\n",
      "Critic Loss: 2.1192116737365723\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 1.7632832527160645\n",
      "Critic Loss: 3.0643019676208496\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.1504596769809723\n",
      "Critic Loss: 2.6498169898986816\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 5.835519790649414\n",
      "Critic Loss: 7.183951377868652\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.6801294088363647\n",
      "Critic Loss: 3.865274429321289\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 4.968395233154297\n",
      "Critic Loss: 3.821786880493164\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 5.9527907371521\n",
      "Critic Loss: 5.635957717895508\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 1.2792896032333374\n",
      "Critic Loss: 2.8250794410705566\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 3.5322184562683105\n",
      "Critic Loss: 2.721676826477051\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.7903230786323547\n",
      "Critic Loss: 3.636141538619995\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 2.977710723876953\n",
      "Critic Loss: 3.004575490951538\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.9183405637741089\n",
      "Critic Loss: 2.831420660018921\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 1.821798324584961\n",
      "Critic Loss: 2.7177648544311523\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 3.6411755084991455\n",
      "Critic Loss: 4.816240310668945\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279fd539c68b40df8cf5adcab2027e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>117.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>121.8</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>3.18405</td></tr><tr><td>Loss/Critic_loss</td><td>4.81624</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.90379</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01304</td></tr><tr><td>Loss/Policy_loss</td><td>3.20593</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>3.64118</td></tr><tr><td>Metric/Explained_variance</td><td>0.5667</td></tr><tr><td>Reward/Mean_train_reward</td><td>5.00267</td></tr><tr><td>Reward/Mean_val_reward</td><td>7.6728</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.41151</td></tr><tr><td>global_step</td><td>90</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-sweep-42</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/rssqc96i' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/rssqc96i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_202048-rssqc96i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8c030a2c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.003361993105234902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.001925392297256925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03267285320372514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9017317783193952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.0816545197750643e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.657119750973004e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_203018-8c030a2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/8c030a2c' target=\"_blank\">decent-sweep-43</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8c030a2c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8c030a2c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.003361993105234902, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001925392297256925, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03267285320372514, 'epochs': 10, 'exponential_factor': 0.9017317783193952, 'gamma': 0.9, 'hidden_sizes': [350, 150, 250, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.0816545197750643e-05, 'l2_factor': 6.657119750973004e-05, 'lrelu': 0.01, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.003361993105234902, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001925392297256925, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03267285320372514, 'epochs': 10, 'exponential_factor': 0.9017317783193952, 'gamma': 0.9, 'l1_factor': 1.0816545197750643e-05, 'l2_factor': 6.657119750973004e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.003361993105234902, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.001925392297256925, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03267285320372514, 'epochs': 10, 'exponential_factor': 0.9017317783193952, 'gamma': 0.9, 'l1_factor': 1.0816545197750643e-05, 'l2_factor': 6.657119750973004e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.003361993105234902, 'critic_lr': 0.001925392297256925, 'decay_method': 'exponential', 'exponential_factor': 0.9017317783193952, 'value_loss_factor': 1, 'entropy': 0.03267285320372514, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.0816545197750643e-05, 'l2_factor': 6.657119750973004e-05, 'T': 768, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [350, 150, 250, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.19512812793254852\n",
      "Critic Loss: 7.768064975738525\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.012819800525903702\n",
      "Critic Loss: 2.7363109588623047\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.7892192006111145\n",
      "Critic Loss: 9.067208290100098\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.1262301206588745\n",
      "Critic Loss: 22.73080825805664\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.024158459156751633\n",
      "Critic Loss: 11.556710243225098\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.07076750695705414\n",
      "Critic Loss: 16.763946533203125\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.01826850324869156\n",
      "Critic Loss: 15.900736808776855\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.031246809288859367\n",
      "Critic Loss: 8.356962203979492\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.11886138468980789\n",
      "Critic Loss: 17.187835693359375\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.05334901064634323\n",
      "Critic Loss: 15.232926368713379\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.0228015948086977\n",
      "Critic Loss: 16.960386276245117\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.028574921190738678\n",
      "Critic Loss: 13.735147476196289\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.013370765373110771\n",
      "Critic Loss: 10.612268447875977\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.010608168318867683\n",
      "Critic Loss: 5.650275230407715\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.018073655664920807\n",
      "Critic Loss: 10.858203887939453\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.09483324736356735\n",
      "Critic Loss: 10.939071655273438\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.02914697676897049\n",
      "Critic Loss: 15.73674488067627\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.012264735996723175\n",
      "Critic Loss: 8.000298500061035\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.029802633449435234\n",
      "Critic Loss: 4.69816255569458\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.019036905840039253\n",
      "Critic Loss: 9.890880584716797\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.02950334921479225\n",
      "Critic Loss: 5.910771369934082\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.030584989115595818\n",
      "Critic Loss: 6.906191825866699\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.024760903790593147\n",
      "Critic Loss: 4.689637660980225\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.031442172825336456\n",
      "Critic Loss: 2.618144989013672\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.020805196836590767\n",
      "Critic Loss: 6.545993328094482\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.05928958207368851\n",
      "Critic Loss: 5.49376106262207\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.02782060205936432\n",
      "Critic Loss: 5.354252338409424\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.04575691372156143\n",
      "Critic Loss: 2.8563740253448486\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.028554465621709824\n",
      "Critic Loss: 2.2768168449401855\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.036671195179224014\n",
      "Critic Loss: 9.001358032226562\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.0016008298844099045\n",
      "Critic Loss: 3.691405773162842\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.059124402701854706\n",
      "Critic Loss: 1.5919609069824219\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.06717050075531006\n",
      "Critic Loss: 5.523599624633789\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.053592145442962646\n",
      "Critic Loss: 4.0182905197143555\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.03370065242052078\n",
      "Critic Loss: 3.5341358184814453\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.013208864256739616\n",
      "Critic Loss: 2.0839459896087646\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.04473891109228134\n",
      "Critic Loss: 2.998985767364502\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.087343230843544\n",
      "Critic Loss: 3.887441396713257\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.03535344451665878\n",
      "Critic Loss: 8.271116256713867\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.05073927342891693\n",
      "Critic Loss: 2.8405938148498535\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.03923064470291138\n",
      "Critic Loss: 1.8728063106536865\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.02508467808365822\n",
      "Critic Loss: 6.996198654174805\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.02746477723121643\n",
      "Critic Loss: 9.716723442077637\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.03257305920124054\n",
      "Critic Loss: 2.5821104049682617\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.034969281405210495\n",
      "Critic Loss: 3.247525691986084\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.010189423337578773\n",
      "Critic Loss: 1.075166940689087\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.02702493779361248\n",
      "Critic Loss: 12.346742630004883\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.018201276659965515\n",
      "Critic Loss: 2.094499111175537\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.024334169924259186\n",
      "Critic Loss: 5.314266681671143\n",
      "\n",
      "New best validation reward reached in update [49/200]\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.035844940692186356\n",
      "Critic Loss: 1.656359314918518\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.006898943334817886\n",
      "Critic Loss: 4.104743003845215\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.04992177337408066\n",
      "Critic Loss: 4.040389537811279\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.04803907126188278\n",
      "Critic Loss: 6.627619743347168\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.05544893443584442\n",
      "Critic Loss: 3.070882558822632\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.006271257996559143\n",
      "Critic Loss: 4.0147929191589355\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.015313633717596531\n",
      "Critic Loss: 6.9406418800354\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.165538489818573\n",
      "Critic Loss: 5.327547550201416\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.02052442356944084\n",
      "Critic Loss: 9.356969833374023\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.047230832278728485\n",
      "Critic Loss: 1.7029094696044922\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.02376638352870941\n",
      "Critic Loss: 6.17202091217041\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.10304971039295197\n",
      "Critic Loss: 4.3882551193237305\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.085561104118824\n",
      "Critic Loss: 3.6381897926330566\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.051665931940078735\n",
      "Critic Loss: 7.27770471572876\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.02537132240831852\n",
      "Critic Loss: 4.095046520233154\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.02668967843055725\n",
      "Critic Loss: 4.5830512046813965\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.029487956315279007\n",
      "Critic Loss: 5.424314022064209\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.02363397926092148\n",
      "Critic Loss: 2.9956088066101074\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.02890390157699585\n",
      "Critic Loss: 2.1153414249420166\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.007766442373394966\n",
      "Critic Loss: 3.7693262100219727\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.04611697047948837\n",
      "Critic Loss: 2.761976718902588\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.07781398296356201\n",
      "Critic Loss: 4.11800479888916\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.07592564821243286\n",
      "Critic Loss: 4.173290729522705\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.012274171225726604\n",
      "Critic Loss: 1.9526565074920654\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.007911931723356247\n",
      "Critic Loss: 8.32063102722168\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.033706896007061005\n",
      "Critic Loss: 7.621614456176758\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.01326296478509903\n",
      "Critic Loss: 4.737818241119385\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.0403863862156868\n",
      "Critic Loss: 6.8472466468811035\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.036649178713560104\n",
      "Critic Loss: 7.964739799499512\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.05242452770471573\n",
      "Critic Loss: 7.295364856719971\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999ca4372da94d1aa66fdffdddcbc788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>89.71429</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>92.1</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.0171</td></tr><tr><td>Loss/Critic_loss</td><td>7.29536</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.41208</td></tr><tr><td>Loss/KL_divergence</td><td>0.02052</td></tr><tr><td>Loss/Policy_loss</td><td>0.06323</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.05242</td></tr><tr><td>Metric/Explained_variance</td><td>0.4138</td></tr><tr><td>Reward/Mean_train_reward</td><td>-28.56271</td></tr><tr><td>Reward/Mean_val_reward</td><td>-34.6849</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-49.2281</td></tr><tr><td>global_step</td><td>79</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-sweep-43</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8c030a2c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8c030a2c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_203018-8c030a2c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vn5vzwr3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.003696374819121163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.005283820588164741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.009656928182571824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9376372955680602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.0407801839131973e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.4377808513506626e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_204129-vn5vzwr3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/vn5vzwr3' target=\"_blank\">genial-sweep-44</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vn5vzwr3' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vn5vzwr3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.003696374819121163, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.005283820588164741, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009656928182571824, 'epochs': 10, 'exponential_factor': 0.9376372955680602, 'gamma': 0.9, 'hidden_sizes': [350, 350, 250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 1.0407801839131973e-06, 'l2_factor': 3.4377808513506626e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.003696374819121163, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.005283820588164741, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009656928182571824, 'epochs': 10, 'exponential_factor': 0.9376372955680602, 'gamma': 0.9, 'l1_factor': 1.0407801839131973e-06, 'l2_factor': 3.4377808513506626e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.003696374819121163, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.005283820588164741, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.009656928182571824, 'epochs': 10, 'exponential_factor': 0.9376372955680602, 'gamma': 0.9, 'l1_factor': 1.0407801839131973e-06, 'l2_factor': 3.4377808513506626e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.003696374819121163, 'critic_lr': 0.005283820588164741, 'decay_method': 'exponential', 'exponential_factor': 0.9376372955680602, 'value_loss_factor': 1, 'entropy': 0.009656928182571824, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.0407801839131973e-06, 'l2_factor': 3.4377808513506626e-05, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [350, 350, 250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.10520285367965698\n",
      "Critic Loss: 14.66693115234375\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.10915903747081757\n",
      "Critic Loss: 10.428559303283691\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.03301100805401802\n",
      "Critic Loss: 15.981847763061523\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.09088507294654846\n",
      "Critic Loss: 6.421086311340332\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.05444490164518356\n",
      "Critic Loss: 15.809112548828125\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.04016580060124397\n",
      "Critic Loss: 6.311524391174316\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.06190783157944679\n",
      "Critic Loss: 6.06403112411499\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.04112687334418297\n",
      "Critic Loss: 6.218576908111572\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.10925071686506271\n",
      "Critic Loss: 4.45053243637085\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.04286336526274681\n",
      "Critic Loss: 4.828509330749512\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.057646188884973526\n",
      "Critic Loss: 4.8013739585876465\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.05675610154867172\n",
      "Critic Loss: 2.777449369430542\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.03965248540043831\n",
      "Critic Loss: 3.4478323459625244\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.02691354602575302\n",
      "Critic Loss: 2.892423629760742\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.08673226088285446\n",
      "Critic Loss: 7.816758155822754\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.07109791785478592\n",
      "Critic Loss: 3.2748231887817383\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.05570509657263756\n",
      "Critic Loss: 2.484382152557373\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.05667007341980934\n",
      "Critic Loss: 2.7175040245056152\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.04904264956712723\n",
      "Critic Loss: 1.3739595413208008\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.031136179342865944\n",
      "Critic Loss: 3.240630626678467\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.03199218586087227\n",
      "Critic Loss: 4.576264381408691\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.03757162019610405\n",
      "Critic Loss: 4.135168552398682\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.033691927790641785\n",
      "Critic Loss: 4.396745681762695\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.03722367435693741\n",
      "Critic Loss: 1.9368364810943604\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.03989393636584282\n",
      "Critic Loss: 4.633374214172363\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.02202707901597023\n",
      "Critic Loss: 4.384266376495361\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.04577619582414627\n",
      "Critic Loss: 12.574974060058594\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.03237578645348549\n",
      "Critic Loss: 9.000201225280762\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.010709960013628006\n",
      "Critic Loss: 5.936610698699951\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.00047211721539497375\n",
      "Critic Loss: 4.364349842071533\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.05291525274515152\n",
      "Critic Loss: 7.632331848144531\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.07175469398498535\n",
      "Critic Loss: 3.7382140159606934\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.04646424204111099\n",
      "Critic Loss: 5.019662380218506\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.05929652974009514\n",
      "Critic Loss: 5.790860176086426\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.0642428770661354\n",
      "Critic Loss: 5.799161911010742\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.052610911428928375\n",
      "Critic Loss: 7.649875164031982\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.03579740598797798\n",
      "Critic Loss: 7.249698638916016\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.01347755640745163\n",
      "Critic Loss: 4.520568370819092\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.01082431897521019\n",
      "Critic Loss: 10.604761123657227\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.03449387103319168\n",
      "Critic Loss: 5.72608757019043\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.06908339262008667\n",
      "Critic Loss: 4.833258628845215\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.05408187583088875\n",
      "Critic Loss: 3.970025062561035\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.001134619116783142\n",
      "Critic Loss: 3.88698148727417\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.033146269619464874\n",
      "Critic Loss: 3.8150546550750732\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.04282986745238304\n",
      "Critic Loss: 5.105118751525879\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.04361243173480034\n",
      "Critic Loss: 6.91064977645874\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.061103418469429016\n",
      "Critic Loss: 7.643439769744873\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.03371641784906387\n",
      "Critic Loss: 6.510797500610352\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a444b03e4c466f9e6dd8b929e83768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>75.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>61.8</td></tr><tr><td>Learning_rate/Actor</td><td>0.00018</td></tr><tr><td>Learning_rate/Critic</td><td>0.00026</td></tr><tr><td>Loss/Actor_loss</td><td>-0.01851</td></tr><tr><td>Loss/Critic_loss</td><td>6.5108</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.61902</td></tr><tr><td>Loss/KL_divergence</td><td>0.01866</td></tr><tr><td>Loss/Policy_loss</td><td>-0.01254</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.03372</td></tr><tr><td>Metric/Explained_variance</td><td>0.3677</td></tr><tr><td>Reward/Mean_train_reward</td><td>-21.086</td></tr><tr><td>Reward/Mean_val_reward</td><td>-40.0872</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-27.38128</td></tr><tr><td>global_step</td><td>48</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sweep-44</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vn5vzwr3' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vn5vzwr3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_204129-vn5vzwr3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nvyymnmu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.004957200393090042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.007403455859055538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.01706657462797869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9776352405257124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 5.238344108372022e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.867134452819901e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_204520-nvyymnmu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/nvyymnmu' target=\"_blank\">lyric-sweep-45</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/nvyymnmu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/nvyymnmu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.004957200393090042, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.007403455859055538, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.01706657462797869, 'epochs': 10, 'exponential_factor': 0.9776352405257124, 'gamma': 0.9, 'hidden_sizes': [150, 250, 250, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 5.238344108372022e-06, 'l2_factor': 4.867134452819901e-05, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.004957200393090042, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007403455859055538, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.01706657462797869, 'epochs': 10, 'exponential_factor': 0.9776352405257124, 'gamma': 0.9, 'l1_factor': 5.238344108372022e-06, 'l2_factor': 4.867134452819901e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.004957200393090042, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007403455859055538, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.01706657462797869, 'epochs': 10, 'exponential_factor': 0.9776352405257124, 'gamma': 0.9, 'l1_factor': 5.238344108372022e-06, 'l2_factor': 4.867134452819901e-05, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.004957200393090042, 'critic_lr': 0.007403455859055538, 'decay_method': 'exponential', 'exponential_factor': 0.9776352405257124, 'value_loss_factor': 1, 'entropy': 0.01706657462797869, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 5.238344108372022e-06, 'l2_factor': 4.867134452819901e-05, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [150, 250, 250, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 16.787216186523438\n",
      "Critic Loss: 15.630098342895508\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 34.67455291748047\n",
      "Critic Loss: 29.71072769165039\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 34.859718322753906\n",
      "Critic Loss: 30.076213836669922\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 7.044719219207764\n",
      "Critic Loss: 10.563918113708496\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 9.830878257751465\n",
      "Critic Loss: 11.853181838989258\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 3.814143419265747\n",
      "Critic Loss: 10.42113971710205\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 6.927725791931152\n",
      "Critic Loss: 9.492791175842285\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 3.5008792877197266\n",
      "Critic Loss: 4.8440327644348145\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 7.489137649536133\n",
      "Critic Loss: 6.152763366699219\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 3.7815747261047363\n",
      "Critic Loss: 3.912652015686035\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 3.561122417449951\n",
      "Critic Loss: 12.870080947875977\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -1.9419515132904053\n",
      "Critic Loss: 3.6243739128112793\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.0525380373001099\n",
      "Critic Loss: 5.754049301147461\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 4.243387222290039\n",
      "Critic Loss: 4.377034664154053\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.5018349885940552\n",
      "Critic Loss: 1.8675432205200195\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.6056253910064697\n",
      "Critic Loss: 2.4085519313812256\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.42862075567245483\n",
      "Critic Loss: 2.669814109802246\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 4.70729923248291\n",
      "Critic Loss: 3.596269369125366\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 7.946101665496826\n",
      "Critic Loss: 5.4897074699401855\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 4.890946388244629\n",
      "Critic Loss: 2.9955554008483887\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.673693835735321\n",
      "Critic Loss: 8.341315269470215\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 3.011864423751831\n",
      "Critic Loss: 5.001258373260498\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 2.0003859996795654\n",
      "Critic Loss: 5.251740455627441\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 2.7468905448913574\n",
      "Critic Loss: 4.192564010620117\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 2.354586362838745\n",
      "Critic Loss: 3.966205358505249\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 2.6328890323638916\n",
      "Critic Loss: 4.167576789855957\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 2.1848158836364746\n",
      "Critic Loss: 3.9412379264831543\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.7156264781951904\n",
      "Critic Loss: 3.0521464347839355\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.4555802047252655\n",
      "Critic Loss: 4.6397199630737305\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.612496018409729\n",
      "Critic Loss: 1.99917733669281\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -2.619924545288086\n",
      "Critic Loss: 1.6299184560775757\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -3.2114803791046143\n",
      "Critic Loss: 3.3459277153015137\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -1.2135212421417236\n",
      "Critic Loss: 1.8957144021987915\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.5363443493843079\n",
      "Critic Loss: 4.474161148071289\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -2.4046883583068848\n",
      "Critic Loss: 1.5158486366271973\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 1.0268234014511108\n",
      "Critic Loss: 3.1347575187683105\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -1.453965663909912\n",
      "Critic Loss: 1.513007640838623\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -1.761004090309143\n",
      "Critic Loss: 0.746086061000824\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -2.33599591255188\n",
      "Critic Loss: 1.7040174007415771\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 3.3158326148986816\n",
      "Critic Loss: 5.404543876647949\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 1.2231333255767822\n",
      "Critic Loss: 6.918194770812988\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 18.115571975708008\n",
      "Critic Loss: 6.4301252365112305\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 5.898849964141846\n",
      "Critic Loss: 4.139809608459473\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 3.2813191413879395\n",
      "Critic Loss: 7.802610397338867\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 6.032624244689941\n",
      "Critic Loss: 2.227653980255127\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 3.6478633880615234\n",
      "Critic Loss: 1.4924968481063843\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 8.790356636047363\n",
      "Critic Loss: 3.1540558338165283\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 12.353105545043945\n",
      "Critic Loss: 6.011832237243652\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 8.008550643920898\n",
      "Critic Loss: 7.8259077072143555\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 3.838426113128662\n",
      "Critic Loss: 2.0206856727600098\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 2.190310478210449\n",
      "Critic Loss: 3.7063159942626953\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 7.030110836029053\n",
      "Critic Loss: 1.783271074295044\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 5.124917030334473\n",
      "Critic Loss: 1.1701600551605225\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 3.4325976371765137\n",
      "Critic Loss: 1.1134710311889648\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 7.088291645050049\n",
      "Critic Loss: 3.7722764015197754\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.5532382726669312\n",
      "Critic Loss: 2.5593581199645996\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -3.407773971557617\n",
      "Critic Loss: 1.9092084169387817\n",
      "\n",
      "New best validation reward reached in update [57/200]\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -1.7701252698898315\n",
      "Critic Loss: 1.0692291259765625\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -2.467482566833496\n",
      "Critic Loss: 0.6466197967529297\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -3.864705801010132\n",
      "Critic Loss: 0.8191664218902588\n",
      "\n",
      "New best validation reward reached in update [60/200]\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -3.7700257301330566\n",
      "Critic Loss: 0.8667407631874084\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -1.1517956256866455\n",
      "Critic Loss: 1.842490553855896\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -3.2199976444244385\n",
      "Critic Loss: 1.1234898567199707\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -4.679898262023926\n",
      "Critic Loss: 0.5148456692695618\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 4.699014186859131\n",
      "Critic Loss: 2.2263240814208984\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -4.544036388397217\n",
      "Critic Loss: 1.0983387231826782\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -5.571445941925049\n",
      "Critic Loss: 0.9554226398468018\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -5.370062828063965\n",
      "Critic Loss: 1.3634822368621826\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -2.25502347946167\n",
      "Critic Loss: 1.1656543016433716\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -3.58381986618042\n",
      "Critic Loss: 1.0146976709365845\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -1.634741187095642\n",
      "Critic Loss: 2.272324562072754\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -4.698844909667969\n",
      "Critic Loss: 0.7529417276382446\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -3.4956820011138916\n",
      "Critic Loss: 0.7709881067276001\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 2.3849592208862305\n",
      "Critic Loss: 1.452129602432251\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -2.5608325004577637\n",
      "Critic Loss: 0.3974531888961792\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.7596056461334229\n",
      "Critic Loss: 3.2951536178588867\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -5.108347415924072\n",
      "Critic Loss: 1.513338327407837\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.8891953229904175\n",
      "Critic Loss: 2.263174057006836\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.20745018124580383\n",
      "Critic Loss: 1.4901759624481201\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -2.080888271331787\n",
      "Critic Loss: 0.7757186889648438\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -3.2545292377471924\n",
      "Critic Loss: 0.7368853688240051\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -3.7129123210906982\n",
      "Critic Loss: 0.505494236946106\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -3.403298854827881\n",
      "Critic Loss: 0.7305888533592224\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -5.13059139251709\n",
      "Critic Loss: 0.762008547782898\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 1.0361382961273193\n",
      "Critic Loss: 1.8682154417037964\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -2.3204665184020996\n",
      "Critic Loss: 0.8472291231155396\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 1.6406508684158325\n",
      "Critic Loss: 1.4121052026748657\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -2.3971736431121826\n",
      "Critic Loss: 3.9272351264953613\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 3.797287702560425\n",
      "Critic Loss: 2.739521026611328\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.8888136148452759\n",
      "Critic Loss: 0.8765944242477417\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.2730228900909424\n",
      "Critic Loss: 1.2579277753829956\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.692112147808075\n",
      "Critic Loss: 0.6189833879470825\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.43658649921417236\n",
      "Critic Loss: 2.3092164993286133\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -1.2812248468399048\n",
      "Critic Loss: 1.3224339485168457\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -1.6773911714553833\n",
      "Critic Loss: 1.687198519706726\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -1.3818278312683105\n",
      "Critic Loss: 1.5594698190689087\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -3.6981639862060547\n",
      "Critic Loss: 2.257528305053711\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 3.2684948444366455\n",
      "Critic Loss: 1.5402324199676514\n",
      "\n",
      "New best validation reward reached in update [98/200]\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.8403648138046265\n",
      "Critic Loss: 1.6094903945922852\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.39143842458724976\n",
      "Critic Loss: 2.5416512489318848\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.3924187421798706\n",
      "Critic Loss: 0.781662106513977\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -2.33156418800354\n",
      "Critic Loss: 0.8780595064163208\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -2.125455617904663\n",
      "Critic Loss: 0.7319879531860352\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -2.6166138648986816\n",
      "Critic Loss: 0.4365801215171814\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -1.5411419868469238\n",
      "Critic Loss: 1.2878698110580444\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -3.6250088214874268\n",
      "Critic Loss: 0.6107728481292725\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 1.26063871383667\n",
      "Critic Loss: 0.8736749291419983\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -2.3510923385620117\n",
      "Critic Loss: 0.4513925015926361\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -1.6911677122116089\n",
      "Critic Loss: 0.9027392864227295\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -1.9743491411209106\n",
      "Critic Loss: 0.5934374928474426\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 1.9286577701568604\n",
      "Critic Loss: 2.433513641357422\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -2.48884654045105\n",
      "Critic Loss: 0.6378780603408813\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.1277553141117096\n",
      "Critic Loss: 0.8547278642654419\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.40103423595428467\n",
      "Critic Loss: 2.388320207595825\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -1.9075812101364136\n",
      "Critic Loss: 0.7087210416793823\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -0.4564216434955597\n",
      "Critic Loss: 1.2560495138168335\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -1.3381506204605103\n",
      "Critic Loss: 2.303630828857422\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -3.9881014823913574\n",
      "Critic Loss: 0.5942144989967346\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.28321021795272827\n",
      "Critic Loss: 0.9604144096374512\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -1.1358931064605713\n",
      "Critic Loss: 2.0358803272247314\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -2.576063632965088\n",
      "Critic Loss: 0.8556790351867676\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -1.8357527256011963\n",
      "Critic Loss: 0.6592890620231628\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -3.0306313037872314\n",
      "Critic Loss: 0.3721097707748413\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -3.8582029342651367\n",
      "Critic Loss: 0.40854570269584656\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -1.8608654737472534\n",
      "Critic Loss: 0.7705546021461487\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.2851073741912842\n",
      "Critic Loss: 1.568993330001831\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -3.8408896923065186\n",
      "Critic Loss: 0.758714497089386\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -3.9846856594085693\n",
      "Critic Loss: 0.4183387756347656\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -1.3132719993591309\n",
      "Critic Loss: 1.0003803968429565\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 3.710170030593872\n",
      "Critic Loss: 3.4305951595306396\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 2.8487257957458496\n",
      "Critic Loss: 2.9487085342407227\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -1.814839482307434\n",
      "Critic Loss: 0.43142738938331604\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.27974069118499756\n",
      "Critic Loss: 2.0691518783569336\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -2.255437135696411\n",
      "Critic Loss: 0.7148329615592957\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 2.654258966445923\n",
      "Critic Loss: 3.884460926055908\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.9642592072486877\n",
      "Critic Loss: 0.5765103697776794\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -2.200425863265991\n",
      "Critic Loss: 0.37927693128585815\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 1.370442509651184\n",
      "Critic Loss: 0.8602216243743896\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: -2.5853633880615234\n",
      "Critic Loss: 0.3978084921836853\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -1.9340819120407104\n",
      "Critic Loss: 0.7226357460021973\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -1.7711272239685059\n",
      "Critic Loss: 2.2537434101104736\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: -2.6585702896118164\n",
      "Critic Loss: 0.7319917678833008\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -5.68053674697876\n",
      "Critic Loss: 0.8961379528045654\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -1.6316550970077515\n",
      "Critic Loss: 0.8401802778244019\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -2.0057311058044434\n",
      "Critic Loss: 0.4006619453430176\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: -3.5174548625946045\n",
      "Critic Loss: 0.8354374170303345\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.3960152566432953\n",
      "Critic Loss: 2.0029759407043457\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.7656343579292297\n",
      "Critic Loss: 0.5361957550048828\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: -2.7441165447235107\n",
      "Critic Loss: 0.5652500987052917\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: -2.6425046920776367\n",
      "Critic Loss: 0.7888818979263306\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: -0.817599892616272\n",
      "Critic Loss: 2.0503969192504883\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -2.785088539123535\n",
      "Critic Loss: 0.36689433455467224\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: -0.4158884584903717\n",
      "Critic Loss: 0.46780532598495483\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: -0.8805257678031921\n",
      "Critic Loss: 0.6285195350646973\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: -4.088754177093506\n",
      "Critic Loss: 0.9608609676361084\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 0.26915836334228516\n",
      "Critic Loss: 0.8085405230522156\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: 0.009711727499961853\n",
      "Critic Loss: 0.6833063364028931\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e37271eecbe4b298d76a51752a3eca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>102.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>101.8</td></tr><tr><td>Learning_rate/Actor</td><td>0.00015</td></tr><tr><td>Learning_rate/Critic</td><td>0.00022</td></tr><tr><td>Loss/Actor_loss</td><td>-0.17985</td></tr><tr><td>Loss/Critic_loss</td><td>0.68331</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.31254</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00861</td></tr><tr><td>Loss/Policy_loss</td><td>-0.17451</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.00971</td></tr><tr><td>Metric/Explained_variance</td><td>0.61377</td></tr><tr><td>Reward/Mean_train_reward</td><td>3.6415</td></tr><tr><td>Reward/Mean_val_reward</td><td>2.8848</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>3.74639</td></tr><tr><td>global_step</td><td>157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-45</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/nvyymnmu' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/nvyymnmu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_204520-nvyymnmu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fddzxfoo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.000637149133195217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00012636155029998258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.033338718445943855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.967362604612464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00011298675076990076\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.375812075517843e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_205648-fddzxfoo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/fddzxfoo' target=\"_blank\">polished-sweep-46</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fddzxfoo' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fddzxfoo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.000637149133195217, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00012636155029998258, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.033338718445943855, 'epochs': 10, 'exponential_factor': 0.967362604612464, 'gamma': 0.95, 'hidden_sizes': [350, 150, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.00011298675076990076, 'l2_factor': 2.375812075517843e-05, 'lrelu': 0.001, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.000637149133195217, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00012636155029998258, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.033338718445943855, 'epochs': 10, 'exponential_factor': 0.967362604612464, 'gamma': 0.95, 'l1_factor': 0.00011298675076990076, 'l2_factor': 2.375812075517843e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.000637149133195217, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00012636155029998258, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.033338718445943855, 'epochs': 10, 'exponential_factor': 0.967362604612464, 'gamma': 0.95, 'l1_factor': 0.00011298675076990076, 'l2_factor': 2.375812075517843e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.000637149133195217, 'critic_lr': 0.00012636155029998258, 'decay_method': 'exponential', 'exponential_factor': 0.967362604612464, 'value_loss_factor': 1, 'entropy': 0.033338718445943855, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00011298675076990076, 'l2_factor': 2.375812075517843e-05, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [350, 150, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.7157508730888367\n",
      "Critic Loss: 15.642705917358398\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.5957694053649902\n",
      "Critic Loss: 10.088762283325195\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.5278409123420715\n",
      "Critic Loss: 10.283385276794434\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.4979446828365326\n",
      "Critic Loss: 5.374999046325684\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.41194114089012146\n",
      "Critic Loss: 10.562915802001953\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.3983135521411896\n",
      "Critic Loss: 11.125329971313477\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.3451760709285736\n",
      "Critic Loss: 14.508068084716797\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.4899860918521881\n",
      "Critic Loss: 5.962831974029541\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.26723164319992065\n",
      "Critic Loss: 14.811603546142578\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.29894569516181946\n",
      "Critic Loss: 7.2514567375183105\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.295352965593338\n",
      "Critic Loss: 9.568644523620605\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.2930404543876648\n",
      "Critic Loss: 13.09406566619873\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.2220962941646576\n",
      "Critic Loss: 13.617985725402832\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.2703361213207245\n",
      "Critic Loss: 5.977216720581055\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.175595223903656\n",
      "Critic Loss: 12.767951011657715\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.23611286282539368\n",
      "Critic Loss: 5.980072021484375\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.19965419173240662\n",
      "Critic Loss: 3.251979112625122\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.23108458518981934\n",
      "Critic Loss: 2.976651906967163\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.21482442319393158\n",
      "Critic Loss: 8.56993293762207\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.35708171129226685\n",
      "Critic Loss: 2.0091304779052734\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.18100915849208832\n",
      "Critic Loss: 8.435052871704102\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.15001602470874786\n",
      "Critic Loss: 5.964763164520264\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.24122771620750427\n",
      "Critic Loss: 3.5832037925720215\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.21452553570270538\n",
      "Critic Loss: 4.822524070739746\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.1778518706560135\n",
      "Critic Loss: 5.743773937225342\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.21228641271591187\n",
      "Critic Loss: 10.242420196533203\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.14974431693553925\n",
      "Critic Loss: 8.518301010131836\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.1673276275396347\n",
      "Critic Loss: 5.456451416015625\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.14458319544792175\n",
      "Critic Loss: 14.640497207641602\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.20286691188812256\n",
      "Critic Loss: 9.352970123291016\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.17737780511379242\n",
      "Critic Loss: 4.329629421234131\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.26566821336746216\n",
      "Critic Loss: 6.043932914733887\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.13363662362098694\n",
      "Critic Loss: 3.6680126190185547\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.15939375758171082\n",
      "Critic Loss: 3.015162944793701\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.1709234118461609\n",
      "Critic Loss: 7.391202926635742\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.13060010969638824\n",
      "Critic Loss: 5.022662162780762\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.1464965045452118\n",
      "Critic Loss: 7.114813327789307\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.1390964239835739\n",
      "Critic Loss: 2.5520195960998535\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.11619241535663605\n",
      "Critic Loss: 3.5252432823181152\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.11432759463787079\n",
      "Critic Loss: 6.419073104858398\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.15134334564208984\n",
      "Critic Loss: 2.223738670349121\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.10175857692956924\n",
      "Critic Loss: 8.131623268127441\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.12346887588500977\n",
      "Critic Loss: 1.9815688133239746\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.18870237469673157\n",
      "Critic Loss: 4.315006732940674\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.1455252468585968\n",
      "Critic Loss: 2.708437204360962\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.13158202171325684\n",
      "Critic Loss: 3.4262778759002686\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.11175753176212311\n",
      "Critic Loss: 3.378263235092163\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.15902937948703766\n",
      "Critic Loss: 4.787084102630615\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.14063751697540283\n",
      "Critic Loss: 4.652548313140869\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.2594085931777954\n",
      "Critic Loss: 6.822065353393555\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.1380930244922638\n",
      "Critic Loss: 3.913109302520752\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.1489429622888565\n",
      "Critic Loss: 3.2847537994384766\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.12105299532413483\n",
      "Critic Loss: 4.253515243530273\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.14790557324886322\n",
      "Critic Loss: 5.794577598571777\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.15100955963134766\n",
      "Critic Loss: 8.105568885803223\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.11786770075559616\n",
      "Critic Loss: 4.594471454620361\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.141448974609375\n",
      "Critic Loss: 4.756139755249023\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.18623128533363342\n",
      "Critic Loss: 6.191856384277344\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.1423822045326233\n",
      "Critic Loss: 2.024981737136841\n",
      "\n",
      "New best validation reward reached in update [59/200]\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.11454775184392929\n",
      "Critic Loss: 4.987419605255127\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.13603898882865906\n",
      "Critic Loss: 3.3552358150482178\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.13734012842178345\n",
      "Critic Loss: 4.933415412902832\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.10910476744174957\n",
      "Critic Loss: 2.625683546066284\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.10441676527261734\n",
      "Critic Loss: 3.8630778789520264\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.1486087590456009\n",
      "Critic Loss: 4.124382495880127\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.1700288951396942\n",
      "Critic Loss: 4.644386291503906\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.21351908147335052\n",
      "Critic Loss: 16.273029327392578\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.13894122838974\n",
      "Critic Loss: 8.597907066345215\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.14509961009025574\n",
      "Critic Loss: 5.253754615783691\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.13507483899593353\n",
      "Critic Loss: 5.702069282531738\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.1826266199350357\n",
      "Critic Loss: 6.075904369354248\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.12016765028238297\n",
      "Critic Loss: 4.386776924133301\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.09533742070198059\n",
      "Critic Loss: 10.050381660461426\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.18534016609191895\n",
      "Critic Loss: 7.561733722686768\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.11409107595682144\n",
      "Critic Loss: 11.330787658691406\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.12789440155029297\n",
      "Critic Loss: 3.641402244567871\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.151957705616951\n",
      "Critic Loss: 5.354437828063965\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.12699519097805023\n",
      "Critic Loss: 4.766549110412598\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.1820373386144638\n",
      "Critic Loss: 2.444357395172119\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.09237641841173172\n",
      "Critic Loss: 5.621368408203125\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.10694320499897003\n",
      "Critic Loss: 3.4796950817108154\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.1704733818769455\n",
      "Critic Loss: 1.822127342224121\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.1408005654811859\n",
      "Critic Loss: 5.320654392242432\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.15080967545509338\n",
      "Critic Loss: 5.590588569641113\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.13335923850536346\n",
      "Critic Loss: 6.333272457122803\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.1238580197095871\n",
      "Critic Loss: 1.762769341468811\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.14728772640228271\n",
      "Critic Loss: 2.9222681522369385\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.11012443155050278\n",
      "Critic Loss: 4.3726067543029785\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.09303981065750122\n",
      "Critic Loss: 3.9151344299316406\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.12616170942783356\n",
      "Critic Loss: 6.512204170227051\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f46ea34defa41d4a56e18a0ddff1fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>89.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>127.5</td></tr><tr><td>Learning_rate/Actor</td><td>3e-05</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.09139</td></tr><tr><td>Loss/Critic_loss</td><td>6.5122</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.48754</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0103</td></tr><tr><td>Loss/Policy_loss</td><td>-0.0418</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.12616</td></tr><tr><td>Metric/Explained_variance</td><td>0.29141</td></tr><tr><td>Reward/Mean_train_reward</td><td>-37.112</td></tr><tr><td>Reward/Mean_val_reward</td><td>-7.0415</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-30.30134</td></tr><tr><td>global_step</td><td>90</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-sweep-46</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fddzxfoo' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fddzxfoo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_205648-fddzxfoo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4588ama9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0003489571514584541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00013453971024447964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.005875806148181214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8761136585214196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.6502689160341216e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0003366487940614071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_210410-4588ama9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/4588ama9' target=\"_blank\">smart-sweep-47</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/4588ama9' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/4588ama9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.0003489571514584541, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013453971024447964, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005875806148181214, 'epochs': 10, 'exponential_factor': 0.8761136585214196, 'gamma': 0.95, 'hidden_sizes': [150, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 2.6502689160341216e-06, 'l2_factor': 0.0003366487940614071, 'lrelu': 0.1, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0003489571514584541, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013453971024447964, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005875806148181214, 'epochs': 10, 'exponential_factor': 0.8761136585214196, 'gamma': 0.95, 'l1_factor': 2.6502689160341216e-06, 'l2_factor': 0.0003366487940614071, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0003489571514584541, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013453971024447964, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005875806148181214, 'epochs': 10, 'exponential_factor': 0.8761136585214196, 'gamma': 0.95, 'l1_factor': 2.6502689160341216e-06, 'l2_factor': 0.0003366487940614071, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0003489571514584541, 'critic_lr': 0.00013453971024447964, 'decay_method': 'exponential', 'exponential_factor': 0.8761136585214196, 'value_loss_factor': 1, 'entropy': 0.005875806148181214, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.6502689160341216e-06, 'l2_factor': 0.0003366487940614071, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [150, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.2757716178894043\n",
      "Critic Loss: 28.596105575561523\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.19583210349082947\n",
      "Critic Loss: 21.952865600585938\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.25682711601257324\n",
      "Critic Loss: 13.335693359375\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.29019707441329956\n",
      "Critic Loss: 13.630091667175293\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.17495842278003693\n",
      "Critic Loss: 16.867738723754883\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.12609508633613586\n",
      "Critic Loss: 13.643570899963379\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.16565415263175964\n",
      "Critic Loss: 8.921927452087402\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.12632641196250916\n",
      "Critic Loss: 9.24048137664795\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.2257511168718338\n",
      "Critic Loss: 10.146575927734375\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.20843157172203064\n",
      "Critic Loss: 12.250837326049805\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.13315866887569427\n",
      "Critic Loss: 7.448735237121582\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.15654653310775757\n",
      "Critic Loss: 11.489156723022461\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.17359094321727753\n",
      "Critic Loss: 8.677864074707031\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.16676335036754608\n",
      "Critic Loss: 9.204212188720703\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.14565224945545197\n",
      "Critic Loss: 11.314818382263184\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.15917792916297913\n",
      "Critic Loss: 12.334400177001953\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.36275696754455566\n",
      "Critic Loss: 8.724193572998047\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.1985541731119156\n",
      "Critic Loss: 6.348813056945801\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.1614932119846344\n",
      "Critic Loss: 12.20971393585205\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.12362350523471832\n",
      "Critic Loss: 7.325523376464844\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.13883107900619507\n",
      "Critic Loss: 11.955483436584473\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.3545098602771759\n",
      "Critic Loss: 11.407632827758789\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.10798031091690063\n",
      "Critic Loss: 10.966714859008789\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.12000731378793716\n",
      "Critic Loss: 12.818122863769531\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.16360652446746826\n",
      "Critic Loss: 7.955451488494873\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.13919343054294586\n",
      "Critic Loss: 7.821185111999512\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.1484285295009613\n",
      "Critic Loss: 12.973336219787598\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.15461258590221405\n",
      "Critic Loss: 12.230646133422852\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.11731161922216415\n",
      "Critic Loss: 12.622855186462402\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.11935271322727203\n",
      "Critic Loss: 10.13943862915039\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.11096785962581635\n",
      "Critic Loss: 9.13953971862793\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.1274087280035019\n",
      "Critic Loss: 11.904358863830566\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.14951211214065552\n",
      "Critic Loss: 9.53749942779541\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.12722641229629517\n",
      "Critic Loss: 10.202354431152344\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.10377413779497147\n",
      "Critic Loss: 11.582165718078613\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.1762758493423462\n",
      "Critic Loss: 10.152283668518066\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.11226710677146912\n",
      "Critic Loss: 8.473198890686035\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.11767394840717316\n",
      "Critic Loss: 6.625526428222656\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.13217511773109436\n",
      "Critic Loss: 10.014175415039062\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.1418517678976059\n",
      "Critic Loss: 9.485879898071289\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.1294170767068863\n",
      "Critic Loss: 9.981171607971191\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.12769143283367157\n",
      "Critic Loss: 10.560626029968262\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.12186603993177414\n",
      "Critic Loss: 9.465362548828125\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.12478494644165039\n",
      "Critic Loss: 10.246564865112305\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d698fc3d4d1b4f40b8dc7380dd5aebc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>109.375</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>205.89999</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00848</td></tr><tr><td>Loss/Critic_loss</td><td>10.24656</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.72862</td></tr><tr><td>Loss/KL_divergence</td><td>0.00382</td></tr><tr><td>Loss/Policy_loss</td><td>-0.0042</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.12478</td></tr><tr><td>Metric/Explained_variance</td><td>0.21634</td></tr><tr><td>Reward/Mean_train_reward</td><td>6.06838</td></tr><tr><td>Reward/Mean_val_reward</td><td>179.7809</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>66.46828</td></tr><tr><td>global_step</td><td>44</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-sweep-47</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/4588ama9' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/4588ama9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_210410-4588ama9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3hxjla7l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0002692020048286012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0011000457691878168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.046153091610309886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.95845005590938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 6.330744846833401e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.2728272919362938e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_211052-3hxjla7l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/3hxjla7l' target=\"_blank\">dulcet-sweep-48</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/3hxjla7l' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/3hxjla7l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0002692020048286012, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011000457691878168, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.046153091610309886, 'epochs': 10, 'exponential_factor': 0.95845005590938, 'gamma': 0.99, 'hidden_sizes': [350, 250, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 6.330744846833401e-06, 'l2_factor': 2.2728272919362938e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0002692020048286012, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011000457691878168, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.046153091610309886, 'epochs': 10, 'exponential_factor': 0.95845005590938, 'gamma': 0.99, 'l1_factor': 6.330744846833401e-06, 'l2_factor': 2.2728272919362938e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0002692020048286012, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011000457691878168, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.046153091610309886, 'epochs': 10, 'exponential_factor': 0.95845005590938, 'gamma': 0.99, 'l1_factor': 6.330744846833401e-06, 'l2_factor': 2.2728272919362938e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0002692020048286012, 'critic_lr': 0.0011000457691878168, 'decay_method': 'exponential', 'exponential_factor': 0.95845005590938, 'value_loss_factor': 1, 'entropy': 0.046153091610309886, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 6.330744846833401e-06, 'l2_factor': 2.2728272919362938e-06, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 250, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 33.187225341796875\n",
      "Critic Loss: 31.457805633544922\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 23.272125244140625\n",
      "Critic Loss: 10.754992485046387\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 13.983409881591797\n",
      "Critic Loss: 9.996767044067383\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 13.23765754699707\n",
      "Critic Loss: 8.074342727661133\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 16.111764907836914\n",
      "Critic Loss: 9.762557983398438\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 15.311018943786621\n",
      "Critic Loss: 6.837016582489014\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 18.141239166259766\n",
      "Critic Loss: 7.039966583251953\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 24.779088973999023\n",
      "Critic Loss: 5.617360591888428\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 28.269681930541992\n",
      "Critic Loss: 5.199334621429443\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 27.902997970581055\n",
      "Critic Loss: 5.7547712326049805\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 20.181947708129883\n",
      "Critic Loss: 3.991004467010498\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 28.728713989257812\n",
      "Critic Loss: 6.0257439613342285\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 33.12320327758789\n",
      "Critic Loss: 5.633809566497803\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 24.814647674560547\n",
      "Critic Loss: 5.260439872741699\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 28.357275009155273\n",
      "Critic Loss: 4.3607306480407715\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 25.981517791748047\n",
      "Critic Loss: 6.328464031219482\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 23.15392303466797\n",
      "Critic Loss: 5.00127649307251\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 18.91273307800293\n",
      "Critic Loss: 4.83623743057251\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 31.48480224609375\n",
      "Critic Loss: 10.288867950439453\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 28.715972900390625\n",
      "Critic Loss: 5.673305988311768\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 29.512367248535156\n",
      "Critic Loss: 11.08998966217041\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 24.489778518676758\n",
      "Critic Loss: 7.415158271789551\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 23.4353084564209\n",
      "Critic Loss: 5.269192218780518\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 26.342683792114258\n",
      "Critic Loss: 7.743340969085693\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 24.24027442932129\n",
      "Critic Loss: 3.9701080322265625\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 24.120967864990234\n",
      "Critic Loss: 5.6474080085754395\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 18.042055130004883\n",
      "Critic Loss: 6.4753737449646\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 19.359895706176758\n",
      "Critic Loss: 5.322442531585693\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 17.045907974243164\n",
      "Critic Loss: 5.205349445343018\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 19.099258422851562\n",
      "Critic Loss: 6.431351184844971\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 16.082368850708008\n",
      "Critic Loss: 5.0752787590026855\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 11.929508209228516\n",
      "Critic Loss: 8.011898040771484\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 17.570980072021484\n",
      "Critic Loss: 5.962157249450684\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 14.878586769104004\n",
      "Critic Loss: 4.918600559234619\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 14.05260944366455\n",
      "Critic Loss: 5.4147467613220215\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 10.14634895324707\n",
      "Critic Loss: 4.22662878036499\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 10.107134819030762\n",
      "Critic Loss: 2.8055825233459473\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 16.508647918701172\n",
      "Critic Loss: 3.2225289344787598\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 12.484210968017578\n",
      "Critic Loss: 5.494650840759277\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 18.902301788330078\n",
      "Critic Loss: 9.065199851989746\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 19.69638442993164\n",
      "Critic Loss: 6.095376491546631\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 12.95026683807373\n",
      "Critic Loss: 3.881990671157837\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 9.411474227905273\n",
      "Critic Loss: 4.951139450073242\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 14.615367889404297\n",
      "Critic Loss: 6.317218780517578\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 15.142609596252441\n",
      "Critic Loss: 3.1586954593658447\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 9.338074684143066\n",
      "Critic Loss: 4.208188056945801\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 6.471209526062012\n",
      "Critic Loss: 5.354958534240723\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 14.314417839050293\n",
      "Critic Loss: 5.14044713973999\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 13.243656158447266\n",
      "Critic Loss: 7.286863803863525\n",
      "\n",
      "New best validation reward reached in update [49/200]\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 8.820402145385742\n",
      "Critic Loss: 3.880031108856201\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 11.364845275878906\n",
      "Critic Loss: 3.3188998699188232\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 8.739970207214355\n",
      "Critic Loss: 4.75789737701416\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 5.956307888031006\n",
      "Critic Loss: 5.240396976470947\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 13.663357734680176\n",
      "Critic Loss: 9.85802936553955\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 7.879799842834473\n",
      "Critic Loss: 4.5895586013793945\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 10.2577543258667\n",
      "Critic Loss: 6.466464519500732\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 7.3172197341918945\n",
      "Critic Loss: 3.022359609603882\n",
      "\n",
      "New best validation reward reached in update [57/200]\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 8.828670501708984\n",
      "Critic Loss: 3.7480227947235107\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 14.185625076293945\n",
      "Critic Loss: 5.379513740539551\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 11.762354850769043\n",
      "Critic Loss: 5.275890827178955\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 15.638141632080078\n",
      "Critic Loss: 3.6967549324035645\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 8.734724998474121\n",
      "Critic Loss: 3.674647331237793\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 6.130492687225342\n",
      "Critic Loss: 2.3564720153808594\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 13.673279762268066\n",
      "Critic Loss: 6.788186073303223\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 12.964761734008789\n",
      "Critic Loss: 5.016134262084961\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 16.390636444091797\n",
      "Critic Loss: 7.326614856719971\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 13.9164457321167\n",
      "Critic Loss: 3.6955671310424805\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 7.755446910858154\n",
      "Critic Loss: 4.165189266204834\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 9.492531776428223\n",
      "Critic Loss: 5.165837287902832\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 11.8174409866333\n",
      "Critic Loss: 2.785189628601074\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 6.330917835235596\n",
      "Critic Loss: 2.7081785202026367\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 4.433813095092773\n",
      "Critic Loss: 2.1759321689605713\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 10.285927772521973\n",
      "Critic Loss: 3.050665855407715\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 9.47760009765625\n",
      "Critic Loss: 5.710550308227539\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 10.127476692199707\n",
      "Critic Loss: 4.580702781677246\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 8.281438827514648\n",
      "Critic Loss: 6.192126274108887\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 10.59829330444336\n",
      "Critic Loss: 7.204658508300781\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 10.799947738647461\n",
      "Critic Loss: 5.74259090423584\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 7.064755916595459\n",
      "Critic Loss: 3.462204933166504\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 14.064229011535645\n",
      "Critic Loss: 7.050258636474609\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 13.317025184631348\n",
      "Critic Loss: 6.10870885848999\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 13.708553314208984\n",
      "Critic Loss: 5.935854911804199\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 11.643671035766602\n",
      "Critic Loss: 2.702436923980713\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 7.026304721832275\n",
      "Critic Loss: 4.043856143951416\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 12.013471603393555\n",
      "Critic Loss: 6.465976715087891\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 6.149528503417969\n",
      "Critic Loss: 2.831193208694458\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 8.349858283996582\n",
      "Critic Loss: 5.475818157196045\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 10.98702621459961\n",
      "Critic Loss: 3.216785430908203\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 8.105294227600098\n",
      "Critic Loss: 3.9923810958862305\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 10.094160079956055\n",
      "Critic Loss: 3.3382620811462402\n",
      "\n",
      "New best validation reward reached in update [90/200]\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 5.993661403656006\n",
      "Critic Loss: 4.840734481811523\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 6.037930965423584\n",
      "Critic Loss: 2.3009331226348877\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 7.590930938720703\n",
      "Critic Loss: 4.7301249504089355\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 8.662348747253418\n",
      "Critic Loss: 3.3130908012390137\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 9.192841529846191\n",
      "Critic Loss: 3.42254638671875\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 10.142170906066895\n",
      "Critic Loss: 4.178478240966797\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 8.923901557922363\n",
      "Critic Loss: 4.469549655914307\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 10.650226593017578\n",
      "Critic Loss: 3.735650062561035\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 10.796843528747559\n",
      "Critic Loss: 3.754288673400879\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 8.547696113586426\n",
      "Critic Loss: 6.756133079528809\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 7.069960594177246\n",
      "Critic Loss: 3.234076976776123\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 12.482369422912598\n",
      "Critic Loss: 6.963686943054199\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 15.388010025024414\n",
      "Critic Loss: 4.129879474639893\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 9.240196228027344\n",
      "Critic Loss: 2.683520793914795\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 7.663357257843018\n",
      "Critic Loss: 4.480292320251465\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 7.428435325622559\n",
      "Critic Loss: 2.8670079708099365\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 5.001758575439453\n",
      "Critic Loss: 2.6788976192474365\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 5.8223876953125\n",
      "Critic Loss: 2.871912956237793\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 11.337198257446289\n",
      "Critic Loss: 3.4476139545440674\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 8.37691879272461\n",
      "Critic Loss: 3.6693274974823\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 12.431873321533203\n",
      "Critic Loss: 4.253198623657227\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 8.211359024047852\n",
      "Critic Loss: 3.2468249797821045\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 11.578804016113281\n",
      "Critic Loss: 6.820830345153809\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 6.615270614624023\n",
      "Critic Loss: 3.08577036857605\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 14.870339393615723\n",
      "Critic Loss: 3.395211935043335\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 11.60207462310791\n",
      "Critic Loss: 4.969377517700195\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 10.73878002166748\n",
      "Critic Loss: 2.459746837615967\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 14.387978553771973\n",
      "Critic Loss: 5.115215301513672\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 9.717162132263184\n",
      "Critic Loss: 3.3172447681427\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 12.083490371704102\n",
      "Critic Loss: 3.2737059593200684\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 8.770819664001465\n",
      "Critic Loss: 4.7379255294799805\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99469a7a7f6a4e21ac5c0f07f202b67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>102.71429</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>109.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>8.67928</td></tr><tr><td>Loss/Critic_loss</td><td>4.73793</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.95945</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01844</td></tr><tr><td>Loss/Policy_loss</td><td>8.72356</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>8.77082</td></tr><tr><td>Metric/Explained_variance</td><td>0.57778</td></tr><tr><td>Reward/Mean_train_reward</td><td>-51.704</td></tr><tr><td>Reward/Mean_val_reward</td><td>-45.628</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-46.47757</td></tr><tr><td>global_step</td><td>121</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dulcet-sweep-48</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/3hxjla7l' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/3hxjla7l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_211052-3hxjla7l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 48ix3zrb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.006179778012259366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004824606345712751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0003725617620204196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9988965030099008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.1663894993434502e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.2781333552433187e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_212358-48ix3zrb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/48ix3zrb' target=\"_blank\">crimson-sweep-49</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/48ix3zrb' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/48ix3zrb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.006179778012259366, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004824606345712751, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0003725617620204196, 'epochs': 10, 'exponential_factor': 0.9988965030099008, 'gamma': 0.9, 'hidden_sizes': [250, 150, 250, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 1.1663894993434502e-05, 'l2_factor': 3.2781333552433187e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.006179778012259366, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004824606345712751, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0003725617620204196, 'epochs': 10, 'exponential_factor': 0.9988965030099008, 'gamma': 0.9, 'l1_factor': 1.1663894993434502e-05, 'l2_factor': 3.2781333552433187e-06, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.006179778012259366, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004824606345712751, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0003725617620204196, 'epochs': 10, 'exponential_factor': 0.9988965030099008, 'gamma': 0.9, 'l1_factor': 1.1663894993434502e-05, 'l2_factor': 3.2781333552433187e-06, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.006179778012259366, 'critic_lr': 0.004824606345712751, 'decay_method': 'exponential', 'exponential_factor': 0.9988965030099008, 'value_loss_factor': 1, 'entropy': 0.0003725617620204196, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.1663894993434502e-05, 'l2_factor': 3.2781333552433187e-06, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [250, 150, 250, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 23.805702209472656\n",
      "Critic Loss: 23.397930145263672\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 11.104374885559082\n",
      "Critic Loss: 9.70785140991211\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 41.1546516418457\n",
      "Critic Loss: 47.981285095214844\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -1.5501445531845093\n",
      "Critic Loss: 3.7238645553588867\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 7.605279445648193\n",
      "Critic Loss: 11.186874389648438\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 16.21332359313965\n",
      "Critic Loss: 6.043191432952881\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -4.207659721374512\n",
      "Critic Loss: 10.688328742980957\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 2.267453193664551\n",
      "Critic Loss: 14.551700592041016\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -1.0612751245498657\n",
      "Critic Loss: 9.424722671508789\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 1.133560299873352\n",
      "Critic Loss: 8.179296493530273\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.3711880445480347\n",
      "Critic Loss: 5.4670562744140625\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 4.237078666687012\n",
      "Critic Loss: 9.006962776184082\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -1.038016676902771\n",
      "Critic Loss: 6.479520797729492\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -3.148642063140869\n",
      "Critic Loss: 2.378448247909546\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.3712173700332642\n",
      "Critic Loss: 2.0508859157562256\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.4581080377101898\n",
      "Critic Loss: 1.257094144821167\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 2.1259424686431885\n",
      "Critic Loss: 2.657292366027832\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -2.585623025894165\n",
      "Critic Loss: 0.6073581576347351\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -3.5825304985046387\n",
      "Critic Loss: 1.241978406906128\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.12393248826265335\n",
      "Critic Loss: 1.081512451171875\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -3.068235158920288\n",
      "Critic Loss: 2.8770079612731934\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -2.9844348430633545\n",
      "Critic Loss: 1.558335781097412\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.650286853313446\n",
      "Critic Loss: 1.7238616943359375\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -1.4486238956451416\n",
      "Critic Loss: 1.410703182220459\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.9535177946090698\n",
      "Critic Loss: 3.098116397857666\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.4420236349105835\n",
      "Critic Loss: 2.554445743560791\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.5484814047813416\n",
      "Critic Loss: 2.6487600803375244\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.05210038647055626\n",
      "Critic Loss: 7.719760894775391\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 6.423773765563965\n",
      "Critic Loss: 7.877567768096924\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.6705164909362793\n",
      "Critic Loss: 7.484958171844482\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -1.4184490442276\n",
      "Critic Loss: 5.977100372314453\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.5819855332374573\n",
      "Critic Loss: 5.2480902671813965\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.256950318813324\n",
      "Critic Loss: 2.112191677093506\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -1.4144264459609985\n",
      "Critic Loss: 1.3667724132537842\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.8640244007110596\n",
      "Critic Loss: 1.1311298608779907\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -1.0391478538513184\n",
      "Critic Loss: 0.7519018054008484\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 1.3994293212890625\n",
      "Critic Loss: 0.997218132019043\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -1.5514516830444336\n",
      "Critic Loss: 1.3319462537765503\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -1.0012426376342773\n",
      "Critic Loss: 0.5849829316139221\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.8077369928359985\n",
      "Critic Loss: 0.8790817856788635\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.40041038393974304\n",
      "Critic Loss: 1.2401179075241089\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.09992196410894394\n",
      "Critic Loss: 0.8077169060707092\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -1.1896246671676636\n",
      "Critic Loss: 0.4806897044181824\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.26810476183891296\n",
      "Critic Loss: 0.813422441482544\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -2.2259066104888916\n",
      "Critic Loss: 4.4367265701293945\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -2.8217580318450928\n",
      "Critic Loss: 0.6553393602371216\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.7741082310676575\n",
      "Critic Loss: 5.663467884063721\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.5785301327705383\n",
      "Critic Loss: 4.058183193206787\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -1.9782658815383911\n",
      "Critic Loss: 2.9387381076812744\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.11917176842689514\n",
      "Critic Loss: 1.5360716581344604\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.8397652506828308\n",
      "Critic Loss: 1.4578875303268433\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.5978673100471497\n",
      "Critic Loss: 0.5521293878555298\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -1.7089262008666992\n",
      "Critic Loss: 2.711984395980835\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 1.8140743970870972\n",
      "Critic Loss: 0.9945768713951111\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -1.083569049835205\n",
      "Critic Loss: 0.9996814727783203\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.4363696873188019\n",
      "Critic Loss: 1.183953881263733\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.9195608496665955\n",
      "Critic Loss: 0.5199687480926514\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -1.7590514421463013\n",
      "Critic Loss: 0.9506357908248901\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.2896311581134796\n",
      "Critic Loss: 0.7769481539726257\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -1.272327184677124\n",
      "Critic Loss: 1.3842347860336304\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -1.1424667835235596\n",
      "Critic Loss: 1.9623498916625977\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.1304604411125183\n",
      "Critic Loss: 1.9913383722305298\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -1.8924760818481445\n",
      "Critic Loss: 2.125483751296997\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -3.080120801925659\n",
      "Critic Loss: 2.8925304412841797\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.2667389512062073\n",
      "Critic Loss: 4.263916015625\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -1.3671859502792358\n",
      "Critic Loss: 14.835169792175293\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -1.9204940795898438\n",
      "Critic Loss: 0.5674509406089783\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.3558400273323059\n",
      "Critic Loss: 0.8640836477279663\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -3.156812906265259\n",
      "Critic Loss: 4.154125213623047\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.465720534324646\n",
      "Critic Loss: 0.37851983308792114\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.8425101041793823\n",
      "Critic Loss: 0.7088971734046936\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 1.171670913696289\n",
      "Critic Loss: 0.35351601243019104\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -2.3547487258911133\n",
      "Critic Loss: 0.7373594641685486\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.6511945128440857\n",
      "Critic Loss: 0.34116241335868835\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -1.5805670022964478\n",
      "Critic Loss: 0.8729804754257202\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.798657238483429\n",
      "Critic Loss: 0.9726203680038452\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.8666199445724487\n",
      "Critic Loss: 1.134880781173706\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c40354304147169a4f2605921a5998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>129.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>129.39999</td></tr><tr><td>Learning_rate/Actor</td><td>0.00568</td></tr><tr><td>Learning_rate/Critic</td><td>0.00444</td></tr><tr><td>Loss/Actor_loss</td><td>-1.00918</td></tr><tr><td>Loss/Critic_loss</td><td>1.13488</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.03452</td></tr><tr><td>Loss/KL_divergence</td><td>0.02159</td></tr><tr><td>Loss/Policy_loss</td><td>-1.00917</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.86662</td></tr><tr><td>Metric/Explained_variance</td><td>0.83316</td></tr><tr><td>Reward/Mean_train_reward</td><td>12.068</td></tr><tr><td>Reward/Mean_val_reward</td><td>10.5924</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>11.74902</td></tr><tr><td>global_step</td><td>77</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-49</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/48ix3zrb' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/48ix3zrb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_212358-48ix3zrb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8x4mrtvi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00012169275453672376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004302512627791511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.018241110283041193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9749493872338776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.7385250123977275e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.284751929735322e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_213252-8x4mrtvi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/8x4mrtvi' target=\"_blank\">frosty-sweep-50</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8x4mrtvi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8x4mrtvi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.00012169275453672376, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004302512627791511, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018241110283041193, 'epochs': 10, 'exponential_factor': 0.9749493872338776, 'gamma': 0.95, 'hidden_sizes': [250, 150, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 2.7385250123977275e-06, 'l2_factor': 6.284751929735322e-05, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 250, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00012169275453672376, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004302512627791511, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018241110283041193, 'epochs': 10, 'exponential_factor': 0.9749493872338776, 'gamma': 0.95, 'l1_factor': 2.7385250123977275e-06, 'l2_factor': 6.284751929735322e-05, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 250, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00012169275453672376, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004302512627791511, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.018241110283041193, 'epochs': 10, 'exponential_factor': 0.9749493872338776, 'gamma': 0.95, 'l1_factor': 2.7385250123977275e-06, 'l2_factor': 6.284751929735322e-05, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00012169275453672376, 'critic_lr': 0.004302512627791511, 'decay_method': 'exponential', 'exponential_factor': 0.9749493872338776, 'value_loss_factor': 1, 'entropy': 0.018241110283041193, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.7385250123977275e-06, 'l2_factor': 6.284751929735322e-05, 'T': 1024, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [250, 150, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 16.838096618652344\n",
      "Critic Loss: 18.78809356689453\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 9.264951705932617\n",
      "Critic Loss: 6.536477565765381\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 12.662299156188965\n",
      "Critic Loss: 11.857535362243652\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 9.322467803955078\n",
      "Critic Loss: 8.211934089660645\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 5.964711666107178\n",
      "Critic Loss: 7.813625335693359\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 5.0809502601623535\n",
      "Critic Loss: 9.986220359802246\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.9471489191055298\n",
      "Critic Loss: 6.619021415710449\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 2.424542188644409\n",
      "Critic Loss: 7.427034378051758\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.8334923982620239\n",
      "Critic Loss: 3.6520681381225586\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -1.5776515007019043\n",
      "Critic Loss: 3.3307955265045166\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.19009095430374146\n",
      "Critic Loss: 4.947102069854736\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.8456177711486816\n",
      "Critic Loss: 4.0441460609436035\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.1039537712931633\n",
      "Critic Loss: 4.677996635437012\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.5390499830245972\n",
      "Critic Loss: 2.7945191860198975\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.7976885437965393\n",
      "Critic Loss: 1.9124350547790527\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.4207819104194641\n",
      "Critic Loss: 4.003029823303223\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.7470519542694092\n",
      "Critic Loss: 4.044293403625488\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.1591675877571106\n",
      "Critic Loss: 3.23862886428833\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -1.1205973625183105\n",
      "Critic Loss: 2.5460243225097656\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.8967668414115906\n",
      "Critic Loss: 2.0524258613586426\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -1.0664846897125244\n",
      "Critic Loss: 2.177083730697632\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -1.4147316217422485\n",
      "Critic Loss: 2.344043254852295\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -2.9986307621002197\n",
      "Critic Loss: 1.9668809175491333\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -1.5115761756896973\n",
      "Critic Loss: 1.5902618169784546\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.26185929775238037\n",
      "Critic Loss: 4.199016571044922\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.1139626502990723\n",
      "Critic Loss: 3.231520891189575\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.8158528804779053\n",
      "Critic Loss: 6.009933948516846\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 2.5296123027801514\n",
      "Critic Loss: 4.468145370483398\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -4.485376358032227\n",
      "Critic Loss: 2.5131335258483887\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 2.618393659591675\n",
      "Critic Loss: 4.218174934387207\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -1.8397443294525146\n",
      "Critic Loss: 3.007301092147827\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.46375229954719543\n",
      "Critic Loss: 3.513728141784668\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -1.575809359550476\n",
      "Critic Loss: 3.8897156715393066\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 1.3491524457931519\n",
      "Critic Loss: 4.781567096710205\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -3.2252299785614014\n",
      "Critic Loss: 2.8902170658111572\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 3.6139559745788574\n",
      "Critic Loss: 5.129324436187744\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 7.529714584350586\n",
      "Critic Loss: 3.9832067489624023\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 6.7538628578186035\n",
      "Critic Loss: 3.4215993881225586\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 8.394875526428223\n",
      "Critic Loss: 3.39686918258667\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 8.203532218933105\n",
      "Critic Loss: 2.2454893589019775\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 12.253215789794922\n",
      "Critic Loss: 3.167215347290039\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 13.140911102294922\n",
      "Critic Loss: 1.948999047279358\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 13.137866020202637\n",
      "Critic Loss: 2.4718055725097656\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 9.660331726074219\n",
      "Critic Loss: 2.1313540935516357\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 12.183642387390137\n",
      "Critic Loss: 2.101722240447998\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 7.051236152648926\n",
      "Critic Loss: 1.4487895965576172\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 10.077404022216797\n",
      "Critic Loss: 1.7273118495941162\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 11.52802562713623\n",
      "Critic Loss: 1.4429675340652466\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 9.610437393188477\n",
      "Critic Loss: 2.7328877449035645\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 11.507596015930176\n",
      "Critic Loss: 3.0807929039001465\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 13.388049125671387\n",
      "Critic Loss: 2.4481253623962402\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 12.437095642089844\n",
      "Critic Loss: 2.851048707962036\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d009023ec14f979c057604c6b1de8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>54.41177</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>54.9</td></tr><tr><td>Learning_rate/Actor</td><td>3e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.00118</td></tr><tr><td>Loss/Actor_loss</td><td>12.34093</td></tr><tr><td>Loss/Critic_loss</td><td>2.85105</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.37546</td></tr><tr><td>Loss/KL_divergence</td><td>0.00475</td></tr><tr><td>Loss/Policy_loss</td><td>12.34778</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>12.4371</td></tr><tr><td>Metric/Explained_variance</td><td>0.80363</td></tr><tr><td>Reward/Mean_train_reward</td><td>-47.37482</td></tr><tr><td>Reward/Mean_val_reward</td><td>-45.8181</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-44.5698</td></tr><tr><td>global_step</td><td>52</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-sweep-50</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/8x4mrtvi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/8x4mrtvi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_213252-8x4mrtvi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3ylgervy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0012405993154504652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00032196669792835625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04997452531330648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9337345121334832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.90465561979168e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0005147770722362436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_213937-3ylgervy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/3ylgervy' target=\"_blank\">happy-sweep-51</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/3ylgervy' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/3ylgervy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.0012405993154504652, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00032196669792835625, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04997452531330648, 'epochs': 10, 'exponential_factor': 0.9337345121334832, 'gamma': 0.9, 'hidden_sizes': [350, 150, 350, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 3.90465561979168e-05, 'l2_factor': 0.0005147770722362436, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0012405993154504652, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00032196669792835625, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04997452531330648, 'epochs': 10, 'exponential_factor': 0.9337345121334832, 'gamma': 0.9, 'l1_factor': 3.90465561979168e-05, 'l2_factor': 0.0005147770722362436, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0012405993154504652, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00032196669792835625, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04997452531330648, 'epochs': 10, 'exponential_factor': 0.9337345121334832, 'gamma': 0.9, 'l1_factor': 3.90465561979168e-05, 'l2_factor': 0.0005147770722362436, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0012405993154504652, 'critic_lr': 0.00032196669792835625, 'decay_method': 'exponential', 'exponential_factor': 0.9337345121334832, 'value_loss_factor': 1, 'entropy': 0.04997452531330648, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.90465561979168e-05, 'l2_factor': 0.0005147770722362436, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [350, 150, 350, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 24.74949836730957\n",
      "Critic Loss: 25.779338836669922\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 10.210274696350098\n",
      "Critic Loss: 11.047104835510254\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 23.31509017944336\n",
      "Critic Loss: 16.410808563232422\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 12.676971435546875\n",
      "Critic Loss: 14.335409164428711\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 10.738351821899414\n",
      "Critic Loss: 11.28171443939209\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 2.0236399173736572\n",
      "Critic Loss: 3.6825432777404785\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.25292062759399414\n",
      "Critic Loss: 3.923271894454956\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.802958607673645\n",
      "Critic Loss: 0.8768516182899475\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 2.8246712684631348\n",
      "Critic Loss: 3.5509400367736816\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 6.202404022216797\n",
      "Critic Loss: 7.60418701171875\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.5984468460083008\n",
      "Critic Loss: 3.274047374725342\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 2.669053077697754\n",
      "Critic Loss: 4.76891565322876\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 5.318321704864502\n",
      "Critic Loss: 5.6957783699035645\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 8.31692123413086\n",
      "Critic Loss: 7.306991100311279\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 3.177902936935425\n",
      "Critic Loss: 3.7757813930511475\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.02913963794708252\n",
      "Critic Loss: 3.347642183303833\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -1.586250901222229\n",
      "Critic Loss: 2.1801180839538574\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.1164627075195312\n",
      "Critic Loss: 2.292383909225464\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 3.5436301231384277\n",
      "Critic Loss: 4.190212726593018\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.5630182027816772\n",
      "Critic Loss: 2.8985137939453125\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 11.5609769821167\n",
      "Critic Loss: 7.384692192077637\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.5860533118247986\n",
      "Critic Loss: 1.3752360343933105\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -2.055373191833496\n",
      "Critic Loss: 2.887211799621582\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.5433269143104553\n",
      "Critic Loss: 1.6616594791412354\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.6447591185569763\n",
      "Critic Loss: 3.2837443351745605\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.41671109199523926\n",
      "Critic Loss: 4.161797046661377\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.0557183027267456\n",
      "Critic Loss: 2.260213613510132\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.05658966302871704\n",
      "Critic Loss: 1.1312971115112305\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -1.342045783996582\n",
      "Critic Loss: 3.039762258529663\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -4.177841663360596\n",
      "Critic Loss: 1.1658167839050293\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 5.725385665893555\n",
      "Critic Loss: 3.390693187713623\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 4.322437763214111\n",
      "Critic Loss: 3.1209921836853027\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 2.776319980621338\n",
      "Critic Loss: 2.4097535610198975\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.9234194755554199\n",
      "Critic Loss: 3.5280046463012695\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 1.2994043827056885\n",
      "Critic Loss: 0.45660895109176636\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 6.879739284515381\n",
      "Critic Loss: 3.654827356338501\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -1.0505397319793701\n",
      "Critic Loss: 3.0344748497009277\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.9471540451049805\n",
      "Critic Loss: 1.3857625722885132\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -3.1305978298187256\n",
      "Critic Loss: 2.1621596813201904\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 4.682248115539551\n",
      "Critic Loss: 1.7915055751800537\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -1.6559913158416748\n",
      "Critic Loss: 1.5916342735290527\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -1.7042791843414307\n",
      "Critic Loss: 2.3296902179718018\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -2.056722402572632\n",
      "Critic Loss: 1.1323773860931396\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.32904571294784546\n",
      "Critic Loss: 2.3310348987579346\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.5099305510520935\n",
      "Critic Loss: 1.648337960243225\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -2.2015559673309326\n",
      "Critic Loss: 1.0880005359649658\n",
      "\n",
      "New best validation reward reached in update [46/200]\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -2.3095791339874268\n",
      "Critic Loss: 1.715146541595459\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 5.423317909240723\n",
      "Critic Loss: 4.82635498046875\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.5632401704788208\n",
      "Critic Loss: 2.2275798320770264\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.010215222835540771\n",
      "Critic Loss: 2.2207999229431152\n",
      "\n",
      "New best validation reward reached in update [50/200]\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -4.468880653381348\n",
      "Critic Loss: 1.783486008644104\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 5.156017303466797\n",
      "Critic Loss: 2.2375965118408203\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -4.4459452629089355\n",
      "Critic Loss: 1.3418891429901123\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -1.415398120880127\n",
      "Critic Loss: 1.1650891304016113\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 4.034777641296387\n",
      "Critic Loss: 2.0372958183288574\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -1.9176299571990967\n",
      "Critic Loss: 1.3365839719772339\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 5.233489513397217\n",
      "Critic Loss: 3.5588927268981934\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -2.8099441528320312\n",
      "Critic Loss: 1.3786985874176025\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 3.583866596221924\n",
      "Critic Loss: 1.8290116786956787\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.7761548161506653\n",
      "Critic Loss: 2.6173408031463623\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -1.7260184288024902\n",
      "Critic Loss: 1.1019927263259888\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.4382673501968384\n",
      "Critic Loss: 1.0207569599151611\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 6.677150249481201\n",
      "Critic Loss: 3.4726414680480957\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.15345776081085205\n",
      "Critic Loss: 2.349375009536743\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 2.555016279220581\n",
      "Critic Loss: 1.3436774015426636\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 2.716122627258301\n",
      "Critic Loss: 1.7961859703063965\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -2.567046642303467\n",
      "Critic Loss: 1.609877109527588\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.871184229850769\n",
      "Critic Loss: 1.0444451570510864\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.8944449424743652\n",
      "Critic Loss: 2.867912530899048\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -1.2171952724456787\n",
      "Critic Loss: 2.2877819538116455\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 2.998687505722046\n",
      "Critic Loss: 1.57295560836792\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 3.6651031970977783\n",
      "Critic Loss: 2.5506248474121094\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -1.2754006385803223\n",
      "Critic Loss: 0.7757250070571899\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -1.3885889053344727\n",
      "Critic Loss: 1.178302526473999\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 5.810060501098633\n",
      "Critic Loss: 3.9474215507507324\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 1.0313072204589844\n",
      "Critic Loss: 1.6942908763885498\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -3.3362536430358887\n",
      "Critic Loss: 2.2559163570404053\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -1.075533151626587\n",
      "Critic Loss: 0.7516137361526489\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -3.0628743171691895\n",
      "Critic Loss: 1.3340773582458496\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -1.0789539813995361\n",
      "Critic Loss: 1.14650559425354\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65055ab9e144b87bde73b068eb3c934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>95.88889</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>90.1</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-2.37723</td></tr><tr><td>Loss/Critic_loss</td><td>1.14651</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.53933</td></tr><tr><td>Loss/KL_divergence</td><td>0.02323</td></tr><tr><td>Loss/Policy_loss</td><td>-2.35027</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-1.07895</td></tr><tr><td>Metric/Explained_variance</td><td>0.80629</td></tr><tr><td>Reward/Mean_train_reward</td><td>4.85933</td></tr><tr><td>Reward/Mean_val_reward</td><td>-1.0149</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>1.59647</td></tr><tr><td>global_step</td><td>80</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-51</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/3ylgervy' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/3ylgervy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_213937-3ylgervy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: enpv4s2d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0003185864450747112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0009749802489896222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.032927301101294014\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9464004767371824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0005344485465055979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.2097712257580445e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_215237-enpv4s2d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/enpv4s2d' target=\"_blank\">ethereal-sweep-52</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/enpv4s2d' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/enpv4s2d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.0003185864450747112, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009749802489896222, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.032927301101294014, 'epochs': 10, 'exponential_factor': 0.9464004767371824, 'gamma': 0.99, 'hidden_sizes': [350, 150, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0005344485465055979, 'l2_factor': 1.2097712257580445e-05, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0003185864450747112, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009749802489896222, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.032927301101294014, 'epochs': 10, 'exponential_factor': 0.9464004767371824, 'gamma': 0.99, 'l1_factor': 0.0005344485465055979, 'l2_factor': 1.2097712257580445e-05, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0003185864450747112, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009749802489896222, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.032927301101294014, 'epochs': 10, 'exponential_factor': 0.9464004767371824, 'gamma': 0.99, 'l1_factor': 0.0005344485465055979, 'l2_factor': 1.2097712257580445e-05, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0003185864450747112, 'critic_lr': 0.0009749802489896222, 'decay_method': 'exponential', 'exponential_factor': 0.9464004767371824, 'value_loss_factor': 1, 'entropy': 0.032927301101294014, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0005344485465055979, 'l2_factor': 1.2097712257580445e-05, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [350, 150, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 61.923370361328125\n",
      "Critic Loss: 38.11903381347656\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 50.0779914855957\n",
      "Critic Loss: 8.794425010681152\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 38.7890625\n",
      "Critic Loss: 11.342279434204102\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 45.76299285888672\n",
      "Critic Loss: 10.563990592956543\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 43.502113342285156\n",
      "Critic Loss: 12.204385757446289\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 37.94782257080078\n",
      "Critic Loss: 11.819604873657227\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 36.91664123535156\n",
      "Critic Loss: 11.93177318572998\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 33.86558532714844\n",
      "Critic Loss: 9.27685546875\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 39.913639068603516\n",
      "Critic Loss: 17.311805725097656\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 27.310300827026367\n",
      "Critic Loss: 12.915443420410156\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 30.595046997070312\n",
      "Critic Loss: 11.062263488769531\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 24.71632194519043\n",
      "Critic Loss: 10.35013484954834\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 32.28190231323242\n",
      "Critic Loss: 12.627668380737305\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 36.627479553222656\n",
      "Critic Loss: 9.154472351074219\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 30.45549964904785\n",
      "Critic Loss: 8.706293106079102\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 34.47198486328125\n",
      "Critic Loss: 8.021183967590332\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 30.774972915649414\n",
      "Critic Loss: 8.58621883392334\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 21.99530029296875\n",
      "Critic Loss: 5.865787029266357\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 25.20307731628418\n",
      "Critic Loss: 4.948774337768555\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 21.645736694335938\n",
      "Critic Loss: 4.710998058319092\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 32.58403396606445\n",
      "Critic Loss: 8.41335391998291\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 30.28535270690918\n",
      "Critic Loss: 7.24926233291626\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 29.842247009277344\n",
      "Critic Loss: 5.641665935516357\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 30.3995418548584\n",
      "Critic Loss: 10.521316528320312\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 26.552127838134766\n",
      "Critic Loss: 6.09796667098999\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 28.08809471130371\n",
      "Critic Loss: 6.074690818786621\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 29.893165588378906\n",
      "Critic Loss: 7.489919662475586\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 30.079851150512695\n",
      "Critic Loss: 11.812716484069824\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 23.89997673034668\n",
      "Critic Loss: 8.032783508300781\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 27.72066879272461\n",
      "Critic Loss: 10.725378036499023\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 31.51662826538086\n",
      "Critic Loss: 7.54611349105835\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 25.652507781982422\n",
      "Critic Loss: 7.292576313018799\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 23.36602210998535\n",
      "Critic Loss: 5.7905449867248535\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 29.31190299987793\n",
      "Critic Loss: 6.055108547210693\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 30.54355812072754\n",
      "Critic Loss: 8.754860877990723\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 26.721235275268555\n",
      "Critic Loss: 7.583223342895508\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 26.941789627075195\n",
      "Critic Loss: 5.1799726486206055\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 25.52460289001465\n",
      "Critic Loss: 6.97006893157959\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 21.73335838317871\n",
      "Critic Loss: 4.934974670410156\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 24.263755798339844\n",
      "Critic Loss: 3.766547441482544\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 29.81138801574707\n",
      "Critic Loss: 7.196742057800293\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 31.667600631713867\n",
      "Critic Loss: 7.761321067810059\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 25.707006454467773\n",
      "Critic Loss: 5.60191011428833\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 26.74673080444336\n",
      "Critic Loss: 6.1585612297058105\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 29.62823486328125\n",
      "Critic Loss: 5.765389919281006\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 26.667043685913086\n",
      "Critic Loss: 4.576303482055664\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 31.06345558166504\n",
      "Critic Loss: 7.106287956237793\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 27.225479125976562\n",
      "Critic Loss: 5.836385726928711\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 25.160987854003906\n",
      "Critic Loss: 4.463155269622803\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 28.8005428314209\n",
      "Critic Loss: 9.473002433776855\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 24.05291175842285\n",
      "Critic Loss: 4.536386489868164\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 33.3399658203125\n",
      "Critic Loss: 4.817134857177734\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 30.180862426757812\n",
      "Critic Loss: 4.05036735534668\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 30.02750587463379\n",
      "Critic Loss: 5.085422992706299\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 29.327713012695312\n",
      "Critic Loss: 6.003346920013428\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 28.280309677124023\n",
      "Critic Loss: 5.754015922546387\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 25.43520164489746\n",
      "Critic Loss: 4.297614097595215\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 27.019289016723633\n",
      "Critic Loss: 5.935096740722656\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 25.25735855102539\n",
      "Critic Loss: 11.279709815979004\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 20.308420181274414\n",
      "Critic Loss: 6.922054290771484\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 32.30549621582031\n",
      "Critic Loss: 6.6263427734375\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 26.724477767944336\n",
      "Critic Loss: 4.382325649261475\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 28.50571060180664\n",
      "Critic Loss: 5.577274322509766\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 28.850074768066406\n",
      "Critic Loss: 5.929770469665527\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 25.024959564208984\n",
      "Critic Loss: 4.6865234375\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 29.143455505371094\n",
      "Critic Loss: 6.643536567687988\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 29.870887756347656\n",
      "Critic Loss: 7.97727108001709\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 24.47426414489746\n",
      "Critic Loss: 6.605733394622803\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 25.66834831237793\n",
      "Critic Loss: 5.662158489227295\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 25.6524658203125\n",
      "Critic Loss: 5.0158610343933105\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 32.58226013183594\n",
      "Critic Loss: 5.965896129608154\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 21.90601921081543\n",
      "Critic Loss: 2.843299388885498\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 25.564760208129883\n",
      "Critic Loss: 8.544727325439453\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 21.202869415283203\n",
      "Critic Loss: 3.7710347175598145\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 30.33915901184082\n",
      "Critic Loss: 6.6562042236328125\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 29.824121475219727\n",
      "Critic Loss: 4.210939407348633\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 28.100200653076172\n",
      "Critic Loss: 4.600778102874756\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 26.659027099609375\n",
      "Critic Loss: 4.943093776702881\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 28.76766014099121\n",
      "Critic Loss: 4.783222198486328\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 28.49418830871582\n",
      "Critic Loss: 4.341241359710693\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 32.444515228271484\n",
      "Critic Loss: 6.51975154876709\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 32.37696075439453\n",
      "Critic Loss: 5.907201766967773\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15910dcea4bc4bc4962324a7e04a4bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>50.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>49.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>26.42885</td></tr><tr><td>Loss/Critic_loss</td><td>5.9072</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.53334</td></tr><tr><td>Loss/KL_divergence</td><td>0.00269</td></tr><tr><td>Loss/Policy_loss</td><td>26.47934</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>32.37696</td></tr><tr><td>Metric/Explained_variance</td><td>0.60309</td></tr><tr><td>Reward/Mean_train_reward</td><td>-65.19957</td></tr><tr><td>Reward/Mean_val_reward</td><td>-68.6516</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-63.32682</td></tr><tr><td>global_step</td><td>82</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-52</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/enpv4s2d' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/enpv4s2d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_215237-enpv4s2d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ykoal2yb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0007683729850399673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0031834290132694626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03910280049020148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9430100887992224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.1088819481269017e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.025686261245071e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_215937-ykoal2yb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/ykoal2yb' target=\"_blank\">absurd-sweep-53</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ykoal2yb' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ykoal2yb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0007683729850399673, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0031834290132694626, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03910280049020148, 'epochs': 10, 'exponential_factor': 0.9430100887992224, 'gamma': 0.9, 'hidden_sizes': [350, 150, 150, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.1088819481269017e-06, 'l2_factor': 4.025686261245071e-06, 'lrelu': 0.001, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0007683729850399673, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0031834290132694626, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03910280049020148, 'epochs': 10, 'exponential_factor': 0.9430100887992224, 'gamma': 0.9, 'l1_factor': 1.1088819481269017e-06, 'l2_factor': 4.025686261245071e-06, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0007683729850399673, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0031834290132694626, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03910280049020148, 'epochs': 10, 'exponential_factor': 0.9430100887992224, 'gamma': 0.9, 'l1_factor': 1.1088819481269017e-06, 'l2_factor': 4.025686261245071e-06, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0007683729850399673, 'critic_lr': 0.0031834290132694626, 'decay_method': 'exponential', 'exponential_factor': 0.9430100887992224, 'value_loss_factor': 1, 'entropy': 0.03910280049020148, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.1088819481269017e-06, 'l2_factor': 4.025686261245071e-06, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 150, 150, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: -0.1003636047244072\n",
      "Critic Loss: 14.59492015838623\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.10552820563316345\n",
      "Critic Loss: 12.652822494506836\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.07330174744129181\n",
      "Critic Loss: 8.38958740234375\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.06625494360923767\n",
      "Critic Loss: 8.539146423339844\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.08705473691225052\n",
      "Critic Loss: 4.560276031494141\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.0725259855389595\n",
      "Critic Loss: 7.262905120849609\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.05038547143340111\n",
      "Critic Loss: 4.347349166870117\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.07063675671815872\n",
      "Critic Loss: 4.433465480804443\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.08623314648866653\n",
      "Critic Loss: 7.019503593444824\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.08142491430044174\n",
      "Critic Loss: 5.252278804779053\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.07628341019153595\n",
      "Critic Loss: 6.725253582000732\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.07849422097206116\n",
      "Critic Loss: 7.1216840744018555\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.06494177877902985\n",
      "Critic Loss: 6.8590569496154785\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.0741206556558609\n",
      "Critic Loss: 5.794773578643799\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.06800223141908646\n",
      "Critic Loss: 4.870667457580566\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.05243288353085518\n",
      "Critic Loss: 5.8382110595703125\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.05791127681732178\n",
      "Critic Loss: 4.038832664489746\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.062141478061676025\n",
      "Critic Loss: 3.974536895751953\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.0593160018324852\n",
      "Critic Loss: 4.825855255126953\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.05366592854261398\n",
      "Critic Loss: 4.638659954071045\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.06418208032846451\n",
      "Critic Loss: 4.238552570343018\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.045386627316474915\n",
      "Critic Loss: 4.129120349884033\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.03285868093371391\n",
      "Critic Loss: 5.053525924682617\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.018078550696372986\n",
      "Critic Loss: 4.665579795837402\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.05098659545183182\n",
      "Critic Loss: 3.5695531368255615\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.019118696451187134\n",
      "Critic Loss: 3.717787742614746\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.012078516185283661\n",
      "Critic Loss: 3.904637098312378\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.04498216509819031\n",
      "Critic Loss: 3.3932182788848877\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.041688092052936554\n",
      "Critic Loss: 2.7726683616638184\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.05253753438591957\n",
      "Critic Loss: 3.0607478618621826\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.04355520009994507\n",
      "Critic Loss: 2.8779497146606445\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.0313078872859478\n",
      "Critic Loss: 3.682190418243408\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.022695161402225494\n",
      "Critic Loss: 5.590673923492432\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.014481216669082642\n",
      "Critic Loss: 4.913175582885742\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.0021338597871363163\n",
      "Critic Loss: 3.7337608337402344\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.01920446753501892\n",
      "Critic Loss: 4.604137420654297\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.015322206541895866\n",
      "Critic Loss: 4.0083818435668945\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.002785222139209509\n",
      "Critic Loss: 4.32663631439209\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.010235071182250977\n",
      "Critic Loss: 4.438962459564209\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.011102739721536636\n",
      "Critic Loss: 3.7260260581970215\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.0054207067005336285\n",
      "Critic Loss: 4.373330116271973\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.004316828679293394\n",
      "Critic Loss: 3.6020452976226807\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.0029264227487146854\n",
      "Critic Loss: 3.5484395027160645\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.00955270603299141\n",
      "Critic Loss: 3.318922996520996\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.003749458584934473\n",
      "Critic Loss: 2.8628122806549072\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.011746667325496674\n",
      "Critic Loss: 2.671677589416504\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.02107236348092556\n",
      "Critic Loss: 2.58905291557312\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.00959797389805317\n",
      "Critic Loss: 2.7995457649230957\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.005928748287260532\n",
      "Critic Loss: 2.6570725440979004\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.004220209084451199\n",
      "Critic Loss: 1.9858403205871582\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.0022872495464980602\n",
      "Critic Loss: 2.004092216491699\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.0013927877880632877\n",
      "Critic Loss: 2.674484968185425\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.00735130812972784\n",
      "Critic Loss: 2.2358295917510986\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.0019581555388867855\n",
      "Critic Loss: 2.4843332767486572\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.0055436743423342705\n",
      "Critic Loss: 3.105945587158203\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.011471467092633247\n",
      "Critic Loss: 2.638848066329956\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.018318509683012962\n",
      "Critic Loss: 2.577214241027832\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.005611739587038755\n",
      "Critic Loss: 1.8916436433792114\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.008033355697989464\n",
      "Critic Loss: 2.5543572902679443\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.0034508835524320602\n",
      "Critic Loss: 1.9627883434295654\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.007028021849691868\n",
      "Critic Loss: 2.1658718585968018\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.0034108292311429977\n",
      "Critic Loss: 1.8095446825027466\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.0054555232636630535\n",
      "Critic Loss: 2.464263439178467\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.032058730721473694\n",
      "Critic Loss: 1.7386772632598877\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.003972925711423159\n",
      "Critic Loss: 2.309614896774292\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.0018476853147149086\n",
      "Critic Loss: 3.0921640396118164\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.015283324755728245\n",
      "Critic Loss: 2.098522186279297\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.002457980066537857\n",
      "Critic Loss: 1.6438655853271484\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.011541113257408142\n",
      "Critic Loss: 1.8697810173034668\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.0028183041140437126\n",
      "Critic Loss: 1.7317001819610596\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.003993289079517126\n",
      "Critic Loss: 1.785624384880066\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.0001661563292145729\n",
      "Critic Loss: 1.9995646476745605\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.011204969137907028\n",
      "Critic Loss: 1.7543195486068726\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.0015925262123346329\n",
      "Critic Loss: 1.8719172477722168\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.005316554103046656\n",
      "Critic Loss: 1.9065747261047363\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.002764904871582985\n",
      "Critic Loss: 2.022691249847412\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.011107203550636768\n",
      "Critic Loss: 1.7815735340118408\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.007682626135647297\n",
      "Critic Loss: 1.8757296800613403\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.010999001562595367\n",
      "Critic Loss: 1.961691975593567\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.027976470068097115\n",
      "Critic Loss: 1.900237798690796\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.009313739836215973\n",
      "Critic Loss: 2.4421072006225586\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.0014347494579851627\n",
      "Critic Loss: 2.1509881019592285\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.007821204140782356\n",
      "Critic Loss: 1.4943435192108154\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.01070562843233347\n",
      "Critic Loss: 1.8253690004348755\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.0012187482789158821\n",
      "Critic Loss: 1.75419020652771\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39f317ec61a42309d8a44ced993a6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>59.33333</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>58.1</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>2e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.01756</td></tr><tr><td>Loss/Critic_loss</td><td>1.75419</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.28842</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0078</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00628</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.00122</td></tr><tr><td>Metric/Explained_variance</td><td>0.93566</td></tr><tr><td>Reward/Mean_train_reward</td><td>-40.075</td></tr><tr><td>Reward/Mean_val_reward</td><td>-40.8189</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-40.79115</td></tr><tr><td>global_step</td><td>85</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-sweep-53</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ykoal2yb' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ykoal2yb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_215937-ykoal2yb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ucweifxw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0018597558455479837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0003802279743328016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.031443250204864874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9913587228241542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.000496235211384677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00022208198245727136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_220400-ucweifxw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/ucweifxw' target=\"_blank\">proud-sweep-54</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ucweifxw' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ucweifxw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0018597558455479837, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0003802279743328016, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.031443250204864874, 'epochs': 10, 'exponential_factor': 0.9913587228241542, 'gamma': 0.9, 'hidden_sizes': [250, 150, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.000496235211384677, 'l2_factor': 0.00022208198245727136, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0018597558455479837, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0003802279743328016, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.031443250204864874, 'epochs': 10, 'exponential_factor': 0.9913587228241542, 'gamma': 0.9, 'l1_factor': 0.000496235211384677, 'l2_factor': 0.00022208198245727136, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0018597558455479837, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0003802279743328016, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.031443250204864874, 'epochs': 10, 'exponential_factor': 0.9913587228241542, 'gamma': 0.9, 'l1_factor': 0.000496235211384677, 'l2_factor': 0.00022208198245727136, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0018597558455479837, 'critic_lr': 0.0003802279743328016, 'decay_method': 'exponential', 'exponential_factor': 0.9913587228241542, 'value_loss_factor': 1, 'entropy': 0.031443250204864874, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.000496235211384677, 'l2_factor': 0.00022208198245727136, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [250, 150, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 3.9806058406829834\n",
      "Critic Loss: 32.24050521850586\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 3.8395512104034424\n",
      "Critic Loss: 29.771224975585938\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 3.707566022872925\n",
      "Critic Loss: 18.851797103881836\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 2.995286703109741\n",
      "Critic Loss: 17.804351806640625\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 2.4748096466064453\n",
      "Critic Loss: 9.304084777832031\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 2.039971113204956\n",
      "Critic Loss: 12.864970207214355\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.6128023862838745\n",
      "Critic Loss: 10.204550743103027\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 1.247351050376892\n",
      "Critic Loss: 8.75614070892334\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.9457072019577026\n",
      "Critic Loss: 7.611861228942871\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.7073685526847839\n",
      "Critic Loss: 8.644449234008789\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.5279802680015564\n",
      "Critic Loss: 6.935020446777344\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.4447099268436432\n",
      "Critic Loss: 6.342954635620117\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.36204180121421814\n",
      "Critic Loss: 6.0183258056640625\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.2972448766231537\n",
      "Critic Loss: 5.144826412200928\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.2486548125743866\n",
      "Critic Loss: 5.45454216003418\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.21096138656139374\n",
      "Critic Loss: 5.3663716316223145\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.18119706213474274\n",
      "Critic Loss: 5.137697219848633\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.1570443958044052\n",
      "Critic Loss: 4.8350982666015625\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.1349974125623703\n",
      "Critic Loss: 4.726110935211182\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.06743185222148895\n",
      "Critic Loss: 4.176180362701416\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.1128246933221817\n",
      "Critic Loss: 4.7824907302856445\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.09955907613039017\n",
      "Critic Loss: 4.51740026473999\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.10588186234235764\n",
      "Critic Loss: 4.617133617401123\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.07972679287195206\n",
      "Critic Loss: 5.042489051818848\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.08415922522544861\n",
      "Critic Loss: 4.5167670249938965\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.05731094628572464\n",
      "Critic Loss: 5.558823585510254\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.06057215854525566\n",
      "Critic Loss: 4.310129165649414\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.06533495336771011\n",
      "Critic Loss: 6.1108551025390625\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.031088516116142273\n",
      "Critic Loss: 5.373480796813965\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.03991536423563957\n",
      "Critic Loss: 4.695080280303955\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.049810558557510376\n",
      "Critic Loss: 4.920054912567139\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.04196758195757866\n",
      "Critic Loss: 5.90750789642334\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.017124900594353676\n",
      "Critic Loss: 5.700779914855957\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.038243066519498825\n",
      "Critic Loss: 10.748624801635742\n",
      "\n",
      "New best validation reward reached in update [34/200]\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.04316999018192291\n",
      "Critic Loss: 7.791801929473877\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.007883832789957523\n",
      "Critic Loss: 7.8880085945129395\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.017762266099452972\n",
      "Critic Loss: 8.837276458740234\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.01989414542913437\n",
      "Critic Loss: 9.640495300292969\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.02390339784324169\n",
      "Critic Loss: 7.8175249099731445\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.008247238583862782\n",
      "Critic Loss: 9.995128631591797\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.008342443965375423\n",
      "Critic Loss: 7.1890034675598145\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.05420234799385071\n",
      "Critic Loss: 8.877250671386719\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.011006643064320087\n",
      "Critic Loss: 6.436043739318848\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.035977765917778015\n",
      "Critic Loss: 6.861715316772461\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.009031180292367935\n",
      "Critic Loss: 4.249567031860352\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.015919025987386703\n",
      "Critic Loss: 6.003993988037109\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.0076416293159127235\n",
      "Critic Loss: 7.080443859100342\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.037600498646497726\n",
      "Critic Loss: 5.781295299530029\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.022214222699403763\n",
      "Critic Loss: 6.6569671630859375\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.006649274379014969\n",
      "Critic Loss: 7.533438682556152\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.0018081781454384327\n",
      "Critic Loss: 7.794102191925049\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.014886738732457161\n",
      "Critic Loss: 9.839268684387207\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.013801745139062405\n",
      "Critic Loss: 8.073128700256348\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.014855930581688881\n",
      "Critic Loss: 8.457483291625977\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.013239248655736446\n",
      "Critic Loss: 9.463489532470703\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.029102586209774017\n",
      "Critic Loss: 6.303060531616211\n",
      "\n",
      "New best validation reward reached in update [56/200]\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.004647953901439905\n",
      "Critic Loss: 5.4346184730529785\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.02338564209640026\n",
      "Critic Loss: 5.917844295501709\n",
      "\n",
      "New best validation reward reached in update [58/200]\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.031813718378543854\n",
      "Critic Loss: 5.582937717437744\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.014231586828827858\n",
      "Critic Loss: 4.448988914489746\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.004759877920150757\n",
      "Critic Loss: 6.367793560028076\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.004668617621064186\n",
      "Critic Loss: 7.065650939941406\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.003858889453113079\n",
      "Critic Loss: 5.999822616577148\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.011358239687979221\n",
      "Critic Loss: 5.17848539352417\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.04554176703095436\n",
      "Critic Loss: 8.173832893371582\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.0016950826393440366\n",
      "Critic Loss: 5.118311405181885\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.011570008471608162\n",
      "Critic Loss: 3.662625789642334\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.008902150206267834\n",
      "Critic Loss: 3.518308639526367\n",
      "\n",
      "New best validation reward reached in update [68/200]\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.008817354217171669\n",
      "Critic Loss: 4.217386245727539\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.011010894551873207\n",
      "Critic Loss: 2.349411964416504\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.009469376876950264\n",
      "Critic Loss: 8.297382354736328\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.015712475404143333\n",
      "Critic Loss: 4.679227828979492\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.00980945024639368\n",
      "Critic Loss: 7.989333152770996\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.009165768511593342\n",
      "Critic Loss: 5.818259239196777\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.009827096946537495\n",
      "Critic Loss: 6.444060325622559\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.004681175108999014\n",
      "Critic Loss: 4.902231216430664\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.006173860281705856\n",
      "Critic Loss: 5.91589879989624\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.0040074726566672325\n",
      "Critic Loss: 6.825101852416992\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.0015170702245086432\n",
      "Critic Loss: 6.501497268676758\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.0022192795295268297\n",
      "Critic Loss: 7.854147434234619\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.013163608498871326\n",
      "Critic Loss: 4.919780731201172\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.014177055098116398\n",
      "Critic Loss: 4.19011116027832\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.0177171528339386\n",
      "Critic Loss: 3.645747661590576\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.029497044160962105\n",
      "Critic Loss: 2.2643253803253174\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.029123425483703613\n",
      "Critic Loss: 2.736966609954834\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.007377015892416239\n",
      "Critic Loss: 4.089309215545654\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.000473648717161268\n",
      "Critic Loss: 2.520183563232422\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.013439840637147427\n",
      "Critic Loss: 4.354194641113281\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.004320343490689993\n",
      "Critic Loss: 2.6129326820373535\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.004900642205029726\n",
      "Critic Loss: 2.7501583099365234\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.007367710582911968\n",
      "Critic Loss: 5.283501625061035\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.007515975274145603\n",
      "Critic Loss: 5.894949913024902\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.007369996048510075\n",
      "Critic Loss: 6.068809509277344\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.014623354189097881\n",
      "Critic Loss: 2.328125476837158\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.021339381113648415\n",
      "Critic Loss: 2.5889697074890137\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.005452759563922882\n",
      "Critic Loss: 5.72802734375\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.004305354785174131\n",
      "Critic Loss: 3.621253490447998\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.01629713922739029\n",
      "Critic Loss: 3.9047131538391113\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.006881244946271181\n",
      "Critic Loss: 2.6161248683929443\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.015808969736099243\n",
      "Critic Loss: 6.35939884185791\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.002049746923148632\n",
      "Critic Loss: 5.390305519104004\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.004627392161637545\n",
      "Critic Loss: 5.788575649261475\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.014687209390103817\n",
      "Critic Loss: 4.030392646789551\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.0018885829485952854\n",
      "Critic Loss: 3.2557308673858643\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.004229015205055475\n",
      "Critic Loss: 2.817469596862793\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.003827570006251335\n",
      "Critic Loss: 4.14392614364624\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.02047664485871792\n",
      "Critic Loss: 4.220339298248291\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.00589789729565382\n",
      "Critic Loss: 3.8993680477142334\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -0.008702880702912807\n",
      "Critic Loss: 3.6257693767547607\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.020918238908052444\n",
      "Critic Loss: 2.2056684494018555\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.005199904553592205\n",
      "Critic Loss: 3.5641210079193115\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.0029526413418352604\n",
      "Critic Loss: 2.6692240238189697\n",
      "\n",
      "New best validation reward reached in update [112/200]\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.006193879526108503\n",
      "Critic Loss: 3.8656904697418213\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -0.015294001437723637\n",
      "Critic Loss: 3.7192587852478027\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -0.002234312240034342\n",
      "Critic Loss: 2.582359790802002\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -0.017705649137496948\n",
      "Critic Loss: 1.7716853618621826\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -0.00698117958381772\n",
      "Critic Loss: 6.0175981521606445\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -0.0031279195100069046\n",
      "Critic Loss: 6.310113906860352\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.013394057750701904\n",
      "Critic Loss: 3.1431286334991455\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.004735351540148258\n",
      "Critic Loss: 3.780400037765503\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -0.006341834086924791\n",
      "Critic Loss: 2.0451269149780273\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -0.01595115102827549\n",
      "Critic Loss: 3.3749709129333496\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -0.02599671296775341\n",
      "Critic Loss: 6.602731704711914\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -0.012115951627492905\n",
      "Critic Loss: 2.932497262954712\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -0.0023017916828393936\n",
      "Critic Loss: 2.371039867401123\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: -0.006139433942735195\n",
      "Critic Loss: 2.5862460136413574\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -0.0016662792768329382\n",
      "Critic Loss: 2.0742862224578857\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -0.014773010276257992\n",
      "Critic Loss: 1.8895008563995361\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -0.003934307489544153\n",
      "Critic Loss: 2.1948978900909424\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.039317596703767776\n",
      "Critic Loss: 2.8655710220336914\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -0.009964901022613049\n",
      "Critic Loss: 2.236417293548584\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -0.013067653402686119\n",
      "Critic Loss: 2.7892158031463623\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.0164713766425848\n",
      "Critic Loss: 3.4440178871154785\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -0.019817069172859192\n",
      "Critic Loss: 1.6888738870620728\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: -0.03238706290721893\n",
      "Critic Loss: 4.546646595001221\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.024917729198932648\n",
      "Critic Loss: 5.585155487060547\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -0.019249018281698227\n",
      "Critic Loss: 4.004315376281738\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -0.013015106320381165\n",
      "Critic Loss: 1.432105541229248\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: -0.010154414921998978\n",
      "Critic Loss: 1.3415729999542236\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -0.021820398047566414\n",
      "Critic Loss: 3.888827323913574\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -0.012492756359279156\n",
      "Critic Loss: 2.429609537124634\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: -0.0003466922207735479\n",
      "Critic Loss: 1.9852956533432007\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.011257034726440907\n",
      "Critic Loss: 3.0928239822387695\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -0.014986634254455566\n",
      "Critic Loss: 2.3020241260528564\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -0.01892768405377865\n",
      "Critic Loss: 4.871252059936523\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: -0.008964368142187595\n",
      "Critic Loss: 4.024672508239746\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: -0.015953144058585167\n",
      "Critic Loss: 7.737429618835449\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: -0.011928685009479523\n",
      "Critic Loss: 5.051430702209473\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: -0.011686383746564388\n",
      "Critic Loss: 5.589449405670166\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: -0.003751295618712902\n",
      "Critic Loss: 5.50570011138916\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: -0.00048003188567236066\n",
      "Critic Loss: 3.2504167556762695\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -0.013998943381011486\n",
      "Critic Loss: 4.321959018707275\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: -0.0023672045208513737\n",
      "Critic Loss: 5.734787940979004\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: -0.0006748106679879129\n",
      "Critic Loss: 4.347855091094971\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: -0.0075860102660954\n",
      "Critic Loss: 4.201371669769287\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 2.968526678159833e-05\n",
      "Critic Loss: 5.172691345214844\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: -0.009612655267119408\n",
      "Critic Loss: 3.8223958015441895\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: -0.008668400347232819\n",
      "Critic Loss: 13.263513565063477\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 0.00037625624099746346\n",
      "Critic Loss: 6.652559280395508\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9402f354914c2eb6b953e083e42ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>66.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>78.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00047</td></tr><tr><td>Learning_rate/Critic</td><td>0.0001</td></tr><tr><td>Loss/Actor_loss</td><td>-0.02632</td></tr><tr><td>Loss/Critic_loss</td><td>6.65256</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.07179</td></tr><tr><td>Loss/KL_divergence</td><td>0.01312</td></tr><tr><td>Loss/Policy_loss</td><td>0.00738</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.00038</td></tr><tr><td>Metric/Explained_variance</td><td>0.23442</td></tr><tr><td>Reward/Mean_train_reward</td><td>-38.86833</td></tr><tr><td>Reward/Mean_val_reward</td><td>-25.779</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-26.86346</td></tr><tr><td>global_step</td><td>159</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-54</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ucweifxw' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ucweifxw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_220400-ucweifxw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wfj2zvtm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0038713416832021888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00022432907397421917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.010608259143273553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8681799642388542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.1915519044225916e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.6536657657638328e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_221229-wfj2zvtm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/wfj2zvtm' target=\"_blank\">glad-sweep-55</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/wfj2zvtm' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/wfj2zvtm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.0038713416832021888, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00022432907397421917, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.010608259143273553, 'epochs': 10, 'exponential_factor': 0.8681799642388542, 'gamma': 0.95, 'hidden_sizes': [150, 250, 150, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 3.1915519044225916e-06, 'l2_factor': 3.6536657657638328e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0038713416832021888, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00022432907397421917, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.010608259143273553, 'epochs': 10, 'exponential_factor': 0.8681799642388542, 'gamma': 0.95, 'l1_factor': 3.1915519044225916e-06, 'l2_factor': 3.6536657657638328e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0038713416832021888, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00022432907397421917, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.010608259143273553, 'epochs': 10, 'exponential_factor': 0.8681799642388542, 'gamma': 0.95, 'l1_factor': 3.1915519044225916e-06, 'l2_factor': 3.6536657657638328e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0038713416832021888, 'critic_lr': 0.00022432907397421917, 'decay_method': 'exponential', 'exponential_factor': 0.8681799642388542, 'value_loss_factor': 1, 'entropy': 0.010608259143273553, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.1915519044225916e-06, 'l2_factor': 3.6536657657638328e-06, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [150, 250, 150, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 29.826480865478516\n",
      "Critic Loss: 26.325403213500977\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 40.56583023071289\n",
      "Critic Loss: 21.290658950805664\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 19.45457649230957\n",
      "Critic Loss: 8.42648696899414\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 15.686827659606934\n",
      "Critic Loss: 9.801263809204102\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 18.527498245239258\n",
      "Critic Loss: 14.420221328735352\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 31.663978576660156\n",
      "Critic Loss: 12.050086975097656\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 31.215578079223633\n",
      "Critic Loss: 14.944684982299805\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 17.46990203857422\n",
      "Critic Loss: 8.827780723571777\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 18.847126007080078\n",
      "Critic Loss: 6.962177753448486\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 15.061031341552734\n",
      "Critic Loss: 7.582624912261963\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 13.244394302368164\n",
      "Critic Loss: 5.265842437744141\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 12.262396812438965\n",
      "Critic Loss: 4.7661452293396\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 7.846134185791016\n",
      "Critic Loss: 3.638014793395996\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 14.719327926635742\n",
      "Critic Loss: 5.1305766105651855\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 16.196537017822266\n",
      "Critic Loss: 4.0810346603393555\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 12.786213874816895\n",
      "Critic Loss: 4.628442764282227\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 17.29109001159668\n",
      "Critic Loss: 6.947687149047852\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 18.989233016967773\n",
      "Critic Loss: 5.90494966506958\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 16.209081649780273\n",
      "Critic Loss: 5.335072040557861\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 10.442177772521973\n",
      "Critic Loss: 4.879640579223633\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 10.020853042602539\n",
      "Critic Loss: 3.677041530609131\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 9.589284896850586\n",
      "Critic Loss: 6.5071330070495605\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 4.571049213409424\n",
      "Critic Loss: 4.192916393280029\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 5.190967559814453\n",
      "Critic Loss: 5.501626014709473\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 7.296517848968506\n",
      "Critic Loss: 8.194504737854004\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 7.204230785369873\n",
      "Critic Loss: 10.011844635009766\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 4.485318660736084\n",
      "Critic Loss: 4.429508209228516\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 7.097163200378418\n",
      "Critic Loss: 6.818188667297363\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.758857011795044\n",
      "Critic Loss: 4.770193099975586\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 7.429514408111572\n",
      "Critic Loss: 8.7517728805542\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -2.6686930656433105\n",
      "Critic Loss: 5.092790603637695\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.4578155279159546\n",
      "Critic Loss: 7.128868579864502\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.8493342995643616\n",
      "Critic Loss: 6.777551651000977\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.046563033014535904\n",
      "Critic Loss: 6.627785682678223\n",
      "\n",
      "New best validation reward reached in update [34/200]\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -1.394696831703186\n",
      "Critic Loss: 7.3218231201171875\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -1.8944443464279175\n",
      "Critic Loss: 4.784876346588135\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -3.1710457801818848\n",
      "Critic Loss: 4.491270065307617\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 3.5653176307678223\n",
      "Critic Loss: 6.260739326477051\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -1.268454909324646\n",
      "Critic Loss: 4.497072219848633\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.6206054091453552\n",
      "Critic Loss: 6.810883522033691\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -2.356247663497925\n",
      "Critic Loss: 4.935219764709473\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -4.508995056152344\n",
      "Critic Loss: 4.002521514892578\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.38624465465545654\n",
      "Critic Loss: 5.570333480834961\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 1.018606185913086\n",
      "Critic Loss: 4.786992073059082\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.12953786551952362\n",
      "Critic Loss: 5.80139684677124\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -1.8502012491226196\n",
      "Critic Loss: 4.424509048461914\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 1.6801409721374512\n",
      "Critic Loss: 6.176936626434326\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 6.618808746337891\n",
      "Critic Loss: 5.397679805755615\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.8379985690116882\n",
      "Critic Loss: 4.9902238845825195\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 1.1895829439163208\n",
      "Critic Loss: 5.016238212585449\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.20409075915813446\n",
      "Critic Loss: 5.203507423400879\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 3.9235963821411133\n",
      "Critic Loss: 4.800546169281006\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 1.1828035116195679\n",
      "Critic Loss: 8.66943359375\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 4.281946182250977\n",
      "Critic Loss: 5.764782428741455\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -4.75269889831543\n",
      "Critic Loss: 4.1149115562438965\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -2.6441731452941895\n",
      "Critic Loss: 4.599230766296387\n",
      "\n",
      "New best validation reward reached in update [56/200]\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 1.3516943454742432\n",
      "Critic Loss: 5.099146366119385\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.5598931312561035\n",
      "Critic Loss: 5.520791053771973\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 1.9775761365890503\n",
      "Critic Loss: 6.325262069702148\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 6.823814868927002\n",
      "Critic Loss: 7.398074150085449\n",
      "\n",
      "New best validation reward reached in update [60/200]\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.3007894456386566\n",
      "Critic Loss: 5.677521705627441\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 4.985238075256348\n",
      "Critic Loss: 6.026605129241943\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -1.9921132326126099\n",
      "Critic Loss: 4.351153373718262\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.8149951100349426\n",
      "Critic Loss: 3.383758306503296\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -3.693830966949463\n",
      "Critic Loss: 5.117650985717773\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -3.7843892574310303\n",
      "Critic Loss: 3.8735849857330322\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 3.039180040359497\n",
      "Critic Loss: 5.6601057052612305\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -1.9036864042282104\n",
      "Critic Loss: 4.4510297775268555\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -5.729292869567871\n",
      "Critic Loss: 5.988105773925781\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -1.993741512298584\n",
      "Critic Loss: 5.793968200683594\n",
      "\n",
      "New best validation reward reached in update [70/200]\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -5.268863677978516\n",
      "Critic Loss: 3.8482561111450195\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -4.363370418548584\n",
      "Critic Loss: 3.342700481414795\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.5893511772155762\n",
      "Critic Loss: 5.098932266235352\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -2.778671979904175\n",
      "Critic Loss: 3.964956521987915\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -2.3838984966278076\n",
      "Critic Loss: 6.428582191467285\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -2.624244213104248\n",
      "Critic Loss: 4.377631664276123\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 2.3250043392181396\n",
      "Critic Loss: 4.571701526641846\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -2.6598007678985596\n",
      "Critic Loss: 6.64593505859375\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.3387696146965027\n",
      "Critic Loss: 6.417490482330322\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.2927418053150177\n",
      "Critic Loss: 5.384659767150879\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.6628868579864502\n",
      "Critic Loss: 5.709042072296143\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 3.18841552734375\n",
      "Critic Loss: 6.43413782119751\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 6.779811859130859\n",
      "Critic Loss: 5.105706214904785\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -1.4751296043395996\n",
      "Critic Loss: 5.818105220794678\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 1.3683432340621948\n",
      "Critic Loss: 5.788630485534668\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 3.4645166397094727\n",
      "Critic Loss: 6.721216678619385\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.9640774130821228\n",
      "Critic Loss: 6.259807586669922\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 2.8508529663085938\n",
      "Critic Loss: 4.904309272766113\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.678224503993988\n",
      "Critic Loss: 6.737325668334961\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 2.2832908630371094\n",
      "Critic Loss: 5.0330915451049805\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.9386109709739685\n",
      "Critic Loss: 4.6449761390686035\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 2.904052734375\n",
      "Critic Loss: 6.486558437347412\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 1.8001538515090942\n",
      "Critic Loss: 4.859349250793457\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 1.6251986026763916\n",
      "Critic Loss: 4.517027854919434\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.17784960567951202\n",
      "Critic Loss: 4.091017246246338\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -1.3120596408843994\n",
      "Critic Loss: 4.641322612762451\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 3.027918815612793\n",
      "Critic Loss: 5.56247615814209\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.9408887624740601\n",
      "Critic Loss: 4.820086479187012\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.20684057474136353\n",
      "Critic Loss: 3.7161247730255127\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -1.9673770666122437\n",
      "Critic Loss: 4.549615383148193\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -2.6167309284210205\n",
      "Critic Loss: 5.3114118576049805\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4352c71f3390469e95014caa06bc02b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>104.875</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>106.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-2.65524</td></tr><tr><td>Loss/Critic_loss</td><td>5.31141</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.58195</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00846</td></tr><tr><td>Loss/Policy_loss</td><td>-2.64907</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-2.61673</td></tr><tr><td>Metric/Explained_variance</td><td>0.54157</td></tr><tr><td>Reward/Mean_train_reward</td><td>-0.25612</td></tr><tr><td>Reward/Mean_val_reward</td><td>2.2817</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>2.66786</td></tr><tr><td>global_step</td><td>101</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-55</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/wfj2zvtm' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/wfj2zvtm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_221229-wfj2zvtm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cr2029ko with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.009714704638392302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0014646310703144909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04362729356760811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.893008138932387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0002553595598511063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.7885447356106316e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_222600-cr2029ko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/cr2029ko' target=\"_blank\">electric-sweep-56</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/cr2029ko' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/cr2029ko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.009714704638392302, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0014646310703144909, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04362729356760811, 'epochs': 10, 'exponential_factor': 0.893008138932387, 'gamma': 0.99, 'hidden_sizes': [150, 250, 250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.0002553595598511063, 'l2_factor': 2.7885447356106316e-05, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.009714704638392302, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0014646310703144909, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04362729356760811, 'epochs': 10, 'exponential_factor': 0.893008138932387, 'gamma': 0.99, 'l1_factor': 0.0002553595598511063, 'l2_factor': 2.7885447356106316e-05, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.009714704638392302, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0014646310703144909, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04362729356760811, 'epochs': 10, 'exponential_factor': 0.893008138932387, 'gamma': 0.99, 'l1_factor': 0.0002553595598511063, 'l2_factor': 2.7885447356106316e-05, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.009714704638392302, 'critic_lr': 0.0014646310703144909, 'decay_method': 'exponential', 'exponential_factor': 0.893008138932387, 'value_loss_factor': 1, 'entropy': 0.04362729356760811, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0002553595598511063, 'l2_factor': 2.7885447356106316e-05, 'T': 768, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [150, 250, 250, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 16.97701072692871\n",
      "Critic Loss: 16.15216636657715\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 23.479415893554688\n",
      "Critic Loss: 17.63840103149414\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 17.973262786865234\n",
      "Critic Loss: 15.86405086517334\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 20.01834487915039\n",
      "Critic Loss: 18.79810333251953\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 29.18117332458496\n",
      "Critic Loss: 21.084291458129883\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 26.493789672851562\n",
      "Critic Loss: 13.780426025390625\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 25.998584747314453\n",
      "Critic Loss: 15.652576446533203\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 15.219159126281738\n",
      "Critic Loss: 11.721586227416992\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 17.3004207611084\n",
      "Critic Loss: 10.251832008361816\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 14.931432723999023\n",
      "Critic Loss: 12.669685363769531\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 15.77379035949707\n",
      "Critic Loss: 11.862330436706543\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 10.30776596069336\n",
      "Critic Loss: 11.526979446411133\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 9.469125747680664\n",
      "Critic Loss: 13.241982460021973\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 10.749372482299805\n",
      "Critic Loss: 10.253743171691895\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 7.5850419998168945\n",
      "Critic Loss: 8.940132141113281\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 5.519906997680664\n",
      "Critic Loss: 8.222332000732422\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 3.864617109298706\n",
      "Critic Loss: 7.174510955810547\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 5.300040245056152\n",
      "Critic Loss: 5.659305572509766\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 7.522602081298828\n",
      "Critic Loss: 7.202389717102051\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 7.637795448303223\n",
      "Critic Loss: 9.666482925415039\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 5.84687614440918\n",
      "Critic Loss: 7.79635763168335\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 11.387825965881348\n",
      "Critic Loss: 9.872756958007812\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 1.774750828742981\n",
      "Critic Loss: 6.618227481842041\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 9.491498947143555\n",
      "Critic Loss: 7.005978107452393\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 7.007382869720459\n",
      "Critic Loss: 7.876368522644043\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 5.5181427001953125\n",
      "Critic Loss: 7.270924091339111\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 3.623657464981079\n",
      "Critic Loss: 9.75084400177002\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 12.787575721740723\n",
      "Critic Loss: 13.407059669494629\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 2.7868106365203857\n",
      "Critic Loss: 9.76793384552002\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 4.7276692390441895\n",
      "Critic Loss: 11.330682754516602\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 5.060084342956543\n",
      "Critic Loss: 9.073486328125\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 5.683966636657715\n",
      "Critic Loss: 11.9974946975708\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 3.4446499347686768\n",
      "Critic Loss: 11.22859001159668\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 2.8580968379974365\n",
      "Critic Loss: 11.285612106323242\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 5.048643112182617\n",
      "Critic Loss: 9.831594467163086\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.24258434772491455\n",
      "Critic Loss: 8.914728164672852\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.8431083559989929\n",
      "Critic Loss: 7.007539749145508\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 3.1970903873443604\n",
      "Critic Loss: 10.200006484985352\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 2.309455394744873\n",
      "Critic Loss: 8.125212669372559\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 2.7315549850463867\n",
      "Critic Loss: 7.827991962432861\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.9968543648719788\n",
      "Critic Loss: 8.760259628295898\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.2057020515203476\n",
      "Critic Loss: 6.431936740875244\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 1.2321195602416992\n",
      "Critic Loss: 8.136409759521484\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.05084308981895447\n",
      "Critic Loss: 6.114901065826416\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 1.1228400468826294\n",
      "Critic Loss: 9.298028945922852\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 2.601834774017334\n",
      "Critic Loss: 8.225747108459473\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.4151574969291687\n",
      "Critic Loss: 7.966814994812012\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 2.966902256011963\n",
      "Critic Loss: 7.543813705444336\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.40927255153656\n",
      "Critic Loss: 6.220035552978516\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.3628537654876709\n",
      "Critic Loss: 6.579021453857422\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 3.0212130546569824\n",
      "Critic Loss: 7.648592472076416\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 2.718104362487793\n",
      "Critic Loss: 8.0460205078125\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 5.640985012054443\n",
      "Critic Loss: 12.000669479370117\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.050640709698200226\n",
      "Critic Loss: 7.035499572753906\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 1.4982643127441406\n",
      "Critic Loss: 7.2148895263671875\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 3.4297194480895996\n",
      "Critic Loss: 8.057361602783203\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 4.432843208312988\n",
      "Critic Loss: 12.86180305480957\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 2.7918312549591064\n",
      "Critic Loss: 8.54143238067627\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 2.0119776725769043\n",
      "Critic Loss: 6.7279863357543945\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 2.208646059036255\n",
      "Critic Loss: 8.239148139953613\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 2.0903525352478027\n",
      "Critic Loss: 8.038161277770996\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 5.678980350494385\n",
      "Critic Loss: 7.813575744628906\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 3.1154558658599854\n",
      "Critic Loss: 7.871983051300049\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.5679284930229187\n",
      "Critic Loss: 8.325292587280273\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 4.528977870941162\n",
      "Critic Loss: 10.09069538116455\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 3.072150707244873\n",
      "Critic Loss: 7.905430793762207\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.7593715786933899\n",
      "Critic Loss: 8.760801315307617\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 4.948193073272705\n",
      "Critic Loss: 8.098670959472656\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 2.219804048538208\n",
      "Critic Loss: 5.889289379119873\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.18512241542339325\n",
      "Critic Loss: 6.100085735321045\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 3.0224132537841797\n",
      "Critic Loss: 7.757740497589111\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 1.7986477613449097\n",
      "Critic Loss: 6.706386566162109\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 3.1902270317077637\n",
      "Critic Loss: 6.68356466293335\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 3.2323966026306152\n",
      "Critic Loss: 8.282349586486816\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 5.407922744750977\n",
      "Critic Loss: 7.346803188323975\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 2.4668736457824707\n",
      "Critic Loss: 5.654595851898193\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 5.439298152923584\n",
      "Critic Loss: 7.984172344207764\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.7109255194664001\n",
      "Critic Loss: 7.562011241912842\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95abe2a551f402fa1449ed2556edf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>107.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>92.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.56111</td></tr><tr><td>Loss/Critic_loss</td><td>7.56201</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.69237</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00215</td></tr><tr><td>Loss/Policy_loss</td><td>-0.5309</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.71093</td></tr><tr><td>Metric/Explained_variance</td><td>0.50909</td></tr><tr><td>Reward/Mean_train_reward</td><td>4.18601</td></tr><tr><td>Reward/Mean_val_reward</td><td>-10.9925</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>2.35427</td></tr><tr><td>global_step</td><td>78</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-56</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/cr2029ko' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/cr2029ko</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_222600-cr2029ko\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dld7dnke with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00020055342134815744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.002891488853364463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.004842289459843772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.89356309053321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.5131024662470609e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.019108441227556e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_223458-dld7dnke</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/dld7dnke' target=\"_blank\">solar-sweep-57</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/dld7dnke' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/dld7dnke</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.00020055342134815744, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.002891488853364463, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004842289459843772, 'epochs': 10, 'exponential_factor': 0.89356309053321, 'gamma': 0.9, 'hidden_sizes': [150, 250, 250, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.5131024662470609e-06, 'l2_factor': 7.019108441227556e-05, 'lrelu': 0.1, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00020055342134815744, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.002891488853364463, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004842289459843772, 'epochs': 10, 'exponential_factor': 0.89356309053321, 'gamma': 0.9, 'l1_factor': 1.5131024662470609e-06, 'l2_factor': 7.019108441227556e-05, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 250, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00020055342134815744, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.002891488853364463, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.004842289459843772, 'epochs': 10, 'exponential_factor': 0.89356309053321, 'gamma': 0.9, 'l1_factor': 1.5131024662470609e-06, 'l2_factor': 7.019108441227556e-05, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00020055342134815744, 'critic_lr': 0.002891488853364463, 'decay_method': 'exponential', 'exponential_factor': 0.89356309053321, 'value_loss_factor': 1, 'entropy': 0.004842289459843772, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.5131024662470609e-06, 'l2_factor': 7.019108441227556e-05, 'T': 1024, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [150, 250, 250, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 11.549670219421387\n",
      "Critic Loss: 13.47976303100586\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 8.886013984680176\n",
      "Critic Loss: 8.95132064819336\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 7.054079532623291\n",
      "Critic Loss: 4.712498188018799\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 12.868463516235352\n",
      "Critic Loss: 5.817018032073975\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 11.725072860717773\n",
      "Critic Loss: 4.671981334686279\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 16.961828231811523\n",
      "Critic Loss: 5.428282737731934\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 11.211014747619629\n",
      "Critic Loss: 6.529344081878662\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 14.174596786499023\n",
      "Critic Loss: 6.391688346862793\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 7.145473003387451\n",
      "Critic Loss: 4.141417980194092\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 5.902237415313721\n",
      "Critic Loss: 3.051342725753784\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 6.487924098968506\n",
      "Critic Loss: 3.678478956222534\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 8.01309871673584\n",
      "Critic Loss: 5.08438777923584\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 6.842504501342773\n",
      "Critic Loss: 4.391687870025635\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.443170189857483\n",
      "Critic Loss: 3.441452980041504\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 4.653797626495361\n",
      "Critic Loss: 4.627355098724365\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 7.007401943206787\n",
      "Critic Loss: 5.586056709289551\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 9.098657608032227\n",
      "Critic Loss: 5.022665023803711\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 6.105635643005371\n",
      "Critic Loss: 5.40281867980957\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 1.9713746309280396\n",
      "Critic Loss: 4.416942596435547\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.46304428577423096\n",
      "Critic Loss: 3.564037799835205\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 2.501687526702881\n",
      "Critic Loss: 2.9244749546051025\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.5636978149414062\n",
      "Critic Loss: 2.9844136238098145\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.5445480942726135\n",
      "Critic Loss: 2.6542863845825195\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 4.10639762878418\n",
      "Critic Loss: 4.581730842590332\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.08647395670413971\n",
      "Critic Loss: 2.209838390350342\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.7931815981864929\n",
      "Critic Loss: 2.644542932510376\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -2.2082302570343018\n",
      "Critic Loss: 2.8766379356384277\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 1.5011969804763794\n",
      "Critic Loss: 2.649263381958008\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.5137650370597839\n",
      "Critic Loss: 3.738685369491577\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.8563838005065918\n",
      "Critic Loss: 1.9228111505508423\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.6527267098426819\n",
      "Critic Loss: 4.828149795532227\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -1.9821475744247437\n",
      "Critic Loss: 1.7571710348129272\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.35119590163230896\n",
      "Critic Loss: 2.153984308242798\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.8064438700675964\n",
      "Critic Loss: 2.853264808654785\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 1.6204077005386353\n",
      "Critic Loss: 3.4109268188476562\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -3.067387819290161\n",
      "Critic Loss: 1.6399084329605103\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.7953015565872192\n",
      "Critic Loss: 1.9335464239120483\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -2.676575183868408\n",
      "Critic Loss: 3.090843677520752\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.991844117641449\n",
      "Critic Loss: 2.3751933574676514\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 3.3923892974853516\n",
      "Critic Loss: 4.3229146003723145\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -2.0605392456054688\n",
      "Critic Loss: 1.5341711044311523\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 1.1619226932525635\n",
      "Critic Loss: 3.8942346572875977\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.3306552767753601\n",
      "Critic Loss: 2.843308925628662\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.7312880754470825\n",
      "Critic Loss: 1.926262617111206\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.2405661642551422\n",
      "Critic Loss: 1.6107898950576782\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -2.227720022201538\n",
      "Critic Loss: 1.7423410415649414\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.8718340992927551\n",
      "Critic Loss: 1.9786208868026733\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.4446316957473755\n",
      "Critic Loss: 2.423171043395996\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.48482102155685425\n",
      "Critic Loss: 2.753573417663574\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.9511557817459106\n",
      "Critic Loss: 2.2941126823425293\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 1.1244455575942993\n",
      "Critic Loss: 2.50974702835083\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.264756977558136\n",
      "Critic Loss: 2.4061596393585205\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.6716547608375549\n",
      "Critic Loss: 2.7075839042663574\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.9197788238525391\n",
      "Critic Loss: 2.60986590385437\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 2.465938091278076\n",
      "Critic Loss: 2.624248743057251\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 2.8895277976989746\n",
      "Critic Loss: 3.3609044551849365\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.5903303027153015\n",
      "Critic Loss: 3.589939832687378\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 1.3011503219604492\n",
      "Critic Loss: 3.4344537258148193\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -3.0194613933563232\n",
      "Critic Loss: 1.8499925136566162\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 1.1138684749603271\n",
      "Critic Loss: 3.6814582347869873\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -2.0720322132110596\n",
      "Critic Loss: 1.561079740524292\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -1.32846999168396\n",
      "Critic Loss: 2.9107658863067627\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 2.057461738586426\n",
      "Critic Loss: 2.582285165786743\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.6710565686225891\n",
      "Critic Loss: 1.8732032775878906\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 2.2059340476989746\n",
      "Critic Loss: 3.051098346710205\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.5998345017433167\n",
      "Critic Loss: 2.1814215183258057\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -1.158131718635559\n",
      "Critic Loss: 2.2962677478790283\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -2.138651132583618\n",
      "Critic Loss: 1.8208587169647217\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -2.3950631618499756\n",
      "Critic Loss: 1.7580456733703613\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.057878509163856506\n",
      "Critic Loss: 1.9135864973068237\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -1.332889437675476\n",
      "Critic Loss: 1.7448344230651855\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -1.7089229822158813\n",
      "Critic Loss: 1.796411156654358\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.9265030026435852\n",
      "Critic Loss: 1.9349009990692139\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 3.4203059673309326\n",
      "Critic Loss: 4.4131550788879395\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.9422460794448853\n",
      "Critic Loss: 2.1802167892456055\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.5861775875091553\n",
      "Critic Loss: 2.7894647121429443\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.07327297329902649\n",
      "Critic Loss: 1.8838125467300415\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 1.8812867403030396\n",
      "Critic Loss: 2.809746742248535\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 1.3328745365142822\n",
      "Critic Loss: 2.042534828186035\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -2.3341875076293945\n",
      "Critic Loss: 1.6718833446502686\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -1.5164873600006104\n",
      "Critic Loss: 1.9444003105163574\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 1.0650116205215454\n",
      "Critic Loss: 2.978161573410034\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 2.775164842605591\n",
      "Critic Loss: 2.701418876647949\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -1.201951265335083\n",
      "Critic Loss: 1.9739501476287842\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.1977839469909668\n",
      "Critic Loss: 2.7282567024230957\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.9312574863433838\n",
      "Critic Loss: 1.9034782648086548\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.7468194365501404\n",
      "Critic Loss: 2.583991527557373\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 1.5555192232131958\n",
      "Critic Loss: 2.704862356185913\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.46139517426490784\n",
      "Critic Loss: 1.8073147535324097\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 1.5075825452804565\n",
      "Critic Loss: 2.2829713821411133\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -1.2279069423675537\n",
      "Critic Loss: 2.2580373287200928\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 1.1161078214645386\n",
      "Critic Loss: 1.972970962524414\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb44625f59c946ccb2b00705df9db414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>118.28571</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>114.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>1.00871</td></tr><tr><td>Loss/Critic_loss</td><td>1.97297</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.76469</td></tr><tr><td>Loss/KL_divergence</td><td>-0.02337</td></tr><tr><td>Loss/Policy_loss</td><td>1.01241</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.11611</td></tr><tr><td>Metric/Explained_variance</td><td>0.79545</td></tr><tr><td>Reward/Mean_train_reward</td><td>4.04871</td></tr><tr><td>Reward/Mean_val_reward</td><td>-6.1786</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-1.79553</td></tr><tr><td>global_step</td><td>92</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-57</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/dld7dnke' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/dld7dnke</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_223458-dld7dnke\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r4p8z4sh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.004227650480453153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004722237754422292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04255686748777848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9470193335949972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0001111048773894366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.7528510920462394e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_224648-r4p8z4sh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/r4p8z4sh' target=\"_blank\">apricot-sweep-58</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/r4p8z4sh' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/r4p8z4sh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.004227650480453153, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004722237754422292, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04255686748777848, 'epochs': 10, 'exponential_factor': 0.9470193335949972, 'gamma': 0.9, 'hidden_sizes': [150, 350, 150, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0001111048773894366, 'l2_factor': 4.7528510920462394e-05, 'lrelu': 0.001, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.004227650480453153, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004722237754422292, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04255686748777848, 'epochs': 10, 'exponential_factor': 0.9470193335949972, 'gamma': 0.9, 'l1_factor': 0.0001111048773894366, 'l2_factor': 4.7528510920462394e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.004227650480453153, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004722237754422292, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04255686748777848, 'epochs': 10, 'exponential_factor': 0.9470193335949972, 'gamma': 0.9, 'l1_factor': 0.0001111048773894366, 'l2_factor': 4.7528510920462394e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.004227650480453153, 'critic_lr': 0.004722237754422292, 'decay_method': 'exponential', 'exponential_factor': 0.9470193335949972, 'value_loss_factor': 1, 'entropy': 0.04255686748777848, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0001111048773894366, 'l2_factor': 4.7528510920462394e-05, 'T': 768, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [150, 350, 150, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 15.62122631072998\n",
      "Critic Loss: 17.303878784179688\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 191.0717010498047\n",
      "Critic Loss: 9.301437377929688\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 106.26370239257812\n",
      "Critic Loss: 35.380859375\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 101.3596420288086\n",
      "Critic Loss: 0.7736062407493591\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 101.24907684326172\n",
      "Critic Loss: 1.3506699800491333\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 81.24409484863281\n",
      "Critic Loss: 0.42027029395103455\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 18.1483154296875\n",
      "Critic Loss: 10.696720123291016\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 101.1977310180664\n",
      "Critic Loss: 2.1982502937316895\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 101.08065795898438\n",
      "Critic Loss: 0.4528607428073883\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 100.96617889404297\n",
      "Critic Loss: 2.327530860900879\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 100.8563232421875\n",
      "Critic Loss: 0.4037846028804779\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 100.7519302368164\n",
      "Critic Loss: 1.865355372428894\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 80.7259750366211\n",
      "Critic Loss: 0.28774112462997437\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 7.024820327758789\n",
      "Critic Loss: 16.584064483642578\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 9.802003860473633\n",
      "Critic Loss: 13.450139045715332\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 80.7279052734375\n",
      "Critic Loss: 1.695676565170288\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 74.00027465820312\n",
      "Critic Loss: 128.3159942626953\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 30.45793342590332\n",
      "Critic Loss: 10.287923812866211\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 22.375032424926758\n",
      "Critic Loss: 18.561452865600586\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 49.10662841796875\n",
      "Critic Loss: 18.66689109802246\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 23.487924575805664\n",
      "Critic Loss: 22.228626251220703\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 38.230567932128906\n",
      "Critic Loss: 17.807401657104492\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 30.114551544189453\n",
      "Critic Loss: 21.82657814025879\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 32.362552642822266\n",
      "Critic Loss: 20.271944046020508\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 13.457653045654297\n",
      "Critic Loss: 15.708263397216797\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 67.18470764160156\n",
      "Critic Loss: 36.06282424926758\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 27.757089614868164\n",
      "Critic Loss: 18.844696044921875\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 105.28545379638672\n",
      "Critic Loss: 22.91028594970703\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 91.2712631225586\n",
      "Critic Loss: 14.728086471557617\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 95.99625396728516\n",
      "Critic Loss: 5.9588093757629395\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 74.33162689208984\n",
      "Critic Loss: 24.394643783569336\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 40.82870864868164\n",
      "Critic Loss: 26.90130043029785\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 27.722461700439453\n",
      "Critic Loss: 22.868701934814453\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 23.249605178833008\n",
      "Critic Loss: 18.104164123535156\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 17.926664352416992\n",
      "Critic Loss: 17.52315902709961\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 16.941570281982422\n",
      "Critic Loss: 14.145160675048828\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 20.140352249145508\n",
      "Critic Loss: 15.72499942779541\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 26.623186111450195\n",
      "Critic Loss: 20.67424964904785\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 25.410221099853516\n",
      "Critic Loss: 17.56747817993164\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 34.65706253051758\n",
      "Critic Loss: 27.088638305664062\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 22.568838119506836\n",
      "Critic Loss: 18.123287200927734\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 22.88159942626953\n",
      "Critic Loss: 17.574386596679688\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 22.37506866455078\n",
      "Critic Loss: 19.33517837524414\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 26.077774047851562\n",
      "Critic Loss: 22.514902114868164\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb5b99f2df644a09ef5c76da74fa633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>33.09091</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>29.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00041</td></tr><tr><td>Learning_rate/Critic</td><td>0.00045</td></tr><tr><td>Loss/Actor_loss</td><td>25.55655</td></tr><tr><td>Loss/Critic_loss</td><td>22.5149</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.49927</td></tr><tr><td>Loss/KL_divergence</td><td>0.04918</td></tr><tr><td>Loss/Policy_loss</td><td>25.5778</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>26.07777</td></tr><tr><td>Metric/Explained_variance</td><td>0.0</td></tr><tr><td>Reward/Mean_train_reward</td><td>-91.55882</td></tr><tr><td>Reward/Mean_val_reward</td><td>-95.068</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-92.99731</td></tr><tr><td>global_step</td><td>44</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-58</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/r4p8z4sh' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/r4p8z4sh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_224648-r4p8z4sh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aq12vc3c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00017998524054240066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.007473688276785075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.035500560212916345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.998385340901956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00024569552643950997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.18356172910808e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_225150-aq12vc3c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/aq12vc3c' target=\"_blank\">tough-sweep-59</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/aq12vc3c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/aq12vc3c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.00017998524054240066, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.007473688276785075, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.035500560212916345, 'epochs': 10, 'exponential_factor': 0.998385340901956, 'gamma': 0.95, 'hidden_sizes': [250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.00024569552643950997, 'l2_factor': 7.18356172910808e-05, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.00017998524054240066, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.007473688276785075, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.035500560212916345, 'epochs': 10, 'exponential_factor': 0.998385340901956, 'gamma': 0.95, 'l1_factor': 0.00024569552643950997, 'l2_factor': 7.18356172910808e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.00017998524054240066, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.007473688276785075, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.035500560212916345, 'epochs': 10, 'exponential_factor': 0.998385340901956, 'gamma': 0.95, 'l1_factor': 0.00024569552643950997, 'l2_factor': 7.18356172910808e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00017998524054240066, 'critic_lr': 0.007473688276785075, 'decay_method': 'exponential', 'exponential_factor': 0.998385340901956, 'value_loss_factor': 1, 'entropy': 0.035500560212916345, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00024569552643950997, 'l2_factor': 7.18356172910808e-05, 'T': 768, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.3269723653793335\n",
      "Critic Loss: 25.185405731201172\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 1.2628861665725708\n",
      "Critic Loss: 300.7452087402344\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 1.206713318824768\n",
      "Critic Loss: 19.753694534301758\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 1.1212552785873413\n",
      "Critic Loss: 9.64709758758545\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 1.0647114515304565\n",
      "Critic Loss: 10.134248733520508\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.9774299263954163\n",
      "Critic Loss: 4.354197025299072\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.9184850454330444\n",
      "Critic Loss: 8.106982231140137\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.8433412313461304\n",
      "Critic Loss: 7.080975532531738\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.8096010684967041\n",
      "Critic Loss: 5.520412921905518\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.7706928849220276\n",
      "Critic Loss: 4.214529037475586\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.7367064356803894\n",
      "Critic Loss: 7.175108432769775\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.7231570482254028\n",
      "Critic Loss: 9.1674222946167\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.7074355483055115\n",
      "Critic Loss: 7.729972839355469\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.7221558094024658\n",
      "Critic Loss: 6.454823970794678\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.7187117338180542\n",
      "Critic Loss: 6.909849166870117\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.6932061314582825\n",
      "Critic Loss: 7.406782150268555\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.6258774995803833\n",
      "Critic Loss: 5.0831170082092285\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.5807855129241943\n",
      "Critic Loss: 7.481986045837402\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.5735324621200562\n",
      "Critic Loss: 6.045407295227051\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.5628705620765686\n",
      "Critic Loss: 12.486130714416504\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.5720360279083252\n",
      "Critic Loss: 9.003189086914062\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.565632164478302\n",
      "Critic Loss: 8.744275093078613\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.5604526996612549\n",
      "Critic Loss: 4.516071796417236\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.5197900533676147\n",
      "Critic Loss: 5.25169563293457\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.5289596319198608\n",
      "Critic Loss: 10.13077449798584\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.49530458450317383\n",
      "Critic Loss: 6.83804988861084\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.4630697965621948\n",
      "Critic Loss: 6.553350448608398\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.47189396619796753\n",
      "Critic Loss: 6.638047695159912\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.3992784023284912\n",
      "Critic Loss: 5.429790496826172\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.4133743345737457\n",
      "Critic Loss: 6.33633279800415\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.3963468670845032\n",
      "Critic Loss: 8.768287658691406\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.36353132128715515\n",
      "Critic Loss: 7.137012481689453\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.34390804171562195\n",
      "Critic Loss: 12.072566986083984\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.3258797824382782\n",
      "Critic Loss: 6.175695896148682\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.33592116832733154\n",
      "Critic Loss: 5.329077243804932\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.30235251784324646\n",
      "Critic Loss: 7.566896438598633\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.31369149684906006\n",
      "Critic Loss: 5.600578784942627\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.29799884557724\n",
      "Critic Loss: 3.602800130844116\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.29426687955856323\n",
      "Critic Loss: 4.534984588623047\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.2723037600517273\n",
      "Critic Loss: 9.58389949798584\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.26504918932914734\n",
      "Critic Loss: 3.8581948280334473\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.25586166977882385\n",
      "Critic Loss: 7.422633647918701\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.24392104148864746\n",
      "Critic Loss: 7.621939182281494\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.29050374031066895\n",
      "Critic Loss: 5.050544261932373\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.26300451159477234\n",
      "Critic Loss: 3.8371596336364746\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.2621159553527832\n",
      "Critic Loss: 5.0035529136657715\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.26322412490844727\n",
      "Critic Loss: 5.202462196350098\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.2509053945541382\n",
      "Critic Loss: 5.451729774475098\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.22332176566123962\n",
      "Critic Loss: 5.641463279724121\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.2247423380613327\n",
      "Critic Loss: 3.686732292175293\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.2148200273513794\n",
      "Critic Loss: 3.6954054832458496\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.2180587351322174\n",
      "Critic Loss: 4.614847660064697\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.22716836631298065\n",
      "Critic Loss: 3.192005157470703\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.1872558891773224\n",
      "Critic Loss: 5.297050476074219\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.19300751388072968\n",
      "Critic Loss: 4.758540630340576\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.1966780722141266\n",
      "Critic Loss: 8.425580978393555\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86fbcd4673f47b39712d60a59a8b6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>39.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>95.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00016</td></tr><tr><td>Learning_rate/Critic</td><td>0.00684</td></tr><tr><td>Loss/Actor_loss</td><td>-0.08387</td></tr><tr><td>Loss/Critic_loss</td><td>8.42558</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.6764</td></tr><tr><td>Loss/KL_divergence</td><td>0.01038</td></tr><tr><td>Loss/Policy_loss</td><td>-0.02436</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.19668</td></tr><tr><td>Metric/Explained_variance</td><td>-0.07204</td></tr><tr><td>Reward/Mean_train_reward</td><td>-81.48671</td></tr><tr><td>Reward/Mean_val_reward</td><td>-56.754</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-58.57402</td></tr><tr><td>global_step</td><td>56</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tough-sweep-59</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/aq12vc3c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/aq12vc3c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_225150-aq12vc3c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: doiq7s0c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0008980291084318372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00013006066403488205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04134412138826988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8790557798450933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 9.0484727547071e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0009097125742153968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_225644-doiq7s0c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/doiq7s0c' target=\"_blank\">curious-sweep-60</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/doiq7s0c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/doiq7s0c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0008980291084318372, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013006066403488205, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04134412138826988, 'epochs': 10, 'exponential_factor': 0.8790557798450933, 'gamma': 0.99, 'hidden_sizes': [150, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 9.0484727547071e-06, 'l2_factor': 0.0009097125742153968, 'lrelu': 0.001, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0008980291084318372, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013006066403488205, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04134412138826988, 'epochs': 10, 'exponential_factor': 0.8790557798450933, 'gamma': 0.99, 'l1_factor': 9.0484727547071e-06, 'l2_factor': 0.0009097125742153968, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0008980291084318372, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013006066403488205, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04134412138826988, 'epochs': 10, 'exponential_factor': 0.8790557798450933, 'gamma': 0.99, 'l1_factor': 9.0484727547071e-06, 'l2_factor': 0.0009097125742153968, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0008980291084318372, 'critic_lr': 0.00013006066403488205, 'decay_method': 'exponential', 'exponential_factor': 0.8790557798450933, 'value_loss_factor': 1, 'entropy': 0.04134412138826988, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 9.0484727547071e-06, 'l2_factor': 0.0009097125742153968, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [150, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.132328987121582\n",
      "Critic Loss: 29.11783218383789\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.8596358895301819\n",
      "Critic Loss: 15.76840877532959\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.8462645411491394\n",
      "Critic Loss: 22.914628982543945\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.7040997743606567\n",
      "Critic Loss: 15.065513610839844\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.7042623162269592\n",
      "Critic Loss: 15.866898536682129\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.6826547980308533\n",
      "Critic Loss: 13.198347091674805\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.6329352855682373\n",
      "Critic Loss: 12.53353214263916\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.6633656620979309\n",
      "Critic Loss: 10.33785629272461\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.668753445148468\n",
      "Critic Loss: 11.915919303894043\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.6159826517105103\n",
      "Critic Loss: 11.16704273223877\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.5549697279930115\n",
      "Critic Loss: 10.050138473510742\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.5734584927558899\n",
      "Critic Loss: 9.192937850952148\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.5338613986968994\n",
      "Critic Loss: 9.627114295959473\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.5105804204940796\n",
      "Critic Loss: 14.515559196472168\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.47461527585983276\n",
      "Critic Loss: 11.557181358337402\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.5234728455543518\n",
      "Critic Loss: 14.93095588684082\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.4925970137119293\n",
      "Critic Loss: 8.666455268859863\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.4687291383743286\n",
      "Critic Loss: 9.34740924835205\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.46886712312698364\n",
      "Critic Loss: 10.775591850280762\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.45138588547706604\n",
      "Critic Loss: 13.772007942199707\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.465370774269104\n",
      "Critic Loss: 10.57734203338623\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.4835815131664276\n",
      "Critic Loss: 11.666449546813965\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.4436044692993164\n",
      "Critic Loss: 12.21948528289795\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.45516616106033325\n",
      "Critic Loss: 11.262503623962402\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.4584580063819885\n",
      "Critic Loss: 13.072516441345215\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.4373747706413269\n",
      "Critic Loss: 12.24880313873291\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.43556666374206543\n",
      "Critic Loss: 9.272989273071289\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.43507760763168335\n",
      "Critic Loss: 13.033153533935547\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.45006442070007324\n",
      "Critic Loss: 11.126254081726074\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.4519575834274292\n",
      "Critic Loss: 13.173608779907227\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.46294963359832764\n",
      "Critic Loss: 11.727519989013672\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.4618944525718689\n",
      "Critic Loss: 13.716991424560547\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.44866445660591125\n",
      "Critic Loss: 10.26944351196289\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.4566234052181244\n",
      "Critic Loss: 7.20401668548584\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.43657130002975464\n",
      "Critic Loss: 13.167366027832031\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.46056297421455383\n",
      "Critic Loss: 8.348078727722168\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.434749960899353\n",
      "Critic Loss: 10.376544952392578\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.4453084170818329\n",
      "Critic Loss: 10.098726272583008\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.4453839063644409\n",
      "Critic Loss: 8.586790084838867\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.47134095430374146\n",
      "Critic Loss: 10.534692764282227\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.46158406138420105\n",
      "Critic Loss: 10.393606185913086\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.45320653915405273\n",
      "Critic Loss: 10.204312324523926\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.4500877857208252\n",
      "Critic Loss: 8.396926879882812\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.44478753209114075\n",
      "Critic Loss: 9.741507530212402\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.44770684838294983\n",
      "Critic Loss: 8.341996192932129\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.4629918336868286\n",
      "Critic Loss: 9.14246654510498\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.4577426612377167\n",
      "Critic Loss: 8.414856910705566\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.46385446190834045\n",
      "Critic Loss: 9.435656547546387\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.4329575002193451\n",
      "Critic Loss: 9.397507667541504\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.44834667444229126\n",
      "Critic Loss: 10.225607872009277\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.44636037945747375\n",
      "Critic Loss: 9.000983238220215\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.44620731472969055\n",
      "Critic Loss: 8.424062728881836\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.4670534133911133\n",
      "Critic Loss: 7.548614501953125\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.4340301752090454\n",
      "Critic Loss: 11.44595718383789\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.43590888381004333\n",
      "Critic Loss: 9.776272773742676\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.45806625485420227\n",
      "Critic Loss: 11.132806777954102\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.44267573952674866\n",
      "Critic Loss: 8.986042022705078\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.4331877529621124\n",
      "Critic Loss: 12.790661811828613\n",
      "\n",
      "New best validation reward reached in update [58/200]\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.4330652952194214\n",
      "Critic Loss: 9.88711929321289\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.42974817752838135\n",
      "Critic Loss: 9.704593658447266\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.43211135268211365\n",
      "Critic Loss: 9.912364959716797\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.4572218060493469\n",
      "Critic Loss: 10.401144981384277\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.45596420764923096\n",
      "Critic Loss: 11.689277648925781\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.42284101247787476\n",
      "Critic Loss: 10.566235542297363\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.4408724009990692\n",
      "Critic Loss: 8.991594314575195\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.4339507818222046\n",
      "Critic Loss: 10.518497467041016\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.4297715425491333\n",
      "Critic Loss: 9.085247039794922\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.4417068362236023\n",
      "Critic Loss: 8.265095710754395\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.45028144121170044\n",
      "Critic Loss: 13.832984924316406\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.42821305990219116\n",
      "Critic Loss: 11.563456535339355\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.43235865235328674\n",
      "Critic Loss: 10.493054389953613\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.416775643825531\n",
      "Critic Loss: 12.364620208740234\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.4577569365501404\n",
      "Critic Loss: 9.204007148742676\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.42195257544517517\n",
      "Critic Loss: 8.249164581298828\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.4688754677772522\n",
      "Critic Loss: 11.372167587280273\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.44343966245651245\n",
      "Critic Loss: 10.438774108886719\n",
      "\n",
      "New best validation reward reached in update [76/200]\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.455098032951355\n",
      "Critic Loss: 8.080617904663086\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.45183509588241577\n",
      "Critic Loss: 7.959455490112305\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.4266146719455719\n",
      "Critic Loss: 7.4593658447265625\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.4569445550441742\n",
      "Critic Loss: 9.973403930664062\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.42006558179855347\n",
      "Critic Loss: 7.496904373168945\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.44679000973701477\n",
      "Critic Loss: 8.173627853393555\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.4501228928565979\n",
      "Critic Loss: 12.505969047546387\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.4491780698299408\n",
      "Critic Loss: 9.946249008178711\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.4341200590133667\n",
      "Critic Loss: 11.499094009399414\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.4315941631793976\n",
      "Critic Loss: 10.759023666381836\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.4440048635005951\n",
      "Critic Loss: 9.652031898498535\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.4354560375213623\n",
      "Critic Loss: 10.235687255859375\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7721bd9f321149cf9d6853d0447af0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>149.60001</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>177.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.05852</td></tr><tr><td>Loss/Critic_loss</td><td>10.23569</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.35582</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00228</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00246</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.43546</td></tr><tr><td>Metric/Explained_variance</td><td>0.1299</td></tr><tr><td>Reward/Mean_train_reward</td><td>-4.20341</td></tr><tr><td>Reward/Mean_val_reward</td><td>12.188</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>7.5435</td></tr><tr><td>global_step</td><td>88</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sweep-60</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/doiq7s0c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/doiq7s0c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_225644-doiq7s0c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: et0v74hy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0029033063094051305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.000683006572710053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.034065828907865206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.980925189282505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 7.505891016580974e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0002676275193260633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_230835-et0v74hy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/et0v74hy' target=\"_blank\">denim-sweep-61</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/et0v74hy' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/et0v74hy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.0029033063094051305, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.000683006572710053, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.034065828907865206, 'epochs': 10, 'exponential_factor': 0.980925189282505, 'gamma': 0.99, 'hidden_sizes': [350, 350, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 7.505891016580974e-06, 'l2_factor': 0.0002676275193260633, 'lrelu': 0.1, 'minibatch_size': 256, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0029033063094051305, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.000683006572710053, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.034065828907865206, 'epochs': 10, 'exponential_factor': 0.980925189282505, 'gamma': 0.99, 'l1_factor': 7.505891016580974e-06, 'l2_factor': 0.0002676275193260633, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0029033063094051305, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.000683006572710053, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.034065828907865206, 'epochs': 10, 'exponential_factor': 0.980925189282505, 'gamma': 0.99, 'l1_factor': 7.505891016580974e-06, 'l2_factor': 0.0002676275193260633, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0029033063094051305, 'critic_lr': 0.000683006572710053, 'decay_method': 'exponential', 'exponential_factor': 0.980925189282505, 'value_loss_factor': 1, 'entropy': 0.034065828907865206, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 7.505891016580974e-06, 'l2_factor': 0.0002676275193260633, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 350, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.8355602025985718\n",
      "Critic Loss: 38.301692962646484\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.7920863628387451\n",
      "Critic Loss: 38.19877624511719\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.7369352579116821\n",
      "Critic Loss: 18.33301544189453\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.7853740453720093\n",
      "Critic Loss: 16.593666076660156\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.7153913378715515\n",
      "Critic Loss: 12.385393142700195\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.4426479935646057\n",
      "Critic Loss: 8.743402481079102\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.6384488344192505\n",
      "Critic Loss: 13.49842357635498\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.6369051933288574\n",
      "Critic Loss: 30.048328399658203\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.5003631711006165\n",
      "Critic Loss: 24.648799896240234\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.5433631539344788\n",
      "Critic Loss: 22.33020782470703\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.46602919697761536\n",
      "Critic Loss: 15.897917747497559\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.4293309152126312\n",
      "Critic Loss: 17.227426528930664\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.4535011053085327\n",
      "Critic Loss: 11.649894714355469\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.40204986929893494\n",
      "Critic Loss: 14.520480155944824\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.3428506851196289\n",
      "Critic Loss: 6.808043956756592\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.4257069528102875\n",
      "Critic Loss: 20.740110397338867\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.3825666308403015\n",
      "Critic Loss: 20.921667098999023\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.3174729645252228\n",
      "Critic Loss: 8.702746391296387\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.3244008421897888\n",
      "Critic Loss: 10.02766227722168\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.37285467982292175\n",
      "Critic Loss: 10.059864044189453\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.5595568418502808\n",
      "Critic Loss: 14.065507888793945\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.30459725856781006\n",
      "Critic Loss: 17.418758392333984\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.3166189193725586\n",
      "Critic Loss: 6.047894477844238\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.2624340355396271\n",
      "Critic Loss: 6.015222549438477\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.46448230743408203\n",
      "Critic Loss: 14.338088989257812\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.366704523563385\n",
      "Critic Loss: 10.28097152709961\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.32183027267456055\n",
      "Critic Loss: 10.339970588684082\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.25867539644241333\n",
      "Critic Loss: 10.391709327697754\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.37592655420303345\n",
      "Critic Loss: 11.95474624633789\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.26752835512161255\n",
      "Critic Loss: 8.592223167419434\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.24804984033107758\n",
      "Critic Loss: 4.620681285858154\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.24570320546627045\n",
      "Critic Loss: 11.305516242980957\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.23648303747177124\n",
      "Critic Loss: 9.176589965820312\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.2293139398097992\n",
      "Critic Loss: 13.52403450012207\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.21000339090824127\n",
      "Critic Loss: 4.91918420791626\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.4523932635784149\n",
      "Critic Loss: 10.76735782623291\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.21148517727851868\n",
      "Critic Loss: 8.983038902282715\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.20238295197486877\n",
      "Critic Loss: 5.958287239074707\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.1647556722164154\n",
      "Critic Loss: 5.008540153503418\n",
      "\n",
      "New best validation reward reached in update [39/200]\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.2340625673532486\n",
      "Critic Loss: 6.292011737823486\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.19712921977043152\n",
      "Critic Loss: 3.1402902603149414\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.1867402344942093\n",
      "Critic Loss: 11.227106094360352\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.13993696868419647\n",
      "Critic Loss: 15.637860298156738\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.17808754742145538\n",
      "Critic Loss: 5.155378818511963\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.1351015865802765\n",
      "Critic Loss: 6.163175582885742\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.16477155685424805\n",
      "Critic Loss: 11.895861625671387\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.1728055626153946\n",
      "Critic Loss: 8.878663063049316\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.12246526777744293\n",
      "Critic Loss: 18.650619506835938\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.46119552850723267\n",
      "Critic Loss: 17.61132049560547\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.1868053376674652\n",
      "Critic Loss: 13.084946632385254\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.14002278447151184\n",
      "Critic Loss: 14.130879402160645\n",
      "\n",
      "New best validation reward reached in update [51/200]\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.1639176309108734\n",
      "Critic Loss: 4.608956336975098\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.15450012683868408\n",
      "Critic Loss: 3.7041373252868652\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.14303046464920044\n",
      "Critic Loss: 10.969788551330566\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.14670291543006897\n",
      "Critic Loss: 16.00824737548828\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.11217145621776581\n",
      "Critic Loss: 9.394878387451172\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.13172680139541626\n",
      "Critic Loss: 8.412040710449219\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.13745242357254028\n",
      "Critic Loss: 14.839179992675781\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.1219276487827301\n",
      "Critic Loss: 7.9272308349609375\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.1025131493806839\n",
      "Critic Loss: 5.819834232330322\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.12501758337020874\n",
      "Critic Loss: 5.9895830154418945\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.15750202536582947\n",
      "Critic Loss: 3.5207324028015137\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.20804443955421448\n",
      "Critic Loss: 0.2594107687473297\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.15738800168037415\n",
      "Critic Loss: 9.099806785583496\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.09991820156574249\n",
      "Critic Loss: 14.473295211791992\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.12309608608484268\n",
      "Critic Loss: 8.58059310913086\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.10780525952577591\n",
      "Critic Loss: 10.124959945678711\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.09459097683429718\n",
      "Critic Loss: 4.17464542388916\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.13777661323547363\n",
      "Critic Loss: 5.150411128997803\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.17361530661582947\n",
      "Critic Loss: 9.82390022277832\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.1258378028869629\n",
      "Critic Loss: 9.183422088623047\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.08147592842578888\n",
      "Critic Loss: 15.540327072143555\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.11205528676509857\n",
      "Critic Loss: 8.04144287109375\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.10298517346382141\n",
      "Critic Loss: 11.241865158081055\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.0854632705450058\n",
      "Critic Loss: 10.411788940429688\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.08910638839006424\n",
      "Critic Loss: 8.529075622558594\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.1522124707698822\n",
      "Critic Loss: 12.805795669555664\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.22623014450073242\n",
      "Critic Loss: 9.21740436553955\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.12395723909139633\n",
      "Critic Loss: 11.69891357421875\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.13472537696361542\n",
      "Critic Loss: 10.347036361694336\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.09964735805988312\n",
      "Critic Loss: 9.652419090270996\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.09279034286737442\n",
      "Critic Loss: 16.684494018554688\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cbbb167f294f9ebb1e1a9700b552ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>67.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>67.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00061</td></tr><tr><td>Learning_rate/Critic</td><td>0.00014</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00833</td></tr><tr><td>Loss/Critic_loss</td><td>16.68449</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.01046</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00382</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00797</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.09279</td></tr><tr><td>Metric/Explained_variance</td><td>0.20555</td></tr><tr><td>Reward/Mean_train_reward</td><td>-78.934</td></tr><tr><td>Reward/Mean_val_reward</td><td>-78.934</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-63.90982</td></tr><tr><td>global_step</td><td>82</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sweep-61</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/et0v74hy' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/et0v74hy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_230835-et0v74hy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fkqp375b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0005180656404794369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0016204377952108307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.005761529568735706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8838766736775941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0001588257060834471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.07911102117607e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_231801-fkqp375b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/fkqp375b' target=\"_blank\">hardy-sweep-62</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fkqp375b' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fkqp375b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.0005180656404794369, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0016204377952108307, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005761529568735706, 'epochs': 10, 'exponential_factor': 0.8838766736775941, 'gamma': 0.95, 'hidden_sizes': [150, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.0001588257060834471, 'l2_factor': 6.07911102117607e-05, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0005180656404794369, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0016204377952108307, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005761529568735706, 'epochs': 10, 'exponential_factor': 0.8838766736775941, 'gamma': 0.95, 'l1_factor': 0.0001588257060834471, 'l2_factor': 6.07911102117607e-05, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0005180656404794369, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0016204377952108307, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.005761529568735706, 'epochs': 10, 'exponential_factor': 0.8838766736775941, 'gamma': 0.95, 'l1_factor': 0.0001588257060834471, 'l2_factor': 6.07911102117607e-05, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0005180656404794369, 'critic_lr': 0.0016204377952108307, 'decay_method': 'exponential', 'exponential_factor': 0.8838766736775941, 'value_loss_factor': 1, 'entropy': 0.005761529568735706, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0001588257060834471, 'l2_factor': 6.07911102117607e-05, 'T': 512, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [150, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.7316751480102539\n",
      "Critic Loss: 27.1602840423584\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.5645921230316162\n",
      "Critic Loss: 12.094316482543945\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.4600721299648285\n",
      "Critic Loss: 13.248411178588867\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.36351490020751953\n",
      "Critic Loss: 9.552178382873535\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.3015449643135071\n",
      "Critic Loss: 10.830495834350586\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.2778642475605011\n",
      "Critic Loss: 11.486330032348633\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.2716311514377594\n",
      "Critic Loss: 9.376620292663574\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.24547789990901947\n",
      "Critic Loss: 8.96823787689209\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.20485378801822662\n",
      "Critic Loss: 5.822469234466553\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.1989595741033554\n",
      "Critic Loss: 6.860129356384277\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.2099343240261078\n",
      "Critic Loss: 7.949060440063477\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.18132612109184265\n",
      "Critic Loss: 7.102761268615723\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.17138423025608063\n",
      "Critic Loss: 6.90566349029541\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.1682223230600357\n",
      "Critic Loss: 6.327943801879883\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.14112447202205658\n",
      "Critic Loss: 8.0094575881958\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.16004471480846405\n",
      "Critic Loss: 7.153188705444336\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.18916891515254974\n",
      "Critic Loss: 5.114381790161133\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.15478432178497314\n",
      "Critic Loss: 4.427863121032715\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.14933595061302185\n",
      "Critic Loss: 5.399019718170166\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.14479510486125946\n",
      "Critic Loss: 3.6686935424804688\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.16853174567222595\n",
      "Critic Loss: 5.859601020812988\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.1542588770389557\n",
      "Critic Loss: 6.827305316925049\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.15561161935329437\n",
      "Critic Loss: 4.874552249908447\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.16359344124794006\n",
      "Critic Loss: 3.3677616119384766\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.15793433785438538\n",
      "Critic Loss: 4.240978717803955\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.14629961550235748\n",
      "Critic Loss: 4.387975692749023\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.1516057252883911\n",
      "Critic Loss: 5.2545166015625\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.1576138436794281\n",
      "Critic Loss: 2.7011566162109375\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.1642158478498459\n",
      "Critic Loss: 3.718148946762085\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.14681777358055115\n",
      "Critic Loss: 4.141639709472656\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.14810025691986084\n",
      "Critic Loss: 3.8003897666931152\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.1514768898487091\n",
      "Critic Loss: 3.463559627532959\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.14552730321884155\n",
      "Critic Loss: 3.4313416481018066\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.1580674797296524\n",
      "Critic Loss: 3.593249559402466\n",
      "\n",
      "New best validation reward reached in update [34/200]\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.15094678103923798\n",
      "Critic Loss: 3.434539318084717\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.16395151615142822\n",
      "Critic Loss: 3.9893221855163574\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.1374870389699936\n",
      "Critic Loss: 3.369647741317749\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.14882509410381317\n",
      "Critic Loss: 2.940131902694702\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.15675702691078186\n",
      "Critic Loss: 4.255709171295166\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.1617344319820404\n",
      "Critic Loss: 3.173304319381714\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.14732524752616882\n",
      "Critic Loss: 4.260860919952393\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.15479706227779388\n",
      "Critic Loss: 3.2195258140563965\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.14204204082489014\n",
      "Critic Loss: 3.366065502166748\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.15420883893966675\n",
      "Critic Loss: 4.25516414642334\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.15599101781845093\n",
      "Critic Loss: 3.6469836235046387\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.1525610089302063\n",
      "Critic Loss: 3.169537305831909\n",
      "\n",
      "New best validation reward reached in update [46/200]\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.16168645024299622\n",
      "Critic Loss: 3.3797366619110107\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.15096327662467957\n",
      "Critic Loss: 3.028667688369751\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.1383911371231079\n",
      "Critic Loss: 3.1171207427978516\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.1491209864616394\n",
      "Critic Loss: 3.1348557472229004\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.1566000133752823\n",
      "Critic Loss: 3.3670997619628906\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.16547532379627228\n",
      "Critic Loss: 3.4683427810668945\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.1607368290424347\n",
      "Critic Loss: 4.623812675476074\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.14628459513187408\n",
      "Critic Loss: 3.1702721118927\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.14820313453674316\n",
      "Critic Loss: 2.2354137897491455\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.15998029708862305\n",
      "Critic Loss: 6.674601078033447\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.15820275247097015\n",
      "Critic Loss: 2.8156187534332275\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.16829033195972443\n",
      "Critic Loss: 3.6301286220550537\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.15767842531204224\n",
      "Critic Loss: 2.738492012023926\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.14260993897914886\n",
      "Critic Loss: 2.488680362701416\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.16045024991035461\n",
      "Critic Loss: 4.980890274047852\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.144944965839386\n",
      "Critic Loss: 3.867236852645874\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.1635962873697281\n",
      "Critic Loss: 2.5564005374908447\n",
      "\n",
      "New best validation reward reached in update [63/200]\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.1555541753768921\n",
      "Critic Loss: 3.2539408206939697\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.15424098074436188\n",
      "Critic Loss: 7.995672225952148\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.15598559379577637\n",
      "Critic Loss: 4.161846160888672\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.15136505663394928\n",
      "Critic Loss: 2.7297675609588623\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.1467769742012024\n",
      "Critic Loss: 3.3227345943450928\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.1539720892906189\n",
      "Critic Loss: 2.4131336212158203\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.15122255682945251\n",
      "Critic Loss: 3.097882032394409\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.14739497005939484\n",
      "Critic Loss: 2.634218692779541\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.15582281351089478\n",
      "Critic Loss: 2.920802116394043\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.145971417427063\n",
      "Critic Loss: 3.1209311485290527\n",
      "\n",
      "New best validation reward reached in update [73/200]\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.1557890772819519\n",
      "Critic Loss: 3.4095330238342285\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.13697318732738495\n",
      "Critic Loss: 3.8180465698242188\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.1528673768043518\n",
      "Critic Loss: 2.791257858276367\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.14842382073402405\n",
      "Critic Loss: 4.296135902404785\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.14893673360347748\n",
      "Critic Loss: 2.8035390377044678\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.16796380281448364\n",
      "Critic Loss: 2.0172617435455322\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.15158848464488983\n",
      "Critic Loss: 2.5451626777648926\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.15658022463321686\n",
      "Critic Loss: 2.371624231338501\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.1564038246870041\n",
      "Critic Loss: 2.30596923828125\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.16028094291687012\n",
      "Critic Loss: 3.242426633834839\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.14943401515483856\n",
      "Critic Loss: 3.2749550342559814\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.16916482150554657\n",
      "Critic Loss: 2.5720930099487305\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.15286047756671906\n",
      "Critic Loss: 5.469503402709961\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b5172f4dd54c278acd7744e74dcf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>56.25</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>54.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00902</td></tr><tr><td>Loss/Critic_loss</td><td>5.4695</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.32785</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00158</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00137</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.15286</td></tr><tr><td>Metric/Explained_variance</td><td>0.62834</td></tr><tr><td>Reward/Mean_train_reward</td><td>-52.20475</td></tr><tr><td>Reward/Mean_val_reward</td><td>-50.5026</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-54.98</td></tr><tr><td>global_step</td><td>86</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-62</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fkqp375b' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fkqp375b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_231801-fkqp375b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 60nrelji with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.004052579156120559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0034942502153542236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04496687499725916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9401843961074492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 5.568161181612745e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.886186219426817e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_232329-60nrelji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/60nrelji' target=\"_blank\">misty-sweep-63</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/60nrelji' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/60nrelji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.004052579156120559, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0034942502153542236, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04496687499725916, 'epochs': 10, 'exponential_factor': 0.9401843961074492, 'gamma': 0.99, 'hidden_sizes': [250, 150, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 5.568161181612745e-06, 'l2_factor': 1.886186219426817e-05, 'lrelu': 0.001, 'minibatch_size': 32, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.004052579156120559, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0034942502153542236, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04496687499725916, 'epochs': 10, 'exponential_factor': 0.9401843961074492, 'gamma': 0.99, 'l1_factor': 5.568161181612745e-06, 'l2_factor': 1.886186219426817e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.004052579156120559, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0034942502153542236, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04496687499725916, 'epochs': 10, 'exponential_factor': 0.9401843961074492, 'gamma': 0.99, 'l1_factor': 5.568161181612745e-06, 'l2_factor': 1.886186219426817e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.004052579156120559, 'critic_lr': 0.0034942502153542236, 'decay_method': 'exponential', 'exponential_factor': 0.9401843961074492, 'value_loss_factor': 1, 'entropy': 0.04496687499725916, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 5.568161181612745e-06, 'l2_factor': 1.886186219426817e-05, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [250, 150, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.016774285584688187\n",
      "Critic Loss: 22.881877899169922\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.019039325416088104\n",
      "Critic Loss: 11.923566818237305\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.027563167735934258\n",
      "Critic Loss: 18.04509735107422\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.07585615664720535\n",
      "Critic Loss: 12.321474075317383\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.028201507404446602\n",
      "Critic Loss: 10.517141342163086\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.02744511514902115\n",
      "Critic Loss: 7.238065719604492\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.08752996474504471\n",
      "Critic Loss: 8.49374008178711\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.05587110295891762\n",
      "Critic Loss: 7.285731315612793\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.03264300152659416\n",
      "Critic Loss: 8.784358024597168\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.020160596817731857\n",
      "Critic Loss: 10.012089729309082\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.07325474917888641\n",
      "Critic Loss: 6.539956092834473\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.042917411774396896\n",
      "Critic Loss: 9.286412239074707\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.0021251006983220577\n",
      "Critic Loss: 6.079229354858398\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.08569987863302231\n",
      "Critic Loss: 8.802167892456055\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.06558363139629364\n",
      "Critic Loss: 4.667773246765137\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.03602948784828186\n",
      "Critic Loss: 6.0406317710876465\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.006484141573309898\n",
      "Critic Loss: 5.376522064208984\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.03715193644165993\n",
      "Critic Loss: 6.198761463165283\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.0802837684750557\n",
      "Critic Loss: 5.475754261016846\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.06823508441448212\n",
      "Critic Loss: 7.598172187805176\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.005267725791782141\n",
      "Critic Loss: 5.219935417175293\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.06231354549527168\n",
      "Critic Loss: 5.999152183532715\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.05907607078552246\n",
      "Critic Loss: 6.698526859283447\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.01032729260623455\n",
      "Critic Loss: 9.810441970825195\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.0007835510186851025\n",
      "Critic Loss: 5.621295928955078\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.008078522980213165\n",
      "Critic Loss: 6.037731647491455\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.02400713413953781\n",
      "Critic Loss: 8.640304565429688\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.0015596016310155392\n",
      "Critic Loss: 11.373445510864258\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.037650126963853836\n",
      "Critic Loss: 4.772948265075684\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.06846336275339127\n",
      "Critic Loss: 5.224727630615234\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.0892186090350151\n",
      "Critic Loss: 7.070614814758301\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.03480471298098564\n",
      "Critic Loss: 3.2778077125549316\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.022056087851524353\n",
      "Critic Loss: 4.784122943878174\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.07190210372209549\n",
      "Critic Loss: 4.179527282714844\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.07406248152256012\n",
      "Critic Loss: 8.18112564086914\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.08450478315353394\n",
      "Critic Loss: 4.735540866851807\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.05448870733380318\n",
      "Critic Loss: 7.698923110961914\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.07391928136348724\n",
      "Critic Loss: 4.431735992431641\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.06082172319293022\n",
      "Critic Loss: 3.5419352054595947\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.07322714477777481\n",
      "Critic Loss: 8.005643844604492\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.0750812441110611\n",
      "Critic Loss: 4.377553462982178\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.024089287966489792\n",
      "Critic Loss: 8.29277229309082\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.0821295976638794\n",
      "Critic Loss: 8.008822441101074\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.08340422809123993\n",
      "Critic Loss: 9.185894966125488\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.03452393785119057\n",
      "Critic Loss: 8.098145484924316\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.07357581704854965\n",
      "Critic Loss: 3.2035694122314453\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.07070650905370712\n",
      "Critic Loss: 2.9553287029266357\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.027924643829464912\n",
      "Critic Loss: 4.704493045806885\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.022018561139702797\n",
      "Critic Loss: 6.1091766357421875\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.01881873793900013\n",
      "Critic Loss: 5.3255720138549805\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.05280980467796326\n",
      "Critic Loss: 4.205076694488525\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.05070675164461136\n",
      "Critic Loss: 8.119674682617188\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.09803435206413269\n",
      "Critic Loss: 6.015369415283203\n",
      "\n",
      "New best validation reward reached in update [53/200]\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.06959479302167892\n",
      "Critic Loss: 4.182859420776367\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.0249309279024601\n",
      "Critic Loss: 4.220427989959717\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.12071527540683746\n",
      "Critic Loss: 5.456013202667236\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.023580018430948257\n",
      "Critic Loss: 2.824995279312134\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.04281853511929512\n",
      "Critic Loss: 3.260439395904541\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.045689310878515244\n",
      "Critic Loss: 8.775142669677734\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.13189682364463806\n",
      "Critic Loss: 11.718290328979492\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.09388305991888046\n",
      "Critic Loss: 8.209207534790039\n",
      "\n",
      "New best validation reward reached in update [61/200]\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.056008268147706985\n",
      "Critic Loss: 3.5276131629943848\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.05967498570680618\n",
      "Critic Loss: 4.592052459716797\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.032358720898628235\n",
      "Critic Loss: 13.273829460144043\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.05581531673669815\n",
      "Critic Loss: 7.093350410461426\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.04783295840024948\n",
      "Critic Loss: 6.3902435302734375\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.09857801347970963\n",
      "Critic Loss: 11.23538589477539\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.014984304085373878\n",
      "Critic Loss: 3.4651684761047363\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.03168884664773941\n",
      "Critic Loss: 8.803635597229004\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.011375008150935173\n",
      "Critic Loss: 4.539320468902588\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.052827138453722\n",
      "Critic Loss: 4.543304443359375\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.06680287420749664\n",
      "Critic Loss: 3.926145315170288\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.09578701853752136\n",
      "Critic Loss: 5.742095470428467\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.0752914771437645\n",
      "Critic Loss: 7.2732696533203125\n",
      "\n",
      "New best validation reward reached in update [74/200]\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.03745245188474655\n",
      "Critic Loss: 9.237105369567871\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.0459413044154644\n",
      "Critic Loss: 3.2949812412261963\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.07434416562318802\n",
      "Critic Loss: 5.528284549713135\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.09031599014997482\n",
      "Critic Loss: 4.188145637512207\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.07393799722194672\n",
      "Critic Loss: 3.6247129440307617\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.11791746318340302\n",
      "Critic Loss: 5.856250286102295\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.06165160983800888\n",
      "Critic Loss: 6.807368278503418\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.013116851449012756\n",
      "Critic Loss: 5.629748821258545\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.02080683782696724\n",
      "Critic Loss: 6.305437088012695\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.014860007911920547\n",
      "Critic Loss: 2.6386563777923584\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.09598001837730408\n",
      "Critic Loss: 5.474377632141113\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.058080535382032394\n",
      "Critic Loss: 10.22799015045166\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.07104844599962234\n",
      "Critic Loss: 5.1267266273498535\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -0.05980575457215309\n",
      "Critic Loss: 6.340274810791016\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.07346038520336151\n",
      "Critic Loss: 4.282034397125244\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.060389015823602676\n",
      "Critic Loss: 2.5082883834838867\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.02037370577454567\n",
      "Critic Loss: 7.559555530548096\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.041332442313432693\n",
      "Critic Loss: 3.0003981590270996\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.07926001399755478\n",
      "Critic Loss: 9.147334098815918\n",
      "\n",
      "New best validation reward reached in update [93/200]\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.07083369046449661\n",
      "Critic Loss: 4.085400104522705\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.07424812018871307\n",
      "Critic Loss: 9.87356948852539\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.011759040877223015\n",
      "Critic Loss: 5.320347309112549\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.05017957463860512\n",
      "Critic Loss: 5.553915023803711\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.06582728028297424\n",
      "Critic Loss: 15.426836967468262\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.04929482564330101\n",
      "Critic Loss: 5.956801414489746\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.0561840794980526\n",
      "Critic Loss: 6.331941604614258\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.07447740435600281\n",
      "Critic Loss: 5.328245639801025\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.06390564143657684\n",
      "Critic Loss: 7.153205394744873\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.03539605811238289\n",
      "Critic Loss: 7.0151262283325195\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.0679144561290741\n",
      "Critic Loss: 6.498771667480469\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5280ba54b94f46118de01bae93f46eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>90.22222</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>153.2</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.08012</td></tr><tr><td>Loss/Critic_loss</td><td>6.49877</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.57689</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00039</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00921</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.06791</td></tr><tr><td>Metric/Explained_variance</td><td>0.30846</td></tr><tr><td>Reward/Mean_train_reward</td><td>-40.91522</td></tr><tr><td>Reward/Mean_val_reward</td><td>7.3042</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-11.39168</td></tr><tr><td>global_step</td><td>104</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-63</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/60nrelji' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/60nrelji</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_232329-60nrelji\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 83qhrogs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.008144618098424513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0002600125533695972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0016039393939105925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.975944427020444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.24685188659723e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 4.586853145018579e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_234554-83qhrogs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/83qhrogs' target=\"_blank\">classic-sweep-64</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/83qhrogs' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/83qhrogs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.008144618098424513, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002600125533695972, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0016039393939105925, 'epochs': 10, 'exponential_factor': 0.975944427020444, 'gamma': 0.95, 'hidden_sizes': [350, 150, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 3.24685188659723e-05, 'l2_factor': 4.586853145018579e-05, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.008144618098424513, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002600125533695972, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0016039393939105925, 'epochs': 10, 'exponential_factor': 0.975944427020444, 'gamma': 0.95, 'l1_factor': 3.24685188659723e-05, 'l2_factor': 4.586853145018579e-05, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 350, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.008144618098424513, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002600125533695972, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0016039393939105925, 'epochs': 10, 'exponential_factor': 0.975944427020444, 'gamma': 0.95, 'l1_factor': 3.24685188659723e-05, 'l2_factor': 4.586853145018579e-05, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.008144618098424513, 'critic_lr': 0.0002600125533695972, 'decay_method': 'exponential', 'exponential_factor': 0.975944427020444, 'value_loss_factor': 1, 'entropy': 0.0016039393939105925, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.24685188659723e-05, 'l2_factor': 4.586853145018579e-05, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [350, 150, 350, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 14.92318344116211\n",
      "Critic Loss: 14.928826332092285\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 13.247631072998047\n",
      "Critic Loss: 11.304851531982422\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 8.09026050567627\n",
      "Critic Loss: 7.669281959533691\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 12.761045455932617\n",
      "Critic Loss: 11.737520217895508\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 14.906109809875488\n",
      "Critic Loss: 13.351339340209961\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 8.190183639526367\n",
      "Critic Loss: 6.815541744232178\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 21.848684310913086\n",
      "Critic Loss: 9.247304916381836\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 9.793316841125488\n",
      "Critic Loss: 6.08389139175415\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 14.968623161315918\n",
      "Critic Loss: 7.912753105163574\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 29.7864933013916\n",
      "Critic Loss: 23.48560333251953\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 13.666472434997559\n",
      "Critic Loss: 6.351073265075684\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.897547721862793\n",
      "Critic Loss: 1.9713842868804932\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 11.453848838806152\n",
      "Critic Loss: 5.363779067993164\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 13.483909606933594\n",
      "Critic Loss: 4.724392890930176\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -3.574122667312622\n",
      "Critic Loss: 15.091734886169434\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 7.924220561981201\n",
      "Critic Loss: 7.117169380187988\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.026051029562950134\n",
      "Critic Loss: 8.758349418640137\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 4.736356735229492\n",
      "Critic Loss: 5.152249336242676\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 2.823866844177246\n",
      "Critic Loss: 6.64240026473999\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -3.9258077144622803\n",
      "Critic Loss: 8.211539268493652\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -5.222846031188965\n",
      "Critic Loss: 7.4141845703125\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -1.2973591089248657\n",
      "Critic Loss: 4.782747268676758\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.4804300367832184\n",
      "Critic Loss: 2.1085903644561768\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -3.5102016925811768\n",
      "Critic Loss: 12.419281959533691\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -9.26848316192627\n",
      "Critic Loss: 10.478113174438477\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 5.554759979248047\n",
      "Critic Loss: 2.5144059658050537\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -2.001831531524658\n",
      "Critic Loss: 2.6008801460266113\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -3.4169464111328125\n",
      "Critic Loss: 3.3274216651916504\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 4.913635730743408\n",
      "Critic Loss: 5.735282897949219\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -8.062224388122559\n",
      "Critic Loss: 1.9988030195236206\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -5.704440593719482\n",
      "Critic Loss: 13.587935447692871\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -5.451742649078369\n",
      "Critic Loss: 11.604568481445312\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -8.006060600280762\n",
      "Critic Loss: 9.156267166137695\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 3.332040548324585\n",
      "Critic Loss: 3.503617763519287\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 2.9791853427886963\n",
      "Critic Loss: 7.630906581878662\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 2.4220521450042725\n",
      "Critic Loss: 5.869277000427246\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 18.409000396728516\n",
      "Critic Loss: 17.367286682128906\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 14.293904304504395\n",
      "Critic Loss: 11.124857902526855\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 13.80650806427002\n",
      "Critic Loss: 8.779815673828125\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 15.227489471435547\n",
      "Critic Loss: 11.785969734191895\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 2.3274638652801514\n",
      "Critic Loss: 1.68472158908844\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 9.024398803710938\n",
      "Critic Loss: 4.283740997314453\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 10.432085037231445\n",
      "Critic Loss: 5.808191299438477\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 2.756972074508667\n",
      "Critic Loss: 3.1472129821777344\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 2.9644808769226074\n",
      "Critic Loss: 2.636471748352051\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 11.21854305267334\n",
      "Critic Loss: 3.75968337059021\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 5.858741760253906\n",
      "Critic Loss: 1.921770691871643\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 48.0526123046875\n",
      "Critic Loss: 2.748171329498291\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 17.212980270385742\n",
      "Critic Loss: 5.576711654663086\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 5.9399871826171875\n",
      "Critic Loss: 1.7213088274002075\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 17.15151596069336\n",
      "Critic Loss: 2.943805456161499\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 11.783744812011719\n",
      "Critic Loss: 2.8509864807128906\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 20.240983963012695\n",
      "Critic Loss: 3.840371608734131\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 14.904935836791992\n",
      "Critic Loss: 3.586146593093872\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 9.134636878967285\n",
      "Critic Loss: 1.5192832946777344\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 5.278642177581787\n",
      "Critic Loss: 1.70274817943573\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 12.455988883972168\n",
      "Critic Loss: 3.0770068168640137\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 9.95252799987793\n",
      "Critic Loss: 2.389991521835327\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 5.577032089233398\n",
      "Critic Loss: 3.0700244903564453\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 8.177406311035156\n",
      "Critic Loss: 3.0579919815063477\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 9.672601699829102\n",
      "Critic Loss: 11.405501365661621\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 6.300828456878662\n",
      "Critic Loss: 12.96978759765625\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac739c5875e40bd8c7c339f7c8f1420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>78.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>93.6</td></tr><tr><td>Learning_rate/Actor</td><td>0.00184</td></tr><tr><td>Learning_rate/Critic</td><td>6e-05</td></tr><tr><td>Loss/Actor_loss</td><td>5.1959</td></tr><tr><td>Loss/Critic_loss</td><td>12.96979</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.09517</td></tr><tr><td>Loss/KL_divergence</td><td>0.03039</td></tr><tr><td>Loss/Policy_loss</td><td>5.19605</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>6.30083</td></tr><tr><td>Metric/Explained_variance</td><td>0.16912</td></tr><tr><td>Reward/Mean_train_reward</td><td>-56.65633</td></tr><tr><td>Reward/Mean_val_reward</td><td>-35.1274</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-47.42704</td></tr><tr><td>global_step</td><td>62</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-64</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/83qhrogs' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/83qhrogs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_234554-83qhrogs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ke7ly39d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.003206761128930413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00020650196370523735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.002727261496555375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9717885516581692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 250, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.263922585940307e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00013152556125165007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_235031-ke7ly39d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/ke7ly39d' target=\"_blank\">fresh-sweep-65</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ke7ly39d' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ke7ly39d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.003206761128930413, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020650196370523735, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.002727261496555375, 'epochs': 10, 'exponential_factor': 0.9717885516581692, 'gamma': 0.9, 'hidden_sizes': [250, 250, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.263922585940307e-06, 'l2_factor': 0.00013152556125165007, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 250, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.003206761128930413, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020650196370523735, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.002727261496555375, 'epochs': 10, 'exponential_factor': 0.9717885516581692, 'gamma': 0.9, 'l1_factor': 1.263922585940307e-06, 'l2_factor': 0.00013152556125165007, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 250, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.003206761128930413, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020650196370523735, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.002727261496555375, 'epochs': 10, 'exponential_factor': 0.9717885516581692, 'gamma': 0.9, 'l1_factor': 1.263922585940307e-06, 'l2_factor': 0.00013152556125165007, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.003206761128930413, 'critic_lr': 0.00020650196370523735, 'decay_method': 'exponential', 'exponential_factor': 0.9717885516581692, 'value_loss_factor': 1, 'entropy': 0.002727261496555375, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.263922585940307e-06, 'l2_factor': 0.00013152556125165007, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [250, 250, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 8.0736665725708\n",
      "Critic Loss: 10.70704174041748\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 13.664989471435547\n",
      "Critic Loss: 12.379857063293457\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 4.414342403411865\n",
      "Critic Loss: 7.308148384094238\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 5.132263660430908\n",
      "Critic Loss: 8.347909927368164\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 3.0679502487182617\n",
      "Critic Loss: 5.519204616546631\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 6.025282382965088\n",
      "Critic Loss: 4.156822681427002\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 5.409032821655273\n",
      "Critic Loss: 8.886236190795898\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 9.213667869567871\n",
      "Critic Loss: 6.669005393981934\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 8.381695747375488\n",
      "Critic Loss: 11.485127449035645\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 6.70737361907959\n",
      "Critic Loss: 7.2551398277282715\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -1.5638905763626099\n",
      "Critic Loss: 6.238236904144287\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 3.722978115081787\n",
      "Critic Loss: 9.353691101074219\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 15.951518058776855\n",
      "Critic Loss: 7.2158050537109375\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 10.826324462890625\n",
      "Critic Loss: 14.487645149230957\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 11.773195266723633\n",
      "Critic Loss: 4.0453596115112305\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 11.06588363647461\n",
      "Critic Loss: 2.007122039794922\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 2.4911510944366455\n",
      "Critic Loss: 3.260316848754883\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 10.786527633666992\n",
      "Critic Loss: 5.066702842712402\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 9.87035846710205\n",
      "Critic Loss: 4.90786600112915\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 14.926342964172363\n",
      "Critic Loss: 5.162480354309082\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 61.812416076660156\n",
      "Critic Loss: 66.46820068359375\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 6.6183881759643555\n",
      "Critic Loss: 3.4987475872039795\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 27.549667358398438\n",
      "Critic Loss: 7.600723743438721\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 12.713800430297852\n",
      "Critic Loss: 5.781642913818359\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 18.725894927978516\n",
      "Critic Loss: 9.322813034057617\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 9.749930381774902\n",
      "Critic Loss: 7.004962921142578\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 13.098746299743652\n",
      "Critic Loss: 3.214996814727783\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 7.923176288604736\n",
      "Critic Loss: 10.034537315368652\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 16.50431251525879\n",
      "Critic Loss: 10.851776123046875\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 10.735177993774414\n",
      "Critic Loss: 3.637643814086914\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 17.06012535095215\n",
      "Critic Loss: 6.123200416564941\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 10.315448760986328\n",
      "Critic Loss: 6.139290809631348\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 15.227580070495605\n",
      "Critic Loss: 5.929976463317871\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 15.395523071289062\n",
      "Critic Loss: 5.046616077423096\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 17.18658447265625\n",
      "Critic Loss: 6.54243803024292\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 15.304854393005371\n",
      "Critic Loss: 8.559944152832031\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 15.798151969909668\n",
      "Critic Loss: 8.795445442199707\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 11.899584770202637\n",
      "Critic Loss: 12.074235916137695\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 3.5867557525634766\n",
      "Critic Loss: 9.60901927947998\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.5644932389259338\n",
      "Critic Loss: 6.472836017608643\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 3.4814939498901367\n",
      "Critic Loss: 6.131404399871826\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 1.3682379722595215\n",
      "Critic Loss: 6.9365553855896\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c2f2415a044180afd670eb7de475ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>104.22222</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>107.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.00099</td></tr><tr><td>Learning_rate/Critic</td><td>6e-05</td></tr><tr><td>Loss/Actor_loss</td><td>0.89316</td></tr><tr><td>Loss/Critic_loss</td><td>6.93656</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.03836</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00406</td></tr><tr><td>Loss/Policy_loss</td><td>0.89327</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.36824</td></tr><tr><td>Metric/Explained_variance</td><td>0.57836</td></tr><tr><td>Reward/Mean_train_reward</td><td>-33.57234</td></tr><tr><td>Reward/Mean_val_reward</td><td>-30.8976</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-52.97613</td></tr><tr><td>global_step</td><td>42</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-65</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ke7ly39d' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ke7ly39d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_235031-ke7ly39d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r6ce1nsa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0004728620279550953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0029223360328311993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04244329235857548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9844045459864492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00024544710003721976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00035550788327161603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240629_235743-r6ce1nsa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/r6ce1nsa' target=\"_blank\">youthful-sweep-66</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/r6ce1nsa' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/r6ce1nsa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.0004728620279550953, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0029223360328311993, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04244329235857548, 'epochs': 10, 'exponential_factor': 0.9844045459864492, 'gamma': 0.9, 'hidden_sizes': [350, 150, 250, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.00024544710003721976, 'l2_factor': 0.00035550788327161603, 'lrelu': 0.001, 'minibatch_size': 32, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0004728620279550953, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0029223360328311993, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04244329235857548, 'epochs': 10, 'exponential_factor': 0.9844045459864492, 'gamma': 0.9, 'l1_factor': 0.00024544710003721976, 'l2_factor': 0.00035550788327161603, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0004728620279550953, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0029223360328311993, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04244329235857548, 'epochs': 10, 'exponential_factor': 0.9844045459864492, 'gamma': 0.9, 'l1_factor': 0.00024544710003721976, 'l2_factor': 0.00035550788327161603, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0004728620279550953, 'critic_lr': 0.0029223360328311993, 'decay_method': 'exponential', 'exponential_factor': 0.9844045459864492, 'value_loss_factor': 1, 'entropy': 0.04244329235857548, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00024544710003721976, 'l2_factor': 0.00035550788327161603, 'T': 512, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [350, 150, 250, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 1.1537898778915405\n",
      "Critic Loss: 15.790009498596191\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.47913858294487\n",
      "Critic Loss: 10.510306358337402\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.24018308520317078\n",
      "Critic Loss: 4.431919097900391\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.20551812648773193\n",
      "Critic Loss: 2.3266360759735107\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.2864338159561157\n",
      "Critic Loss: 4.328683376312256\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.07465365529060364\n",
      "Critic Loss: 4.756887912750244\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.017134130001068115\n",
      "Critic Loss: 5.614800453186035\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.0044681355357170105\n",
      "Critic Loss: 4.954575538635254\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.033429089933633804\n",
      "Critic Loss: 3.955402135848999\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.021973207592964172\n",
      "Critic Loss: 3.1685843467712402\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.006750098429620266\n",
      "Critic Loss: 7.69423246383667\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.04014364629983902\n",
      "Critic Loss: 5.475320816040039\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.010123403742909431\n",
      "Critic Loss: 3.1287262439727783\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.054324015974998474\n",
      "Critic Loss: 6.05975341796875\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.03937224671244621\n",
      "Critic Loss: 3.9067163467407227\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.06321224570274353\n",
      "Critic Loss: 3.2016208171844482\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.04031144827604294\n",
      "Critic Loss: 4.1715545654296875\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.06992654502391815\n",
      "Critic Loss: 4.7557573318481445\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.04518863558769226\n",
      "Critic Loss: 1.4195865392684937\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.030809471383690834\n",
      "Critic Loss: 2.1962099075317383\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.035816408693790436\n",
      "Critic Loss: 2.51503849029541\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.010507909581065178\n",
      "Critic Loss: 3.7025606632232666\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.028991490602493286\n",
      "Critic Loss: 1.1100777387619019\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.059584785252809525\n",
      "Critic Loss: 0.8330973982810974\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.0547742024064064\n",
      "Critic Loss: 1.0729668140411377\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.029956171289086342\n",
      "Critic Loss: 2.9513800144195557\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.02867414802312851\n",
      "Critic Loss: 3.098116636276245\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.023697152733802795\n",
      "Critic Loss: 2.1331281661987305\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.04889381676912308\n",
      "Critic Loss: 5.672277927398682\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.06074710190296173\n",
      "Critic Loss: 2.3221471309661865\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.06076231971383095\n",
      "Critic Loss: 0.7124453186988831\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.08247420191764832\n",
      "Critic Loss: 0.9404483437538147\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.05783296376466751\n",
      "Critic Loss: 0.35383689403533936\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.04485085606575012\n",
      "Critic Loss: 2.120598316192627\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.05916191264986992\n",
      "Critic Loss: 3.879866123199463\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.05761437490582466\n",
      "Critic Loss: 1.819049596786499\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.052126042544841766\n",
      "Critic Loss: 0.8233377933502197\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.04550332576036453\n",
      "Critic Loss: 1.7261124849319458\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.07580012828111649\n",
      "Critic Loss: 1.6333823204040527\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.02052130363881588\n",
      "Critic Loss: 0.5462309122085571\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.05196493864059448\n",
      "Critic Loss: 3.988159418106079\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.013557635247707367\n",
      "Critic Loss: 1.8179343938827515\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.021260324865579605\n",
      "Critic Loss: 1.0074384212493896\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.06238345056772232\n",
      "Critic Loss: 1.2026840448379517\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.024576161056756973\n",
      "Critic Loss: 2.195096015930176\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.045859865844249725\n",
      "Critic Loss: 2.086472511291504\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.05159321054816246\n",
      "Critic Loss: 1.2428779602050781\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.052666038274765015\n",
      "Critic Loss: 1.4201619625091553\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.06934864073991776\n",
      "Critic Loss: 0.917734682559967\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.05386541038751602\n",
      "Critic Loss: 2.777475357055664\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.010189788416028023\n",
      "Critic Loss: 5.670968055725098\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.00015775999054312706\n",
      "Critic Loss: 1.4894293546676636\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.05874868854880333\n",
      "Critic Loss: 0.8500473499298096\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.0719524472951889\n",
      "Critic Loss: 0.748846173286438\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.012363305315375328\n",
      "Critic Loss: 2.6029868125915527\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.0593283548951149\n",
      "Critic Loss: 0.6117336750030518\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.07115941494703293\n",
      "Critic Loss: 3.2450127601623535\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee3f68fb9cf4b609eec168d0800832c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>145.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>94.1</td></tr><tr><td>Learning_rate/Actor</td><td>0.0002</td></tr><tr><td>Learning_rate/Critic</td><td>0.00121</td></tr><tr><td>Loss/Actor_loss</td><td>-0.09323</td></tr><tr><td>Loss/Critic_loss</td><td>3.24501</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.34062</td></tr><tr><td>Loss/KL_divergence</td><td>-0.017</td></tr><tr><td>Loss/Policy_loss</td><td>-0.03633</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.07116</td></tr><tr><td>Metric/Explained_variance</td><td>0.12057</td></tr><tr><td>Reward/Mean_train_reward</td><td>5.44401</td></tr><tr><td>Reward/Mean_val_reward</td><td>-22.5109</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-28.35946</td></tr><tr><td>global_step</td><td>57</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-66</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/r6ce1nsa' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/r6ce1nsa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240629_235743-r6ce1nsa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mg0tz5ck with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0052650493798370515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.006817389482693877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.022634920610638997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.937297037733714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 250, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0001701640774272107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.583502565084314e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_000403-mg0tz5ck</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/mg0tz5ck' target=\"_blank\">wobbly-sweep-67</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/mg0tz5ck' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/mg0tz5ck</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0052650493798370515, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.006817389482693877, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022634920610638997, 'epochs': 10, 'exponential_factor': 0.937297037733714, 'gamma': 0.99, 'hidden_sizes': [250, 250, 250, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0001701640774272107, 'l2_factor': 7.583502565084314e-05, 'lrelu': 0.1, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 250, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0052650493798370515, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.006817389482693877, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022634920610638997, 'epochs': 10, 'exponential_factor': 0.937297037733714, 'gamma': 0.99, 'l1_factor': 0.0001701640774272107, 'l2_factor': 7.583502565084314e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 250, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0052650493798370515, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.006817389482693877, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022634920610638997, 'epochs': 10, 'exponential_factor': 0.937297037733714, 'gamma': 0.99, 'l1_factor': 0.0001701640774272107, 'l2_factor': 7.583502565084314e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0052650493798370515, 'critic_lr': 0.006817389482693877, 'decay_method': 'exponential', 'exponential_factor': 0.937297037733714, 'value_loss_factor': 1, 'entropy': 0.022634920610638997, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0001701640774272107, 'l2_factor': 7.583502565084314e-05, 'T': 768, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [250, 250, 250, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 2.7636027336120605\n",
      "Critic Loss: 25.14752960205078\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 2.0170059204101562\n",
      "Critic Loss: 18.94552230834961\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.8788976073265076\n",
      "Critic Loss: 18.726612091064453\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.6338489651679993\n",
      "Critic Loss: 14.981539726257324\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.4396663010120392\n",
      "Critic Loss: 13.736018180847168\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.34548765420913696\n",
      "Critic Loss: 10.463958740234375\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.33860716223716736\n",
      "Critic Loss: 9.965469360351562\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.2524102032184601\n",
      "Critic Loss: 11.268209457397461\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.23916681110858917\n",
      "Critic Loss: 11.370686531066895\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.2422868311405182\n",
      "Critic Loss: 11.215737342834473\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.2584935128688812\n",
      "Critic Loss: 9.583013534545898\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.2155745029449463\n",
      "Critic Loss: 9.956743240356445\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.18322502076625824\n",
      "Critic Loss: 10.882335662841797\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.21760424971580505\n",
      "Critic Loss: 13.554574966430664\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.21005722880363464\n",
      "Critic Loss: 14.456382751464844\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.19224423170089722\n",
      "Critic Loss: 11.35800838470459\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.2175668478012085\n",
      "Critic Loss: 17.677562713623047\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.19513222575187683\n",
      "Critic Loss: 16.855815887451172\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.22954276204109192\n",
      "Critic Loss: 17.110021591186523\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.15841858088970184\n",
      "Critic Loss: 16.816450119018555\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.164236918091774\n",
      "Critic Loss: 9.138391494750977\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.14224563539028168\n",
      "Critic Loss: 8.112110137939453\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.15577782690525055\n",
      "Critic Loss: 8.883787155151367\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.12548601627349854\n",
      "Critic Loss: 6.607070446014404\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.07807666063308716\n",
      "Critic Loss: 13.76292610168457\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.11716344952583313\n",
      "Critic Loss: 12.242249488830566\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.1345541775226593\n",
      "Critic Loss: 12.747326850891113\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.08177901059389114\n",
      "Critic Loss: 10.06767749786377\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.1317954957485199\n",
      "Critic Loss: 11.33601188659668\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.09018106758594513\n",
      "Critic Loss: 10.885812759399414\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.05320001393556595\n",
      "Critic Loss: 8.292729377746582\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.10698765516281128\n",
      "Critic Loss: 11.570961952209473\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.05161005258560181\n",
      "Critic Loss: 9.871786117553711\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.07226113229990005\n",
      "Critic Loss: 9.870489120483398\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.07428184151649475\n",
      "Critic Loss: 9.576788902282715\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.09621793031692505\n",
      "Critic Loss: 11.189692497253418\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.08736661076545715\n",
      "Critic Loss: 9.556300163269043\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.10737516731023788\n",
      "Critic Loss: 12.463632583618164\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.09757143259048462\n",
      "Critic Loss: 10.92694091796875\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.07854325324296951\n",
      "Critic Loss: 10.499170303344727\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.04829638823866844\n",
      "Critic Loss: 10.653620719909668\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.04568430408835411\n",
      "Critic Loss: 8.459707260131836\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.0513879656791687\n",
      "Critic Loss: 10.933048248291016\n",
      "\n",
      "New best validation reward reached in update [43/200]\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.03820887580513954\n",
      "Critic Loss: 9.027443885803223\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.03581845015287399\n",
      "Critic Loss: 10.620552062988281\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.029673444107174873\n",
      "Critic Loss: 7.735494613647461\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.03893540799617767\n",
      "Critic Loss: 13.150418281555176\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.04415258392691612\n",
      "Critic Loss: 10.184633255004883\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.05655628442764282\n",
      "Critic Loss: 8.537650108337402\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.0365494042634964\n",
      "Critic Loss: 7.770352363586426\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.046127237379550934\n",
      "Critic Loss: 10.52477741241455\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.06623731553554535\n",
      "Critic Loss: 6.127183437347412\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.03937084972858429\n",
      "Critic Loss: 8.304781913757324\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.046080946922302246\n",
      "Critic Loss: 9.016189575195312\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.024609049782156944\n",
      "Critic Loss: 8.77697467803955\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.036779649555683136\n",
      "Critic Loss: 9.933528900146484\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.036670658737421036\n",
      "Critic Loss: 12.004857063293457\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.045532505959272385\n",
      "Critic Loss: 12.344747543334961\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.03569140285253525\n",
      "Critic Loss: 10.523435592651367\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.005124252755194902\n",
      "Critic Loss: 10.533553123474121\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.03111380711197853\n",
      "Critic Loss: 9.00950813293457\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.019235385581851006\n",
      "Critic Loss: 9.690114974975586\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.024548374116420746\n",
      "Critic Loss: 9.25139331817627\n",
      "\n",
      "New best validation reward reached in update [63/200]\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.05588918179273605\n",
      "Critic Loss: 13.352323532104492\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.058511439710855484\n",
      "Critic Loss: 9.887358665466309\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.03638524189591408\n",
      "Critic Loss: 7.819503307342529\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.06388916075229645\n",
      "Critic Loss: 8.977875709533691\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.024768419563770294\n",
      "Critic Loss: 9.084877967834473\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.03246041759848595\n",
      "Critic Loss: 6.743261337280273\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.03448721766471863\n",
      "Critic Loss: 5.528288841247559\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.025098243728280067\n",
      "Critic Loss: 7.416874885559082\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.030914004892110825\n",
      "Critic Loss: 6.9094648361206055\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.01923125982284546\n",
      "Critic Loss: 7.024311065673828\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.018781935796141624\n",
      "Critic Loss: 6.808213233947754\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.021614331752061844\n",
      "Critic Loss: 6.077291488647461\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.037227094173431396\n",
      "Critic Loss: 8.087286949157715\n",
      "\n",
      "New best validation reward reached in update [76/200]\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.03358718380331993\n",
      "Critic Loss: 5.185665130615234\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.022015422582626343\n",
      "Critic Loss: 7.333705425262451\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.0333876870572567\n",
      "Critic Loss: 6.798770427703857\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.0293060801923275\n",
      "Critic Loss: 6.5840253829956055\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.034056104719638824\n",
      "Critic Loss: 4.810218811035156\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.011112421751022339\n",
      "Critic Loss: 5.270716667175293\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.027070287615060806\n",
      "Critic Loss: 6.314731597900391\n",
      "\n",
      "New best validation reward reached in update [83/200]\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.036115504801273346\n",
      "Critic Loss: 5.782169342041016\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.04323310777544975\n",
      "Critic Loss: 5.882221221923828\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.021155908703804016\n",
      "Critic Loss: 4.597928524017334\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.019266800954937935\n",
      "Critic Loss: 6.910593509674072\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.026889199391007423\n",
      "Critic Loss: 4.627613067626953\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.04110000655055046\n",
      "Critic Loss: 4.740719318389893\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.023153793066740036\n",
      "Critic Loss: 7.511653900146484\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.036965399980545044\n",
      "Critic Loss: 6.861714839935303\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.04276597872376442\n",
      "Critic Loss: 7.41694974899292\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.04013938829302788\n",
      "Critic Loss: 7.80757999420166\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.031327489763498306\n",
      "Critic Loss: 7.940053462982178\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.03306342288851738\n",
      "Critic Loss: 6.358695030212402\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.014066515490412712\n",
      "Critic Loss: 4.664632797241211\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.023533685132861137\n",
      "Critic Loss: 6.124149322509766\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.04897313937544823\n",
      "Critic Loss: 5.961795806884766\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.032113272696733475\n",
      "Critic Loss: 5.138189315795898\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.03576105460524559\n",
      "Critic Loss: 8.083216667175293\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.03205719217658043\n",
      "Critic Loss: 4.542941570281982\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.03188952058553696\n",
      "Critic Loss: 8.212794303894043\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.03935886174440384\n",
      "Critic Loss: 7.73153829574585\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.03426993265748024\n",
      "Critic Loss: 5.266705513000488\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.038000598549842834\n",
      "Critic Loss: 5.530568599700928\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.0260469987988472\n",
      "Critic Loss: 5.9170427322387695\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.03439902141690254\n",
      "Critic Loss: 5.477733135223389\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.03361669182777405\n",
      "Critic Loss: 4.17256498336792\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.030589347705245018\n",
      "Critic Loss: 5.07320499420166\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.03313786908984184\n",
      "Critic Loss: 6.047770023345947\n",
      "\n",
      "New best validation reward reached in update [110/200]\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.033662039786577225\n",
      "Critic Loss: 4.256658554077148\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.034921176731586456\n",
      "Critic Loss: 4.458459377288818\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.033066876232624054\n",
      "Critic Loss: 4.566683769226074\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.03672020137310028\n",
      "Critic Loss: 6.620126724243164\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.02494187466800213\n",
      "Critic Loss: 8.262554168701172\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.05055977404117584\n",
      "Critic Loss: 6.163289546966553\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.03979143500328064\n",
      "Critic Loss: 8.430097579956055\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.03964942693710327\n",
      "Critic Loss: 7.585001468658447\n",
      "\n",
      "New best validation reward reached in update [118/200]\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.03472849354147911\n",
      "Critic Loss: 7.082962989807129\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.0399002842605114\n",
      "Critic Loss: 10.986837387084961\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.04376408830285072\n",
      "Critic Loss: 6.2180891036987305\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.023981090635061264\n",
      "Critic Loss: 9.176331520080566\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.037996020168066025\n",
      "Critic Loss: 8.918143272399902\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.027113284915685654\n",
      "Critic Loss: 10.71605110168457\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.033291615545749664\n",
      "Critic Loss: 8.159062385559082\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.038343094289302826\n",
      "Critic Loss: 7.981328010559082\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.02336529828608036\n",
      "Critic Loss: 10.312219619750977\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.052509453147649765\n",
      "Critic Loss: 9.57752799987793\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.04391096904873848\n",
      "Critic Loss: 7.529318809509277\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.031238332390785217\n",
      "Critic Loss: 9.75766372680664\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.041790612041950226\n",
      "Critic Loss: 10.912496566772461\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.029033273458480835\n",
      "Critic Loss: 6.095852851867676\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.03893159329891205\n",
      "Critic Loss: 9.196191787719727\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.031760238111019135\n",
      "Critic Loss: 10.637774467468262\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.015244286507368088\n",
      "Critic Loss: 7.661627292633057\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.03753754869103432\n",
      "Critic Loss: 9.541358947753906\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.02994023635983467\n",
      "Critic Loss: 9.583467483520508\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.031795792281627655\n",
      "Critic Loss: 9.143224716186523\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.04631705954670906\n",
      "Critic Loss: 9.654694557189941\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.04096311703324318\n",
      "Critic Loss: 6.410599231719971\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.03532912954688072\n",
      "Critic Loss: 6.1177778244018555\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.046839550137519836\n",
      "Critic Loss: 8.296540260314941\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 0.041191667318344116\n",
      "Critic Loss: 4.428568363189697\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.034906771034002304\n",
      "Critic Loss: 8.877909660339355\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.034675274044275284\n",
      "Critic Loss: 8.461387634277344\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 0.036895498633384705\n",
      "Critic Loss: 7.905211448669434\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.03564624488353729\n",
      "Critic Loss: 9.172395706176758\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.02875794656574726\n",
      "Critic Loss: 11.38410472869873\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3905c315a74a47ffa57dd467b0651fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>74.625</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>114.2</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.03733</td></tr><tr><td>Loss/Critic_loss</td><td>11.3841</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.39598</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00775</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00573</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.02876</td></tr><tr><td>Metric/Explained_variance</td><td>0.15063</td></tr><tr><td>Reward/Mean_train_reward</td><td>-39.77137</td></tr><tr><td>Reward/Mean_val_reward</td><td>-12.8468</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-7.10569</td></tr><tr><td>global_step</td><td>148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-sweep-67</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/mg0tz5ck' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/mg0tz5ck</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_000403-mg0tz5ck\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vicrs3fw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0018352252924859769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00018537676531231489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.040986889057491725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.932728628102976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 4.135279870320934e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.424698266542142e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_002014-vicrs3fw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/vicrs3fw' target=\"_blank\">good-sweep-68</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vicrs3fw' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vicrs3fw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0018352252924859769, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00018537676531231489, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.040986889057491725, 'epochs': 10, 'exponential_factor': 0.932728628102976, 'gamma': 0.9, 'hidden_sizes': [350, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 4.135279870320934e-06, 'l2_factor': 1.424698266542142e-06, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0018352252924859769, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00018537676531231489, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.040986889057491725, 'epochs': 10, 'exponential_factor': 0.932728628102976, 'gamma': 0.9, 'l1_factor': 4.135279870320934e-06, 'l2_factor': 1.424698266542142e-06, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0018352252924859769, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00018537676531231489, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.040986889057491725, 'epochs': 10, 'exponential_factor': 0.932728628102976, 'gamma': 0.9, 'l1_factor': 4.135279870320934e-06, 'l2_factor': 1.424698266542142e-06, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0018352252924859769, 'critic_lr': 0.00018537676531231489, 'decay_method': 'exponential', 'exponential_factor': 0.932728628102976, 'value_loss_factor': 1, 'entropy': 0.040986889057491725, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 4.135279870320934e-06, 'l2_factor': 1.424698266542142e-06, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [350, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: -0.11636918038129807\n",
      "Critic Loss: 34.21089172363281\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.0910431444644928\n",
      "Critic Loss: 71.64106750488281\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.04401814192533493\n",
      "Critic Loss: 15.173869132995605\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.06280279159545898\n",
      "Critic Loss: 14.531782150268555\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.06547600775957108\n",
      "Critic Loss: 14.291516304016113\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.04548889771103859\n",
      "Critic Loss: 13.622633934020996\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.00611083535477519\n",
      "Critic Loss: 12.993337631225586\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.00453876331448555\n",
      "Critic Loss: 12.566658020019531\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.008887427859008312\n",
      "Critic Loss: 12.222668647766113\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.012033266015350819\n",
      "Critic Loss: 11.93040657043457\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.0027348147705197334\n",
      "Critic Loss: 11.701708793640137\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.055011264979839325\n",
      "Critic Loss: 11.553808212280273\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.04026823490858078\n",
      "Critic Loss: 11.46179485321045\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.057532601058483124\n",
      "Critic Loss: 11.280405044555664\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.017472034320235252\n",
      "Critic Loss: 11.260517120361328\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.011101806536316872\n",
      "Critic Loss: 11.045900344848633\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.04452468082308769\n",
      "Critic Loss: 10.797402381896973\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.006416305899620056\n",
      "Critic Loss: 10.979525566101074\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.012142418883740902\n",
      "Critic Loss: 10.843154907226562\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.001324832672253251\n",
      "Critic Loss: 10.408470153808594\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -8.917285595089197e-05\n",
      "Critic Loss: 10.522841453552246\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.01574876345694065\n",
      "Critic Loss: 10.472272872924805\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.002894873730838299\n",
      "Critic Loss: 10.229399681091309\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.00013516366016119719\n",
      "Critic Loss: 10.245638847351074\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.011806896887719631\n",
      "Critic Loss: 10.284157752990723\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.013193040154874325\n",
      "Critic Loss: 10.109978675842285\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.001630363054573536\n",
      "Critic Loss: 10.230377197265625\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.005687579046934843\n",
      "Critic Loss: 10.261858940124512\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.0016301090363413095\n",
      "Critic Loss: 10.068243026733398\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.01021646335721016\n",
      "Critic Loss: 9.909430503845215\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.006970586255192757\n",
      "Critic Loss: 9.542948722839355\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.0014882159885019064\n",
      "Critic Loss: 9.404462814331055\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -2.590985968708992e-05\n",
      "Critic Loss: 9.344253540039062\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.012755154632031918\n",
      "Critic Loss: 9.5335111618042\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.001976408064365387\n",
      "Critic Loss: 9.292540550231934\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.010487736202776432\n",
      "Critic Loss: 9.091130256652832\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.007926459424197674\n",
      "Critic Loss: 9.2029447555542\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.0077711716294288635\n",
      "Critic Loss: 8.976282119750977\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.001049892627634108\n",
      "Critic Loss: 8.949277877807617\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.010356889106333256\n",
      "Critic Loss: 8.880946159362793\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.016289029270410538\n",
      "Critic Loss: 9.020057678222656\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.004586453549563885\n",
      "Critic Loss: 8.936580657958984\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.00861863512545824\n",
      "Critic Loss: 8.614418029785156\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.0008985967142507434\n",
      "Critic Loss: 8.746706008911133\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.012135321274399757\n",
      "Critic Loss: 8.341511726379395\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.009219280444085598\n",
      "Critic Loss: 8.826766014099121\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.0006796630332246423\n",
      "Critic Loss: 8.601076126098633\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe21b91552224295bf38c86cae34e059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>36.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>36.2</td></tr><tr><td>Learning_rate/Actor</td><td>7e-05</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.02518</td></tr><tr><td>Loss/Critic_loss</td><td>8.60108</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.39589</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0064</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00896</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.00068</td></tr><tr><td>Metric/Explained_variance</td><td>0.35644</td></tr><tr><td>Reward/Mean_train_reward</td><td>-75.63784</td></tr><tr><td>Reward/Mean_val_reward</td><td>-76.6248</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-76.6711</td></tr><tr><td>global_step</td><td>47</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-sweep-68</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/vicrs3fw' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/vicrs3fw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_002014-vicrs3fw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e56xosey with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0003890321865708933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0029868783807762618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.019452482745950593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.992071384721833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.3360839403032858e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.508372418204239e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_002212-e56xosey</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/e56xosey' target=\"_blank\">exalted-sweep-69</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/e56xosey' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/e56xosey</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.0003890321865708933, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0029868783807762618, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.019452482745950593, 'epochs': 10, 'exponential_factor': 0.992071384721833, 'gamma': 0.9, 'hidden_sizes': [350, 150, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 1.3360839403032858e-06, 'l2_factor': 3.508372418204239e-05, 'lrelu': 0.1, 'minibatch_size': 256, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0003890321865708933, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0029868783807762618, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.019452482745950593, 'epochs': 10, 'exponential_factor': 0.992071384721833, 'gamma': 0.9, 'l1_factor': 1.3360839403032858e-06, 'l2_factor': 3.508372418204239e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0003890321865708933, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0029868783807762618, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.019452482745950593, 'epochs': 10, 'exponential_factor': 0.992071384721833, 'gamma': 0.9, 'l1_factor': 1.3360839403032858e-06, 'l2_factor': 3.508372418204239e-05, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0003890321865708933, 'critic_lr': 0.0029868783807762618, 'decay_method': 'exponential', 'exponential_factor': 0.992071384721833, 'value_loss_factor': 1, 'entropy': 0.019452482745950593, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.3360839403032858e-06, 'l2_factor': 3.508372418204239e-05, 'T': 512, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [350, 150, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 10.253552436828613\n",
      "Critic Loss: 22.7006893157959\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 20.022600173950195\n",
      "Critic Loss: 28.37747573852539\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 16.73044776916504\n",
      "Critic Loss: 9.916479110717773\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 17.06129264831543\n",
      "Critic Loss: 6.097764492034912\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 8.402392387390137\n",
      "Critic Loss: 6.448382377624512\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 9.254483222961426\n",
      "Critic Loss: 5.742036819458008\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 6.780802249908447\n",
      "Critic Loss: 6.501378059387207\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 7.505453109741211\n",
      "Critic Loss: 4.311593532562256\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 8.193841934204102\n",
      "Critic Loss: 5.624258995056152\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 8.09130859375\n",
      "Critic Loss: 2.999911069869995\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 8.789794921875\n",
      "Critic Loss: 4.333444595336914\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 8.27270793914795\n",
      "Critic Loss: 4.133586883544922\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 8.719504356384277\n",
      "Critic Loss: 4.498348236083984\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 6.137045383453369\n",
      "Critic Loss: 3.5830845832824707\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 4.289348602294922\n",
      "Critic Loss: 2.752304792404175\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 6.132466793060303\n",
      "Critic Loss: 2.317239284515381\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 5.787345886230469\n",
      "Critic Loss: 2.938138246536255\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 7.719702243804932\n",
      "Critic Loss: 4.2901153564453125\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 5.024398326873779\n",
      "Critic Loss: 3.991462230682373\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 7.818965435028076\n",
      "Critic Loss: 5.082671165466309\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 6.455413341522217\n",
      "Critic Loss: 6.301939487457275\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 6.693315505981445\n",
      "Critic Loss: 5.254125595092773\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 7.975375652313232\n",
      "Critic Loss: 3.7113733291625977\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 7.941045761108398\n",
      "Critic Loss: 3.5454421043395996\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 10.036806106567383\n",
      "Critic Loss: 5.2015814781188965\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 5.154484748840332\n",
      "Critic Loss: 3.2750728130340576\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 7.465542793273926\n",
      "Critic Loss: 2.9631106853485107\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 6.7417778968811035\n",
      "Critic Loss: 2.4986653327941895\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 7.588391304016113\n",
      "Critic Loss: 2.5105350017547607\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 5.740523815155029\n",
      "Critic Loss: 2.559549331665039\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 7.85099983215332\n",
      "Critic Loss: 2.846461534500122\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 7.252066135406494\n",
      "Critic Loss: 2.4226198196411133\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 9.439663887023926\n",
      "Critic Loss: 2.849151849746704\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 8.36993408203125\n",
      "Critic Loss: 2.4953770637512207\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 7.852131366729736\n",
      "Critic Loss: 2.5510263442993164\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 7.810651779174805\n",
      "Critic Loss: 4.637824058532715\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 10.22392463684082\n",
      "Critic Loss: 3.1055781841278076\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 5.135126113891602\n",
      "Critic Loss: 2.00675892829895\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 4.443928241729736\n",
      "Critic Loss: 2.326467990875244\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 8.065845489501953\n",
      "Critic Loss: 2.2967569828033447\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 6.830227851867676\n",
      "Critic Loss: 3.0749080181121826\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 4.936056613922119\n",
      "Critic Loss: 2.428837537765503\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 6.934136867523193\n",
      "Critic Loss: 2.460453510284424\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 8.939414024353027\n",
      "Critic Loss: 2.3257689476013184\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 7.010179042816162\n",
      "Critic Loss: 1.8625662326812744\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 5.935024261474609\n",
      "Critic Loss: 2.318695545196533\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 8.506510734558105\n",
      "Critic Loss: 3.0798895359039307\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 6.408655166625977\n",
      "Critic Loss: 6.282597541809082\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 7.009096145629883\n",
      "Critic Loss: 3.8488833904266357\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 7.637429237365723\n",
      "Critic Loss: 2.7435739040374756\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 7.37641716003418\n",
      "Critic Loss: 3.142061710357666\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 9.11164665222168\n",
      "Critic Loss: 2.06305193901062\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 6.964025497436523\n",
      "Critic Loss: 1.8520056009292603\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 7.514007091522217\n",
      "Critic Loss: 2.7296977043151855\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 6.0731306076049805\n",
      "Critic Loss: 1.5605485439300537\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 7.344808578491211\n",
      "Critic Loss: 1.9127681255340576\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 8.925458908081055\n",
      "Critic Loss: 1.749066948890686\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 6.685389518737793\n",
      "Critic Loss: 1.8853349685668945\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 6.570232391357422\n",
      "Critic Loss: 1.6905800104141235\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebf58058d8c42748c56231a8d5fbaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>51.11111</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>55.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.00025</td></tr><tr><td>Learning_rate/Critic</td><td>0.00188</td></tr><tr><td>Loss/Actor_loss</td><td>6.54048</td></tr><tr><td>Loss/Critic_loss</td><td>1.69058</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.52347</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00512</td></tr><tr><td>Loss/Policy_loss</td><td>6.55066</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>6.57023</td></tr><tr><td>Metric/Explained_variance</td><td>0.73256</td></tr><tr><td>Reward/Mean_train_reward</td><td>-51.96322</td></tr><tr><td>Reward/Mean_val_reward</td><td>-47.9735</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-51.41837</td></tr><tr><td>global_step</td><td>59</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sweep-69</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/e56xosey' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/e56xosey</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_002212-e56xosey\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jhmxypqc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0029937580820940737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004167242233592737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.007037513330415272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9919659998497216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00031764585669922873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0006572605363383026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_002547-jhmxypqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/jhmxypqc' target=\"_blank\">eternal-sweep-70</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/jhmxypqc' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/jhmxypqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.0029937580820940737, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004167242233592737, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.007037513330415272, 'epochs': 10, 'exponential_factor': 0.9919659998497216, 'gamma': 0.99, 'hidden_sizes': [150, 350, 250, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.00031764585669922873, 'l2_factor': 0.0006572605363383026, 'lrelu': 0.001, 'minibatch_size': 32, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0029937580820940737, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004167242233592737, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.007037513330415272, 'epochs': 10, 'exponential_factor': 0.9919659998497216, 'gamma': 0.99, 'l1_factor': 0.00031764585669922873, 'l2_factor': 0.0006572605363383026, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0029937580820940737, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004167242233592737, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.007037513330415272, 'epochs': 10, 'exponential_factor': 0.9919659998497216, 'gamma': 0.99, 'l1_factor': 0.00031764585669922873, 'l2_factor': 0.0006572605363383026, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0029937580820940737, 'critic_lr': 0.0004167242233592737, 'decay_method': 'exponential', 'exponential_factor': 0.9919659998497216, 'value_loss_factor': 1, 'entropy': 0.007037513330415272, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00031764585669922873, 'l2_factor': 0.0006572605363383026, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [150, 350, 250, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 2.181668519973755\n",
      "Critic Loss: 30.90176010131836\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.01526076253503561\n",
      "Critic Loss: 4.3673935579136014e-07\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.03442058339715004\n",
      "Critic Loss: 18.775924682617188\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.05013033747673035\n",
      "Critic Loss: 13.740325927734375\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.04396649822592735\n",
      "Critic Loss: 17.68978500366211\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.03869016841053963\n",
      "Critic Loss: 5.7544660568237305\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.004443383775651455\n",
      "Critic Loss: 8.541553497314453\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.016283655539155006\n",
      "Critic Loss: 7.9972124099731445\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.002893954049795866\n",
      "Critic Loss: 14.609457969665527\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.010809692554175854\n",
      "Critic Loss: 4.656426906585693\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.019937094300985336\n",
      "Critic Loss: 6.949793815612793\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.04678752273321152\n",
      "Critic Loss: 9.969223022460938\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.0455060675740242\n",
      "Critic Loss: 9.618429183959961\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.04954012483358383\n",
      "Critic Loss: 5.877108097076416\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.008642645552754402\n",
      "Critic Loss: 3.8894705772399902\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.010036502033472061\n",
      "Critic Loss: 4.699431896209717\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.040270451456308365\n",
      "Critic Loss: 5.4355692863464355\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.00942130945622921\n",
      "Critic Loss: 4.328120708465576\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.04239693656563759\n",
      "Critic Loss: 8.767333984375\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.0357215441763401\n",
      "Critic Loss: 9.009566307067871\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.04918660968542099\n",
      "Critic Loss: 7.998076438903809\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.026045719161629677\n",
      "Critic Loss: 10.6319580078125\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.0450083389878273\n",
      "Critic Loss: 8.108795166015625\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.023797256872057915\n",
      "Critic Loss: 8.825425148010254\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.0037996582686901093\n",
      "Critic Loss: 6.624854564666748\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.037778809666633606\n",
      "Critic Loss: 4.628696441650391\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.013688988983631134\n",
      "Critic Loss: 4.5334625244140625\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.0026735751889646053\n",
      "Critic Loss: 4.882740020751953\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.022933244705200195\n",
      "Critic Loss: 6.246750354766846\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.0353592149913311\n",
      "Critic Loss: 6.060990810394287\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.001640658127143979\n",
      "Critic Loss: 8.549452781677246\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.014420611783862114\n",
      "Critic Loss: 5.635149955749512\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.0157958772033453\n",
      "Critic Loss: 7.306515216827393\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.015308428555727005\n",
      "Critic Loss: 8.809062957763672\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.011729859746992588\n",
      "Critic Loss: 3.9606313705444336\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.04053268954157829\n",
      "Critic Loss: 6.823787212371826\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.05366827920079231\n",
      "Critic Loss: 11.72810173034668\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.005100797861814499\n",
      "Critic Loss: 6.551879405975342\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.018444934859871864\n",
      "Critic Loss: 3.2244811058044434\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.019687175750732422\n",
      "Critic Loss: 10.28605842590332\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.019197184592485428\n",
      "Critic Loss: 4.625002861022949\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.028053145855665207\n",
      "Critic Loss: 7.509872913360596\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.0338403694331646\n",
      "Critic Loss: 4.486542224884033\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.007475418038666248\n",
      "Critic Loss: 3.8362021446228027\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.02262558974325657\n",
      "Critic Loss: 5.081095218658447\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.043188564479351044\n",
      "Critic Loss: 3.461995840072632\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.01217366848140955\n",
      "Critic Loss: 4.549863338470459\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.014686506241559982\n",
      "Critic Loss: 3.221717596054077\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.026493843644857407\n",
      "Critic Loss: 2.055830717086792\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.04604603350162506\n",
      "Critic Loss: 4.135001182556152\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.0025560068897902966\n",
      "Critic Loss: 3.6731021404266357\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.02897081896662712\n",
      "Critic Loss: 5.887338161468506\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.03916511684656143\n",
      "Critic Loss: 4.2553863525390625\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.00748154753819108\n",
      "Critic Loss: 2.539564609527588\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.024324635043740273\n",
      "Critic Loss: 5.485827922821045\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.01663917303085327\n",
      "Critic Loss: 3.9352614879608154\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.02144256792962551\n",
      "Critic Loss: 2.9701437950134277\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.0062121436931192875\n",
      "Critic Loss: 4.738604545593262\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.02205292508006096\n",
      "Critic Loss: 6.5708417892456055\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.029554815962910652\n",
      "Critic Loss: 3.6450202465057373\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.003724327776581049\n",
      "Critic Loss: 4.205230236053467\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.0007538003847002983\n",
      "Critic Loss: 3.674422264099121\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.015210011042654514\n",
      "Critic Loss: 2.118809938430786\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.017195984721183777\n",
      "Critic Loss: 3.4741899967193604\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.03097386658191681\n",
      "Critic Loss: 5.313263416290283\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.03217240422964096\n",
      "Critic Loss: 5.612707614898682\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.011945294216275215\n",
      "Critic Loss: 4.612188816070557\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.0077533479779958725\n",
      "Critic Loss: 5.9711480140686035\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.029698725789785385\n",
      "Critic Loss: 3.5080137252807617\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.011306419037282467\n",
      "Critic Loss: 3.8180453777313232\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.027353528887033463\n",
      "Critic Loss: 3.9161171913146973\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.0077974190935492516\n",
      "Critic Loss: 7.647773265838623\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.020314551889896393\n",
      "Critic Loss: 5.298688888549805\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.007961014285683632\n",
      "Critic Loss: 4.067421913146973\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.00488869147375226\n",
      "Critic Loss: 6.235926151275635\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.032626572996377945\n",
      "Critic Loss: 5.914100170135498\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.01705922931432724\n",
      "Critic Loss: 4.225512504577637\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.05541742220520973\n",
      "Critic Loss: 9.080345153808594\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.006341839674860239\n",
      "Critic Loss: 3.32364559173584\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.028467727825045586\n",
      "Critic Loss: 3.89396071434021\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.021174121648073196\n",
      "Critic Loss: 2.8565964698791504\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.010841181501746178\n",
      "Critic Loss: 6.329686164855957\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.0019330461509525776\n",
      "Critic Loss: 6.592683792114258\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.01510067842900753\n",
      "Critic Loss: 6.426239013671875\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.002419769298285246\n",
      "Critic Loss: 5.287275791168213\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.01599939353764057\n",
      "Critic Loss: 4.726677417755127\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.013129916042089462\n",
      "Critic Loss: 2.755565643310547\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.01488693431019783\n",
      "Critic Loss: 2.18544864654541\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.012523381039500237\n",
      "Critic Loss: 4.629317283630371\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.03827780857682228\n",
      "Critic Loss: 8.384937286376953\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.011841371655464172\n",
      "Critic Loss: 3.5024352073669434\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.0027473527006804943\n",
      "Critic Loss: 3.1124496459960938\n",
      "\n",
      "New best validation reward reached in update [92/200]\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.01725357584655285\n",
      "Critic Loss: 4.927411079406738\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.044424381107091904\n",
      "Critic Loss: 3.50166392326355\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.007783988956362009\n",
      "Critic Loss: 1.7711743116378784\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.0005968399345874786\n",
      "Critic Loss: 2.9991466999053955\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.024404922500252724\n",
      "Critic Loss: 4.1417670249938965\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.00349061144515872\n",
      "Critic Loss: 2.8562073707580566\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.0013102954253554344\n",
      "Critic Loss: 3.0049798488616943\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.006196651607751846\n",
      "Critic Loss: 2.3612799644470215\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.0033381949178874493\n",
      "Critic Loss: 3.3578855991363525\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.006556268315762281\n",
      "Critic Loss: 3.2483246326446533\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.005918772425502539\n",
      "Critic Loss: 5.395719528198242\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.010894621722400188\n",
      "Critic Loss: 3.7886722087860107\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.009588157758116722\n",
      "Critic Loss: 1.8396748304367065\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.015404436737298965\n",
      "Critic Loss: 3.5297253131866455\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.01030544564127922\n",
      "Critic Loss: 2.8915131092071533\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.018874790519475937\n",
      "Critic Loss: 4.469732761383057\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.010341555811464787\n",
      "Critic Loss: 2.197079658508301\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.012095358222723007\n",
      "Critic Loss: 2.3931517601013184\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.018267473205924034\n",
      "Critic Loss: 3.9593098163604736\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.004508634563535452\n",
      "Critic Loss: 4.494846820831299\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.028711140155792236\n",
      "Critic Loss: 4.318685531616211\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.014907900243997574\n",
      "Critic Loss: 2.7617080211639404\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.015137812122702599\n",
      "Critic Loss: 2.473970890045166\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.020405584946274757\n",
      "Critic Loss: 2.591371536254883\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.0008972007781267166\n",
      "Critic Loss: 3.414849281311035\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.017637265846133232\n",
      "Critic Loss: 3.897679328918457\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.0032039335928857327\n",
      "Critic Loss: 4.130363941192627\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.003397073596715927\n",
      "Critic Loss: 2.4857876300811768\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.009377123787999153\n",
      "Critic Loss: 2.796414613723755\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.04041023924946785\n",
      "Critic Loss: 2.99923038482666\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -0.0007682745344936848\n",
      "Critic Loss: 4.876216411590576\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -0.002266127150505781\n",
      "Critic Loss: 1.323256492614746\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -0.0002524205483496189\n",
      "Critic Loss: 4.108778953552246\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.015256000682711601\n",
      "Critic Loss: 4.056477069854736\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.042426567524671555\n",
      "Critic Loss: 1.6504793167114258\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -0.005428845528513193\n",
      "Critic Loss: 4.364145755767822\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.011389301158487797\n",
      "Critic Loss: 4.064189434051514\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.007374875247478485\n",
      "Critic Loss: 3.056375026702881\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.0037477738223969936\n",
      "Critic Loss: 3.2557432651519775\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.03045511804521084\n",
      "Critic Loss: 6.247409820556641\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.0048139882273972034\n",
      "Critic Loss: 5.691108703613281\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.012649254873394966\n",
      "Critic Loss: 2.658864974975586\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.015267296694219112\n",
      "Critic Loss: 2.038236141204834\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.00601003784686327\n",
      "Critic Loss: 2.20574688911438\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.02189202979207039\n",
      "Critic Loss: 3.3356668949127197\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -0.01823480986058712\n",
      "Critic Loss: 2.395906448364258\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.036265239119529724\n",
      "Critic Loss: 4.394979953765869\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -0.006591723300516605\n",
      "Critic Loss: 5.513345718383789\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.008480526506900787\n",
      "Critic Loss: 2.7043864727020264\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.0071035041473805904\n",
      "Critic Loss: 5.933068752288818\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.004849049728363752\n",
      "Critic Loss: 1.9930391311645508\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.01676522009074688\n",
      "Critic Loss: 3.7274527549743652\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.018684905022382736\n",
      "Critic Loss: 2.5945661067962646\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: -0.007656908594071865\n",
      "Critic Loss: 1.7228363752365112\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: -0.005535386968404055\n",
      "Critic Loss: 4.464718341827393\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: -0.005303140264004469\n",
      "Critic Loss: 4.841334342956543\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.02316150814294815\n",
      "Critic Loss: 3.6804890632629395\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.011043061502277851\n",
      "Critic Loss: 2.1734976768493652\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 0.015214081853628159\n",
      "Critic Loss: 3.776603937149048\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -0.009934158064424992\n",
      "Critic Loss: 2.2666783332824707\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: 0.0073471954092383385\n",
      "Critic Loss: 2.7569074630737305\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: 0.026539569720625877\n",
      "Critic Loss: 3.9057936668395996\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: 0.0012344191782176495\n",
      "Critic Loss: 3.6595041751861572\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 0.026237614452838898\n",
      "Critic Loss: 2.8425426483154297\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: 0.008877018466591835\n",
      "Critic Loss: 5.104680061340332\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 0.010911138728260994\n",
      "Critic Loss: 3.3532145023345947\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 0.00915789045393467\n",
      "Critic Loss: 1.9387483596801758\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: 0.01669200509786606\n",
      "Critic Loss: 2.455178737640381\n",
      "\n",
      "Update [161/200]\n",
      "Actor Loss: -0.0036152610555291176\n",
      "Critic Loss: 1.9640172719955444\n",
      "\n",
      "Update [162/200]\n",
      "Actor Loss: -0.0012645735405385494\n",
      "Critic Loss: 3.1929237842559814\n",
      "\n",
      "Update [163/200]\n",
      "Actor Loss: 0.00708814850077033\n",
      "Critic Loss: 4.076982498168945\n",
      "\n",
      "Update [164/200]\n",
      "Actor Loss: 0.019587766379117966\n",
      "Critic Loss: 2.5192246437072754\n",
      "\n",
      "Update [165/200]\n",
      "Actor Loss: 0.0009932923130691051\n",
      "Critic Loss: 4.05549955368042\n",
      "\n",
      "Update [166/200]\n",
      "Actor Loss: 0.0019266903400421143\n",
      "Critic Loss: 1.9783234596252441\n",
      "\n",
      "Update [167/200]\n",
      "Actor Loss: 0.006081567611545324\n",
      "Critic Loss: 2.7041702270507812\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0a63c4e54745678202843bff487567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>45.71429</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>39.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00078</td></tr><tr><td>Learning_rate/Critic</td><td>0.00011</td></tr><tr><td>Loss/Actor_loss</td><td>-0.0079</td></tr><tr><td>Loss/Critic_loss</td><td>2.70417</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.73057</td></tr><tr><td>Loss/KL_divergence</td><td>0.01585</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00275</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.00608</td></tr><tr><td>Metric/Explained_variance</td><td>0.65923</td></tr><tr><td>Reward/Mean_train_reward</td><td>-63.361</td></tr><tr><td>Reward/Mean_val_reward</td><td>-70.878</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-69.11223</td></tr><tr><td>global_step</td><td>167</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-sweep-70</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/jhmxypqc' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/jhmxypqc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_002547-jhmxypqc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e1sqf2su with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0013669635726713542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004933848267949176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03997901933869671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9055316744558706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00014926236462563936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0001065560773851522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_005244-e1sqf2su</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/e1sqf2su' target=\"_blank\">glamorous-sweep-71</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/e1sqf2su' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/e1sqf2su</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0013669635726713542, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004933848267949176, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03997901933869671, 'epochs': 10, 'exponential_factor': 0.9055316744558706, 'gamma': 0.9, 'hidden_sizes': [150, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.00014926236462563936, 'l2_factor': 0.0001065560773851522, 'lrelu': 0.01, 'minibatch_size': 32, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0013669635726713542, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004933848267949176, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03997901933869671, 'epochs': 10, 'exponential_factor': 0.9055316744558706, 'gamma': 0.9, 'l1_factor': 0.00014926236462563936, 'l2_factor': 0.0001065560773851522, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0013669635726713542, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004933848267949176, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03997901933869671, 'epochs': 10, 'exponential_factor': 0.9055316744558706, 'gamma': 0.9, 'l1_factor': 0.00014926236462563936, 'l2_factor': 0.0001065560773851522, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0013669635726713542, 'critic_lr': 0.0004933848267949176, 'decay_method': 'exponential', 'exponential_factor': 0.9055316744558706, 'value_loss_factor': 1, 'entropy': 0.03997901933869671, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00014926236462563936, 'l2_factor': 0.0001065560773851522, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [150, 150, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.652367353439331\n",
      "Critic Loss: 18.832128524780273\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.6205359101295471\n",
      "Critic Loss: 8.303854942321777\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.4183317720890045\n",
      "Critic Loss: 9.254179000854492\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.3905964195728302\n",
      "Critic Loss: 6.57390832901001\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.4078056514263153\n",
      "Critic Loss: 2.5179495811462402\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.21458512544631958\n",
      "Critic Loss: 13.321306228637695\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.35578399896621704\n",
      "Critic Loss: 6.268143177032471\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.23765026032924652\n",
      "Critic Loss: 6.433539390563965\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.331662654876709\n",
      "Critic Loss: 3.4678382873535156\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.21800844371318817\n",
      "Critic Loss: 9.105356216430664\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.13937710225582123\n",
      "Critic Loss: 5.98783016204834\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.1533581018447876\n",
      "Critic Loss: 4.659634113311768\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.17757980525493622\n",
      "Critic Loss: 2.867918014526367\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.22538429498672485\n",
      "Critic Loss: 3.620056629180908\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.12260543555021286\n",
      "Critic Loss: 5.264861583709717\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.14785735309123993\n",
      "Critic Loss: 6.27558708190918\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.14356620609760284\n",
      "Critic Loss: 7.1396098136901855\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.11540680378675461\n",
      "Critic Loss: 5.8742499351501465\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.10036724805831909\n",
      "Critic Loss: 10.944584846496582\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.15034201741218567\n",
      "Critic Loss: 2.6782238483428955\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.09500088542699814\n",
      "Critic Loss: 4.196000099182129\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.13842840492725372\n",
      "Critic Loss: 1.1514067649841309\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.17122378945350647\n",
      "Critic Loss: 1.4848662614822388\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.17588917911052704\n",
      "Critic Loss: 4.233125686645508\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.12845714390277863\n",
      "Critic Loss: 4.289368152618408\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.09735755622386932\n",
      "Critic Loss: 3.4374747276306152\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.10710811614990234\n",
      "Critic Loss: 7.497107028961182\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.08763893693685532\n",
      "Critic Loss: 6.277677536010742\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.10340023040771484\n",
      "Critic Loss: 4.122490882873535\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.09927409142255783\n",
      "Critic Loss: 2.9214282035827637\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.1276097446680069\n",
      "Critic Loss: 7.283865451812744\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.0955885574221611\n",
      "Critic Loss: 3.551100969314575\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.08874223381280899\n",
      "Critic Loss: 4.488762855529785\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.09990467876195908\n",
      "Critic Loss: 5.214040279388428\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.13900643587112427\n",
      "Critic Loss: 2.967219352722168\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.10419118404388428\n",
      "Critic Loss: 5.853568077087402\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.10005616396665573\n",
      "Critic Loss: 3.9321279525756836\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.08724799752235413\n",
      "Critic Loss: 5.572070121765137\n",
      "\n",
      "New best validation reward reached in update [38/200]\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.12364000082015991\n",
      "Critic Loss: 3.8136160373687744\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.12436406314373016\n",
      "Critic Loss: 3.4172914028167725\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.1400173455476761\n",
      "Critic Loss: 5.354928970336914\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.14557847380638123\n",
      "Critic Loss: 3.5925393104553223\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.15105614066123962\n",
      "Critic Loss: 1.8265771865844727\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.11068950593471527\n",
      "Critic Loss: 1.2549329996109009\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.1006324514746666\n",
      "Critic Loss: 1.9722864627838135\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.106167271733284\n",
      "Critic Loss: 2.0199644565582275\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.08800458908081055\n",
      "Critic Loss: 2.0688247680664062\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.09410067647695541\n",
      "Critic Loss: 6.040318012237549\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.12459372729063034\n",
      "Critic Loss: 8.181747436523438\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.08053518086671829\n",
      "Critic Loss: 2.755847930908203\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.12768211960792542\n",
      "Critic Loss: 2.331420421600342\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.10965612530708313\n",
      "Critic Loss: 6.127840042114258\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.11238420009613037\n",
      "Critic Loss: 2.6905357837677\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.11046268790960312\n",
      "Critic Loss: 2.9434967041015625\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.14167922735214233\n",
      "Critic Loss: 2.742553949356079\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.13539934158325195\n",
      "Critic Loss: 4.068612098693848\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.11586407572031021\n",
      "Critic Loss: 7.59016227722168\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.1216408759355545\n",
      "Critic Loss: 11.254837036132812\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.13384047150611877\n",
      "Critic Loss: 1.88924241065979\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.09181491285562515\n",
      "Critic Loss: 4.979836463928223\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.11764198541641235\n",
      "Critic Loss: 0.8564978837966919\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.13678869605064392\n",
      "Critic Loss: 6.277281761169434\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.137266606092453\n",
      "Critic Loss: 3.288814067840576\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.11386265605688095\n",
      "Critic Loss: 5.923908710479736\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.09279187023639679\n",
      "Critic Loss: 5.284326076507568\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.12482187896966934\n",
      "Critic Loss: 5.317261695861816\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.1224636510014534\n",
      "Critic Loss: 3.21742844581604\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.12270376086235046\n",
      "Critic Loss: 1.2735004425048828\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.08753296732902527\n",
      "Critic Loss: 4.255369663238525\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.12556320428848267\n",
      "Critic Loss: 2.10996150970459\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.09648729115724564\n",
      "Critic Loss: 2.531810998916626\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.09588975459337234\n",
      "Critic Loss: 3.861351728439331\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.09531103074550629\n",
      "Critic Loss: 4.455316543579102\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.12677276134490967\n",
      "Critic Loss: 5.4672017097473145\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.1217050701379776\n",
      "Critic Loss: 1.6333539485931396\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.09175145626068115\n",
      "Critic Loss: 8.554312705993652\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.12443821132183075\n",
      "Critic Loss: 3.0179433822631836\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.12959526479244232\n",
      "Critic Loss: 2.739821672439575\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.13052107393741608\n",
      "Critic Loss: 5.524805545806885\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.1082518994808197\n",
      "Critic Loss: 2.1459085941314697\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.10433627665042877\n",
      "Critic Loss: 10.643857955932617\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.10728143155574799\n",
      "Critic Loss: 2.3089771270751953\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.09457089006900787\n",
      "Critic Loss: 3.919837474822998\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.10979771614074707\n",
      "Critic Loss: 5.07481050491333\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.11216391623020172\n",
      "Critic Loss: 3.5420308113098145\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.09533576667308807\n",
      "Critic Loss: 4.56552791595459\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.09905574470758438\n",
      "Critic Loss: 2.53702974319458\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.126216322183609\n",
      "Critic Loss: 7.898272514343262\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.12344220280647278\n",
      "Critic Loss: 2.8561604022979736\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.1198163703083992\n",
      "Critic Loss: 3.219531536102295\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.10312458872795105\n",
      "Critic Loss: 2.000753164291382\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.1209537461400032\n",
      "Critic Loss: 3.8347837924957275\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.1231178417801857\n",
      "Critic Loss: 4.537912368774414\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.14771617949008942\n",
      "Critic Loss: 2.7189128398895264\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.12915091216564178\n",
      "Critic Loss: 3.811060905456543\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.10184779763221741\n",
      "Critic Loss: 2.798671007156372\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.10215166211128235\n",
      "Critic Loss: 3.150911808013916\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.10434485971927643\n",
      "Critic Loss: 3.2843799591064453\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.10377216339111328\n",
      "Critic Loss: 3.586530923843384\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.09362749755382538\n",
      "Critic Loss: 8.426255226135254\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.1133006364107132\n",
      "Critic Loss: 6.253190517425537\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.10765617340803146\n",
      "Critic Loss: 1.952364444732666\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.1339590847492218\n",
      "Critic Loss: 6.5574421882629395\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.12146486341953278\n",
      "Critic Loss: 4.194594383239746\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.12511329352855682\n",
      "Critic Loss: 2.2045466899871826\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.12429611384868622\n",
      "Critic Loss: 4.406970977783203\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.10262739658355713\n",
      "Critic Loss: 5.430522918701172\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78152fbc0387419daf832dddb4f05cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>71.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>69.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.06994</td></tr><tr><td>Loss/Critic_loss</td><td>5.43052</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.34777</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00863</td></tr><tr><td>Loss/Policy_loss</td><td>-0.01605</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.10263</td></tr><tr><td>Metric/Explained_variance</td><td>0.53312</td></tr><tr><td>Reward/Mean_train_reward</td><td>-42.45</td></tr><tr><td>Reward/Mean_val_reward</td><td>-41.1116</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-42.84385</td></tr><tr><td>global_step</td><td>107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-sweep-71</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/e1sqf2su' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/e1sqf2su</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_005244-e1sqf2su\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0f5p099f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0015898729814662598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0009282871046169554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.01804968291806467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8607210863126157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0006147232514912152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.00028731083369277317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_005843-0f5p099f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/0f5p099f' target=\"_blank\">lemon-sweep-72</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0f5p099f' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0f5p099f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.0015898729814662598, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009282871046169554, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.01804968291806467, 'epochs': 10, 'exponential_factor': 0.8607210863126157, 'gamma': 0.9, 'hidden_sizes': [250, 250, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0006147232514912152, 'l2_factor': 0.00028731083369277317, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0015898729814662598, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009282871046169554, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.01804968291806467, 'epochs': 10, 'exponential_factor': 0.8607210863126157, 'gamma': 0.9, 'l1_factor': 0.0006147232514912152, 'l2_factor': 0.00028731083369277317, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0015898729814662598, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0009282871046169554, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.01804968291806467, 'epochs': 10, 'exponential_factor': 0.8607210863126157, 'gamma': 0.9, 'l1_factor': 0.0006147232514912152, 'l2_factor': 0.00028731083369277317, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0015898729814662598, 'critic_lr': 0.0009282871046169554, 'decay_method': 'exponential', 'exponential_factor': 0.8607210863126157, 'value_loss_factor': 1, 'entropy': 0.01804968291806467, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0006147232514912152, 'l2_factor': 0.00028731083369277317, 'T': 768, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [250, 250, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 5.602140426635742\n",
      "Critic Loss: 22.9655704498291\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.7284359335899353\n",
      "Critic Loss: 3.818697452545166\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.28055763244628906\n",
      "Critic Loss: 7.465767860412598\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.26709499955177307\n",
      "Critic Loss: 10.184759140014648\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.10354089736938477\n",
      "Critic Loss: 12.022092819213867\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.146697536110878\n",
      "Critic Loss: 12.327285766601562\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.07461873441934586\n",
      "Critic Loss: 9.618566513061523\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.09812894463539124\n",
      "Critic Loss: 17.658212661743164\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.03646554797887802\n",
      "Critic Loss: 13.02993392944336\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.03522881865501404\n",
      "Critic Loss: 11.038823127746582\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.06124411150813103\n",
      "Critic Loss: 8.835549354553223\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.022868677973747253\n",
      "Critic Loss: 10.047430038452148\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.06620603054761887\n",
      "Critic Loss: 9.178266525268555\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.022300325334072113\n",
      "Critic Loss: 10.276466369628906\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.03194465860724449\n",
      "Critic Loss: 11.509574890136719\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.11616721004247665\n",
      "Critic Loss: 13.05384635925293\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.04202711582183838\n",
      "Critic Loss: 12.309310913085938\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.046589963138103485\n",
      "Critic Loss: 10.929226875305176\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.05668613314628601\n",
      "Critic Loss: 13.537906646728516\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.05644244700670242\n",
      "Critic Loss: 16.848499298095703\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.06421760469675064\n",
      "Critic Loss: 13.245508193969727\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.046144939959049225\n",
      "Critic Loss: 15.495674133300781\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.02323632501065731\n",
      "Critic Loss: 12.108661651611328\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.05256893113255501\n",
      "Critic Loss: 8.187387466430664\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.02994360215961933\n",
      "Critic Loss: 13.812238693237305\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.03213460370898247\n",
      "Critic Loss: 8.43563461303711\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.07274709641933441\n",
      "Critic Loss: 9.765119552612305\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.04432638734579086\n",
      "Critic Loss: 11.53012752532959\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.03018196113407612\n",
      "Critic Loss: 10.689056396484375\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.02846497669816017\n",
      "Critic Loss: 8.20836067199707\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.05501999706029892\n",
      "Critic Loss: 6.831598281860352\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.05091872438788414\n",
      "Critic Loss: 9.303582191467285\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.029371943324804306\n",
      "Critic Loss: 11.102090835571289\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.036591798067092896\n",
      "Critic Loss: 10.068926811218262\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.042262520641088486\n",
      "Critic Loss: 13.568942070007324\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.012108727358281612\n",
      "Critic Loss: 11.656786918640137\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.05022328719496727\n",
      "Critic Loss: 6.441765785217285\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.017986129969358444\n",
      "Critic Loss: 9.837875366210938\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.03767906129360199\n",
      "Critic Loss: 7.600312232971191\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.05752498656511307\n",
      "Critic Loss: 12.301905632019043\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.02728901617228985\n",
      "Critic Loss: 7.351193904876709\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.025238528847694397\n",
      "Critic Loss: 6.025907516479492\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.014041109010577202\n",
      "Critic Loss: 13.293122291564941\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.03442956134676933\n",
      "Critic Loss: 7.643932819366455\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.03626089170575142\n",
      "Critic Loss: 8.38730525970459\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.03304561972618103\n",
      "Critic Loss: 14.150557518005371\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.01294370274990797\n",
      "Critic Loss: 10.01689624786377\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.03962450101971626\n",
      "Critic Loss: 10.60460376739502\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.03467763215303421\n",
      "Critic Loss: 5.912107467651367\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.027378296479582787\n",
      "Critic Loss: 10.20665454864502\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.06437940895557404\n",
      "Critic Loss: 7.415841579437256\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.07806534320116043\n",
      "Critic Loss: 11.003999710083008\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.023411395028233528\n",
      "Critic Loss: 7.53953742980957\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.08899214118719101\n",
      "Critic Loss: 11.22324275970459\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.03258217126131058\n",
      "Critic Loss: 9.560011863708496\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.029766611754894257\n",
      "Critic Loss: 9.9849214553833\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.058138709515333176\n",
      "Critic Loss: 7.790889739990234\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.028081385418772697\n",
      "Critic Loss: 6.4905219078063965\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.013009019196033478\n",
      "Critic Loss: 8.123294830322266\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.06976006180047989\n",
      "Critic Loss: 8.06338882446289\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.04550807178020477\n",
      "Critic Loss: 8.434664726257324\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.0011321479687467217\n",
      "Critic Loss: 8.250951766967773\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.07766593247652054\n",
      "Critic Loss: 10.630072593688965\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.10686340928077698\n",
      "Critic Loss: 8.774585723876953\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.02969192899763584\n",
      "Critic Loss: 8.035431861877441\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.03955146670341492\n",
      "Critic Loss: 10.759978294372559\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.05751170217990875\n",
      "Critic Loss: 8.756433486938477\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.03898220136761665\n",
      "Critic Loss: 8.843811988830566\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.04261007159948349\n",
      "Critic Loss: 11.17548942565918\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.041503679007291794\n",
      "Critic Loss: 10.339425086975098\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.04253039509057999\n",
      "Critic Loss: 5.7322540283203125\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.04995012655854225\n",
      "Critic Loss: 6.30208683013916\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.0219130776822567\n",
      "Critic Loss: 5.096307277679443\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.03546144440770149\n",
      "Critic Loss: 6.453151702880859\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.04356514289975166\n",
      "Critic Loss: 4.3773112297058105\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.03186960518360138\n",
      "Critic Loss: 7.286074638366699\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.06723695993423462\n",
      "Critic Loss: 8.30599594116211\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b777c4062246e4b92bd6ab02d52408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>67.63636</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>71.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.0192</td></tr><tr><td>Loss/Critic_loss</td><td>8.306</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.06953</td></tr><tr><td>Loss/KL_divergence</td><td>0.00101</td></tr><tr><td>Loss/Policy_loss</td><td>0.0385</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.06724</td></tr><tr><td>Metric/Explained_variance</td><td>0.20135</td></tr><tr><td>Reward/Mean_train_reward</td><td>-80.62063</td></tr><tr><td>Reward/Mean_val_reward</td><td>-81.0536</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-81.36821</td></tr><tr><td>global_step</td><td>77</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-72</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0f5p099f' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0f5p099f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_005843-0f5p099f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ztje6vd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.007808937764403372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004725791374954232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03229711593663933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8502460911098485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.826547052415299e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0009231804665215436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_010609-7ztje6vd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/7ztje6vd' target=\"_blank\">hearty-sweep-73</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/7ztje6vd' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/7ztje6vd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.007808937764403372, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004725791374954232, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03229711593663933, 'epochs': 10, 'exponential_factor': 0.8502460911098485, 'gamma': 0.99, 'hidden_sizes': [350, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.826547052415299e-06, 'l2_factor': 0.0009231804665215436, 'lrelu': 0.1, 'minibatch_size': 64, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.007808937764403372, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004725791374954232, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03229711593663933, 'epochs': 10, 'exponential_factor': 0.8502460911098485, 'gamma': 0.99, 'l1_factor': 1.826547052415299e-06, 'l2_factor': 0.0009231804665215436, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.007808937764403372, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004725791374954232, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03229711593663933, 'epochs': 10, 'exponential_factor': 0.8502460911098485, 'gamma': 0.99, 'l1_factor': 1.826547052415299e-06, 'l2_factor': 0.0009231804665215436, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.007808937764403372, 'critic_lr': 0.004725791374954232, 'decay_method': 'exponential', 'exponential_factor': 0.8502460911098485, 'value_loss_factor': 1, 'entropy': 0.03229711593663933, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.826547052415299e-06, 'l2_factor': 0.0009231804665215436, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [350, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.29633575677871704\n",
      "Critic Loss: 17.993877410888672\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.24107903242111206\n",
      "Critic Loss: 17.87279510498047\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.3565615713596344\n",
      "Critic Loss: 16.4776554107666\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.008067738264799118\n",
      "Critic Loss: 20.12909698486328\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.10958753526210785\n",
      "Critic Loss: 15.787398338317871\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.015807881951332092\n",
      "Critic Loss: 16.36896514892578\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.018298842012882233\n",
      "Critic Loss: 10.905385971069336\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.028755836188793182\n",
      "Critic Loss: 10.27900218963623\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.058156393468379974\n",
      "Critic Loss: 7.437998294830322\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.05008658021688461\n",
      "Critic Loss: 10.809819221496582\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.008385581895709038\n",
      "Critic Loss: 11.082172393798828\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.011566970497369766\n",
      "Critic Loss: 14.175878524780273\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.06572485715150833\n",
      "Critic Loss: 5.945161819458008\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.03195274621248245\n",
      "Critic Loss: 6.333400726318359\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.033801689743995667\n",
      "Critic Loss: 8.365630149841309\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.07816726714372635\n",
      "Critic Loss: 8.124785423278809\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.058615438640117645\n",
      "Critic Loss: 3.589953899383545\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.046157579869031906\n",
      "Critic Loss: 4.428822994232178\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.08675529062747955\n",
      "Critic Loss: 3.361178398132324\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.10795662552118301\n",
      "Critic Loss: 5.9259443283081055\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.0859317034482956\n",
      "Critic Loss: 4.211182594299316\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.042122989892959595\n",
      "Critic Loss: 7.634585857391357\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.06394127011299133\n",
      "Critic Loss: 3.3169288635253906\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.09703190624713898\n",
      "Critic Loss: 9.944573402404785\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.030997131019830704\n",
      "Critic Loss: 6.509616851806641\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.04440280422568321\n",
      "Critic Loss: 2.6821818351745605\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.014331534504890442\n",
      "Critic Loss: 4.148449897766113\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.026198431849479675\n",
      "Critic Loss: 5.301898956298828\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.040325649082660675\n",
      "Critic Loss: 4.9453911781311035\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.03969203680753708\n",
      "Critic Loss: 3.4629316329956055\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.0954037755727768\n",
      "Critic Loss: 6.323462009429932\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.05130764842033386\n",
      "Critic Loss: 2.8328773975372314\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.020565742626786232\n",
      "Critic Loss: 6.350792407989502\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.037422917783260345\n",
      "Critic Loss: 4.053774833679199\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.043609730899333954\n",
      "Critic Loss: 3.5918383598327637\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.03126678615808487\n",
      "Critic Loss: 5.521080493927002\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.037135232239961624\n",
      "Critic Loss: 3.8287830352783203\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.04551991447806358\n",
      "Critic Loss: 7.6077094078063965\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.032303981482982635\n",
      "Critic Loss: 5.045570373535156\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.05946744978427887\n",
      "Critic Loss: 5.151271820068359\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.025719666853547096\n",
      "Critic Loss: 4.68846321105957\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.030920343473553658\n",
      "Critic Loss: 2.8568663597106934\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.04041928052902222\n",
      "Critic Loss: 4.531378269195557\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.03527414798736572\n",
      "Critic Loss: 4.438912391662598\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.033593371510505676\n",
      "Critic Loss: 4.092217445373535\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.03893585130572319\n",
      "Critic Loss: 4.856939792633057\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.03082164190709591\n",
      "Critic Loss: 5.48501443862915\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.022632723674178123\n",
      "Critic Loss: 5.032380104064941\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.03220619261264801\n",
      "Critic Loss: 8.3295259475708\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.02887703664600849\n",
      "Critic Loss: 7.736485004425049\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.02649984508752823\n",
      "Critic Loss: 4.374174118041992\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.026342805474996567\n",
      "Critic Loss: 2.8604745864868164\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.025826413184404373\n",
      "Critic Loss: 6.29605770111084\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.026178400963544846\n",
      "Critic Loss: 3.5716919898986816\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.02386760152876377\n",
      "Critic Loss: 4.812786102294922\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.024851791560649872\n",
      "Critic Loss: 2.8169846534729004\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.02533642202615738\n",
      "Critic Loss: 4.802393913269043\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.025533482432365417\n",
      "Critic Loss: 3.0361039638519287\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.025565585121512413\n",
      "Critic Loss: 4.104089260101318\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.026653092354536057\n",
      "Critic Loss: 5.429213523864746\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.026739289984107018\n",
      "Critic Loss: 4.791024684906006\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.023872744292020798\n",
      "Critic Loss: 4.270120620727539\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.0249826367944479\n",
      "Critic Loss: 3.146512031555176\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.02490861900150776\n",
      "Critic Loss: 3.8213071823120117\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.025403380393981934\n",
      "Critic Loss: 10.174834251403809\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.02427922748029232\n",
      "Critic Loss: 4.649855613708496\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.024838663637638092\n",
      "Critic Loss: 4.671885967254639\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.024797888472676277\n",
      "Critic Loss: 4.21772575378418\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.021823063492774963\n",
      "Critic Loss: 4.06803035736084\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.024086765944957733\n",
      "Critic Loss: 4.574458599090576\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.025093236938118935\n",
      "Critic Loss: 5.7937846183776855\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.021599793806672096\n",
      "Critic Loss: 4.627665042877197\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.02410789392888546\n",
      "Critic Loss: 2.6927385330200195\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.023479295894503593\n",
      "Critic Loss: 6.646727085113525\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.021217528730630875\n",
      "Critic Loss: 4.343315124511719\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.027339236810803413\n",
      "Critic Loss: 5.087872505187988\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.024977052584290504\n",
      "Critic Loss: 5.1897969245910645\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.025488248094916344\n",
      "Critic Loss: 5.176440238952637\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.025310276076197624\n",
      "Critic Loss: 3.1677327156066895\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.02445152960717678\n",
      "Critic Loss: 3.9521052837371826\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.02310655452311039\n",
      "Critic Loss: 4.498313903808594\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.022551873698830605\n",
      "Critic Loss: 4.995256423950195\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.02347872406244278\n",
      "Critic Loss: 3.6978118419647217\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.02350962907075882\n",
      "Critic Loss: 5.571798324584961\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.023996762931346893\n",
      "Critic Loss: 4.849906921386719\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.022671760991215706\n",
      "Critic Loss: 4.410073280334473\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.023954378440976143\n",
      "Critic Loss: 5.839230537414551\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -0.02452513389289379\n",
      "Critic Loss: 11.615482330322266\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.024418910965323448\n",
      "Critic Loss: 11.062799453735352\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c488275fdca4ece970f1082cca16d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>63.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>77.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.04641</td></tr><tr><td>Loss/Critic_loss</td><td>11.0628</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.43643</td></tr><tr><td>Loss/KL_divergence</td><td>0.0</td></tr><tr><td>Loss/Policy_loss</td><td>-1e-05</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.02442</td></tr><tr><td>Metric/Explained_variance</td><td>0.17028</td></tr><tr><td>Reward/Mean_train_reward</td><td>-68.0375</td></tr><tr><td>Reward/Mean_val_reward</td><td>-50.688</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-51.90782</td></tr><tr><td>global_step</td><td>89</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-73</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/7ztje6vd' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/7ztje6vd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_010609-7ztje6vd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 19sck1eo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.005737003962212396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00022277023218567415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.022346115711028677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9432818055899356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 8.914319128762696e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.6850570155198736e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_011048-19sck1eo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/19sck1eo' target=\"_blank\">devout-sweep-74</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/19sck1eo' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/19sck1eo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.005737003962212396, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00022277023218567415, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022346115711028677, 'epochs': 10, 'exponential_factor': 0.9432818055899356, 'gamma': 0.9, 'hidden_sizes': [150, 250, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 8.914319128762696e-05, 'l2_factor': 2.6850570155198736e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.005737003962212396, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00022277023218567415, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022346115711028677, 'epochs': 10, 'exponential_factor': 0.9432818055899356, 'gamma': 0.9, 'l1_factor': 8.914319128762696e-05, 'l2_factor': 2.6850570155198736e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 350, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.005737003962212396, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00022277023218567415, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.022346115711028677, 'epochs': 10, 'exponential_factor': 0.9432818055899356, 'gamma': 0.9, 'l1_factor': 8.914319128762696e-05, 'l2_factor': 2.6850570155198736e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.005737003962212396, 'critic_lr': 0.00022277023218567415, 'decay_method': 'exponential', 'exponential_factor': 0.9432818055899356, 'value_loss_factor': 1, 'entropy': 0.022346115711028677, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 8.914319128762696e-05, 'l2_factor': 2.6850570155198736e-06, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [150, 250, 350, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.6867607235908508\n",
      "Critic Loss: 16.581470489501953\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.5368951559066772\n",
      "Critic Loss: 20.8629207611084\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.44495248794555664\n",
      "Critic Loss: 22.907546997070312\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.5798938870429993\n",
      "Critic Loss: 12.227594375610352\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.39418062567710876\n",
      "Critic Loss: 16.979381561279297\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.3459450900554657\n",
      "Critic Loss: 7.583843231201172\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.328565388917923\n",
      "Critic Loss: 7.7614874839782715\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.25439345836639404\n",
      "Critic Loss: 8.505287170410156\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.32839706540107727\n",
      "Critic Loss: 7.757349967956543\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.24494490027427673\n",
      "Critic Loss: 7.015719413757324\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.2837602198123932\n",
      "Critic Loss: 7.0373640060424805\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.3287673592567444\n",
      "Critic Loss: 9.519035339355469\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.2683982253074646\n",
      "Critic Loss: 14.340328216552734\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.2505682110786438\n",
      "Critic Loss: 7.525782585144043\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.270680695772171\n",
      "Critic Loss: 5.76348352432251\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.22424501180648804\n",
      "Critic Loss: 6.9851765632629395\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.32131990790367126\n",
      "Critic Loss: 4.800097465515137\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.2935698926448822\n",
      "Critic Loss: 8.624506950378418\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.2861657440662384\n",
      "Critic Loss: 7.083824157714844\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.2200135439634323\n",
      "Critic Loss: 8.75509262084961\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.2044917643070221\n",
      "Critic Loss: 9.245118141174316\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.1977321356534958\n",
      "Critic Loss: 9.522370338439941\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.30262166261672974\n",
      "Critic Loss: 7.774689197540283\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.1842889040708542\n",
      "Critic Loss: 7.975517272949219\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.20015302300453186\n",
      "Critic Loss: 8.656188011169434\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.22054430842399597\n",
      "Critic Loss: 13.422886848449707\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.18678593635559082\n",
      "Critic Loss: 7.202473163604736\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.20489296317100525\n",
      "Critic Loss: 5.8288726806640625\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.19511134922504425\n",
      "Critic Loss: 7.358455657958984\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.21221387386322021\n",
      "Critic Loss: 7.57786226272583\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.22923307120800018\n",
      "Critic Loss: 4.8565192222595215\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.21367640793323517\n",
      "Critic Loss: 3.807185411453247\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.19004924595355988\n",
      "Critic Loss: 5.434354782104492\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.2780171036720276\n",
      "Critic Loss: 6.521858215332031\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.1413615643978119\n",
      "Critic Loss: 6.729689121246338\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.19130723178386688\n",
      "Critic Loss: 7.086952209472656\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.24026429653167725\n",
      "Critic Loss: 6.760878086090088\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.14997683465480804\n",
      "Critic Loss: 4.518672466278076\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.16893376410007477\n",
      "Critic Loss: 4.685295104980469\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.1336415410041809\n",
      "Critic Loss: 7.507537841796875\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.15227824449539185\n",
      "Critic Loss: 5.010701656341553\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.29039937257766724\n",
      "Critic Loss: 4.431394577026367\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.15412192046642303\n",
      "Critic Loss: 5.702506065368652\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.1655133068561554\n",
      "Critic Loss: 5.8004536628723145\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.16357333958148956\n",
      "Critic Loss: 5.707253456115723\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.20046351850032806\n",
      "Critic Loss: 5.856661796569824\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.15314587950706482\n",
      "Critic Loss: 5.830813407897949\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.25296351313591003\n",
      "Critic Loss: 6.046011924743652\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.17619305849075317\n",
      "Critic Loss: 5.385157108306885\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.25315767526626587\n",
      "Critic Loss: 5.459071159362793\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.1392238438129425\n",
      "Critic Loss: 5.6497626304626465\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.16519024968147278\n",
      "Critic Loss: 4.685151100158691\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.1552606076002121\n",
      "Critic Loss: 4.669076442718506\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.13393139839172363\n",
      "Critic Loss: 4.243380069732666\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.15653611719608307\n",
      "Critic Loss: 6.09819221496582\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.13625074923038483\n",
      "Critic Loss: 6.43470573425293\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.1757875382900238\n",
      "Critic Loss: 4.244351387023926\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.1551419049501419\n",
      "Critic Loss: 5.376472473144531\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.1804310530424118\n",
      "Critic Loss: 6.940123558044434\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.14344334602355957\n",
      "Critic Loss: 3.9956164360046387\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.13761433959007263\n",
      "Critic Loss: 7.196052074432373\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.18442435562610626\n",
      "Critic Loss: 6.008902072906494\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.17253635823726654\n",
      "Critic Loss: 4.438581943511963\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.26633381843566895\n",
      "Critic Loss: 4.411149978637695\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.24023017287254333\n",
      "Critic Loss: 4.772678375244141\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.18427513539791107\n",
      "Critic Loss: 6.305532932281494\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.14754995703697205\n",
      "Critic Loss: 4.709353923797607\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.22006264328956604\n",
      "Critic Loss: 7.526596546173096\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.13049709796905518\n",
      "Critic Loss: 5.937267780303955\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.3256774842739105\n",
      "Critic Loss: 3.534682035446167\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.14509062469005585\n",
      "Critic Loss: 6.247345447540283\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.18512475490570068\n",
      "Critic Loss: 6.021755695343018\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.2073749452829361\n",
      "Critic Loss: 4.586215019226074\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.13097213208675385\n",
      "Critic Loss: 5.064661026000977\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.14544697105884552\n",
      "Critic Loss: 5.684236526489258\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.20370465517044067\n",
      "Critic Loss: 5.76404333114624\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.1943378895521164\n",
      "Critic Loss: 5.606084823608398\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.28565073013305664\n",
      "Critic Loss: 5.412984371185303\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.20068924129009247\n",
      "Critic Loss: 5.457810401916504\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.18185560405254364\n",
      "Critic Loss: 4.610363483428955\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.2424192577600479\n",
      "Critic Loss: 7.808899879455566\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.12536029517650604\n",
      "Critic Loss: 4.770993709564209\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.12725844979286194\n",
      "Critic Loss: 4.492397785186768\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.20641101896762848\n",
      "Critic Loss: 3.1756792068481445\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.1786847710609436\n",
      "Critic Loss: 4.757076740264893\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.16314224898815155\n",
      "Critic Loss: 6.050365447998047\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.1312127560377121\n",
      "Critic Loss: 5.043771743774414\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.1252809762954712\n",
      "Critic Loss: 4.33414363861084\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.139915332198143\n",
      "Critic Loss: 5.182183265686035\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.1404251605272293\n",
      "Critic Loss: 5.917438983917236\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.12613563239574432\n",
      "Critic Loss: 6.251669883728027\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.19026175141334534\n",
      "Critic Loss: 7.137959957122803\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.13110440969467163\n",
      "Critic Loss: 5.134500026702881\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.10987451672554016\n",
      "Critic Loss: 4.883096218109131\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.14212973415851593\n",
      "Critic Loss: 4.936132907867432\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.18772147595882416\n",
      "Critic Loss: 4.692997455596924\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.1427501142024994\n",
      "Critic Loss: 4.981916427612305\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.21422472596168518\n",
      "Critic Loss: 5.130185604095459\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.1465601623058319\n",
      "Critic Loss: 4.9781270027160645\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.1804458051919937\n",
      "Critic Loss: 6.894049644470215\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.20006708800792694\n",
      "Critic Loss: 5.035598278045654\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.15889650583267212\n",
      "Critic Loss: 6.402082443237305\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.15203817188739777\n",
      "Critic Loss: 4.9422149658203125\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.13240568339824677\n",
      "Critic Loss: 8.402576446533203\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.1793585866689682\n",
      "Critic Loss: 5.999685287475586\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.20223946869373322\n",
      "Critic Loss: 5.232303619384766\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.14531461894512177\n",
      "Critic Loss: 6.241691589355469\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.16245009005069733\n",
      "Critic Loss: 6.924510955810547\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.13756810128688812\n",
      "Critic Loss: 4.782399654388428\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.1536177098751068\n",
      "Critic Loss: 4.844531059265137\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.1479126214981079\n",
      "Critic Loss: 5.6372880935668945\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.1910925656557083\n",
      "Critic Loss: 6.275489807128906\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.19849297404289246\n",
      "Critic Loss: 5.7581329345703125\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.17839016020298004\n",
      "Critic Loss: 4.852453231811523\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.16757091879844666\n",
      "Critic Loss: 6.877772331237793\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.14016063511371613\n",
      "Critic Loss: 5.660764217376709\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.125641867518425\n",
      "Critic Loss: 5.520383358001709\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.14741045236587524\n",
      "Critic Loss: 4.008510589599609\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.23815853893756866\n",
      "Critic Loss: 3.913477897644043\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.14199276268482208\n",
      "Critic Loss: 5.90696907043457\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.1532839685678482\n",
      "Critic Loss: 5.535030841827393\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.16360008716583252\n",
      "Critic Loss: 5.896364212036133\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.31965771317481995\n",
      "Critic Loss: 7.052560329437256\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.1601269245147705\n",
      "Critic Loss: 4.1315507888793945\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.15005463361740112\n",
      "Critic Loss: 4.166606426239014\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.15139281749725342\n",
      "Critic Loss: 3.827749013900757\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.19653666019439697\n",
      "Critic Loss: 6.563855171203613\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.15400941669940948\n",
      "Critic Loss: 4.781622409820557\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.16030193865299225\n",
      "Critic Loss: 4.833705902099609\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.12518996000289917\n",
      "Critic Loss: 5.1438751220703125\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.13781999051570892\n",
      "Critic Loss: 3.9059698581695557\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.16783152520656586\n",
      "Critic Loss: 3.7914159297943115\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.21034832298755646\n",
      "Critic Loss: 5.847414970397949\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.20527780055999756\n",
      "Critic Loss: 6.20676326751709\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44299a36ac7486b8e8849ebc436b8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>61.66667</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>58.2</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.03925</td></tr><tr><td>Loss/Critic_loss</td><td>6.20676</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.0645</td></tr><tr><td>Loss/KL_divergence</td><td>0.03507</td></tr><tr><td>Loss/Policy_loss</td><td>0.06303</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.20528</td></tr><tr><td>Metric/Explained_variance</td><td>0.53784</td></tr><tr><td>Reward/Mean_train_reward</td><td>-45.67267</td></tr><tr><td>Reward/Mean_val_reward</td><td>-46.5868</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-47.95021</td></tr><tr><td>global_step</td><td>134</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-74</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/19sck1eo' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/19sck1eo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_011048-19sck1eo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xy65lks2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00015221838222414085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.003696215347491537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04188146959753264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.903731918460126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0008005852231136583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.222725348677951e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_011809-xy65lks2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/xy65lks2' target=\"_blank\">swept-sweep-75</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/xy65lks2' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/xy65lks2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.00015221838222414085, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003696215347491537, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04188146959753264, 'epochs': 10, 'exponential_factor': 0.903731918460126, 'gamma': 0.9, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.0008005852231136583, 'l2_factor': 7.222725348677951e-05, 'lrelu': 0.01, 'minibatch_size': 32, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.00015221838222414085, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003696215347491537, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04188146959753264, 'epochs': 10, 'exponential_factor': 0.903731918460126, 'gamma': 0.9, 'l1_factor': 0.0008005852231136583, 'l2_factor': 7.222725348677951e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.00015221838222414085, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.003696215347491537, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04188146959753264, 'epochs': 10, 'exponential_factor': 0.903731918460126, 'gamma': 0.9, 'l1_factor': 0.0008005852231136583, 'l2_factor': 7.222725348677951e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00015221838222414085, 'critic_lr': 0.003696215347491537, 'decay_method': 'exponential', 'exponential_factor': 0.903731918460126, 'value_loss_factor': 1, 'entropy': 0.04188146959753264, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0008005852231136583, 'l2_factor': 7.222725348677951e-05, 'T': 512, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [350, 350, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 8.449981689453125\n",
      "Critic Loss: 29.680185317993164\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 6.076531410217285\n",
      "Critic Loss: 20.57240104675293\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 4.6848530769348145\n",
      "Critic Loss: 14.273284912109375\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 3.795043706893921\n",
      "Critic Loss: 8.652260780334473\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 3.1964995861053467\n",
      "Critic Loss: 5.941673278808594\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 2.8978869915008545\n",
      "Critic Loss: 2.8082802295684814\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 2.5618045330047607\n",
      "Critic Loss: 1.818028211593628\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 2.469916820526123\n",
      "Critic Loss: 4.875412940979004\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 2.2750601768493652\n",
      "Critic Loss: 4.00186014175415\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 2.184922933578491\n",
      "Critic Loss: 0.5219766497612\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 2.0569815635681152\n",
      "Critic Loss: 5.553886413574219\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.9728944301605225\n",
      "Critic Loss: 2.367799997329712\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.9207218885421753\n",
      "Critic Loss: 7.2571892738342285\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.8417404890060425\n",
      "Critic Loss: 6.68112850189209\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.7914164066314697\n",
      "Critic Loss: 6.080782413482666\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.762153148651123\n",
      "Critic Loss: 1.2638335227966309\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 1.7307090759277344\n",
      "Critic Loss: 0.43746963143348694\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.745498538017273\n",
      "Critic Loss: 2.120987892150879\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 1.6856681108474731\n",
      "Critic Loss: 4.663036823272705\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 1.6325340270996094\n",
      "Critic Loss: 2.7812182903289795\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 1.644526720046997\n",
      "Critic Loss: 5.711478233337402\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 1.6196315288543701\n",
      "Critic Loss: 7.011152267456055\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 1.590201735496521\n",
      "Critic Loss: 4.099340438842773\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 1.588181495666504\n",
      "Critic Loss: 6.25975227355957\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 1.656866192817688\n",
      "Critic Loss: 1.0187221765518188\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 1.5998343229293823\n",
      "Critic Loss: 0.2702687084674835\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 1.5532876253128052\n",
      "Critic Loss: 6.600515365600586\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 1.6550827026367188\n",
      "Critic Loss: 0.5049936175346375\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 1.5566831827163696\n",
      "Critic Loss: 1.6212842464447021\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 1.5547237396240234\n",
      "Critic Loss: 2.3619842529296875\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 1.534469485282898\n",
      "Critic Loss: 2.4759280681610107\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.5596107244491577\n",
      "Critic Loss: 5.620960235595703\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 1.5236446857452393\n",
      "Critic Loss: 4.516731262207031\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 1.5841567516326904\n",
      "Critic Loss: 4.526034832000732\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 1.535025954246521\n",
      "Critic Loss: 2.2185046672821045\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 1.5912621021270752\n",
      "Critic Loss: 8.270671844482422\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 1.5176615715026855\n",
      "Critic Loss: 0.6098949909210205\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 1.5382744073867798\n",
      "Critic Loss: 1.8075627088546753\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 1.5535378456115723\n",
      "Critic Loss: 2.9505467414855957\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 1.5262824296951294\n",
      "Critic Loss: 0.8482661843299866\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 1.5827704668045044\n",
      "Critic Loss: 1.1667011976242065\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 1.515325903892517\n",
      "Critic Loss: 6.9933319091796875\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 1.545642375946045\n",
      "Critic Loss: 1.0461835861206055\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 1.5029716491699219\n",
      "Critic Loss: 7.954002380371094\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 1.5093047618865967\n",
      "Critic Loss: 5.542758941650391\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 1.5433367490768433\n",
      "Critic Loss: 3.1413943767547607\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 1.5150020122528076\n",
      "Critic Loss: 4.562304973602295\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 1.5132906436920166\n",
      "Critic Loss: 8.456059455871582\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.502617597579956\n",
      "Critic Loss: 8.125910758972168\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 1.5114610195159912\n",
      "Critic Loss: 1.9992557764053345\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 1.548988699913025\n",
      "Critic Loss: 8.488272666931152\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 1.5511990785598755\n",
      "Critic Loss: 1.8343572616577148\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 1.5137288570404053\n",
      "Critic Loss: 1.1735730171203613\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 1.5201404094696045\n",
      "Critic Loss: 1.8994190692901611\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 1.5468727350234985\n",
      "Critic Loss: 4.645742416381836\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 1.5566449165344238\n",
      "Critic Loss: 1.008014440536499\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 1.507836937904358\n",
      "Critic Loss: 7.663994789123535\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 1.4967471361160278\n",
      "Critic Loss: 4.188036918640137\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 1.544053316116333\n",
      "Critic Loss: 4.842836380004883\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 1.5160400867462158\n",
      "Critic Loss: 1.8680986166000366\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d893480b5e4da78b681beec4705be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>99.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>137.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.09162</td></tr><tr><td>Loss/Critic_loss</td><td>1.8681</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.64893</td></tr><tr><td>Loss/KL_divergence</td><td>0.00019</td></tr><tr><td>Loss/Policy_loss</td><td>-0.02256</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>1.51604</td></tr><tr><td>Metric/Explained_variance</td><td>0.05571</td></tr><tr><td>Reward/Mean_train_reward</td><td>-68.48867</td></tr><tr><td>Reward/Mean_val_reward</td><td>-60.5155</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-62.62831</td></tr><tr><td>global_step</td><td>60</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-75</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/xy65lks2' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/xy65lks2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_011809-xy65lks2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cmu6tnwn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00015893232929343475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004771544674128819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.029901548193467596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9394569340757029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 4.682310327648073e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 8.326398290580943e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_012724-cmu6tnwn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/cmu6tnwn' target=\"_blank\">twilight-sweep-76</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/cmu6tnwn' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/cmu6tnwn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.00015893232929343475, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004771544674128819, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029901548193467596, 'epochs': 10, 'exponential_factor': 0.9394569340757029, 'gamma': 0.9, 'hidden_sizes': [350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 4.682310327648073e-05, 'l2_factor': 8.326398290580943e-05, 'lrelu': 0.001, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00015893232929343475, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004771544674128819, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029901548193467596, 'epochs': 10, 'exponential_factor': 0.9394569340757029, 'gamma': 0.9, 'l1_factor': 4.682310327648073e-05, 'l2_factor': 8.326398290580943e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.001, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00015893232929343475, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004771544674128819, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029901548193467596, 'epochs': 10, 'exponential_factor': 0.9394569340757029, 'gamma': 0.9, 'l1_factor': 4.682310327648073e-05, 'l2_factor': 8.326398290580943e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00015893232929343475, 'critic_lr': 0.004771544674128819, 'decay_method': 'exponential', 'exponential_factor': 0.9394569340757029, 'value_loss_factor': 1, 'entropy': 0.029901548193467596, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 4.682310327648073e-05, 'l2_factor': 8.326398290580943e-05, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [350, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.2582504451274872\n",
      "Critic Loss: 14.433076858520508\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.24390122294425964\n",
      "Critic Loss: 6.896568298339844\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.2896033823490143\n",
      "Critic Loss: 7.509177207946777\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.19370050728321075\n",
      "Critic Loss: 6.296017646789551\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.23724092543125153\n",
      "Critic Loss: 4.219342231750488\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.19862864911556244\n",
      "Critic Loss: 5.125391960144043\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.18282940983772278\n",
      "Critic Loss: 8.129136085510254\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.17143496870994568\n",
      "Critic Loss: 8.123879432678223\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.1767897605895996\n",
      "Critic Loss: 5.0846076011657715\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.16768372058868408\n",
      "Critic Loss: 7.097796440124512\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.156464084982872\n",
      "Critic Loss: 7.896344184875488\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.12855182588100433\n",
      "Critic Loss: 1.592718482017517\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.19843165576457977\n",
      "Critic Loss: 9.06357192993164\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.13485947251319885\n",
      "Critic Loss: 2.2935709953308105\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.1880466490983963\n",
      "Critic Loss: 5.480377197265625\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.13020995259284973\n",
      "Critic Loss: 2.7996368408203125\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.1573069989681244\n",
      "Critic Loss: 0.9805763363838196\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.2116450071334839\n",
      "Critic Loss: 0.7202981114387512\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.2288038730621338\n",
      "Critic Loss: 1.4710136651992798\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.11421149969100952\n",
      "Critic Loss: 6.034969329833984\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.19158320128917694\n",
      "Critic Loss: 6.78375244140625\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.17140066623687744\n",
      "Critic Loss: 0.9828957915306091\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.20428918302059174\n",
      "Critic Loss: 3.397887945175171\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.16790759563446045\n",
      "Critic Loss: 3.5997562408447266\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.21311363577842712\n",
      "Critic Loss: 2.1879215240478516\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.15279017388820648\n",
      "Critic Loss: 1.3324453830718994\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.19930344820022583\n",
      "Critic Loss: 5.8369059562683105\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.14918729662895203\n",
      "Critic Loss: 1.2460273504257202\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.1602180153131485\n",
      "Critic Loss: 4.184359073638916\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.14257989823818207\n",
      "Critic Loss: 0.9067017436027527\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.167555570602417\n",
      "Critic Loss: 2.0391860008239746\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.20174619555473328\n",
      "Critic Loss: 2.9738051891326904\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.17126969993114471\n",
      "Critic Loss: 3.4410319328308105\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.1274118721485138\n",
      "Critic Loss: 4.136432647705078\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.21142446994781494\n",
      "Critic Loss: 2.5934152603149414\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.14869818091392517\n",
      "Critic Loss: 3.801224946975708\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.1458619236946106\n",
      "Critic Loss: 2.751176118850708\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.13579414784908295\n",
      "Critic Loss: 2.5335488319396973\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.16019079089164734\n",
      "Critic Loss: 2.5703792572021484\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.17348691821098328\n",
      "Critic Loss: 0.7265404462814331\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.10122543573379517\n",
      "Critic Loss: 2.871495485305786\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.1596425175666809\n",
      "Critic Loss: 0.8574069142341614\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.2192821055650711\n",
      "Critic Loss: 4.486822128295898\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.16788245737552643\n",
      "Critic Loss: 1.559881567955017\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.2060759961605072\n",
      "Critic Loss: 1.4087790250778198\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.10459580272436142\n",
      "Critic Loss: 2.2447257041931152\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.15527263283729553\n",
      "Critic Loss: 4.744438171386719\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.1809116005897522\n",
      "Critic Loss: 2.9576902389526367\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.18067048490047455\n",
      "Critic Loss: 4.097271919250488\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.14489594101905823\n",
      "Critic Loss: 4.544456481933594\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.145924910902977\n",
      "Critic Loss: 1.8869246244430542\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.14433851838111877\n",
      "Critic Loss: 6.467443466186523\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.12774239480495453\n",
      "Critic Loss: 2.054893732070923\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.18022137880325317\n",
      "Critic Loss: 2.7915706634521484\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.15664170682430267\n",
      "Critic Loss: 1.6830720901489258\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.11957646906375885\n",
      "Critic Loss: 1.3061994314193726\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.24741370975971222\n",
      "Critic Loss: 4.8876118659973145\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.18237660825252533\n",
      "Critic Loss: 0.7910410761833191\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.17153608798980713\n",
      "Critic Loss: 0.7483192682266235\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.1088089868426323\n",
      "Critic Loss: 0.9402323961257935\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.26896220445632935\n",
      "Critic Loss: 2.431382656097412\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c359a1d4197e427bae956609c751c0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>132.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>91.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.00011</td></tr><tr><td>Loss/Actor_loss</td><td>0.08183</td></tr><tr><td>Loss/Critic_loss</td><td>2.43138</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.36039</td></tr><tr><td>Loss/KL_divergence</td><td>0.03014</td></tr><tr><td>Loss/Policy_loss</td><td>0.12251</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.26896</td></tr><tr><td>Metric/Explained_variance</td><td>0.52051</td></tr><tr><td>Reward/Mean_train_reward</td><td>9.38434</td></tr><tr><td>Reward/Mean_val_reward</td><td>-30.2776</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-11.39919</td></tr><tr><td>global_step</td><td>61</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-76</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/cmu6tnwn' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/cmu6tnwn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_012724-cmu6tnwn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0mi4xva with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0003711888311974464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.002052301984690872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03369282791864424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.989941847911452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.4913615509297983e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.8748087676914505e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_013943-a0mi4xva</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/a0mi4xva' target=\"_blank\">sandy-sweep-77</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/a0mi4xva' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/a0mi4xva</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.0003711888311974464, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.002052301984690872, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03369282791864424, 'epochs': 10, 'exponential_factor': 0.989941847911452, 'gamma': 0.99, 'hidden_sizes': [350, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 2.4913615509297983e-05, 'l2_factor': 2.8748087676914505e-06, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0003711888311974464, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.002052301984690872, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03369282791864424, 'epochs': 10, 'exponential_factor': 0.989941847911452, 'gamma': 0.99, 'l1_factor': 2.4913615509297983e-05, 'l2_factor': 2.8748087676914505e-06, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0003711888311974464, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.002052301984690872, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03369282791864424, 'epochs': 10, 'exponential_factor': 0.989941847911452, 'gamma': 0.99, 'l1_factor': 2.4913615509297983e-05, 'l2_factor': 2.8748087676914505e-06, 'minibatch_size': 256, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0003711888311974464, 'critic_lr': 0.002052301984690872, 'decay_method': 'exponential', 'exponential_factor': 0.989941847911452, 'value_loss_factor': 1, 'entropy': 0.03369282791864424, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.4913615509297983e-05, 'l2_factor': 2.8748087676914505e-06, 'T': 1024, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 68.9065170288086\n",
      "Critic Loss: 35.91965103149414\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 53.88082504272461\n",
      "Critic Loss: 27.631946563720703\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 23.458616256713867\n",
      "Critic Loss: 33.80205535888672\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 24.613496780395508\n",
      "Critic Loss: 19.38220977783203\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 36.385040283203125\n",
      "Critic Loss: 13.308354377746582\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 25.243595123291016\n",
      "Critic Loss: 14.656750679016113\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 27.868473052978516\n",
      "Critic Loss: 14.59825325012207\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 26.6788272857666\n",
      "Critic Loss: 11.303568840026855\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 28.076587677001953\n",
      "Critic Loss: 15.426058769226074\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 31.292861938476562\n",
      "Critic Loss: 17.523448944091797\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 24.758411407470703\n",
      "Critic Loss: 15.474719047546387\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 22.55507469177246\n",
      "Critic Loss: 12.27012825012207\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 22.75172233581543\n",
      "Critic Loss: 13.429976463317871\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 20.990062713623047\n",
      "Critic Loss: 12.757389068603516\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 22.036165237426758\n",
      "Critic Loss: 11.283662796020508\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 19.43239402770996\n",
      "Critic Loss: 10.541009902954102\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 23.15555191040039\n",
      "Critic Loss: 16.732223510742188\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 19.52503204345703\n",
      "Critic Loss: 9.686013221740723\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 17.213048934936523\n",
      "Critic Loss: 12.266849517822266\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 23.272550582885742\n",
      "Critic Loss: 18.66060447692871\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 18.398662567138672\n",
      "Critic Loss: 11.659912109375\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 23.046571731567383\n",
      "Critic Loss: 11.759337425231934\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 19.88191795349121\n",
      "Critic Loss: 9.296504974365234\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 20.222612380981445\n",
      "Critic Loss: 12.066496849060059\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 13.380528450012207\n",
      "Critic Loss: 13.53060245513916\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 17.602886199951172\n",
      "Critic Loss: 10.933500289916992\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 22.180421829223633\n",
      "Critic Loss: 8.677391052246094\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 13.67759895324707\n",
      "Critic Loss: 12.229683876037598\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 12.441376686096191\n",
      "Critic Loss: 16.153785705566406\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 9.95593547821045\n",
      "Critic Loss: 10.314355850219727\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 20.838308334350586\n",
      "Critic Loss: 9.700563430786133\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 20.412273406982422\n",
      "Critic Loss: 13.252034187316895\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 17.16963768005371\n",
      "Critic Loss: 12.707029342651367\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 15.365955352783203\n",
      "Critic Loss: 11.453104972839355\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 14.576071739196777\n",
      "Critic Loss: 7.3408708572387695\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 16.311500549316406\n",
      "Critic Loss: 10.74875545501709\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 16.728349685668945\n",
      "Critic Loss: 9.977731704711914\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 17.434160232543945\n",
      "Critic Loss: 11.867881774902344\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 17.77260971069336\n",
      "Critic Loss: 9.734081268310547\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 21.05139923095703\n",
      "Critic Loss: 13.589431762695312\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 19.79349136352539\n",
      "Critic Loss: 14.758964538574219\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 20.465110778808594\n",
      "Critic Loss: 11.504486083984375\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 17.951801300048828\n",
      "Critic Loss: 12.569879531860352\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 18.17692756652832\n",
      "Critic Loss: 9.905280113220215\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 18.04753875732422\n",
      "Critic Loss: 16.62409210205078\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 14.229170799255371\n",
      "Critic Loss: 8.370941162109375\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 22.2100830078125\n",
      "Critic Loss: 12.290412902832031\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 14.528005599975586\n",
      "Critic Loss: 8.865665435791016\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 13.601520538330078\n",
      "Critic Loss: 6.950593948364258\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 19.218158721923828\n",
      "Critic Loss: 9.169388771057129\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 14.534180641174316\n",
      "Critic Loss: 10.9658784866333\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 25.660058975219727\n",
      "Critic Loss: 16.81456756591797\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 22.52203369140625\n",
      "Critic Loss: 17.5057430267334\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 18.4663028717041\n",
      "Critic Loss: 9.73615837097168\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 19.2259578704834\n",
      "Critic Loss: 9.909440994262695\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 17.258441925048828\n",
      "Critic Loss: 11.141286849975586\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 25.650257110595703\n",
      "Critic Loss: 16.906753540039062\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 19.174062728881836\n",
      "Critic Loss: 13.242382049560547\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 18.529794692993164\n",
      "Critic Loss: 11.617508888244629\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503dfb397f61443eadf21c1d8996b5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>43.45454</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>54.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.00021</td></tr><tr><td>Learning_rate/Critic</td><td>0.00114</td></tr><tr><td>Loss/Actor_loss</td><td>18.36545</td></tr><tr><td>Loss/Critic_loss</td><td>11.61751</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.6941</td></tr><tr><td>Loss/KL_divergence</td><td>0.01491</td></tr><tr><td>Loss/Policy_loss</td><td>18.42253</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>18.52979</td></tr><tr><td>Metric/Explained_variance</td><td>0.0819</td></tr><tr><td>Reward/Mean_train_reward</td><td>-78.95028</td></tr><tr><td>Reward/Mean_val_reward</td><td>-81.3503</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-80.87312</td></tr><tr><td>global_step</td><td>59</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-sweep-77</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/a0mi4xva' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/a0mi4xva</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_013943-a0mi4xva\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zcwd3cwx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0020391379396020315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0001493701248538289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.02264339278667309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.93826319032749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0002291442674219355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0004255506725380319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_014501-zcwd3cwx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/zcwd3cwx' target=\"_blank\">polar-sweep-78</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/zcwd3cwx' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/zcwd3cwx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'lrelu', 'actor_lr': 0.0020391379396020315, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0001493701248538289, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02264339278667309, 'epochs': 10, 'exponential_factor': 0.93826319032749, 'gamma': 0.95, 'hidden_sizes': [350, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.0002291442674219355, 'l2_factor': 0.0004255506725380319, 'lrelu': 0.1, 'minibatch_size': 128, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0020391379396020315, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0001493701248538289, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02264339278667309, 'epochs': 10, 'exponential_factor': 0.93826319032749, 'gamma': 0.95, 'l1_factor': 0.0002291442674219355, 'l2_factor': 0.0004255506725380319, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0020391379396020315, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0001493701248538289, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02264339278667309, 'epochs': 10, 'exponential_factor': 0.93826319032749, 'gamma': 0.95, 'l1_factor': 0.0002291442674219355, 'l2_factor': 0.0004255506725380319, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0020391379396020315, 'critic_lr': 0.0001493701248538289, 'decay_method': 'exponential', 'exponential_factor': 0.93826319032749, 'value_loss_factor': 1, 'entropy': 0.02264339278667309, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0002291442674219355, 'l2_factor': 0.0004255506725380319, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 4.510161399841309\n",
      "Critic Loss: 20.437801361083984\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.5306364297866821\n",
      "Critic Loss: 9.5470552444458\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.04495960846543312\n",
      "Critic Loss: 7.389083385467529\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.03289075195789337\n",
      "Critic Loss: 12.619549751281738\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.014295577071607113\n",
      "Critic Loss: 16.311391830444336\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.03332740068435669\n",
      "Critic Loss: 16.40015411376953\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.015535472892224789\n",
      "Critic Loss: 16.795949935913086\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.005798371508717537\n",
      "Critic Loss: 17.396522521972656\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.003862959798425436\n",
      "Critic Loss: 14.696988105773926\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.025723692029714584\n",
      "Critic Loss: 15.706480026245117\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.032989054918289185\n",
      "Critic Loss: 12.592961311340332\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.014242240227758884\n",
      "Critic Loss: 14.149246215820312\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.00963832437992096\n",
      "Critic Loss: 15.063180923461914\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.010481812991201878\n",
      "Critic Loss: 16.52667999267578\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.006129219196736813\n",
      "Critic Loss: 13.364593505859375\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.010924160480499268\n",
      "Critic Loss: 12.659074783325195\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.03664303198456764\n",
      "Critic Loss: 14.34401798248291\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.013598269782960415\n",
      "Critic Loss: 13.458166122436523\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.0024131634272634983\n",
      "Critic Loss: 18.04939842224121\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.01067621260881424\n",
      "Critic Loss: 13.854575157165527\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.023121878504753113\n",
      "Critic Loss: 19.192380905151367\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.025654926896095276\n",
      "Critic Loss: 14.386458396911621\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.015667501837015152\n",
      "Critic Loss: 11.746696472167969\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.020737167447805405\n",
      "Critic Loss: 10.932226181030273\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.009045945480465889\n",
      "Critic Loss: 9.9017972946167\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.008621512912213802\n",
      "Critic Loss: 16.176088333129883\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.01562660187482834\n",
      "Critic Loss: 10.463623046875\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.01425893884152174\n",
      "Critic Loss: 14.800179481506348\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.006948813796043396\n",
      "Critic Loss: 14.477493286132812\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.009178097359836102\n",
      "Critic Loss: 8.101715087890625\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.014826349914073944\n",
      "Critic Loss: 11.347455978393555\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.01844150386750698\n",
      "Critic Loss: 11.192526817321777\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.01436547003686428\n",
      "Critic Loss: 12.213783264160156\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.032368943095207214\n",
      "Critic Loss: 9.865141868591309\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.0070604742504656315\n",
      "Critic Loss: 11.893223762512207\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.0031716027297079563\n",
      "Critic Loss: 10.570367813110352\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.021822640672326088\n",
      "Critic Loss: 7.500697612762451\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.014672758057713509\n",
      "Critic Loss: 9.825420379638672\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.015612617135047913\n",
      "Critic Loss: 12.59616470336914\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.0006914936238899827\n",
      "Critic Loss: 8.579245567321777\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.02815178968012333\n",
      "Critic Loss: 7.736178874969482\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.020887836813926697\n",
      "Critic Loss: 11.96196174621582\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.015099432319402695\n",
      "Critic Loss: 5.901138782501221\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.01294639054685831\n",
      "Critic Loss: 13.320651054382324\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.002944858744740486\n",
      "Critic Loss: 8.901331901550293\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.013302929699420929\n",
      "Critic Loss: 10.813539505004883\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.004194001201540232\n",
      "Critic Loss: 11.354934692382812\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.023505255579948425\n",
      "Critic Loss: 10.144675254821777\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.005552537739276886\n",
      "Critic Loss: 14.056097030639648\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.004603727720677853\n",
      "Critic Loss: 11.826179504394531\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.012756641954183578\n",
      "Critic Loss: 11.286701202392578\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.013949519023299217\n",
      "Critic Loss: 12.143756866455078\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.001964488998055458\n",
      "Critic Loss: 7.883047103881836\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.01055925153195858\n",
      "Critic Loss: 11.844377517700195\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.032043617218732834\n",
      "Critic Loss: 12.291467666625977\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.010246560908854008\n",
      "Critic Loss: 10.361336708068848\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.02076670527458191\n",
      "Critic Loss: 8.335860252380371\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.02207781933248043\n",
      "Critic Loss: 9.329916000366211\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.028797509148716927\n",
      "Critic Loss: 10.167719841003418\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.012919696979224682\n",
      "Critic Loss: 9.017633438110352\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.008541377261281013\n",
      "Critic Loss: 8.139101028442383\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.026487259194254875\n",
      "Critic Loss: 11.652949333190918\n",
      "\n",
      "New best validation reward reached in update [62/200]\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.0166942086070776\n",
      "Critic Loss: 7.516251564025879\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.016613848507404327\n",
      "Critic Loss: 10.100671768188477\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.015031266026198864\n",
      "Critic Loss: 9.492629051208496\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.021588169038295746\n",
      "Critic Loss: 8.483061790466309\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.0026130639016628265\n",
      "Critic Loss: 8.229710578918457\n",
      "\n",
      "New best validation reward reached in update [67/200]\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.0033136820420622826\n",
      "Critic Loss: 10.338651657104492\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.008629675954580307\n",
      "Critic Loss: 8.182865142822266\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.008243321441113949\n",
      "Critic Loss: 8.176599502563477\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.008193406276404858\n",
      "Critic Loss: 7.1412153244018555\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.0062727853655815125\n",
      "Critic Loss: 9.846611022949219\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.03470652177929878\n",
      "Critic Loss: 9.512001991271973\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.011273317039012909\n",
      "Critic Loss: 7.282772064208984\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.015071367844939232\n",
      "Critic Loss: 8.231101036071777\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.0062447190284729\n",
      "Critic Loss: 7.2504563331604\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.024582838639616966\n",
      "Critic Loss: 9.238851547241211\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.0032933983020484447\n",
      "Critic Loss: 8.843544960021973\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.01527196355164051\n",
      "Critic Loss: 8.813572883605957\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.01774599775671959\n",
      "Critic Loss: 8.45482063293457\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.01131372805684805\n",
      "Critic Loss: 10.6167631149292\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.006306062452495098\n",
      "Critic Loss: 13.650894165039062\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.00048240635078400373\n",
      "Critic Loss: 11.285872459411621\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.00807101558893919\n",
      "Critic Loss: 8.725711822509766\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.014023183844983578\n",
      "Critic Loss: 7.511429786682129\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.0062343645840883255\n",
      "Critic Loss: 7.435148239135742\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.009800921194255352\n",
      "Critic Loss: 10.568657875061035\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -0.00947713851928711\n",
      "Critic Loss: 9.799755096435547\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.0007839885074645281\n",
      "Critic Loss: 12.128790855407715\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.02270841784775257\n",
      "Critic Loss: 9.128169059753418\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.023049872368574142\n",
      "Critic Loss: 12.915000915527344\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.02073500119149685\n",
      "Critic Loss: 9.56513786315918\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.0023716979194432497\n",
      "Critic Loss: 7.235238075256348\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.017408151179552078\n",
      "Critic Loss: 7.037716388702393\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.011913015507161617\n",
      "Critic Loss: 8.464801788330078\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.0016656301449984312\n",
      "Critic Loss: 9.417734146118164\n",
      "\n",
      "New best validation reward reached in update [96/200]\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.01670723594725132\n",
      "Critic Loss: 8.408964157104492\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.005528513807803392\n",
      "Critic Loss: 7.430855751037598\n",
      "\n",
      "New best validation reward reached in update [98/200]\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.0011327669490128756\n",
      "Critic Loss: 11.129779815673828\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.0011983619770035148\n",
      "Critic Loss: 8.309005737304688\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.02571745589375496\n",
      "Critic Loss: 6.948137283325195\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.004965067375451326\n",
      "Critic Loss: 10.173550605773926\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.008870900608599186\n",
      "Critic Loss: 12.19641399383545\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.009911807253956795\n",
      "Critic Loss: 6.692657470703125\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -0.013692180626094341\n",
      "Critic Loss: 9.268102645874023\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.006838278379291296\n",
      "Critic Loss: 8.722230911254883\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.010000703856348991\n",
      "Critic Loss: 4.198432922363281\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -0.013330071233212948\n",
      "Critic Loss: 5.869826316833496\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.0023168763145804405\n",
      "Critic Loss: 6.100884437561035\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -0.016239013522863388\n",
      "Critic Loss: 10.760333061218262\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -0.01744610071182251\n",
      "Critic Loss: 7.482374668121338\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.02051379904150963\n",
      "Critic Loss: 7.740489959716797\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.0051362169906497\n",
      "Critic Loss: 9.531488418579102\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -0.009741646237671375\n",
      "Critic Loss: 9.800077438354492\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.005636141635477543\n",
      "Critic Loss: 8.503189086914062\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -0.023402966558933258\n",
      "Critic Loss: 8.348071098327637\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -0.008805511519312859\n",
      "Critic Loss: 7.353984355926514\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -0.02279573306441307\n",
      "Critic Loss: 10.976228713989258\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.006230995059013367\n",
      "Critic Loss: 11.575004577636719\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.0004978707293048501\n",
      "Critic Loss: 11.410602569580078\n",
      "\n",
      "New best validation reward reached in update [120/200]\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.04204360768198967\n",
      "Critic Loss: 9.913839340209961\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -0.00710911862552166\n",
      "Critic Loss: 8.322333335876465\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -0.007430661469697952\n",
      "Critic Loss: 9.145773887634277\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -0.008008059114217758\n",
      "Critic Loss: 7.702282428741455\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -0.03118273615837097\n",
      "Critic Loss: 9.350973129272461\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.0027129719965159893\n",
      "Critic Loss: 9.042794227600098\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -0.0054927123710513115\n",
      "Critic Loss: 7.654391288757324\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -0.00946732796728611\n",
      "Critic Loss: 8.710843086242676\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -0.02758515067398548\n",
      "Critic Loss: 7.845855236053467\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.017113950103521347\n",
      "Critic Loss: 8.782856941223145\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e9b4482e664c57aa619a1d52a6da98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>94.25</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>81.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.03317</td></tr><tr><td>Loss/Critic_loss</td><td>8.78286</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.31111</td></tr><tr><td>Loss/KL_divergence</td><td>0.00802</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00349</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.01711</td></tr><tr><td>Metric/Explained_variance</td><td>0.26041</td></tr><tr><td>Reward/Mean_train_reward</td><td>-71.28675</td></tr><tr><td>Reward/Mean_val_reward</td><td>-77.5555</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-74.76527</td></tr><tr><td>global_step</td><td>130</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-78</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/zcwd3cwx' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/zcwd3cwx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_014501-zcwd3cwx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k6x8s6dy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0009946089387856578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0013294521847346972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.021713228241210053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.930294471916696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.1176874201725062e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.711984147565895e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_015719-k6x8s6dy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/k6x8s6dy' target=\"_blank\">faithful-sweep-79</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/k6x8s6dy' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/k6x8s6dy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'tanh', 'actor_lr': 0.0009946089387856578, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0013294521847346972, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.021713228241210053, 'epochs': 10, 'exponential_factor': 0.930294471916696, 'gamma': 0.9, 'hidden_sizes': [150, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 1.1176874201725062e-05, 'l2_factor': 7.711984147565895e-05, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0009946089387856578, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0013294521847346972, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.021713228241210053, 'epochs': 10, 'exponential_factor': 0.930294471916696, 'gamma': 0.9, 'l1_factor': 1.1176874201725062e-05, 'l2_factor': 7.711984147565895e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 350], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0009946089387856578, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0013294521847346972, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.021713228241210053, 'epochs': 10, 'exponential_factor': 0.930294471916696, 'gamma': 0.9, 'l1_factor': 1.1176874201725062e-05, 'l2_factor': 7.711984147565895e-05, 'minibatch_size': 32, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0009946089387856578, 'critic_lr': 0.0013294521847346972, 'decay_method': 'exponential', 'exponential_factor': 0.930294471916696, 'value_loss_factor': 1, 'entropy': 0.021713228241210053, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.1176874201725062e-05, 'l2_factor': 7.711984147565895e-05, 'T': 512, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [150, 350, 350], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 33.50030517578125\n",
      "Critic Loss: 25.80484390258789\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 9.341124534606934\n",
      "Critic Loss: 12.658380508422852\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 3.5953238010406494\n",
      "Critic Loss: 6.651950359344482\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -1.737109899520874\n",
      "Critic Loss: 2.600917339324951\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 24.8602352142334\n",
      "Critic Loss: 17.368417739868164\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 6.493870258331299\n",
      "Critic Loss: 7.70213508605957\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 14.499262809753418\n",
      "Critic Loss: 7.486342906951904\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.40674889087677\n",
      "Critic Loss: 6.950101852416992\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 2.162489891052246\n",
      "Critic Loss: 5.174469947814941\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 4.429519176483154\n",
      "Critic Loss: 5.322421550750732\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 7.585500240325928\n",
      "Critic Loss: 4.304929733276367\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.5106117725372314\n",
      "Critic Loss: 5.697196006774902\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 11.97767162322998\n",
      "Critic Loss: 9.94093132019043\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 17.650224685668945\n",
      "Critic Loss: 11.124454498291016\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 2.7186899185180664\n",
      "Critic Loss: 3.019343376159668\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 3.9962775707244873\n",
      "Critic Loss: 3.3520710468292236\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 8.887287139892578\n",
      "Critic Loss: 4.628329753875732\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 5.025065898895264\n",
      "Critic Loss: 2.8100411891937256\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 5.660508632659912\n",
      "Critic Loss: 3.9628686904907227\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -3.677529811859131\n",
      "Critic Loss: 2.8047115802764893\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 10.24634838104248\n",
      "Critic Loss: 3.8059706687927246\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 13.367648124694824\n",
      "Critic Loss: 6.250679016113281\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 2.3777706623077393\n",
      "Critic Loss: 2.659881353378296\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.22208157181739807\n",
      "Critic Loss: 2.9616615772247314\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 11.961584091186523\n",
      "Critic Loss: 2.460132598876953\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 8.90583324432373\n",
      "Critic Loss: 1.9983962774276733\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 14.38964557647705\n",
      "Critic Loss: 5.723519325256348\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 3.5769503116607666\n",
      "Critic Loss: 2.655456066131592\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 2.7578067779541016\n",
      "Critic Loss: 3.162566661834717\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 6.852545738220215\n",
      "Critic Loss: 1.6363176107406616\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 6.53861141204834\n",
      "Critic Loss: 2.347885847091675\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 5.94210147857666\n",
      "Critic Loss: 3.4880781173706055\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -2.0913772583007812\n",
      "Critic Loss: 2.770423650741577\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 7.0214524269104\n",
      "Critic Loss: 2.875216245651245\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 10.600991249084473\n",
      "Critic Loss: 1.771956205368042\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.6880649924278259\n",
      "Critic Loss: 2.3588240146636963\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 10.15711498260498\n",
      "Critic Loss: 2.7037975788116455\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 15.4102144241333\n",
      "Critic Loss: 5.645074844360352\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -3.3608243465423584\n",
      "Critic Loss: 2.774533748626709\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 3.7617249488830566\n",
      "Critic Loss: 1.31345796585083\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 1.9320745468139648\n",
      "Critic Loss: 4.0033111572265625\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.0240795761346817\n",
      "Critic Loss: 1.947102427482605\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 2.6179678440093994\n",
      "Critic Loss: 1.9932187795639038\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 8.513663291931152\n",
      "Critic Loss: 2.326768398284912\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 2.1940221786499023\n",
      "Critic Loss: 1.776437520980835\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 7.277938365936279\n",
      "Critic Loss: 2.8768279552459717\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 3.2805016040802\n",
      "Critic Loss: 1.198639988899231\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 9.893198013305664\n",
      "Critic Loss: 3.062995433807373\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 1.5705795288085938\n",
      "Critic Loss: 1.9482959508895874\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 10.60018539428711\n",
      "Critic Loss: 2.254376173019409\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 8.101480484008789\n",
      "Critic Loss: 2.460827350616455\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.7389234900474548\n",
      "Critic Loss: 2.8675506114959717\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 7.900267601013184\n",
      "Critic Loss: 3.3028829097747803\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 6.778616905212402\n",
      "Critic Loss: 2.575319528579712\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 18.099340438842773\n",
      "Critic Loss: 6.039577007293701\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 5.0443339347839355\n",
      "Critic Loss: 1.9883650541305542\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 5.184168815612793\n",
      "Critic Loss: 2.240251064300537\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 4.362726211547852\n",
      "Critic Loss: 1.850107192993164\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 11.78763198852539\n",
      "Critic Loss: 3.1377217769622803\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 9.330191612243652\n",
      "Critic Loss: 3.7854862213134766\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 1.8084650039672852\n",
      "Critic Loss: 1.944534182548523\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 11.284393310546875\n",
      "Critic Loss: 2.0097224712371826\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 8.246564865112305\n",
      "Critic Loss: 2.463223695755005\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 3.967193126678467\n",
      "Critic Loss: 2.3327255249023438\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.2804841101169586\n",
      "Critic Loss: 1.7435367107391357\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 5.559817314147949\n",
      "Critic Loss: 1.5808672904968262\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.3333429992198944\n",
      "Critic Loss: 3.1285252571105957\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 7.630969047546387\n",
      "Critic Loss: 2.434668779373169\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 8.099017143249512\n",
      "Critic Loss: 2.8399980068206787\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 5.681672096252441\n",
      "Critic Loss: 2.454533576965332\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 6.069982528686523\n",
      "Critic Loss: 2.0749287605285645\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 13.937151908874512\n",
      "Critic Loss: 4.068657398223877\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 3.5230019092559814\n",
      "Critic Loss: 3.6162824630737305\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 3.531412124633789\n",
      "Critic Loss: 1.00725519657135\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 4.077147483825684\n",
      "Critic Loss: 2.153958559036255\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 2.4909043312072754\n",
      "Critic Loss: 1.8060314655303955\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.6214883923530579\n",
      "Critic Loss: 1.3726115226745605\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 5.932355880737305\n",
      "Critic Loss: 2.798617124557495\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 9.95866870880127\n",
      "Critic Loss: 2.157048225402832\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.6212270259857178\n",
      "Critic Loss: 2.8684701919555664\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 11.205363273620605\n",
      "Critic Loss: 3.635410785675049\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 7.139911651611328\n",
      "Critic Loss: 3.9586398601531982\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 18.657224655151367\n",
      "Critic Loss: 7.085683822631836\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 8.894546508789062\n",
      "Critic Loss: 2.4463839530944824\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 4.752112865447998\n",
      "Critic Loss: 1.6728501319885254\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 13.00109577178955\n",
      "Critic Loss: 3.2192699909210205\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 1.0911680459976196\n",
      "Critic Loss: 1.5430634021759033\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 5.9911956787109375\n",
      "Critic Loss: 2.2096433639526367\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eeca11d70a470ba50e504a25b90615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>56.25</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>56.7</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>5.68506</td></tr><tr><td>Loss/Critic_loss</td><td>2.20964</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.33642</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01509</td></tr><tr><td>Loss/Policy_loss</td><td>5.69236</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>5.9912</td></tr><tr><td>Metric/Explained_variance</td><td>0.93567</td></tr><tr><td>Reward/Mean_train_reward</td><td>-43.81475</td></tr><tr><td>Reward/Mean_val_reward</td><td>-42.8203</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-43.02589</td></tr><tr><td>global_step</td><td>88</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-79</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/k6x8s6dy' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/k6x8s6dy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_015719-k6x8s6dy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y2vgdysr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00956831874476812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0005531724485946037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.034161780379417694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8653163840188317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.2828593297696874e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0005961001406206773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_020639-y2vgdysr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/y2vgdysr' target=\"_blank\">eternal-sweep-80</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/y2vgdysr' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/y2vgdysr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.00956831874476812, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0005531724485946037, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.034161780379417694, 'epochs': 10, 'exponential_factor': 0.8653163840188317, 'gamma': 0.99, 'hidden_sizes': [250, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 1.2828593297696874e-05, 'l2_factor': 0.0005961001406206773, 'lrelu': 0.001, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00956831874476812, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0005531724485946037, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.034161780379417694, 'epochs': 10, 'exponential_factor': 0.8653163840188317, 'gamma': 0.99, 'l1_factor': 1.2828593297696874e-05, 'l2_factor': 0.0005961001406206773, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00956831874476812, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0005531724485946037, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.034161780379417694, 'epochs': 10, 'exponential_factor': 0.8653163840188317, 'gamma': 0.99, 'l1_factor': 1.2828593297696874e-05, 'l2_factor': 0.0005961001406206773, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00956831874476812, 'critic_lr': 0.0005531724485946037, 'decay_method': 'exponential', 'exponential_factor': 0.8653163840188317, 'value_loss_factor': 1, 'entropy': 0.034161780379417694, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.2828593297696874e-05, 'l2_factor': 0.0005961001406206773, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [250, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.2385997772216797\n",
      "Critic Loss: 29.632007598876953\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.1353304088115692\n",
      "Critic Loss: 80.47331237792969\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.004998050630092621\n",
      "Critic Loss: 25.200456619262695\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.06026894971728325\n",
      "Critic Loss: 12.689929962158203\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.0006411373615264893\n",
      "Critic Loss: 16.496057510375977\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.011331632733345032\n",
      "Critic Loss: 19.825542449951172\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.044329747557640076\n",
      "Critic Loss: 16.140499114990234\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.03003111109137535\n",
      "Critic Loss: 15.698980331420898\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.0006858967244625092\n",
      "Critic Loss: 17.247102737426758\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.02481186017394066\n",
      "Critic Loss: 13.523372650146484\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.0076210834085941315\n",
      "Critic Loss: 9.747492790222168\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.016809502616524696\n",
      "Critic Loss: 10.633867263793945\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.0019004419445991516\n",
      "Critic Loss: 8.025466918945312\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.03035338595509529\n",
      "Critic Loss: 8.50638484954834\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.03167515993118286\n",
      "Critic Loss: 7.209636688232422\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.002655263990163803\n",
      "Critic Loss: 7.2888712882995605\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.02615169994533062\n",
      "Critic Loss: 5.256513595581055\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.007778286933898926\n",
      "Critic Loss: 0.8542377948760986\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.03901563584804535\n",
      "Critic Loss: 5.638105392456055\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.029787488281726837\n",
      "Critic Loss: 7.80355167388916\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.0392228439450264\n",
      "Critic Loss: 1.0805439949035645\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.049531202763319016\n",
      "Critic Loss: 6.919720649719238\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.01903611049056053\n",
      "Critic Loss: 8.470771789550781\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.018533756956458092\n",
      "Critic Loss: 7.571747303009033\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.027746153995394707\n",
      "Critic Loss: 10.165987014770508\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.055329058319330215\n",
      "Critic Loss: 14.548942565917969\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.014289313927292824\n",
      "Critic Loss: 13.296022415161133\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.016705790534615517\n",
      "Critic Loss: 9.193607330322266\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.02668728679418564\n",
      "Critic Loss: 8.147168159484863\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.018458697944879532\n",
      "Critic Loss: 19.58559226989746\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.0057558417320251465\n",
      "Critic Loss: 10.174457550048828\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.03601638972759247\n",
      "Critic Loss: 18.831314086914062\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.046016447246074677\n",
      "Critic Loss: 16.55084991455078\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.0395301952958107\n",
      "Critic Loss: 17.513412475585938\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.015853900462388992\n",
      "Critic Loss: 17.565765380859375\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.00496814027428627\n",
      "Critic Loss: 12.425956726074219\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.03360816091299057\n",
      "Critic Loss: 14.342768669128418\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.023596007376909256\n",
      "Critic Loss: 18.350996017456055\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.022763200104236603\n",
      "Critic Loss: 14.011009216308594\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.019037701189517975\n",
      "Critic Loss: 10.592377662658691\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.02156464383006096\n",
      "Critic Loss: 15.622858047485352\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.0027545392513275146\n",
      "Critic Loss: 13.142156600952148\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.013167297467589378\n",
      "Critic Loss: 15.333187103271484\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.026522506028413773\n",
      "Critic Loss: 12.899311065673828\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.007716784253716469\n",
      "Critic Loss: 12.682731628417969\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.0025909189134836197\n",
      "Critic Loss: 12.039539337158203\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.009231584146618843\n",
      "Critic Loss: 13.506219863891602\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.0013591237366199493\n",
      "Critic Loss: 11.134536743164062\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.030694158747792244\n",
      "Critic Loss: 13.088568687438965\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4df07216e5a4f13b7d3ecc2fce6be86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>âââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>âââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>121.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>105.9</td></tr><tr><td>Learning_rate/Actor</td><td>1e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.06188</td></tr><tr><td>Loss/Critic_loss</td><td>13.08857</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.12141</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00319</td></tr><tr><td>Loss/Policy_loss</td><td>-0.02357</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.03069</td></tr><tr><td>Metric/Explained_variance</td><td>0.07931</td></tr><tr><td>Reward/Mean_train_reward</td><td>-3.22</td></tr><tr><td>Reward/Mean_val_reward</td><td>-14.2431</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-22.59944</td></tr><tr><td>global_step</td><td>49</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-sweep-80</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/y2vgdysr' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/y2vgdysr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_020639-y2vgdysr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3m894vuo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.007134139754695279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0007079128550560811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.026892372310174346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8909132937934793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0003721921016927357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 5.6259325338682934e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_021009-3m894vuo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/3m894vuo' target=\"_blank\">classic-sweep-81</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/3m894vuo' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/3m894vuo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.007134139754695279, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007079128550560811, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.026892372310174346, 'epochs': 10, 'exponential_factor': 0.8909132937934793, 'gamma': 0.99, 'hidden_sizes': [250, 150, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.0003721921016927357, 'l2_factor': 5.6259325338682934e-06, 'lrelu': 0.001, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.007134139754695279, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007079128550560811, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.026892372310174346, 'epochs': 10, 'exponential_factor': 0.8909132937934793, 'gamma': 0.99, 'l1_factor': 0.0003721921016927357, 'l2_factor': 5.6259325338682934e-06, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 250, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.007134139754695279, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007079128550560811, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.026892372310174346, 'epochs': 10, 'exponential_factor': 0.8909132937934793, 'gamma': 0.99, 'l1_factor': 0.0003721921016927357, 'l2_factor': 5.6259325338682934e-06, 'minibatch_size': 128, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.007134139754695279, 'critic_lr': 0.0007079128550560811, 'decay_method': 'exponential', 'exponential_factor': 0.8909132937934793, 'value_loss_factor': 1, 'entropy': 0.026892372310174346, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0003721921016927357, 'l2_factor': 5.6259325338682934e-06, 'T': 768, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [250, 150, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 2.110057830810547\n",
      "Critic Loss: 25.862829208374023\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.10821481794118881\n",
      "Critic Loss: 11.922871589660645\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.13005287945270538\n",
      "Critic Loss: 14.031864166259766\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.053388893604278564\n",
      "Critic Loss: 11.297137260437012\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.021819502115249634\n",
      "Critic Loss: 13.624703407287598\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.056474000215530396\n",
      "Critic Loss: 13.912491798400879\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.04362170770764351\n",
      "Critic Loss: 6.662736892700195\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.039170268923044205\n",
      "Critic Loss: 12.010701179504395\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.025893844664096832\n",
      "Critic Loss: 5.490151882171631\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.005610075779259205\n",
      "Critic Loss: 3.7473537921905518\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.06632719933986664\n",
      "Critic Loss: 9.773390769958496\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.006627812050282955\n",
      "Critic Loss: 6.802659034729004\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.002870283555239439\n",
      "Critic Loss: 11.648237228393555\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.01268363744020462\n",
      "Critic Loss: 10.148150444030762\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.006463618483394384\n",
      "Critic Loss: 3.980985641479492\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.0024617307353764772\n",
      "Critic Loss: 8.790390968322754\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.009496205486357212\n",
      "Critic Loss: 2.988267183303833\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.02442227676510811\n",
      "Critic Loss: 4.018874645233154\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.021413147449493408\n",
      "Critic Loss: 3.9441473484039307\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.0379122756421566\n",
      "Critic Loss: 2.602128505706787\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.018579987809062004\n",
      "Critic Loss: 6.28073787689209\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.02793806977570057\n",
      "Critic Loss: 7.465790271759033\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.039863891899585724\n",
      "Critic Loss: 5.122706413269043\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.029782572761178017\n",
      "Critic Loss: 3.3093392848968506\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.02828020416200161\n",
      "Critic Loss: 2.1667532920837402\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.01599222607910633\n",
      "Critic Loss: 1.842556357383728\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.04342149943113327\n",
      "Critic Loss: 5.016810894012451\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.014923728071153164\n",
      "Critic Loss: 4.0872802734375\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.028796307742595673\n",
      "Critic Loss: 5.392030239105225\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.017940698191523552\n",
      "Critic Loss: 2.52463436126709\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.03120385855436325\n",
      "Critic Loss: 2.808574914932251\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.024503368884325027\n",
      "Critic Loss: 5.49189567565918\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.015851031988859177\n",
      "Critic Loss: 7.8316755294799805\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.011956524103879929\n",
      "Critic Loss: 3.638634204864502\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.009600558318197727\n",
      "Critic Loss: 7.628700256347656\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.02295944280922413\n",
      "Critic Loss: 6.0968828201293945\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.03816691413521767\n",
      "Critic Loss: 3.22927188873291\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.007533202413469553\n",
      "Critic Loss: 4.653278350830078\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.02938983216881752\n",
      "Critic Loss: 3.276085615158081\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.01828767918050289\n",
      "Critic Loss: 3.455095052719116\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.046681150794029236\n",
      "Critic Loss: 4.820456027984619\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.03799157589673996\n",
      "Critic Loss: 10.529173851013184\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.024254856631159782\n",
      "Critic Loss: 3.4934537410736084\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.02560357376933098\n",
      "Critic Loss: 4.121561527252197\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.014977069571614265\n",
      "Critic Loss: 5.0558295249938965\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.022213924676179886\n",
      "Critic Loss: 4.957721710205078\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.016608307138085365\n",
      "Critic Loss: 5.920411586761475\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.024802783504128456\n",
      "Critic Loss: 5.184488773345947\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.026807500049471855\n",
      "Critic Loss: 6.190070152282715\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.017132248729467392\n",
      "Critic Loss: 4.4973320960998535\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.020902179181575775\n",
      "Critic Loss: 3.034548759460449\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.026255259290337563\n",
      "Critic Loss: 7.272737503051758\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.016228551045060158\n",
      "Critic Loss: 5.3697710037231445\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.013232395984232426\n",
      "Critic Loss: 7.940456867218018\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.017987126484513283\n",
      "Critic Loss: 3.8589954376220703\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.01405466441065073\n",
      "Critic Loss: 3.4831156730651855\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.01482382882386446\n",
      "Critic Loss: 8.086136817932129\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.015196749940514565\n",
      "Critic Loss: 7.217453956604004\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.018086032941937447\n",
      "Critic Loss: 6.966305732727051\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.010575990192592144\n",
      "Critic Loss: 3.647156000137329\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.014638754539191723\n",
      "Critic Loss: 4.5036163330078125\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.0134348813444376\n",
      "Critic Loss: 5.485650062561035\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.013232925906777382\n",
      "Critic Loss: 4.969786643981934\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.014127642847597599\n",
      "Critic Loss: 5.535923957824707\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.008974711410701275\n",
      "Critic Loss: 3.1279900074005127\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.01410733349621296\n",
      "Critic Loss: 3.637664556503296\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.012577658519148827\n",
      "Critic Loss: 4.299853324890137\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.011989769525825977\n",
      "Critic Loss: 4.400076866149902\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.012999971397221088\n",
      "Critic Loss: 3.1271159648895264\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.011593799106776714\n",
      "Critic Loss: 2.461087226867676\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.011067057959735394\n",
      "Critic Loss: 7.030106544494629\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.012302850373089314\n",
      "Critic Loss: 4.8368144035339355\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.012466687709093094\n",
      "Critic Loss: 3.7650766372680664\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.012392324395477772\n",
      "Critic Loss: 4.792560577392578\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.01317443884909153\n",
      "Critic Loss: 4.9732561111450195\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.011615007184445858\n",
      "Critic Loss: 3.7100186347961426\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.01145234890282154\n",
      "Critic Loss: 3.0727455615997314\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.011724738404154778\n",
      "Critic Loss: 3.08697247505188\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.012045882642269135\n",
      "Critic Loss: 3.891979217529297\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.010952385142445564\n",
      "Critic Loss: 3.7695460319519043\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.011218221858143806\n",
      "Critic Loss: 7.54246187210083\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.011886938475072384\n",
      "Critic Loss: 2.8380727767944336\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.012478935532271862\n",
      "Critic Loss: 5.924806594848633\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.011655888520181179\n",
      "Critic Loss: 6.564479827880859\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf789ce2b35454396e1fa3b1e6fdd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>128.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>143.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.04046</td></tr><tr><td>Loss/Critic_loss</td><td>6.56448</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.49913</td></tr><tr><td>Loss/KL_divergence</td><td>6e-05</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00014</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.01166</td></tr><tr><td>Metric/Explained_variance</td><td>0.49769</td></tr><tr><td>Reward/Mean_train_reward</td><td>-17.06501</td></tr><tr><td>Reward/Mean_val_reward</td><td>-13.5935</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-15.12234</td></tr><tr><td>global_step</td><td>84</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-81</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/3m894vuo' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/3m894vuo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_021009-3m894vuo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c4efcst2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.000257865439738344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0011216788406097128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.002441431645634638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9329502280167148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 250, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00028722056835260015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.859095592652245e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_022000-c4efcst2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/c4efcst2' target=\"_blank\">glad-sweep-82</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/c4efcst2' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/c4efcst2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.000257865439738344, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011216788406097128, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.002441431645634638, 'epochs': 10, 'exponential_factor': 0.9329502280167148, 'gamma': 0.95, 'hidden_sizes': [250, 250, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 0.00028722056835260015, 'l2_factor': 2.859095592652245e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.000257865439738344, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011216788406097128, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.002441431645634638, 'epochs': 10, 'exponential_factor': 0.9329502280167148, 'gamma': 0.95, 'l1_factor': 0.00028722056835260015, 'l2_factor': 2.859095592652245e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.8, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.000257865439738344, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011216788406097128, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.002441431645634638, 'epochs': 10, 'exponential_factor': 0.9329502280167148, 'gamma': 0.95, 'l1_factor': 0.00028722056835260015, 'l2_factor': 2.859095592652245e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.000257865439738344, 'critic_lr': 0.0011216788406097128, 'decay_method': 'exponential', 'exponential_factor': 0.9329502280167148, 'value_loss_factor': 1, 'entropy': 0.002441431645634638, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00028722056835260015, 'l2_factor': 2.859095592652245e-06, 'T': 1024, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [250, 250, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 2.356022596359253\n",
      "Critic Loss: 19.876760482788086\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 2.321536064147949\n",
      "Critic Loss: 11.96256160736084\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 2.308621883392334\n",
      "Critic Loss: 13.069665908813477\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 2.06931471824646\n",
      "Critic Loss: 7.711404800415039\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 1.9004392623901367\n",
      "Critic Loss: 6.830185890197754\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 1.9022306203842163\n",
      "Critic Loss: 10.177081108093262\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.8137285709381104\n",
      "Critic Loss: 6.159499168395996\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 1.7248445749282837\n",
      "Critic Loss: 7.944490432739258\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 1.6164618730545044\n",
      "Critic Loss: 6.668572425842285\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 1.5301151275634766\n",
      "Critic Loss: 6.955188274383545\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.4283689260482788\n",
      "Critic Loss: 6.11954402923584\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.393271803855896\n",
      "Critic Loss: 8.128606796264648\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.3184301853179932\n",
      "Critic Loss: 7.695064067840576\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.2403161525726318\n",
      "Critic Loss: 5.772878646850586\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.204282522201538\n",
      "Critic Loss: 6.590779781341553\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.1556286811828613\n",
      "Critic Loss: 7.511548042297363\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 1.154567003250122\n",
      "Critic Loss: 7.830150127410889\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 1.128597378730774\n",
      "Critic Loss: 4.557392120361328\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 1.1069008111953735\n",
      "Critic Loss: 5.4674530029296875\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 1.0447906255722046\n",
      "Critic Loss: 5.827038288116455\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 1.0241873264312744\n",
      "Critic Loss: 3.696465015411377\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 1.0111206769943237\n",
      "Critic Loss: 5.901752948760986\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.9809572696685791\n",
      "Critic Loss: 6.131383895874023\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.9701182246208191\n",
      "Critic Loss: 4.610754013061523\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.9364041686058044\n",
      "Critic Loss: 3.6835761070251465\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.9462670683860779\n",
      "Critic Loss: 2.6725425720214844\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.9562846422195435\n",
      "Critic Loss: 3.2940995693206787\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.9026862978935242\n",
      "Critic Loss: 3.1566126346588135\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.9091572761535645\n",
      "Critic Loss: 3.040787696838379\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.9006996750831604\n",
      "Critic Loss: 2.7792301177978516\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.9142743349075317\n",
      "Critic Loss: 3.8971238136291504\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.8474845886230469\n",
      "Critic Loss: 7.168442726135254\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.8728684186935425\n",
      "Critic Loss: 5.07114315032959\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.8865602612495422\n",
      "Critic Loss: 8.722484588623047\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.834216833114624\n",
      "Critic Loss: 4.4709696769714355\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.9408293962478638\n",
      "Critic Loss: 4.698838233947754\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.8357400298118591\n",
      "Critic Loss: 3.25465726852417\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.8289958238601685\n",
      "Critic Loss: 4.568173885345459\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.8206526637077332\n",
      "Critic Loss: 2.9847068786621094\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.824661374092102\n",
      "Critic Loss: 5.3166985511779785\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.809623122215271\n",
      "Critic Loss: 4.657327651977539\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.8338726162910461\n",
      "Critic Loss: 5.320847511291504\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.8101591467857361\n",
      "Critic Loss: 5.851810932159424\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.8410834074020386\n",
      "Critic Loss: 5.0836310386657715\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.8571836948394775\n",
      "Critic Loss: 5.2523040771484375\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.8030534982681274\n",
      "Critic Loss: 4.319803714752197\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.8748147487640381\n",
      "Critic Loss: 4.628568649291992\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.7796595096588135\n",
      "Critic Loss: 3.033113479614258\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.8162238597869873\n",
      "Critic Loss: 3.5785717964172363\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.788576066493988\n",
      "Critic Loss: 4.468724727630615\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.8100281953811646\n",
      "Critic Loss: 4.896804332733154\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.802245020866394\n",
      "Critic Loss: 4.230700492858887\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.7890185713768005\n",
      "Critic Loss: 4.811756134033203\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.8370246887207031\n",
      "Critic Loss: 5.272560119628906\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.7764965295791626\n",
      "Critic Loss: 4.639807224273682\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.825198769569397\n",
      "Critic Loss: 4.6200270652771\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.8172589540481567\n",
      "Critic Loss: 3.0656020641326904\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.8076861500740051\n",
      "Critic Loss: 5.689297676086426\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.7764331698417664\n",
      "Critic Loss: 8.008604049682617\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.7853266596794128\n",
      "Critic Loss: 6.230043411254883\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07cd7cd431f42218f8b48ecfc5d28a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>47.85</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>48.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>2e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00895</td></tr><tr><td>Loss/Critic_loss</td><td>6.23004</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.29918</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01732</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00822</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.78533</td></tr><tr><td>Metric/Explained_variance</td><td>0.63446</td></tr><tr><td>Reward/Mean_train_reward</td><td>-56.44315</td></tr><tr><td>Reward/Mean_val_reward</td><td>-55.6445</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-58.07499</td></tr><tr><td>global_step</td><td>60</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-82</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/c4efcst2' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/c4efcst2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_022000-c4efcst2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6v7fhosi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00015634875099178417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0011795897106670475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.029973643646906637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.998037235633636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0007642350770447983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.849752049952352e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_022609-6v7fhosi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/6v7fhosi' target=\"_blank\">restful-sweep-83</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/6v7fhosi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/6v7fhosi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.00015634875099178417, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011795897106670475, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029973643646906637, 'epochs': 10, 'exponential_factor': 0.998037235633636, 'gamma': 0.9, 'hidden_sizes': [250, 150, 350, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0007642350770447983, 'l2_factor': 1.849752049952352e-06, 'lrelu': 0.01, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00015634875099178417, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011795897106670475, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029973643646906637, 'epochs': 10, 'exponential_factor': 0.998037235633636, 'gamma': 0.9, 'l1_factor': 0.0007642350770447983, 'l2_factor': 1.849752049952352e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 350, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00015634875099178417, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011795897106670475, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029973643646906637, 'epochs': 10, 'exponential_factor': 0.998037235633636, 'gamma': 0.9, 'l1_factor': 0.0007642350770447983, 'l2_factor': 1.849752049952352e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00015634875099178417, 'critic_lr': 0.0011795897106670475, 'decay_method': 'exponential', 'exponential_factor': 0.998037235633636, 'value_loss_factor': 1, 'entropy': 0.029973643646906637, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0007642350770447983, 'l2_factor': 1.849752049952352e-06, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [250, 150, 350, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 8.148035049438477\n",
      "Critic Loss: 19.27388572692871\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 7.312367916107178\n",
      "Critic Loss: 17.11202621459961\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 5.046222686767578\n",
      "Critic Loss: 9.696840286254883\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 4.091629981994629\n",
      "Critic Loss: 8.602611541748047\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 2.9085707664489746\n",
      "Critic Loss: 3.3994696140289307\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 2.2379047870635986\n",
      "Critic Loss: 4.627871513366699\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 1.812769889831543\n",
      "Critic Loss: 3.712766170501709\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 1.5314791202545166\n",
      "Critic Loss: 3.0429530143737793\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 1.368401050567627\n",
      "Critic Loss: 4.381906986236572\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 1.4129117727279663\n",
      "Critic Loss: 5.018840312957764\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 1.2046096324920654\n",
      "Critic Loss: 2.493959426879883\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 1.1870712041854858\n",
      "Critic Loss: 4.04364013671875\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 1.0804136991500854\n",
      "Critic Loss: 4.0093889236450195\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 1.1820768117904663\n",
      "Critic Loss: 4.365293025970459\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 1.1382144689559937\n",
      "Critic Loss: 2.6602749824523926\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 1.1229251623153687\n",
      "Critic Loss: 3.435936689376831\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.9828189611434937\n",
      "Critic Loss: 5.083592891693115\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.9039717316627502\n",
      "Critic Loss: 3.6340689659118652\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.8595073223114014\n",
      "Critic Loss: 3.537977933883667\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.8948185443878174\n",
      "Critic Loss: 3.3797364234924316\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.8255688548088074\n",
      "Critic Loss: 2.242455005645752\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.7465383410453796\n",
      "Critic Loss: 4.516726493835449\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.8163978457450867\n",
      "Critic Loss: 3.341237783432007\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.7105335593223572\n",
      "Critic Loss: 3.8543477058410645\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.697158694267273\n",
      "Critic Loss: 2.216459035873413\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.6397113800048828\n",
      "Critic Loss: 6.052273273468018\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.6438025236129761\n",
      "Critic Loss: 3.553807020187378\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.6568519473075867\n",
      "Critic Loss: 3.6900722980499268\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.72044438123703\n",
      "Critic Loss: 2.6022748947143555\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.5663796067237854\n",
      "Critic Loss: 4.314681529998779\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.5753939151763916\n",
      "Critic Loss: 5.850504398345947\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 1.1126487255096436\n",
      "Critic Loss: 4.380737781524658\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.5399056673049927\n",
      "Critic Loss: 4.414646148681641\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.590435266494751\n",
      "Critic Loss: 1.5300883054733276\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.5056105256080627\n",
      "Critic Loss: 3.0804131031036377\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.5559837222099304\n",
      "Critic Loss: 2.4834253787994385\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.4436461329460144\n",
      "Critic Loss: 2.5012333393096924\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.44617369771003723\n",
      "Critic Loss: 5.03537654876709\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.4986127018928528\n",
      "Critic Loss: 3.2875733375549316\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.4404226243495941\n",
      "Critic Loss: 3.77860951423645\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.4076550304889679\n",
      "Critic Loss: 2.0509681701660156\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.36912912130355835\n",
      "Critic Loss: 2.145749568939209\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.36889150738716125\n",
      "Critic Loss: 2.095435619354248\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.32402902841567993\n",
      "Critic Loss: 5.450713634490967\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.32438695430755615\n",
      "Critic Loss: 4.004421710968018\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.3029918372631073\n",
      "Critic Loss: 5.113007545471191\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.28512874245643616\n",
      "Critic Loss: 5.876272678375244\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.3796462118625641\n",
      "Critic Loss: 4.389908313751221\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.29623985290527344\n",
      "Critic Loss: 2.8466715812683105\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7debe5e2e2442b9eb9f15bc60a89eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>59.76471</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>105.1</td></tr><tr><td>Learning_rate/Actor</td><td>0.00014</td></tr><tr><td>Learning_rate/Critic</td><td>0.00107</td></tr><tr><td>Loss/Actor_loss</td><td>-0.08265</td></tr><tr><td>Loss/Critic_loss</td><td>2.84667</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.61494</td></tr><tr><td>Loss/KL_divergence</td><td>-0.0142</td></tr><tr><td>Loss/Policy_loss</td><td>-0.03424</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.29624</td></tr><tr><td>Metric/Explained_variance</td><td>-0.33172</td></tr><tr><td>Reward/Mean_train_reward</td><td>-63.50124</td></tr><tr><td>Reward/Mean_val_reward</td><td>-46.0519</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-46.66666</td></tr><tr><td>global_step</td><td>49</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-83</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/6v7fhosi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/6v7fhosi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_022609-6v7fhosi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fec6gnix with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.007777993899669044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00017829699216775452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.013988089568541102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9945009684366972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 250, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 9.659596095862054e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 6.486958398522311e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_023406-fec6gnix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/fec6gnix' target=\"_blank\">lyric-sweep-84</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fec6gnix' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fec6gnix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.007777993899669044, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017829699216775452, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.013988089568541102, 'epochs': 10, 'exponential_factor': 0.9945009684366972, 'gamma': 0.95, 'hidden_sizes': [150, 250, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 9.659596095862054e-05, 'l2_factor': 6.486958398522311e-05, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.007777993899669044, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017829699216775452, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.013988089568541102, 'epochs': 10, 'exponential_factor': 0.9945009684366972, 'gamma': 0.95, 'l1_factor': 9.659596095862054e-05, 'l2_factor': 6.486958398522311e-05, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 250, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.007777993899669044, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017829699216775452, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.013988089568541102, 'epochs': 10, 'exponential_factor': 0.9945009684366972, 'gamma': 0.95, 'l1_factor': 9.659596095862054e-05, 'l2_factor': 6.486958398522311e-05, 'minibatch_size': 32, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.007777993899669044, 'critic_lr': 0.00017829699216775452, 'decay_method': 'exponential', 'exponential_factor': 0.9945009684366972, 'value_loss_factor': 1, 'entropy': 0.013988089568541102, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 9.659596095862054e-05, 'l2_factor': 6.486958398522311e-05, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [150, 250, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 19.386749267578125\n",
      "Critic Loss: 21.678918838500977\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 4.162807464599609\n",
      "Critic Loss: 8.419108390808105\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 1.758646011352539\n",
      "Critic Loss: 7.8092451095581055\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -1.254908561706543\n",
      "Critic Loss: 4.444483280181885\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -3.3961901664733887\n",
      "Critic Loss: 4.703497409820557\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 1.5686533451080322\n",
      "Critic Loss: 8.138877868652344\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -4.115027904510498\n",
      "Critic Loss: 4.163943767547607\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -2.6696457862854004\n",
      "Critic Loss: 4.027566909790039\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.15396949648857117\n",
      "Critic Loss: 4.833834171295166\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -2.7584402561187744\n",
      "Critic Loss: 6.894224643707275\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -3.9296767711639404\n",
      "Critic Loss: 5.946382999420166\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 3.2199418544769287\n",
      "Critic Loss: 8.45175552368164\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -6.497039318084717\n",
      "Critic Loss: 5.7793402671813965\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -4.525542259216309\n",
      "Critic Loss: 6.615500450134277\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.06807099282741547\n",
      "Critic Loss: 8.49733829498291\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.3107951879501343\n",
      "Critic Loss: 7.847373962402344\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -3.356991767883301\n",
      "Critic Loss: 4.276489734649658\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 2.340029239654541\n",
      "Critic Loss: 9.472556114196777\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 80.3620834350586\n",
      "Critic Loss: 98.68118286132812\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 78.51536560058594\n",
      "Critic Loss: 87.39154052734375\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 60.56050491333008\n",
      "Critic Loss: 70.56159210205078\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 81.662841796875\n",
      "Critic Loss: 107.99311828613281\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 25.315858840942383\n",
      "Critic Loss: 27.889089584350586\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 12.4285888671875\n",
      "Critic Loss: 9.213884353637695\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 20.38294219970703\n",
      "Critic Loss: 15.263995170593262\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 14.687651634216309\n",
      "Critic Loss: 7.485456466674805\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 22.531402587890625\n",
      "Critic Loss: 6.572789669036865\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 13.831602096557617\n",
      "Critic Loss: 18.431337356567383\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 4.441748142242432\n",
      "Critic Loss: 10.925494194030762\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 3.463277578353882\n",
      "Critic Loss: 8.419570922851562\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.9181502461433411\n",
      "Critic Loss: 7.148584842681885\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 4.300178050994873\n",
      "Critic Loss: 10.133675575256348\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 1.7163941860198975\n",
      "Critic Loss: 8.181029319763184\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.8221413493156433\n",
      "Critic Loss: 11.29279899597168\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 5.2573628425598145\n",
      "Critic Loss: 11.917089462280273\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 14.26246166229248\n",
      "Critic Loss: 9.185023307800293\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 5.488944053649902\n",
      "Critic Loss: 9.391582489013672\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 10.740335464477539\n",
      "Critic Loss: 10.626514434814453\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 31.955991744995117\n",
      "Critic Loss: 26.31925392150879\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 122.80567169189453\n",
      "Critic Loss: 107.60271453857422\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 86.30109405517578\n",
      "Critic Loss: 111.58307647705078\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 83.34137725830078\n",
      "Critic Loss: 110.28913879394531\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 37.211204528808594\n",
      "Critic Loss: 26.640146255493164\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 42.513916015625\n",
      "Critic Loss: 34.97517013549805\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 42.93804168701172\n",
      "Critic Loss: 28.689441680908203\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22e6fd54919406c8ee5d4f7aec363b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>25.33333</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>26.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.0061</td></tr><tr><td>Learning_rate/Critic</td><td>0.00014</td></tr><tr><td>Loss/Actor_loss</td><td>40.51084</td></tr><tr><td>Loss/Critic_loss</td><td>28.68944</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.00547</td></tr><tr><td>Loss/KL_divergence</td><td>0.01057</td></tr><tr><td>Loss/Policy_loss</td><td>40.51092</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>42.93804</td></tr><tr><td>Metric/Explained_variance</td><td>0.05069</td></tr><tr><td>Reward/Mean_train_reward</td><td>-87.86012</td></tr><tr><td>Reward/Mean_val_reward</td><td>-86.975</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-81.03611</td></tr><tr><td>global_step</td><td>45</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-84</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fec6gnix' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fec6gnix</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_023406-fec6gnix\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mfc25q2f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0029187950737004317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00031332809876424383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.026731588806783772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9584592583804542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 5.54582712004736e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.0015565442953912e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_023732-mfc25q2f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/mfc25q2f' target=\"_blank\">glorious-sweep-85</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/mfc25q2f' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/mfc25q2f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 768, 'activation': 'tanh', 'actor_lr': 0.0029187950737004317, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00031332809876424383, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.026731588806783772, 'epochs': 10, 'exponential_factor': 0.9584592583804542, 'gamma': 0.95, 'hidden_sizes': [150, 350, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 5.54582712004736e-06, 'l2_factor': 1.0015565442953912e-05, 'lrelu': 0.01, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0029187950737004317, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00031332809876424383, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.026731588806783772, 'epochs': 10, 'exponential_factor': 0.9584592583804542, 'gamma': 0.95, 'l1_factor': 5.54582712004736e-06, 'l2_factor': 1.0015565442953912e-05, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'tanh', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 768, 'actor_lr': 0.0029187950737004317, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00031332809876424383, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.026731588806783772, 'epochs': 10, 'exponential_factor': 0.9584592583804542, 'gamma': 0.95, 'l1_factor': 5.54582712004736e-06, 'l2_factor': 1.0015565442953912e-05, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0029187950737004317, 'critic_lr': 0.00031332809876424383, 'decay_method': 'exponential', 'exponential_factor': 0.9584592583804542, 'value_loss_factor': 1, 'entropy': 0.026731588806783772, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 5.54582712004736e-06, 'l2_factor': 1.0015565442953912e-05, 'T': 768, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.2, 'hidden_sizes': [150, 350, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: -0.034408312290906906\n",
      "Critic Loss: 23.194528579711914\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.037445612251758575\n",
      "Critic Loss: 15.564847946166992\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.0075699929147958755\n",
      "Critic Loss: 8.681387901306152\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.025292839854955673\n",
      "Critic Loss: 10.776342391967773\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.01025007851421833\n",
      "Critic Loss: 8.873035430908203\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.0011148592457175255\n",
      "Critic Loss: 10.080915451049805\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.0012286603450775146\n",
      "Critic Loss: 6.988119602203369\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.015909193083643913\n",
      "Critic Loss: 5.781500339508057\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.015271419659256935\n",
      "Critic Loss: 5.80258846282959\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.020451892167329788\n",
      "Critic Loss: 8.104846000671387\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.01602601818740368\n",
      "Critic Loss: 6.992556571960449\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.02189074084162712\n",
      "Critic Loss: 8.496091842651367\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.020361529663205147\n",
      "Critic Loss: 4.935574054718018\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.008886238560080528\n",
      "Critic Loss: 5.419893264770508\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.005261484067887068\n",
      "Critic Loss: 6.091736316680908\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.026919379830360413\n",
      "Critic Loss: 6.071364879608154\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.037007469683885574\n",
      "Critic Loss: 4.909753799438477\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.006269353441894054\n",
      "Critic Loss: 5.918184280395508\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.019086599349975586\n",
      "Critic Loss: 6.703847885131836\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.03454536944627762\n",
      "Critic Loss: 5.363117694854736\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.0051079704426229\n",
      "Critic Loss: 5.358107089996338\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.02603144198656082\n",
      "Critic Loss: 5.254661560058594\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.01648814231157303\n",
      "Critic Loss: 8.357893943786621\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.02280326932668686\n",
      "Critic Loss: 4.524557590484619\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.0022332705557346344\n",
      "Critic Loss: 7.691952228546143\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.016190305352211\n",
      "Critic Loss: 5.384426116943359\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.0021019307896494865\n",
      "Critic Loss: 7.364541530609131\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.006729401182383299\n",
      "Critic Loss: 6.839114665985107\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.026655659079551697\n",
      "Critic Loss: 5.231999397277832\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.013313781470060349\n",
      "Critic Loss: 5.452230453491211\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.02847723290324211\n",
      "Critic Loss: 4.649991035461426\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.004356405232101679\n",
      "Critic Loss: 4.957778453826904\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.015282943844795227\n",
      "Critic Loss: 4.945831775665283\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.003852228168398142\n",
      "Critic Loss: 5.800584316253662\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.007612899411469698\n",
      "Critic Loss: 6.617295265197754\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.007921434938907623\n",
      "Critic Loss: 5.19597864151001\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.019922476261854172\n",
      "Critic Loss: 4.733405113220215\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.0028786822222173214\n",
      "Critic Loss: 7.608425140380859\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.018704835325479507\n",
      "Critic Loss: 6.402866840362549\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.021414248272776604\n",
      "Critic Loss: 6.666049480438232\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.007516482844948769\n",
      "Critic Loss: 4.488100051879883\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.004448136314749718\n",
      "Critic Loss: 6.295434951782227\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.008329857140779495\n",
      "Critic Loss: 4.3558125495910645\n",
      "\n",
      "New best validation reward reached in update [43/200]\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.0004648622125387192\n",
      "Critic Loss: 4.218569278717041\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.010799946263432503\n",
      "Critic Loss: 3.79548978805542\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.010442421771585941\n",
      "Critic Loss: 3.883275032043457\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.017257343977689743\n",
      "Critic Loss: 3.221485137939453\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.030095156282186508\n",
      "Critic Loss: 4.791359901428223\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.026425248011946678\n",
      "Critic Loss: 6.556638240814209\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.015275446698069572\n",
      "Critic Loss: 5.768401622772217\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.013554519973695278\n",
      "Critic Loss: 3.8634538650512695\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.004361481871455908\n",
      "Critic Loss: 3.582249641418457\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.031131329014897346\n",
      "Critic Loss: 5.226396560668945\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.03484874218702316\n",
      "Critic Loss: 5.62515115737915\n",
      "\n",
      "New best validation reward reached in update [54/200]\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.02629336528480053\n",
      "Critic Loss: 8.761483192443848\n",
      "\n",
      "New best validation reward reached in update [55/200]\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.012492254376411438\n",
      "Critic Loss: 5.197195529937744\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.0004613329656422138\n",
      "Critic Loss: 3.787055730819702\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.039387185126543045\n",
      "Critic Loss: 7.244579315185547\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.004341418389230967\n",
      "Critic Loss: 3.2483201026916504\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.02565952017903328\n",
      "Critic Loss: 4.775899410247803\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.009727264754474163\n",
      "Critic Loss: 4.657116889953613\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.0015548733063042164\n",
      "Critic Loss: 6.684968948364258\n",
      "\n",
      "New best validation reward reached in update [62/200]\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.0005664648488163948\n",
      "Critic Loss: 6.092956066131592\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.031149208545684814\n",
      "Critic Loss: 8.550914764404297\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.025586441159248352\n",
      "Critic Loss: 5.743901252746582\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.020936956629157066\n",
      "Critic Loss: 4.309422492980957\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.01641198806464672\n",
      "Critic Loss: 4.887246131896973\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.014960061758756638\n",
      "Critic Loss: 4.294278144836426\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.01879860647022724\n",
      "Critic Loss: 3.6323864459991455\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.04970507323741913\n",
      "Critic Loss: 5.220015525817871\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.027642633765935898\n",
      "Critic Loss: 3.7824184894561768\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.01725122705101967\n",
      "Critic Loss: 9.545201301574707\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.015284597873687744\n",
      "Critic Loss: 5.46104097366333\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.026057593524456024\n",
      "Critic Loss: 6.231138229370117\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.024818889796733856\n",
      "Critic Loss: 3.1816277503967285\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.02638847567141056\n",
      "Critic Loss: 4.520595550537109\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.035025134682655334\n",
      "Critic Loss: 3.1804542541503906\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.01614004746079445\n",
      "Critic Loss: 7.186564922332764\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.02692466601729393\n",
      "Critic Loss: 6.734424591064453\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.03257497027516365\n",
      "Critic Loss: 7.281041145324707\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.003381319809705019\n",
      "Critic Loss: 4.670324325561523\n",
      "\n",
      "New best validation reward reached in update [81/200]\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.023092802613973618\n",
      "Critic Loss: 3.990469217300415\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.02900148369371891\n",
      "Critic Loss: 6.470632553100586\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.01924622617661953\n",
      "Critic Loss: 6.399300575256348\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.03176424652338028\n",
      "Critic Loss: 5.102709770202637\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.015542613342404366\n",
      "Critic Loss: 7.293025970458984\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.01634075678884983\n",
      "Critic Loss: 5.806553840637207\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.029234329238533974\n",
      "Critic Loss: 5.565644264221191\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.016171466559171677\n",
      "Critic Loss: 5.204667568206787\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.02527955174446106\n",
      "Critic Loss: 6.0450310707092285\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.01962972804903984\n",
      "Critic Loss: 4.395691871643066\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.025227917358279228\n",
      "Critic Loss: 4.391692161560059\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.016811294481158257\n",
      "Critic Loss: 6.615273475646973\n",
      "\n",
      "New best validation reward reached in update [93/200]\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.0017287391237914562\n",
      "Critic Loss: 4.983705997467041\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.027936553582549095\n",
      "Critic Loss: 7.873335838317871\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.018750660121440887\n",
      "Critic Loss: 7.177013397216797\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.024376604706048965\n",
      "Critic Loss: 4.485164642333984\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.00248198164626956\n",
      "Critic Loss: 3.9484286308288574\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.03726433590054512\n",
      "Critic Loss: 6.570394039154053\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.018376832827925682\n",
      "Critic Loss: 12.240257263183594\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.019848544150590897\n",
      "Critic Loss: 7.544816970825195\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.016379177570343018\n",
      "Critic Loss: 6.710140228271484\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.021825725212693214\n",
      "Critic Loss: 8.427811622619629\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.02683872915804386\n",
      "Critic Loss: 3.9911913871765137\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.017477726563811302\n",
      "Critic Loss: 7.281595706939697\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.014353206381201744\n",
      "Critic Loss: 5.231026649475098\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.04266417399048805\n",
      "Critic Loss: 6.787593841552734\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.019482014700770378\n",
      "Critic Loss: 5.214217662811279\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.018732590600848198\n",
      "Critic Loss: 7.8709917068481445\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.03597291186451912\n",
      "Critic Loss: 7.230252265930176\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.0019567017443478107\n",
      "Critic Loss: 4.540353775024414\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.016200199723243713\n",
      "Critic Loss: 6.377388000488281\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.020539307966828346\n",
      "Critic Loss: 5.3939361572265625\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.012363366782665253\n",
      "Critic Loss: 3.822352409362793\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.027993477880954742\n",
      "Critic Loss: 5.107299327850342\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.01904132217168808\n",
      "Critic Loss: 6.65738582611084\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.022432247176766396\n",
      "Critic Loss: 3.809478282928467\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.017634904012084007\n",
      "Critic Loss: 4.587281703948975\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.02440941520035267\n",
      "Critic Loss: 4.3518171310424805\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.015247995033860207\n",
      "Critic Loss: 8.342713356018066\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.01509212888777256\n",
      "Critic Loss: 6.385375022888184\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.02375587448477745\n",
      "Critic Loss: 9.024412155151367\n",
      "\n",
      "New best validation reward reached in update [122/200]\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.030523283407092094\n",
      "Critic Loss: 5.528933525085449\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.028748363256454468\n",
      "Critic Loss: 4.944862365722656\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.011322205886244774\n",
      "Critic Loss: 5.300623893737793\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.023882409557700157\n",
      "Critic Loss: 6.0229172706604\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.021914426237344742\n",
      "Critic Loss: 6.142603874206543\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.006520245689898729\n",
      "Critic Loss: 4.541229248046875\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.02502022683620453\n",
      "Critic Loss: 8.068336486816406\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.03275115042924881\n",
      "Critic Loss: 6.3749918937683105\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.023339122533798218\n",
      "Critic Loss: 4.488631725311279\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.029332853853702545\n",
      "Critic Loss: 5.178440093994141\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.03463895618915558\n",
      "Critic Loss: 7.273166656494141\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.023337915539741516\n",
      "Critic Loss: 6.2311506271362305\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.02583511359989643\n",
      "Critic Loss: 4.435746669769287\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.02887002006173134\n",
      "Critic Loss: 3.9388320446014404\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.009526770561933517\n",
      "Critic Loss: 5.16791296005249\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.023187974467873573\n",
      "Critic Loss: 4.644929885864258\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.023289617151021957\n",
      "Critic Loss: 6.551279544830322\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.07968305796384811\n",
      "Critic Loss: 7.221580982208252\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.024401631206274033\n",
      "Critic Loss: 8.346273422241211\n",
      "\n",
      "New best validation reward reached in update [141/200]\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.011350393295288086\n",
      "Critic Loss: 7.550477981567383\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 0.025897720828652382\n",
      "Critic Loss: 7.7946648597717285\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.025264602154493332\n",
      "Critic Loss: 5.7446441650390625\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.03215774521231651\n",
      "Critic Loss: 7.802402496337891\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 0.021713532507419586\n",
      "Critic Loss: 5.19959020614624\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.02177480235695839\n",
      "Critic Loss: 5.021418571472168\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.028482189401984215\n",
      "Critic Loss: 8.382152557373047\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.040797021239995956\n",
      "Critic Loss: 8.338325500488281\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.024437475949525833\n",
      "Critic Loss: 5.566249847412109\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 0.03564932197332382\n",
      "Critic Loss: 7.212717533111572\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: 0.013936571776866913\n",
      "Critic Loss: 7.758328914642334\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: 0.012342581525444984\n",
      "Critic Loss: 4.801058769226074\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: 0.025821704417467117\n",
      "Critic Loss: 6.198018550872803\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: 0.08469075709581375\n",
      "Critic Loss: 5.971317768096924\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 0.012177947908639908\n",
      "Critic Loss: 5.894742488861084\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: 0.029210560023784637\n",
      "Critic Loss: 4.898673057556152\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 0.029476672410964966\n",
      "Critic Loss: 6.537909507751465\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 0.029396187514066696\n",
      "Critic Loss: 5.476537227630615\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: 0.02656797133386135\n",
      "Critic Loss: 4.630481719970703\n",
      "\n",
      "Update [161/200]\n",
      "Actor Loss: 0.020403530448675156\n",
      "Critic Loss: 4.591792583465576\n",
      "\n",
      "Update [162/200]\n",
      "Actor Loss: 0.01920468546450138\n",
      "Critic Loss: 5.557389736175537\n",
      "\n",
      "Update [163/200]\n",
      "Actor Loss: 0.019999444484710693\n",
      "Critic Loss: 6.07605504989624\n",
      "\n",
      "New best validation reward reached in update [163/200]\n",
      "\n",
      "Update [164/200]\n",
      "Actor Loss: 0.01897738128900528\n",
      "Critic Loss: 3.7373130321502686\n",
      "\n",
      "Update [165/200]\n",
      "Actor Loss: 0.022211182862520218\n",
      "Critic Loss: 4.989857196807861\n",
      "\n",
      "Update [166/200]\n",
      "Actor Loss: 0.030779734253883362\n",
      "Critic Loss: 3.9805002212524414\n",
      "\n",
      "Update [167/200]\n",
      "Actor Loss: 0.033822692930698395\n",
      "Critic Loss: 3.915750741958618\n",
      "\n",
      "Update [168/200]\n",
      "Actor Loss: 0.026627840474247932\n",
      "Critic Loss: 3.7167625427246094\n",
      "\n",
      "Update [169/200]\n",
      "Actor Loss: 0.02724308893084526\n",
      "Critic Loss: 6.959432601928711\n",
      "\n",
      "Update [170/200]\n",
      "Actor Loss: 0.03580332174897194\n",
      "Critic Loss: 5.721868515014648\n",
      "\n",
      "Update [171/200]\n",
      "Actor Loss: 0.028521418571472168\n",
      "Critic Loss: 7.915407180786133\n",
      "\n",
      "New best validation reward reached in update [171/200]\n",
      "\n",
      "Update [172/200]\n",
      "Actor Loss: 0.033262334764003754\n",
      "Critic Loss: 6.131842613220215\n",
      "\n",
      "Update [173/200]\n",
      "Actor Loss: 0.02888869121670723\n",
      "Critic Loss: 6.06633186340332\n",
      "\n",
      "Update [174/200]\n",
      "Actor Loss: 0.029986131936311722\n",
      "Critic Loss: 6.052089214324951\n",
      "\n",
      "Update [175/200]\n",
      "Actor Loss: 0.03716448321938515\n",
      "Critic Loss: 5.7710394859313965\n",
      "\n",
      "Update [176/200]\n",
      "Actor Loss: 0.04077363759279251\n",
      "Critic Loss: 5.35126256942749\n",
      "\n",
      "Update [177/200]\n",
      "Actor Loss: 0.023675352334976196\n",
      "Critic Loss: 4.713292598724365\n",
      "\n",
      "Update [178/200]\n",
      "Actor Loss: 0.021987304091453552\n",
      "Critic Loss: 5.56329870223999\n",
      "\n",
      "Update [179/200]\n",
      "Actor Loss: 0.031731076538562775\n",
      "Critic Loss: 4.131610870361328\n",
      "\n",
      "Update [180/200]\n",
      "Actor Loss: 0.015225391834974289\n",
      "Critic Loss: 5.7231926918029785\n",
      "\n",
      "Update [181/200]\n",
      "Actor Loss: 0.014914721250534058\n",
      "Critic Loss: 6.576479911804199\n",
      "\n",
      "Update [182/200]\n",
      "Actor Loss: 0.03320935368537903\n",
      "Critic Loss: 6.1947407722473145\n",
      "\n",
      "Update [183/200]\n",
      "Actor Loss: 0.021460505202412605\n",
      "Critic Loss: 6.897184371948242\n",
      "\n",
      "Update [184/200]\n",
      "Actor Loss: 0.024965675547719002\n",
      "Critic Loss: 4.546607971191406\n",
      "\n",
      "Update [185/200]\n",
      "Actor Loss: 0.021619293838739395\n",
      "Critic Loss: 4.33882999420166\n",
      "\n",
      "Update [186/200]\n",
      "Actor Loss: 0.033321261405944824\n",
      "Critic Loss: 4.955922603607178\n",
      "\n",
      "Update [187/200]\n",
      "Actor Loss: 0.0284133143723011\n",
      "Critic Loss: 7.357837677001953\n",
      "\n",
      "Update [188/200]\n",
      "Actor Loss: 0.04368702694773674\n",
      "Critic Loss: 7.699546813964844\n",
      "\n",
      "Update [189/200]\n",
      "Actor Loss: 0.030291130766272545\n",
      "Critic Loss: 7.806392192840576\n",
      "\n",
      "Update [190/200]\n",
      "Actor Loss: 0.04492060840129852\n",
      "Critic Loss: 11.877447128295898\n",
      "\n",
      "Update [191/200]\n",
      "Actor Loss: 0.021401720121502876\n",
      "Critic Loss: 6.0633087158203125\n",
      "\n",
      "Update [192/200]\n",
      "Actor Loss: 0.04264094680547714\n",
      "Critic Loss: 6.472266674041748\n",
      "\n",
      "Update [193/200]\n",
      "Actor Loss: 0.02391783893108368\n",
      "Critic Loss: 4.693917751312256\n",
      "\n",
      "Update [194/200]\n",
      "Actor Loss: 0.01867358200252056\n",
      "Critic Loss: 7.214555740356445\n",
      "\n",
      "Update [195/200]\n",
      "Actor Loss: 0.025731127709150314\n",
      "Critic Loss: 4.878794193267822\n",
      "\n",
      "Update [196/200]\n",
      "Actor Loss: 0.026136230677366257\n",
      "Critic Loss: 5.220057010650635\n",
      "\n",
      "Update [197/200]\n",
      "Actor Loss: 0.018261147662997246\n",
      "Critic Loss: 5.245687484741211\n",
      "\n",
      "Update [198/200]\n",
      "Actor Loss: 0.02648121863603592\n",
      "Critic Loss: 6.081254959106445\n",
      "\n",
      "Update [199/200]\n",
      "Actor Loss: 0.0406113937497139\n",
      "Critic Loss: 5.252334117889404\n",
      "\n",
      "Update [200/200]\n",
      "Actor Loss: 0.041650693863630295\n",
      "Critic Loss: 3.4981276988983154\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2c6bd3e386459887dab4c1a2cc3672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>240.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>191.10001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.00794</td></tr><tr><td>Loss/Critic_loss</td><td>3.49813</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.48926</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00122</td></tr><tr><td>Loss/Policy_loss</td><td>0.02102</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.04165</td></tr><tr><td>Metric/Explained_variance</td><td>0.17723</td></tr><tr><td>Reward/Mean_train_reward</td><td>322.85953</td></tr><tr><td>Reward/Mean_val_reward</td><td>199.0381</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>267.39975</td></tr><tr><td>global_step</td><td>200</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-sweep-85</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/mfc25q2f' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/mfc25q2f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_023732-mfc25q2f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jn6jm2zv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0013464344254923513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0007630369473629689\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.033396804024958156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8892942856033342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.171552141796959e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 0.0005857793816828786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_030342-jn6jm2zv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/jn6jm2zv' target=\"_blank\">autumn-sweep-86</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/jn6jm2zv' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/jn6jm2zv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0013464344254923513, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007630369473629689, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.033396804024958156, 'epochs': 10, 'exponential_factor': 0.8892942856033342, 'gamma': 0.9, 'hidden_sizes': [350, 350, 250, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 3.171552141796959e-05, 'l2_factor': 0.0005857793816828786, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0013464344254923513, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007630369473629689, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.033396804024958156, 'epochs': 10, 'exponential_factor': 0.8892942856033342, 'gamma': 0.9, 'l1_factor': 3.171552141796959e-05, 'l2_factor': 0.0005857793816828786, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 250], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0013464344254923513, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0007630369473629689, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.033396804024958156, 'epochs': 10, 'exponential_factor': 0.8892942856033342, 'gamma': 0.9, 'l1_factor': 3.171552141796959e-05, 'l2_factor': 0.0005857793816828786, 'minibatch_size': 256, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0013464344254923513, 'critic_lr': 0.0007630369473629689, 'decay_method': 'exponential', 'exponential_factor': 0.8892942856033342, 'value_loss_factor': 1, 'entropy': 0.033396804024958156, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.171552141796959e-05, 'l2_factor': 0.0005857793816828786, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.3, 'hidden_sizes': [350, 350, 250, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 33.06084442138672\n",
      "Critic Loss: 38.7660026550293\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 41.10561752319336\n",
      "Critic Loss: 49.75469207763672\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 23.867156982421875\n",
      "Critic Loss: 52.300472259521484\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 33.5258674621582\n",
      "Critic Loss: 27.745136260986328\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 34.15427780151367\n",
      "Critic Loss: 28.479019165039062\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 34.05957794189453\n",
      "Critic Loss: 32.35790252685547\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 35.156253814697266\n",
      "Critic Loss: 35.80208969116211\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 34.77511215209961\n",
      "Critic Loss: 26.91569709777832\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 37.854190826416016\n",
      "Critic Loss: 18.053592681884766\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 30.983734130859375\n",
      "Critic Loss: 16.612960815429688\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 22.05843734741211\n",
      "Critic Loss: 16.068185806274414\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 13.024127006530762\n",
      "Critic Loss: 13.57312297821045\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 12.352699279785156\n",
      "Critic Loss: 14.486087799072266\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 11.240557670593262\n",
      "Critic Loss: 14.826018333435059\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 15.654541969299316\n",
      "Critic Loss: 18.362558364868164\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 25.357532501220703\n",
      "Critic Loss: 28.96270751953125\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 24.070863723754883\n",
      "Critic Loss: 28.886497497558594\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 18.77510643005371\n",
      "Critic Loss: 20.802112579345703\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 29.44369888305664\n",
      "Critic Loss: 29.315980911254883\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 29.51166343688965\n",
      "Critic Loss: 27.411054611206055\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 24.666645050048828\n",
      "Critic Loss: 22.19174575805664\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 30.354764938354492\n",
      "Critic Loss: 23.354843139648438\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 30.765697479248047\n",
      "Critic Loss: 22.95523452758789\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 30.63427734375\n",
      "Critic Loss: 21.349096298217773\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 32.11469650268555\n",
      "Critic Loss: 19.98808479309082\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 22.753765106201172\n",
      "Critic Loss: 20.532461166381836\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 21.98526382446289\n",
      "Critic Loss: 21.25326156616211\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 16.7372989654541\n",
      "Critic Loss: 17.89269256591797\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 15.311022758483887\n",
      "Critic Loss: 18.032573699951172\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 13.596085548400879\n",
      "Critic Loss: 16.64083480834961\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 16.944049835205078\n",
      "Critic Loss: 18.34798812866211\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 12.917752265930176\n",
      "Critic Loss: 15.413887023925781\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 12.878150939941406\n",
      "Critic Loss: 17.34213638305664\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 12.718961715698242\n",
      "Critic Loss: 15.030336380004883\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 12.25329875946045\n",
      "Critic Loss: 16.14863395690918\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 12.44434928894043\n",
      "Critic Loss: 16.504566192626953\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 11.083365440368652\n",
      "Critic Loss: 15.844924926757812\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 15.254720687866211\n",
      "Critic Loss: 17.682571411132812\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 11.997875213623047\n",
      "Critic Loss: 14.698614120483398\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 11.26296329498291\n",
      "Critic Loss: 13.949674606323242\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 14.815781593322754\n",
      "Critic Loss: 14.542757987976074\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 12.67851734161377\n",
      "Critic Loss: 14.621423721313477\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 13.996877670288086\n",
      "Critic Loss: 16.026010513305664\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 13.070202827453613\n",
      "Critic Loss: 15.2061767578125\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 13.859342575073242\n",
      "Critic Loss: 15.51478385925293\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 14.101012229919434\n",
      "Critic Loss: 14.452255249023438\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 11.951003074645996\n",
      "Critic Loss: 15.323979377746582\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 12.576504707336426\n",
      "Critic Loss: 14.2281494140625\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 9.125466346740723\n",
      "Critic Loss: 14.026260375976562\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 13.368078231811523\n",
      "Critic Loss: 13.724161148071289\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 13.794089317321777\n",
      "Critic Loss: 13.466572761535645\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 17.278026580810547\n",
      "Critic Loss: 17.070703506469727\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 14.484975814819336\n",
      "Critic Loss: 14.184125900268555\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 14.997236251831055\n",
      "Critic Loss: 13.93571662902832\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 13.386898040771484\n",
      "Critic Loss: 13.781386375427246\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 12.123066902160645\n",
      "Critic Loss: 12.851137161254883\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 9.434857368469238\n",
      "Critic Loss: 12.18488883972168\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 13.621886253356934\n",
      "Critic Loss: 14.314579010009766\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 7.990071773529053\n",
      "Critic Loss: 12.994013786315918\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 18.05238151550293\n",
      "Critic Loss: 18.69437599182129\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 13.469513893127441\n",
      "Critic Loss: 13.236942291259766\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 11.160920143127441\n",
      "Critic Loss: 12.202383995056152\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 13.576045036315918\n",
      "Critic Loss: 14.374349594116211\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 12.539745330810547\n",
      "Critic Loss: 15.011481285095215\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 14.104898452758789\n",
      "Critic Loss: 16.19058609008789\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 10.38404655456543\n",
      "Critic Loss: 14.730226516723633\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 15.008530616760254\n",
      "Critic Loss: 16.788389205932617\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 12.449602127075195\n",
      "Critic Loss: 15.059804916381836\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 13.915032386779785\n",
      "Critic Loss: 13.288468360900879\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 12.555170059204102\n",
      "Critic Loss: 13.63361644744873\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324c3658e9054275b554965c62010801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>47.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>50.1</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>10.98855</td></tr><tr><td>Loss/Critic_loss</td><td>13.63362</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.48354</td></tr><tr><td>Loss/KL_divergence</td><td>0.03609</td></tr><tr><td>Loss/Policy_loss</td><td>11.00469</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>12.55517</td></tr><tr><td>Metric/Explained_variance</td><td>0.32355</td></tr><tr><td>Reward/Mean_train_reward</td><td>-57.104</td></tr><tr><td>Reward/Mean_val_reward</td><td>-52.5909</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-58.1554</td></tr><tr><td>global_step</td><td>70</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-86</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/jn6jm2zv' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/jn6jm2zv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_030342-jn6jm2zv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sd1pl88m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.006654488259229976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0015656912336263088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04298588313278487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9497457958975826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0008160435316339294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.9065888959087276e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_030632-sd1pl88m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/sd1pl88m' target=\"_blank\">radiant-sweep-87</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/sd1pl88m' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/sd1pl88m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.006654488259229976, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0015656912336263088, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04298588313278487, 'epochs': 10, 'exponential_factor': 0.9497457958975826, 'gamma': 0.99, 'hidden_sizes': [350, 150, 150, 150], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0008160435316339294, 'l2_factor': 1.9065888959087276e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.006654488259229976, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0015656912336263088, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04298588313278487, 'epochs': 10, 'exponential_factor': 0.9497457958975826, 'gamma': 0.99, 'l1_factor': 0.0008160435316339294, 'l2_factor': 1.9065888959087276e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.8, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.006654488259229976, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0015656912336263088, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04298588313278487, 'epochs': 10, 'exponential_factor': 0.9497457958975826, 'gamma': 0.99, 'l1_factor': 0.0008160435316339294, 'l2_factor': 1.9065888959087276e-06, 'minibatch_size': 128, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.006654488259229976, 'critic_lr': 0.0015656912336263088, 'decay_method': 'exponential', 'exponential_factor': 0.9497457958975826, 'value_loss_factor': 1, 'entropy': 0.04298588313278487, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0008160435316339294, 'l2_factor': 1.9065888959087276e-06, 'T': 1024, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 150, 150, 150], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 53.95594024658203\n",
      "Critic Loss: 28.75955581665039\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 101.98638153076172\n",
      "Critic Loss: 7.44581413269043\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 101.05497741699219\n",
      "Critic Loss: 0.8238664865493774\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 100.62802124023438\n",
      "Critic Loss: 6.096310138702393\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 100.40519714355469\n",
      "Critic Loss: 1.5324056148529053\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 81.2418441772461\n",
      "Critic Loss: 5.266328811645508\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 100.83792877197266\n",
      "Critic Loss: 1.9857020378112793\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 100.63851165771484\n",
      "Critic Loss: 4.023159027099609\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 100.51631927490234\n",
      "Critic Loss: 2.307936429977417\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 100.4326400756836\n",
      "Critic Loss: 4.206508636474609\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 100.37107849121094\n",
      "Critic Loss: 2.2182066440582275\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 100.32421112060547\n",
      "Critic Loss: 3.8620922565460205\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 100.28722381591797\n",
      "Critic Loss: 2.3880062103271484\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 80.53125\n",
      "Critic Loss: 3.455150604248047\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 50.17702865600586\n",
      "Critic Loss: 5.685842514038086\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 69.1009521484375\n",
      "Critic Loss: 15.318136215209961\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 69.1700439453125\n",
      "Critic Loss: 13.666642189025879\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 19.45326805114746\n",
      "Critic Loss: 20.55260467529297\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 34.67518997192383\n",
      "Critic Loss: 10.614631652832031\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 33.24018096923828\n",
      "Critic Loss: 10.260565757751465\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 31.872949600219727\n",
      "Critic Loss: 8.968891143798828\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 28.83266830444336\n",
      "Critic Loss: 10.055620193481445\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 27.463111877441406\n",
      "Critic Loss: 7.781133651733398\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 24.110698699951172\n",
      "Critic Loss: 9.214059829711914\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 25.950490951538086\n",
      "Critic Loss: 11.970111846923828\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 32.656822204589844\n",
      "Critic Loss: 8.987892150878906\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 26.422897338867188\n",
      "Critic Loss: 7.570248603820801\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 16.74835968017578\n",
      "Critic Loss: 8.834595680236816\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 14.001932144165039\n",
      "Critic Loss: 6.781971454620361\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 16.4705753326416\n",
      "Critic Loss: 7.051494121551514\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 13.212555885314941\n",
      "Critic Loss: 6.550008773803711\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 9.366312026977539\n",
      "Critic Loss: 9.90210247039795\n",
      "\n",
      "New best validation reward reached in update [32/200]\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 7.174145698547363\n",
      "Critic Loss: 7.085700988769531\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 3.183851480484009\n",
      "Critic Loss: 5.333322048187256\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -1.3803815841674805\n",
      "Critic Loss: 5.054694175720215\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.6820726990699768\n",
      "Critic Loss: 3.158527135848999\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.06876062601804733\n",
      "Critic Loss: 3.355578899383545\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.7839846611022949\n",
      "Critic Loss: 4.322368621826172\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 3.220252513885498\n",
      "Critic Loss: 3.9763426780700684\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.36123114824295044\n",
      "Critic Loss: 2.8343863487243652\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 4.342824459075928\n",
      "Critic Loss: 3.4998183250427246\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 6.400730133056641\n",
      "Critic Loss: 6.43731689453125\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 7.231418609619141\n",
      "Critic Loss: 7.6051249504089355\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 5.300520896911621\n",
      "Critic Loss: 5.560914039611816\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 9.567116737365723\n",
      "Critic Loss: 3.92315673828125\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.4878270626068115\n",
      "Critic Loss: 6.0926079750061035\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 3.4384520053863525\n",
      "Critic Loss: 6.468568325042725\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 8.765275001525879\n",
      "Critic Loss: 5.700687408447266\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 3.461618185043335\n",
      "Critic Loss: 6.752073287963867\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 1.2464834451675415\n",
      "Critic Loss: 2.912879228591919\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 1.2505993843078613\n",
      "Critic Loss: 6.135156631469727\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.31818968057632446\n",
      "Critic Loss: 2.678762197494507\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 1.3531131744384766\n",
      "Critic Loss: 2.76051664352417\n",
      "\n",
      "New best validation reward reached in update [53/200]\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 2.8302741050720215\n",
      "Critic Loss: 2.840177059173584\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 3.871985673904419\n",
      "Critic Loss: 2.7037031650543213\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 2.493121385574341\n",
      "Critic Loss: 6.968552112579346\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -1.6011312007904053\n",
      "Critic Loss: 5.7601118087768555\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -1.3403805494308472\n",
      "Critic Loss: 5.057268142700195\n",
      "\n",
      "New best validation reward reached in update [58/200]\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 2.568913459777832\n",
      "Critic Loss: 3.7290585041046143\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 1.8334859609603882\n",
      "Critic Loss: 5.740975379943848\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 6.486395835876465\n",
      "Critic Loss: 4.926775932312012\n",
      "\n",
      "New best validation reward reached in update [61/200]\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.19666647911071777\n",
      "Critic Loss: 6.8697967529296875\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 2.682562828063965\n",
      "Critic Loss: 4.805573463439941\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -2.8137526512145996\n",
      "Critic Loss: 5.13753080368042\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 5.020089149475098\n",
      "Critic Loss: 7.537206649780273\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 9.052802085876465\n",
      "Critic Loss: 3.87599778175354\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.01911088265478611\n",
      "Critic Loss: 6.0148606300354\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.4820566177368164\n",
      "Critic Loss: 3.654691457748413\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 6.38148307800293\n",
      "Critic Loss: 3.0187246799468994\n",
      "\n",
      "New best validation reward reached in update [69/200]\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -1.6559350490570068\n",
      "Critic Loss: 6.175309181213379\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -2.5492405891418457\n",
      "Critic Loss: 6.71537446975708\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.9056678414344788\n",
      "Critic Loss: 4.52878475189209\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 5.641268253326416\n",
      "Critic Loss: 5.876163482666016\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 7.804356575012207\n",
      "Critic Loss: 8.330268859863281\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.2199418693780899\n",
      "Critic Loss: 6.136319160461426\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.582503080368042\n",
      "Critic Loss: 8.035588264465332\n",
      "\n",
      "New best validation reward reached in update [76/200]\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -2.8758792877197266\n",
      "Critic Loss: 6.725833892822266\n",
      "\n",
      "New best validation reward reached in update [77/200]\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 2.190929889678955\n",
      "Critic Loss: 5.630555152893066\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -4.327178478240967\n",
      "Critic Loss: 7.483773708343506\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -5.368366241455078\n",
      "Critic Loss: 3.8730976581573486\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -2.9944822788238525\n",
      "Critic Loss: 7.891286373138428\n",
      "\n",
      "New best validation reward reached in update [81/200]\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -6.848454475402832\n",
      "Critic Loss: 7.6308088302612305\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -5.370452404022217\n",
      "Critic Loss: 5.9884538650512695\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -2.9272918701171875\n",
      "Critic Loss: 8.12524700164795\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -11.03066635131836\n",
      "Critic Loss: 9.356090545654297\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -13.560001373291016\n",
      "Critic Loss: 9.054786682128906\n",
      "\n",
      "New best validation reward reached in update [86/200]\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -11.074954986572266\n",
      "Critic Loss: 9.918464660644531\n",
      "\n",
      "New best validation reward reached in update [87/200]\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -13.728800773620605\n",
      "Critic Loss: 8.508062362670898\n",
      "\n",
      "New best validation reward reached in update [88/200]\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -19.978805541992188\n",
      "Critic Loss: 7.639427185058594\n",
      "\n",
      "New best validation reward reached in update [89/200]\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -20.75765609741211\n",
      "Critic Loss: 7.418447494506836\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -22.8511905670166\n",
      "Critic Loss: 5.047638416290283\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -16.24497413635254\n",
      "Critic Loss: 5.179011344909668\n",
      "\n",
      "New best validation reward reached in update [92/200]\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -18.728330612182617\n",
      "Critic Loss: 5.279336929321289\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -12.667022705078125\n",
      "Critic Loss: 6.082056999206543\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -14.162232398986816\n",
      "Critic Loss: 5.378419399261475\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -16.246353149414062\n",
      "Critic Loss: 7.4676408767700195\n",
      "\n",
      "New best validation reward reached in update [96/200]\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -17.0946102142334\n",
      "Critic Loss: 5.384120941162109\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -20.485288619995117\n",
      "Critic Loss: 5.041433334350586\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -21.32147216796875\n",
      "Critic Loss: 5.1379780769348145\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -19.083532333374023\n",
      "Critic Loss: 5.461471080780029\n",
      "\n",
      "New best validation reward reached in update [100/200]\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -20.763620376586914\n",
      "Critic Loss: 5.1551947593688965\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -17.451059341430664\n",
      "Critic Loss: 6.041350364685059\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -17.50265884399414\n",
      "Critic Loss: 6.298674583435059\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -23.896183013916016\n",
      "Critic Loss: 3.9505629539489746\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -19.422719955444336\n",
      "Critic Loss: 4.4157609939575195\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -20.734342575073242\n",
      "Critic Loss: 4.651895523071289\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -22.356998443603516\n",
      "Critic Loss: 5.062146186828613\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -21.261734008789062\n",
      "Critic Loss: 5.619275093078613\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -23.2867488861084\n",
      "Critic Loss: 3.896714210510254\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -21.42911148071289\n",
      "Critic Loss: 4.650264263153076\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -23.89988136291504\n",
      "Critic Loss: 3.468222141265869\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -19.857765197753906\n",
      "Critic Loss: 4.143501281738281\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -18.55147933959961\n",
      "Critic Loss: 6.042585849761963\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -19.074684143066406\n",
      "Critic Loss: 7.106954574584961\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -21.864376068115234\n",
      "Critic Loss: 5.147072792053223\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -18.40575408935547\n",
      "Critic Loss: 8.587775230407715\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -19.234455108642578\n",
      "Critic Loss: 6.946244239807129\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -18.011533737182617\n",
      "Critic Loss: 6.599797248840332\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -19.57941436767578\n",
      "Critic Loss: 4.858564853668213\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -13.349226951599121\n",
      "Critic Loss: 11.408110618591309\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -17.092288970947266\n",
      "Critic Loss: 7.811879634857178\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -22.326833724975586\n",
      "Critic Loss: 5.063623428344727\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -18.428712844848633\n",
      "Critic Loss: 6.156335353851318\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -18.351625442504883\n",
      "Critic Loss: 5.947332382202148\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -22.56393814086914\n",
      "Critic Loss: 6.012070655822754\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: -16.35945701599121\n",
      "Critic Loss: 9.279380798339844\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -14.991156578063965\n",
      "Critic Loss: 6.976641654968262\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -10.256688117980957\n",
      "Critic Loss: 11.910431861877441\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -12.383410453796387\n",
      "Critic Loss: 7.384059429168701\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -16.44310760498047\n",
      "Critic Loss: 8.058551788330078\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -22.940942764282227\n",
      "Critic Loss: 3.7746732234954834\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -21.37607765197754\n",
      "Critic Loss: 3.504789352416992\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -19.892345428466797\n",
      "Critic Loss: 5.278169631958008\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -19.247894287109375\n",
      "Critic Loss: 8.221123695373535\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: -19.59572982788086\n",
      "Critic Loss: 6.859147071838379\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -24.626047134399414\n",
      "Critic Loss: 4.3340935707092285\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -19.36846923828125\n",
      "Critic Loss: 6.251188278198242\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -19.513328552246094\n",
      "Critic Loss: 5.918978214263916\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: -12.361491203308105\n",
      "Critic Loss: 12.06826400756836\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -19.43875503540039\n",
      "Critic Loss: 5.165733337402344\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -18.239360809326172\n",
      "Critic Loss: 7.2576375007629395\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f669ae6c24340ed9b47290876102808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>141.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>255.2</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-18.8177</td></tr><tr><td>Loss/Critic_loss</td><td>7.25764</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.53707</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00504</td></tr><tr><td>Loss/Policy_loss</td><td>-18.79461</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-18.23936</td></tr><tr><td>Metric/Explained_variance</td><td>0.14257</td></tr><tr><td>Reward/Mean_train_reward</td><td>1.78</td></tr><tr><td>Reward/Mean_val_reward</td><td>140.59821</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>204.13394</td></tr><tr><td>global_step</td><td>141</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-87</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/sd1pl88m' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/sd1pl88m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_030632-sd1pl88m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z550fq3j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.009030073718482556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0005080864438277403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.036336246949039815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.956328476161138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0001086571790345529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.981505172140598e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_033014-z550fq3j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/z550fq3j' target=\"_blank\">helpful-sweep-88</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/z550fq3j' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/z550fq3j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.009030073718482556, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0005080864438277403, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.036336246949039815, 'epochs': 10, 'exponential_factor': 0.956328476161138, 'gamma': 0.95, 'hidden_sizes': [350, 150, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 0.0001086571790345529, 'l2_factor': 7.981505172140598e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.009030073718482556, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0005080864438277403, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.036336246949039815, 'epochs': 10, 'exponential_factor': 0.956328476161138, 'gamma': 0.95, 'l1_factor': 0.0001086571790345529, 'l2_factor': 7.981505172140598e-06, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 250], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.009030073718482556, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0005080864438277403, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.036336246949039815, 'epochs': 10, 'exponential_factor': 0.956328476161138, 'gamma': 0.95, 'l1_factor': 0.0001086571790345529, 'l2_factor': 7.981505172140598e-06, 'minibatch_size': 64, 'target_kl': 0.03, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.009030073718482556, 'critic_lr': 0.0005080864438277403, 'decay_method': 'exponential', 'exponential_factor': 0.956328476161138, 'value_loss_factor': 1, 'entropy': 0.036336246949039815, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0001086571790345529, 'l2_factor': 7.981505172140598e-06, 'T': 512, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.03, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [350, 150, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.6951353549957275\n",
      "Critic Loss: 49.49399185180664\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.20238548517227173\n",
      "Critic Loss: 16.377355575561523\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.4538798928260803\n",
      "Critic Loss: 12.760163307189941\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.0981370061635971\n",
      "Critic Loss: 88.73768615722656\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.16675247251987457\n",
      "Critic Loss: 87.524169921875\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.15801265835762024\n",
      "Critic Loss: 52.61308288574219\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.045563459396362305\n",
      "Critic Loss: 28.407840728759766\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.0274350568652153\n",
      "Critic Loss: 24.5582275390625\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.12280214577913284\n",
      "Critic Loss: 20.346113204956055\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.06511939316987991\n",
      "Critic Loss: 14.737373352050781\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.03799023479223251\n",
      "Critic Loss: 14.178934097290039\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.038407690823078156\n",
      "Critic Loss: 15.123373985290527\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.02386174350976944\n",
      "Critic Loss: 7.9878082275390625\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.0023987034801393747\n",
      "Critic Loss: 5.596835613250732\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.10658961534500122\n",
      "Critic Loss: 8.30013656616211\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.03861493617296219\n",
      "Critic Loss: 5.39865255355835\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.05933644250035286\n",
      "Critic Loss: 8.481973648071289\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.008014213293790817\n",
      "Critic Loss: 5.114602088928223\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.013152509927749634\n",
      "Critic Loss: 3.8657400608062744\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.017998933792114258\n",
      "Critic Loss: 4.150293350219727\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.07062533497810364\n",
      "Critic Loss: 5.34332275390625\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.03444117680191994\n",
      "Critic Loss: 8.232190132141113\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.00893060490489006\n",
      "Critic Loss: 5.884339332580566\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.025710193440318108\n",
      "Critic Loss: 4.309909343719482\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.058553025126457214\n",
      "Critic Loss: 7.99357795715332\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.0001502250088378787\n",
      "Critic Loss: 3.298776626586914\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.053073517978191376\n",
      "Critic Loss: 3.295203685760498\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.03017462231218815\n",
      "Critic Loss: 3.9932689666748047\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.02045663818717003\n",
      "Critic Loss: 3.3170015811920166\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.010087875649333\n",
      "Critic Loss: 4.8559794425964355\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.02417314611375332\n",
      "Critic Loss: 3.949465751647949\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.07898297160863876\n",
      "Critic Loss: 3.1085357666015625\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.025130409747362137\n",
      "Critic Loss: 6.445521831512451\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.02762988768517971\n",
      "Critic Loss: 8.026973724365234\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.017619455233216286\n",
      "Critic Loss: 3.8638525009155273\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.018134575337171555\n",
      "Critic Loss: 2.1179561614990234\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.028789782896637917\n",
      "Critic Loss: 3.1064977645874023\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.04994512349367142\n",
      "Critic Loss: 2.9400601387023926\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.011167963966727257\n",
      "Critic Loss: 4.813011169433594\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.05336245521903038\n",
      "Critic Loss: 5.091267108917236\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.049822960048913956\n",
      "Critic Loss: 5.960056304931641\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.035001009702682495\n",
      "Critic Loss: 3.7480807304382324\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.011380255222320557\n",
      "Critic Loss: 4.0660786628723145\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.02822430059313774\n",
      "Critic Loss: 3.239163875579834\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.0051824552938342094\n",
      "Critic Loss: 2.726463556289673\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.008039169944822788\n",
      "Critic Loss: 3.490684986114502\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.027500713244080544\n",
      "Critic Loss: 4.971463203430176\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.027376867830753326\n",
      "Critic Loss: 3.7400028705596924\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.0423637218773365\n",
      "Critic Loss: 4.776071071624756\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.014657245948910713\n",
      "Critic Loss: 3.6925361156463623\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.030921470373868942\n",
      "Critic Loss: 3.563206434249878\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.042622681707143784\n",
      "Critic Loss: 3.8919498920440674\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.040491752326488495\n",
      "Critic Loss: 4.608057498931885\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.013624082319438457\n",
      "Critic Loss: 4.059933185577393\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.05754159763455391\n",
      "Critic Loss: 3.1053268909454346\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.06137048080563545\n",
      "Critic Loss: 3.9486024379730225\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.05427340790629387\n",
      "Critic Loss: 6.163934707641602\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.07364906370639801\n",
      "Critic Loss: 3.821756601333618\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.0697355568408966\n",
      "Critic Loss: 4.762425899505615\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.03173579275608063\n",
      "Critic Loss: 7.15175199508667\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.03708088770508766\n",
      "Critic Loss: 3.241272449493408\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.054117459803819656\n",
      "Critic Loss: 4.689505577087402\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.03577233478426933\n",
      "Critic Loss: 4.984735012054443\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.016993587836623192\n",
      "Critic Loss: 8.844144821166992\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.035850945860147476\n",
      "Critic Loss: 4.365170955657959\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.038643959909677505\n",
      "Critic Loss: 4.563394546508789\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.037544332444667816\n",
      "Critic Loss: 2.4915361404418945\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.027512790635228157\n",
      "Critic Loss: 3.440315008163452\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.04540566727519035\n",
      "Critic Loss: 4.124724388122559\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.05054318904876709\n",
      "Critic Loss: 4.182519435882568\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.012341299094259739\n",
      "Critic Loss: 6.260205268859863\n",
      "\n",
      "New best validation reward reached in update [71/200]\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.0321057103574276\n",
      "Critic Loss: 6.581278324127197\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.010338926687836647\n",
      "Critic Loss: 5.796292304992676\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.05412772670388222\n",
      "Critic Loss: 6.830496311187744\n",
      "\n",
      "New best validation reward reached in update [74/200]\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.053131867200136185\n",
      "Critic Loss: 7.478601455688477\n",
      "\n",
      "New best validation reward reached in update [75/200]\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.01161868404597044\n",
      "Critic Loss: 8.512242317199707\n",
      "\n",
      "New best validation reward reached in update [76/200]\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.014756999909877777\n",
      "Critic Loss: 7.032711029052734\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.02476043440401554\n",
      "Critic Loss: 7.399834632873535\n",
      "\n",
      "New best validation reward reached in update [78/200]\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.04379428178071976\n",
      "Critic Loss: 3.723409652709961\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.028791608288884163\n",
      "Critic Loss: 4.547189235687256\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.0024347584694623947\n",
      "Critic Loss: 7.749042987823486\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.04432222247123718\n",
      "Critic Loss: 7.7563090324401855\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.0069414423778653145\n",
      "Critic Loss: 6.221406936645508\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.007541624363511801\n",
      "Critic Loss: 4.262073516845703\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.003224343992769718\n",
      "Critic Loss: 5.100683689117432\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.012556297704577446\n",
      "Critic Loss: 6.862398147583008\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.0003365337906870991\n",
      "Critic Loss: 3.4480044841766357\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.001935671316459775\n",
      "Critic Loss: 4.128966331481934\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.03255094215273857\n",
      "Critic Loss: 3.1635773181915283\n",
      "\n",
      "New best validation reward reached in update [89/200]\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.05738505348563194\n",
      "Critic Loss: 2.998650312423706\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.021378962323069572\n",
      "Critic Loss: 5.043645858764648\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.006202089600265026\n",
      "Critic Loss: 5.585730075836182\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.03805488348007202\n",
      "Critic Loss: 5.250627517700195\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.003234108444303274\n",
      "Critic Loss: 5.173128128051758\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.0148591548204422\n",
      "Critic Loss: 5.432521343231201\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.012194176204502583\n",
      "Critic Loss: 4.5875139236450195\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.0023284261114895344\n",
      "Critic Loss: 3.8837554454803467\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.010347029194235802\n",
      "Critic Loss: 3.437556743621826\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.012718272395431995\n",
      "Critic Loss: 3.632652759552002\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.0036924572195857763\n",
      "Critic Loss: 3.454582452774048\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.018942855298519135\n",
      "Critic Loss: 3.0561859607696533\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.0206361822783947\n",
      "Critic Loss: 3.5909457206726074\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.004661219660192728\n",
      "Critic Loss: 3.5912396907806396\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.02110079489648342\n",
      "Critic Loss: 5.079424858093262\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.01647312007844448\n",
      "Critic Loss: 5.259281158447266\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.005781637039035559\n",
      "Critic Loss: 3.0269112586975098\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.018935615196824074\n",
      "Critic Loss: 4.551254749298096\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -0.04046374559402466\n",
      "Critic Loss: 6.623085975646973\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -0.014323587529361248\n",
      "Critic Loss: 3.9313695430755615\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -0.03083912841975689\n",
      "Critic Loss: 2.526876926422119\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -0.015493998304009438\n",
      "Critic Loss: 6.448807239532471\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.030395373702049255\n",
      "Critic Loss: 3.0922865867614746\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.010034721344709396\n",
      "Critic Loss: 3.6963789463043213\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.0028628099244087934\n",
      "Critic Loss: 2.374582290649414\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -0.018561210483312607\n",
      "Critic Loss: 4.914340019226074\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -0.017073730006814003\n",
      "Critic Loss: 10.15474796295166\n",
      "\n",
      "New best validation reward reached in update [116/200]\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.018858203664422035\n",
      "Critic Loss: 4.839766502380371\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -0.013268443755805492\n",
      "Critic Loss: 3.5545175075531006\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.0039758277125656605\n",
      "Critic Loss: 5.130385398864746\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.05145479738712311\n",
      "Critic Loss: 2.853860378265381\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.01837063580751419\n",
      "Critic Loss: 3.3251724243164062\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -0.01705649122595787\n",
      "Critic Loss: 4.842471122741699\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.0054681021720170975\n",
      "Critic Loss: 8.403854370117188\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.014683231711387634\n",
      "Critic Loss: 3.263260841369629\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.0006869470234960318\n",
      "Critic Loss: 5.701156139373779\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.026983123272657394\n",
      "Critic Loss: 5.332310199737549\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -0.004206718876957893\n",
      "Critic Loss: 6.660003662109375\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -0.007042777258902788\n",
      "Critic Loss: 4.264261722564697\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -0.03279673680663109\n",
      "Critic Loss: 2.93689227104187\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.01492535974830389\n",
      "Critic Loss: 3.5625152587890625\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.0478334054350853\n",
      "Critic Loss: 2.936436891555786\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -0.0013183221453800797\n",
      "Critic Loss: 3.726470470428467\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.01575647108256817\n",
      "Critic Loss: 3.0576281547546387\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.02034800313413143\n",
      "Critic Loss: 4.361898422241211\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.00043327457387931645\n",
      "Critic Loss: 3.54067063331604\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.017652977257966995\n",
      "Critic Loss: 2.990682601928711\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -0.034800369292497635\n",
      "Critic Loss: 4.1614580154418945\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -0.028491390869021416\n",
      "Critic Loss: 3.543057918548584\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.0035889933351427317\n",
      "Critic Loss: 2.5457582473754883\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -0.001181563944555819\n",
      "Critic Loss: 4.047762393951416\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -0.03782649710774422\n",
      "Critic Loss: 7.407745361328125\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.021960163488984108\n",
      "Critic Loss: 4.882144451141357\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.023113541305065155\n",
      "Critic Loss: 5.840856552124023\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -0.0003993094142060727\n",
      "Critic Loss: 2.4960319995880127\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -0.017883598804473877\n",
      "Critic Loss: 3.5842556953430176\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: -0.01926732435822487\n",
      "Critic Loss: 2.6953916549682617\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.01338981743901968\n",
      "Critic Loss: 2.31002140045166\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.02297857776284218\n",
      "Critic Loss: 2.064554452896118\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.008889995515346527\n",
      "Critic Loss: 5.675098419189453\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.003455214900895953\n",
      "Critic Loss: 3.496072769165039\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 0.013367019593715668\n",
      "Critic Loss: 4.3415374755859375\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -0.01270078681409359\n",
      "Critic Loss: 3.697392702102661\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: -0.022156814113259315\n",
      "Critic Loss: 4.136474132537842\n",
      "\n",
      "New best validation reward reached in update [153/200]\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: -0.018836088478565216\n",
      "Critic Loss: 2.356839179992676\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: -0.0014277289155870676\n",
      "Critic Loss: 2.320587396621704\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 0.007313182111829519\n",
      "Critic Loss: 4.2173895835876465\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: -0.01871676929295063\n",
      "Critic Loss: 4.333300590515137\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 0.04051312431693077\n",
      "Critic Loss: 5.143558979034424\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: -0.005044619087129831\n",
      "Critic Loss: 2.921454906463623\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: 0.006025339476764202\n",
      "Critic Loss: 5.177825927734375\n",
      "\n",
      "Update [161/200]\n",
      "Actor Loss: -0.007891455665230751\n",
      "Critic Loss: 2.3404088020324707\n",
      "\n",
      "Update [162/200]\n",
      "Actor Loss: 0.017644381150603294\n",
      "Critic Loss: 3.02048921585083\n",
      "\n",
      "Update [163/200]\n",
      "Actor Loss: 0.006566159892827272\n",
      "Critic Loss: 2.994245767593384\n",
      "\n",
      "Update [164/200]\n",
      "Actor Loss: -0.01094913762062788\n",
      "Critic Loss: 2.0668985843658447\n",
      "\n",
      "Update [165/200]\n",
      "Actor Loss: 0.0012224734527990222\n",
      "Critic Loss: 2.774625539779663\n",
      "\n",
      "Update [166/200]\n",
      "Actor Loss: -0.044417232275009155\n",
      "Critic Loss: 3.0315093994140625\n",
      "\n",
      "Update [167/200]\n",
      "Actor Loss: -0.01373656839132309\n",
      "Critic Loss: 6.149554252624512\n",
      "\n",
      "Update [168/200]\n",
      "Actor Loss: 0.008623841218650341\n",
      "Critic Loss: 2.4180331230163574\n",
      "\n",
      "Update [169/200]\n",
      "Actor Loss: 0.002846128772944212\n",
      "Critic Loss: 6.256734371185303\n",
      "\n",
      "Update [170/200]\n",
      "Actor Loss: 0.008396281860768795\n",
      "Critic Loss: 1.76276695728302\n",
      "\n",
      "Update [171/200]\n",
      "Actor Loss: 0.01857120729982853\n",
      "Critic Loss: 3.181236982345581\n",
      "\n",
      "Update [172/200]\n",
      "Actor Loss: -0.028439316898584366\n",
      "Critic Loss: 2.621685743331909\n",
      "\n",
      "Update [173/200]\n",
      "Actor Loss: -0.02482270821928978\n",
      "Critic Loss: 2.547999382019043\n",
      "\n",
      "Update [174/200]\n",
      "Actor Loss: 0.006067486479878426\n",
      "Critic Loss: 2.3328280448913574\n",
      "\n",
      "Update [175/200]\n",
      "Actor Loss: -0.0043215625919401646\n",
      "Critic Loss: 2.7333779335021973\n",
      "\n",
      "Update [176/200]\n",
      "Actor Loss: -0.025465646758675575\n",
      "Critic Loss: 3.064908981323242\n",
      "\n",
      "Update [177/200]\n",
      "Actor Loss: -0.029267262667417526\n",
      "Critic Loss: 4.212536811828613\n",
      "\n",
      "Update [178/200]\n",
      "Actor Loss: -0.018231339752674103\n",
      "Critic Loss: 2.856231689453125\n",
      "\n",
      "Update [179/200]\n",
      "Actor Loss: 0.007847031578421593\n",
      "Critic Loss: 6.577002048492432\n",
      "\n",
      "Update [180/200]\n",
      "Actor Loss: 0.002826615469530225\n",
      "Critic Loss: 3.78952956199646\n",
      "\n",
      "Update [181/200]\n",
      "Actor Loss: -0.022588815540075302\n",
      "Critic Loss: 2.255847930908203\n",
      "\n",
      "Update [182/200]\n",
      "Actor Loss: 0.002888784045353532\n",
      "Critic Loss: 2.702873945236206\n",
      "\n",
      "Update [183/200]\n",
      "Actor Loss: -0.009697922505438328\n",
      "Critic Loss: 2.8452227115631104\n",
      "\n",
      "Update [184/200]\n",
      "Actor Loss: 0.028008490800857544\n",
      "Critic Loss: 4.288479804992676\n",
      "\n",
      "Update [185/200]\n",
      "Actor Loss: 0.0009953611297532916\n",
      "Critic Loss: 3.376891613006592\n",
      "\n",
      "Update [186/200]\n",
      "Actor Loss: -0.0073348707519471645\n",
      "Critic Loss: 2.5982980728149414\n",
      "\n",
      "Update [187/200]\n",
      "Actor Loss: -0.03582148998975754\n",
      "Critic Loss: 2.2350122928619385\n",
      "\n",
      "Update [188/200]\n",
      "Actor Loss: -0.025881733745336533\n",
      "Critic Loss: 4.469197750091553\n",
      "\n",
      "Update [189/200]\n",
      "Actor Loss: 0.007513740565627813\n",
      "Critic Loss: 8.210588455200195\n",
      "\n",
      "Update [190/200]\n",
      "Actor Loss: 0.02168053202331066\n",
      "Critic Loss: 1.9557690620422363\n",
      "\n",
      "Update [191/200]\n",
      "Actor Loss: -0.0116610461845994\n",
      "Critic Loss: 2.6196751594543457\n",
      "\n",
      "Update [192/200]\n",
      "Actor Loss: 0.024142371490597725\n",
      "Critic Loss: 2.7546727657318115\n",
      "\n",
      "Update [193/200]\n",
      "Actor Loss: -0.013349712826311588\n",
      "Critic Loss: 2.495396614074707\n",
      "\n",
      "Update [194/200]\n",
      "Actor Loss: -0.02115718275308609\n",
      "Critic Loss: 4.0277910232543945\n",
      "\n",
      "Update [195/200]\n",
      "Actor Loss: 0.03348099812865257\n",
      "Critic Loss: 5.274002552032471\n",
      "\n",
      "Update [196/200]\n",
      "Actor Loss: 0.07170315086841583\n",
      "Critic Loss: 1.874765396118164\n",
      "\n",
      "Update [197/200]\n",
      "Actor Loss: -0.010767761617898941\n",
      "Critic Loss: 4.472524642944336\n",
      "\n",
      "Update [198/200]\n",
      "Actor Loss: -0.01473899558186531\n",
      "Critic Loss: 4.158877372741699\n",
      "\n",
      "Update [199/200]\n",
      "Actor Loss: 0.028216848149895668\n",
      "Critic Loss: 2.256495714187622\n",
      "\n",
      "Update [200/200]\n",
      "Actor Loss: -0.015594800934195518\n",
      "Critic Loss: 3.7412776947021484\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a390533ec44334b093d8f692b77386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>137.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>93.9</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.04522</td></tr><tr><td>Loss/Critic_loss</td><td>3.74128</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.17656</td></tr><tr><td>Loss/KL_divergence</td><td>0.00987</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00247</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.01559</td></tr><tr><td>Metric/Explained_variance</td><td>0.90967</td></tr><tr><td>Reward/Mean_train_reward</td><td>4.8365</td></tr><tr><td>Reward/Mean_val_reward</td><td>-16.0031</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-0.981</td></tr><tr><td>global_step</td><td>200</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-sweep-88</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/z550fq3j' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/z550fq3j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_033014-z550fq3j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4hyl7x4n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0016471526238193343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0004726406677126958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.028822420523710323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9460267963755316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.00014563171845030388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.0378492374470233e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_034953-4hyl7x4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/4hyl7x4n' target=\"_blank\">crimson-sweep-89</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/4hyl7x4n' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/4hyl7x4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0016471526238193343, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004726406677126958, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.028822420523710323, 'epochs': 10, 'exponential_factor': 0.9460267963755316, 'gamma': 0.99, 'hidden_sizes': [350, 150, 150, 150], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.00014563171845030388, 'l2_factor': 2.0378492374470233e-06, 'lrelu': 0.001, 'minibatch_size': 64, 'momentum': 0.8, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0016471526238193343, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004726406677126958, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.028822420523710323, 'epochs': 10, 'exponential_factor': 0.9460267963755316, 'gamma': 0.99, 'l1_factor': 0.00014563171845030388, 'l2_factor': 2.0378492374470233e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150, 150, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.001, 'bn': False, 'momentum': 0.8, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0016471526238193343, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0004726406677126958, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.028822420523710323, 'epochs': 10, 'exponential_factor': 0.9460267963755316, 'gamma': 0.99, 'l1_factor': 0.00014563171845030388, 'l2_factor': 2.0378492374470233e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0016471526238193343, 'critic_lr': 0.0004726406677126958, 'decay_method': 'exponential', 'exponential_factor': 0.9460267963755316, 'value_loss_factor': 1, 'entropy': 0.028822420523710323, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.00014563171845030388, 'l2_factor': 2.0378492374470233e-06, 'T': 256, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 150, 150, 150], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.8, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 46.831905364990234\n",
      "Critic Loss: 37.433128356933594\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 73.89745330810547\n",
      "Critic Loss: 13.178135871887207\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 74.05294036865234\n",
      "Critic Loss: 11.785341262817383\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 25.45298194885254\n",
      "Critic Loss: 7.387448310852051\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 78.33396911621094\n",
      "Critic Loss: 9.39883041381836\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 67.4214859008789\n",
      "Critic Loss: 10.157848358154297\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 78.98754119873047\n",
      "Critic Loss: 12.143806457519531\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 69.18429565429688\n",
      "Critic Loss: 7.078412055969238\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 71.51903533935547\n",
      "Critic Loss: 9.1696138381958\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 69.20738220214844\n",
      "Critic Loss: 8.007820129394531\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 72.90608215332031\n",
      "Critic Loss: 8.711935043334961\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 70.33869934082031\n",
      "Critic Loss: 8.08047103881836\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 72.64542388916016\n",
      "Critic Loss: 6.085257053375244\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 73.1846694946289\n",
      "Critic Loss: 5.611847400665283\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 68.70062255859375\n",
      "Critic Loss: 6.1514058113098145\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 74.42510986328125\n",
      "Critic Loss: 5.957309722900391\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 71.69071960449219\n",
      "Critic Loss: 4.984891891479492\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 76.09556579589844\n",
      "Critic Loss: 4.688647270202637\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 68.6148681640625\n",
      "Critic Loss: 3.4788966178894043\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 68.45221710205078\n",
      "Critic Loss: 4.727819442749023\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 71.83124542236328\n",
      "Critic Loss: 3.308955192565918\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 68.34773254394531\n",
      "Critic Loss: 3.542541742324829\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 67.05960845947266\n",
      "Critic Loss: 2.6330738067626953\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 67.84317779541016\n",
      "Critic Loss: 3.2704551219940186\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 68.3450698852539\n",
      "Critic Loss: 3.5277786254882812\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 70.93909454345703\n",
      "Critic Loss: 3.2255282402038574\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 73.5601806640625\n",
      "Critic Loss: 2.9334733486175537\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 68.17821502685547\n",
      "Critic Loss: 3.1003165245056152\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 68.81101989746094\n",
      "Critic Loss: 4.316684722900391\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 73.01395416259766\n",
      "Critic Loss: 3.179666519165039\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 69.71784973144531\n",
      "Critic Loss: 2.379415988922119\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 70.8884048461914\n",
      "Critic Loss: 2.409398317337036\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 71.57141876220703\n",
      "Critic Loss: 2.4932689666748047\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb427056ec224316ab7c83dbb90c752d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>âââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>âââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>18.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>18.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00028</td></tr><tr><td>Learning_rate/Critic</td><td>8e-05</td></tr><tr><td>Loss/Actor_loss</td><td>70.88287</td></tr><tr><td>Loss/Critic_loss</td><td>2.49327</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.0</td></tr><tr><td>Loss/KL_divergence</td><td>0.0</td></tr><tr><td>Loss/Policy_loss</td><td>70.88287</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>71.57142</td></tr><tr><td>Metric/Explained_variance</td><td>0.83948</td></tr><tr><td>Reward/Mean_train_reward</td><td>-93.863</td></tr><tr><td>Reward/Mean_val_reward</td><td>-93.863</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-93.85261</td></tr><tr><td>global_step</td><td>33</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-89</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/4hyl7x4n' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/4hyl7x4n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_034953-4hyl7x4n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tgo2grkx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0012148203300319407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.007967818922842752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03417704927241633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9484429329144144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.66160526562478e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 5.444665603148154e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_035131-tgo2grkx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/tgo2grkx' target=\"_blank\">colorful-sweep-90</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/tgo2grkx' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/tgo2grkx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.0012148203300319407, 'adv_std': False, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007967818922842752, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03417704927241633, 'epochs': 10, 'exponential_factor': 0.9484429329144144, 'gamma': 0.99, 'hidden_sizes': [250, 350, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 3.66160526562478e-05, 'l2_factor': 5.444665603148154e-06, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0012148203300319407, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007967818922842752, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03417704927241633, 'epochs': 10, 'exponential_factor': 0.9484429329144144, 'gamma': 0.99, 'l1_factor': 3.66160526562478e-05, 'l2_factor': 5.444665603148154e-06, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 350], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0012148203300319407, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.007967818922842752, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03417704927241633, 'epochs': 10, 'exponential_factor': 0.9484429329144144, 'gamma': 0.99, 'l1_factor': 3.66160526562478e-05, 'l2_factor': 5.444665603148154e-06, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0012148203300319407, 'critic_lr': 0.007967818922842752, 'decay_method': 'exponential', 'exponential_factor': 0.9484429329144144, 'value_loss_factor': 1, 'entropy': 0.03417704927241633, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.66160526562478e-05, 'l2_factor': 5.444665603148154e-06, 'T': 1024, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0, 'hidden_sizes': [250, 350, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 50.621463775634766\n",
      "Critic Loss: 27.52054214477539\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 68.09286499023438\n",
      "Critic Loss: 5.177395820617676\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 77.04473114013672\n",
      "Critic Loss: 1.26787531375885\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 70.43550109863281\n",
      "Critic Loss: 3.513150215148926\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 77.61846923828125\n",
      "Critic Loss: 0.2657269835472107\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 73.32814025878906\n",
      "Critic Loss: 1.0355942249298096\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 70.671142578125\n",
      "Critic Loss: 0.10512488335371017\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 70.83209991455078\n",
      "Critic Loss: 0.34634917974472046\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 74.75051879882812\n",
      "Critic Loss: 0.10263847559690475\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 70.85948944091797\n",
      "Critic Loss: 1.477111577987671\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 72.46269226074219\n",
      "Critic Loss: 0.23478591442108154\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 71.39237213134766\n",
      "Critic Loss: 0.11870260536670685\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 68.10970306396484\n",
      "Critic Loss: 2.3617186546325684\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 78.40325927734375\n",
      "Critic Loss: 0.26524826884269714\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 69.76810455322266\n",
      "Critic Loss: 0.13649094104766846\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 69.13473510742188\n",
      "Critic Loss: 4.438198566436768\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 61.20358657836914\n",
      "Critic Loss: 0.24219588935375214\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 46.41957092285156\n",
      "Critic Loss: 56.4720458984375\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 61.43996047973633\n",
      "Critic Loss: 0.2992042601108551\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 41.456153869628906\n",
      "Critic Loss: 0.1187366396188736\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 50.84317398071289\n",
      "Critic Loss: 0.3111976981163025\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 41.252471923828125\n",
      "Critic Loss: 0.5017685890197754\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 48.195072174072266\n",
      "Critic Loss: 0.07962919026613235\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 41.87847137451172\n",
      "Critic Loss: 0.4557391405105591\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 40.833072662353516\n",
      "Critic Loss: 1.3596199750900269\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 49.89036178588867\n",
      "Critic Loss: 0.3397845923900604\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 46.76211166381836\n",
      "Critic Loss: 0.8273680806159973\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 54.18123245239258\n",
      "Critic Loss: 0.7963684797286987\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 42.959835052490234\n",
      "Critic Loss: 1.29482102394104\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 45.01730728149414\n",
      "Critic Loss: 0.45837146043777466\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 42.566837310791016\n",
      "Critic Loss: 1.2605026960372925\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 49.36713409423828\n",
      "Critic Loss: 0.38299107551574707\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 48.83888626098633\n",
      "Critic Loss: 3.358246326446533\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 52.31916809082031\n",
      "Critic Loss: 0.5577257871627808\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 43.69818115234375\n",
      "Critic Loss: 0.7596603631973267\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 44.080604553222656\n",
      "Critic Loss: 0.5955448150634766\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 49.215797424316406\n",
      "Critic Loss: 2.304020404815674\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 56.56170654296875\n",
      "Critic Loss: 0.49579566717147827\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 52.38920211791992\n",
      "Critic Loss: 0.22937344014644623\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 49.483699798583984\n",
      "Critic Loss: 0.09170129895210266\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 34.70879364013672\n",
      "Critic Loss: 0.2345322072505951\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 57.58277130126953\n",
      "Critic Loss: 22.61893653869629\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 35.06462860107422\n",
      "Critic Loss: 4.851121425628662\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 39.79385757446289\n",
      "Critic Loss: 9.690975189208984\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 33.9100456237793\n",
      "Critic Loss: 5.391244411468506\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 20.678363800048828\n",
      "Critic Loss: 6.611214637756348\n",
      "\n",
      "New best validation reward reached in update [46/200]\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 26.609251022338867\n",
      "Critic Loss: 3.498194932937622\n",
      "\n",
      "New best validation reward reached in update [47/200]\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 8.384376525878906\n",
      "Critic Loss: 3.086371421813965\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 18.186899185180664\n",
      "Critic Loss: 5.045049667358398\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 22.480571746826172\n",
      "Critic Loss: 2.7231595516204834\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 10.119051933288574\n",
      "Critic Loss: 4.233863830566406\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.9478132724761963\n",
      "Critic Loss: 7.183645248413086\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 13.28537368774414\n",
      "Critic Loss: 7.625140190124512\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 12.962151527404785\n",
      "Critic Loss: 4.997177600860596\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 8.096183776855469\n",
      "Critic Loss: 9.18257999420166\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 22.771997451782227\n",
      "Critic Loss: 6.125278949737549\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 16.800294876098633\n",
      "Critic Loss: 8.892343521118164\n",
      "\n",
      "New best validation reward reached in update [57/200]\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 27.214256286621094\n",
      "Critic Loss: 6.172890663146973\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 21.411731719970703\n",
      "Critic Loss: 13.751855850219727\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 12.050793647766113\n",
      "Critic Loss: 6.241672515869141\n",
      "\n",
      "New best validation reward reached in update [60/200]\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 1.8247685432434082\n",
      "Critic Loss: 3.917696237564087\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 1.5624415874481201\n",
      "Critic Loss: 4.613071441650391\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 4.072354316711426\n",
      "Critic Loss: 4.1271162033081055\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -5.253272533416748\n",
      "Critic Loss: 4.149543762207031\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 2.7707128524780273\n",
      "Critic Loss: 3.9959516525268555\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 6.10081672668457\n",
      "Critic Loss: 1.8938068151474\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -4.217185020446777\n",
      "Critic Loss: 1.6627216339111328\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 5.915238857269287\n",
      "Critic Loss: 2.9666988849639893\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.5165096521377563\n",
      "Critic Loss: 2.725693941116333\n",
      "\n",
      "New best validation reward reached in update [69/200]\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -1.3087598085403442\n",
      "Critic Loss: 2.333162546157837\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 11.784948348999023\n",
      "Critic Loss: 1.5960168838500977\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 11.63116455078125\n",
      "Critic Loss: 3.771881103515625\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 1.3771380186080933\n",
      "Critic Loss: 3.027982234954834\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -2.5970728397369385\n",
      "Critic Loss: 2.0893659591674805\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 6.266565799713135\n",
      "Critic Loss: 3.5967960357666016\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -5.227743625640869\n",
      "Critic Loss: 1.5911198854446411\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -2.05023455619812\n",
      "Critic Loss: 2.034247875213623\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.9802334904670715\n",
      "Critic Loss: 7.285163879394531\n",
      "\n",
      "New best validation reward reached in update [78/200]\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 1.2798714637756348\n",
      "Critic Loss: 2.2850911617279053\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.4643220901489258\n",
      "Critic Loss: 2.1670353412628174\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -5.080427169799805\n",
      "Critic Loss: 1.5296039581298828\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 2.2916815280914307\n",
      "Critic Loss: 4.687933444976807\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.07814162969589233\n",
      "Critic Loss: 3.184201717376709\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -1.9989837408065796\n",
      "Critic Loss: 2.1392557621002197\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.9179198145866394\n",
      "Critic Loss: 4.179719924926758\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.6069480776786804\n",
      "Critic Loss: 2.5108225345611572\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 1.4769115447998047\n",
      "Critic Loss: 8.28396987915039\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 2.0382676124572754\n",
      "Critic Loss: 5.386770248413086\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 8.069626808166504\n",
      "Critic Loss: 1.5636680126190186\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 2.955441474914551\n",
      "Critic Loss: 2.4836530685424805\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -7.25807523727417\n",
      "Critic Loss: 1.9491099119186401\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 5.16262149810791\n",
      "Critic Loss: 2.5168395042419434\n",
      "\n",
      "New best validation reward reached in update [92/200]\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 2.704639196395874\n",
      "Critic Loss: 3.5390191078186035\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.768622100353241\n",
      "Critic Loss: 4.142735481262207\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 11.704821586608887\n",
      "Critic Loss: 2.658174991607666\n",
      "\n",
      "New best validation reward reached in update [95/200]\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -3.8561043739318848\n",
      "Critic Loss: 3.0919787883758545\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 4.015052318572998\n",
      "Critic Loss: 4.286745071411133\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 5.673766136169434\n",
      "Critic Loss: 7.633757591247559\n",
      "\n",
      "New best validation reward reached in update [98/200]\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -2.6750648021698\n",
      "Critic Loss: 4.034720420837402\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 3.069897174835205\n",
      "Critic Loss: 2.1218435764312744\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 6.667486667633057\n",
      "Critic Loss: 4.354003429412842\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.01858363300561905\n",
      "Critic Loss: 3.7742247581481934\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.1318993717432022\n",
      "Critic Loss: 7.817653656005859\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -3.037584066390991\n",
      "Critic Loss: 4.215632438659668\n",
      "\n",
      "New best validation reward reached in update [104/200]\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 2.8816301822662354\n",
      "Critic Loss: 4.385519504547119\n",
      "\n",
      "New best validation reward reached in update [105/200]\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 4.086063385009766\n",
      "Critic Loss: 6.566702842712402\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -1.7129868268966675\n",
      "Critic Loss: 4.41560697555542\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -11.64293098449707\n",
      "Critic Loss: 2.730903387069702\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -8.276533126831055\n",
      "Critic Loss: 3.173574924468994\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 13.534937858581543\n",
      "Critic Loss: 8.431735038757324\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 2.5950684547424316\n",
      "Critic Loss: 4.508589744567871\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -11.90190601348877\n",
      "Critic Loss: 4.4451003074646\n",
      "\n",
      "New best validation reward reached in update [112/200]\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -5.144224643707275\n",
      "Critic Loss: 5.008752346038818\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -23.539918899536133\n",
      "Critic Loss: 12.924173355102539\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -8.906355857849121\n",
      "Critic Loss: 5.803128719329834\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 6.534030437469482\n",
      "Critic Loss: 3.200547933578491\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -6.28817892074585\n",
      "Critic Loss: 4.278076171875\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -9.63167667388916\n",
      "Critic Loss: 7.358375072479248\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -9.331243515014648\n",
      "Critic Loss: 4.68693733215332\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -19.253446578979492\n",
      "Critic Loss: 10.558051109313965\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -17.960554122924805\n",
      "Critic Loss: 4.503495693206787\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -32.130367279052734\n",
      "Critic Loss: 13.58739948272705\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -17.083768844604492\n",
      "Critic Loss: 11.093156814575195\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -3.734743118286133\n",
      "Critic Loss: 7.1636152267456055\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -14.745772361755371\n",
      "Critic Loss: 8.960683822631836\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: -8.434123992919922\n",
      "Critic Loss: 4.047764778137207\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -14.687655448913574\n",
      "Critic Loss: 11.159056663513184\n",
      "\n",
      "New best validation reward reached in update [127/200]\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -26.134199142456055\n",
      "Critic Loss: 8.297138214111328\n",
      "\n",
      "New best validation reward reached in update [128/200]\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -16.893783569335938\n",
      "Critic Loss: 8.480853080749512\n",
      "\n",
      "New best validation reward reached in update [129/200]\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -11.067482948303223\n",
      "Critic Loss: 6.234839916229248\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -24.14134979248047\n",
      "Critic Loss: 6.690616607666016\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -22.818639755249023\n",
      "Critic Loss: 2.6580708026885986\n",
      "\n",
      "New best validation reward reached in update [132/200]\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -15.13861083984375\n",
      "Critic Loss: 1.8552769422531128\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -21.963842391967773\n",
      "Critic Loss: 1.99916672706604\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: -20.417739868164062\n",
      "Critic Loss: 8.314497947692871\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -11.553348541259766\n",
      "Critic Loss: 7.298853397369385\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -29.59158706665039\n",
      "Critic Loss: 15.273515701293945\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -15.032941818237305\n",
      "Critic Loss: 8.507807731628418\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: -16.608190536499023\n",
      "Critic Loss: 6.329895973205566\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -25.02570343017578\n",
      "Critic Loss: 4.511036396026611\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -28.363191604614258\n",
      "Critic Loss: 7.67802619934082\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: -34.8372688293457\n",
      "Critic Loss: 7.929004669189453\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -30.908050537109375\n",
      "Critic Loss: 8.309067726135254\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -8.649900436401367\n",
      "Critic Loss: 8.579304695129395\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -9.369440078735352\n",
      "Critic Loss: 7.405825614929199\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: -29.925989151000977\n",
      "Critic Loss: 13.062321662902832\n",
      "\n",
      "New best validation reward reached in update [146/200]\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: -15.76986026763916\n",
      "Critic Loss: 10.901458740234375\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: -20.590471267700195\n",
      "Critic Loss: 4.6555328369140625\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: -4.251469135284424\n",
      "Critic Loss: 5.238994121551514\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: -25.74541664123535\n",
      "Critic Loss: 10.347197532653809\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: -13.415470123291016\n",
      "Critic Loss: 5.606849670410156\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -19.381433486938477\n",
      "Critic Loss: 4.785190582275391\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: -19.516958236694336\n",
      "Critic Loss: 5.028666973114014\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: -18.82744026184082\n",
      "Critic Loss: 8.64598560333252\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: -28.396411895751953\n",
      "Critic Loss: 2.719155788421631\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: -23.50627899169922\n",
      "Critic Loss: 9.606325149536133\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: -15.779915809631348\n",
      "Critic Loss: 7.98775053024292\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: -27.649747848510742\n",
      "Critic Loss: 7.093451499938965\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 1.3301641941070557\n",
      "Critic Loss: 12.185454368591309\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: -15.776084899902344\n",
      "Critic Loss: 8.487648010253906\n",
      "\n",
      "Update [161/200]\n",
      "Actor Loss: -12.68777847290039\n",
      "Critic Loss: 5.701972007751465\n",
      "\n",
      "Update [162/200]\n",
      "Actor Loss: -13.328763008117676\n",
      "Critic Loss: 6.153705596923828\n",
      "\n",
      "Update [163/200]\n",
      "Actor Loss: -20.44373321533203\n",
      "Critic Loss: 3.969371795654297\n",
      "\n",
      "Update [164/200]\n",
      "Actor Loss: -32.114688873291016\n",
      "Critic Loss: 9.96074104309082\n",
      "\n",
      "Update [165/200]\n",
      "Actor Loss: -23.435409545898438\n",
      "Critic Loss: 4.588235855102539\n",
      "\n",
      "Update [166/200]\n",
      "Actor Loss: -27.810420989990234\n",
      "Critic Loss: 8.186214447021484\n",
      "\n",
      "Update [167/200]\n",
      "Actor Loss: -24.52644920349121\n",
      "Critic Loss: 3.2237539291381836\n",
      "\n",
      "Update [168/200]\n",
      "Actor Loss: -22.9503231048584\n",
      "Critic Loss: 5.755589008331299\n",
      "\n",
      "Update [169/200]\n",
      "Actor Loss: -42.08226776123047\n",
      "Critic Loss: 18.706600189208984\n",
      "\n",
      "Update [170/200]\n",
      "Actor Loss: -12.956113815307617\n",
      "Critic Loss: 7.570357799530029\n",
      "\n",
      "Update [171/200]\n",
      "Actor Loss: -16.467567443847656\n",
      "Critic Loss: 11.183013916015625\n",
      "\n",
      "Update [172/200]\n",
      "Actor Loss: -14.52687931060791\n",
      "Critic Loss: 12.689449310302734\n",
      "\n",
      "Update [173/200]\n",
      "Actor Loss: -23.9914493560791\n",
      "Critic Loss: 8.416502952575684\n",
      "\n",
      "Update [174/200]\n",
      "Actor Loss: -25.915430068969727\n",
      "Critic Loss: 3.5866801738739014\n",
      "\n",
      "Update [175/200]\n",
      "Actor Loss: -25.346742630004883\n",
      "Critic Loss: 9.982185363769531\n",
      "\n",
      "Update [176/200]\n",
      "Actor Loss: -12.841618537902832\n",
      "Critic Loss: 6.651303768157959\n",
      "\n",
      "Update [177/200]\n",
      "Actor Loss: -22.96807861328125\n",
      "Critic Loss: 6.208396911621094\n",
      "\n",
      "Update [178/200]\n",
      "Actor Loss: -13.419514656066895\n",
      "Critic Loss: 7.685871601104736\n",
      "\n",
      "Update [179/200]\n",
      "Actor Loss: -27.507427215576172\n",
      "Critic Loss: 16.149150848388672\n",
      "\n",
      "Update [180/200]\n",
      "Actor Loss: -23.8165283203125\n",
      "Critic Loss: 2.0996108055114746\n",
      "\n",
      "Update [181/200]\n",
      "Actor Loss: -7.562816143035889\n",
      "Critic Loss: 8.523263931274414\n",
      "\n",
      "Update [182/200]\n",
      "Actor Loss: -24.847267150878906\n",
      "Critic Loss: 5.9799485206604\n",
      "\n",
      "Update [183/200]\n",
      "Actor Loss: -20.911821365356445\n",
      "Critic Loss: 5.385615348815918\n",
      "\n",
      "Update [184/200]\n",
      "Actor Loss: -25.94389533996582\n",
      "Critic Loss: 11.12891960144043\n",
      "\n",
      "Update [185/200]\n",
      "Actor Loss: -13.296104431152344\n",
      "Critic Loss: 5.383617877960205\n",
      "\n",
      "Update [186/200]\n",
      "Actor Loss: -33.46318435668945\n",
      "Critic Loss: 13.798823356628418\n",
      "\n",
      "Update [187/200]\n",
      "Actor Loss: -17.876720428466797\n",
      "Critic Loss: 6.516297340393066\n",
      "\n",
      "Update [188/200]\n",
      "Actor Loss: -9.398909568786621\n",
      "Critic Loss: 12.506608963012695\n",
      "\n",
      "Update [189/200]\n",
      "Actor Loss: -17.244491577148438\n",
      "Critic Loss: 5.3141560554504395\n",
      "\n",
      "Update [190/200]\n",
      "Actor Loss: -14.684017181396484\n",
      "Critic Loss: 5.223964691162109\n",
      "\n",
      "Update [191/200]\n",
      "Actor Loss: -8.213383674621582\n",
      "Critic Loss: 10.124271392822266\n",
      "\n",
      "Update [192/200]\n",
      "Actor Loss: -23.17024040222168\n",
      "Critic Loss: 7.152749538421631\n",
      "\n",
      "Update [193/200]\n",
      "Actor Loss: -27.76943016052246\n",
      "Critic Loss: 6.4336676597595215\n",
      "\n",
      "Update [194/200]\n",
      "Actor Loss: -25.368873596191406\n",
      "Critic Loss: 4.758704662322998\n",
      "\n",
      "Update [195/200]\n",
      "Actor Loss: -9.992263793945312\n",
      "Critic Loss: 6.729823589324951\n",
      "\n",
      "Update [196/200]\n",
      "Actor Loss: -23.15918731689453\n",
      "Critic Loss: 5.813137531280518\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c72f91c6e93497cad6faf8391d4bc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>289.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>244.89999</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-23.21521</td></tr><tr><td>Loss/Critic_loss</td><td>5.81314</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.7188</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00013</td></tr><tr><td>Loss/Policy_loss</td><td>-23.19064</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-23.15919</td></tr><tr><td>Metric/Explained_variance</td><td>0.10758</td></tr><tr><td>Reward/Mean_train_reward</td><td>360.84799</td></tr><tr><td>Reward/Mean_val_reward</td><td>189.4319</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>164.7536</td></tr><tr><td>global_step</td><td>196</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-sweep-90</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/tgo2grkx' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/tgo2grkx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_035131-tgo2grkx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4dlj2pl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.002613511253353624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0014613079023404385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.024549175124887367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9100960325350222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 250, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 8.809835747837358e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.2090590696316883e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_042848-z4dlj2pl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/z4dlj2pl' target=\"_blank\">pious-sweep-91</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/z4dlj2pl' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/z4dlj2pl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.002613511253353624, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0014613079023404385, 'decay_method': 'exponential', 'dropout_prob': 0, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024549175124887367, 'epochs': 10, 'exponential_factor': 0.9100960325350222, 'gamma': 0.9, 'hidden_sizes': [250, 250, 350, 250], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 8.809835747837358e-06, 'l2_factor': 2.2090590696316883e-05, 'lrelu': 0.1, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 350, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.002613511253353624, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0014613079023404385, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024549175124887367, 'epochs': 10, 'exponential_factor': 0.9100960325350222, 'gamma': 0.9, 'l1_factor': 8.809835747837358e-06, 'l2_factor': 2.2090590696316883e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 350, 250], 'output_size': 6, 'dropout_prob': 0, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.002613511253353624, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0014613079023404385, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024549175124887367, 'epochs': 10, 'exponential_factor': 0.9100960325350222, 'gamma': 0.9, 'l1_factor': 8.809835747837358e-06, 'l2_factor': 2.2090590696316883e-05, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.002613511253353624, 'critic_lr': 0.0014613079023404385, 'decay_method': 'exponential', 'exponential_factor': 0.9100960325350222, 'value_loss_factor': 1, 'entropy': 0.024549175124887367, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 8.809835747837358e-06, 'l2_factor': 2.2090590696316883e-05, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0, 'hidden_sizes': [250, 250, 350, 250], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.15120011568069458\n",
      "Critic Loss: 11.300568580627441\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.18309707939624786\n",
      "Critic Loss: 12.282255172729492\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.14306741952896118\n",
      "Critic Loss: 18.40395736694336\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.1412217617034912\n",
      "Critic Loss: 11.370087623596191\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.04132428020238876\n",
      "Critic Loss: 7.137781143188477\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.1169743537902832\n",
      "Critic Loss: 5.811367511749268\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.11065809428691864\n",
      "Critic Loss: 7.348701477050781\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.011325350031256676\n",
      "Critic Loss: 4.383060932159424\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.07509675621986389\n",
      "Critic Loss: 5.391623497009277\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.013343600556254387\n",
      "Critic Loss: 3.357132911682129\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.014347359538078308\n",
      "Critic Loss: 5.4297614097595215\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.1026480495929718\n",
      "Critic Loss: 3.964954376220703\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.029768940061330795\n",
      "Critic Loss: 2.2601590156555176\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.003088429570198059\n",
      "Critic Loss: 1.743791937828064\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.14149656891822815\n",
      "Critic Loss: 2.6619880199432373\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.0441674068570137\n",
      "Critic Loss: 1.8150190114974976\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.08587794005870819\n",
      "Critic Loss: 1.9519636631011963\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.035855937749147415\n",
      "Critic Loss: 2.108548164367676\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.04355234652757645\n",
      "Critic Loss: 2.1531929969787598\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.036875829100608826\n",
      "Critic Loss: 1.5258281230926514\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.07299759984016418\n",
      "Critic Loss: 1.8480770587921143\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.028045237064361572\n",
      "Critic Loss: 0.8974689841270447\n",
      "\n",
      "New best validation reward reached in update [22/200]\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.007959699258208275\n",
      "Critic Loss: 1.9858577251434326\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.06945739686489105\n",
      "Critic Loss: 3.4860239028930664\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.04142564535140991\n",
      "Critic Loss: 1.664905071258545\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.03471957892179489\n",
      "Critic Loss: 3.061110496520996\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.013434845954179764\n",
      "Critic Loss: 0.6619127988815308\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.004717988893389702\n",
      "Critic Loss: 1.3376044034957886\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.012287773191928864\n",
      "Critic Loss: 1.8911832571029663\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.02610798366367817\n",
      "Critic Loss: 3.2495527267456055\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.007167218253016472\n",
      "Critic Loss: 1.5847506523132324\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.019080759957432747\n",
      "Critic Loss: 1.1323506832122803\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.061086006462574005\n",
      "Critic Loss: 1.3628123998641968\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.040189728140830994\n",
      "Critic Loss: 2.5017404556274414\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.019726913422346115\n",
      "Critic Loss: 1.1956982612609863\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.0276186503469944\n",
      "Critic Loss: 1.1072943210601807\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.0051585603505373\n",
      "Critic Loss: 1.2733973264694214\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.05486796796321869\n",
      "Critic Loss: 1.0263112783432007\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.014521429315209389\n",
      "Critic Loss: 1.7659565210342407\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.04583476483821869\n",
      "Critic Loss: 1.3490679264068604\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.027939781546592712\n",
      "Critic Loss: 1.0955910682678223\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.0378214456140995\n",
      "Critic Loss: 1.7487304210662842\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.02466493286192417\n",
      "Critic Loss: 3.0329465866088867\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.004438817501068115\n",
      "Critic Loss: 2.8570728302001953\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.05518382787704468\n",
      "Critic Loss: 1.367891788482666\n",
      "\n",
      "New best validation reward reached in update [45/200]\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.03104713186621666\n",
      "Critic Loss: 1.4546334743499756\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.030371909961104393\n",
      "Critic Loss: 2.12150239944458\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.006172627210617065\n",
      "Critic Loss: 1.127079725265503\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.027394089847803116\n",
      "Critic Loss: 3.338528633117676\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.04337485879659653\n",
      "Critic Loss: 1.1911836862564087\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.009966665878891945\n",
      "Critic Loss: 3.046649932861328\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.03245500102639198\n",
      "Critic Loss: 2.248438835144043\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.0033897385001182556\n",
      "Critic Loss: 1.3377799987792969\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.05201302096247673\n",
      "Critic Loss: 1.8596687316894531\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.004124348983168602\n",
      "Critic Loss: 1.66074538230896\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.003034507855772972\n",
      "Critic Loss: 0.8724897503852844\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.02169964089989662\n",
      "Critic Loss: 1.3454713821411133\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.0144905224442482\n",
      "Critic Loss: 1.0266984701156616\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.029463618993759155\n",
      "Critic Loss: 0.7230664491653442\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.02805422805249691\n",
      "Critic Loss: 0.5880484580993652\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.04351226985454559\n",
      "Critic Loss: 2.0913493633270264\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.01952141709625721\n",
      "Critic Loss: 1.2648677825927734\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.018050668761134148\n",
      "Critic Loss: 1.5009808540344238\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.041284799575805664\n",
      "Critic Loss: 1.9190020561218262\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.016164710745215416\n",
      "Critic Loss: 2.4442732334136963\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.033935487270355225\n",
      "Critic Loss: 2.621023178100586\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.008203424513339996\n",
      "Critic Loss: 2.8303089141845703\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.029422346502542496\n",
      "Critic Loss: 1.3522666692733765\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.018997875973582268\n",
      "Critic Loss: 1.2464232444763184\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.031266286969184875\n",
      "Critic Loss: 1.1468145847320557\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.03424815088510513\n",
      "Critic Loss: 1.2310044765472412\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.03478825092315674\n",
      "Critic Loss: 0.9648566842079163\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.02790946140885353\n",
      "Critic Loss: 2.2450504302978516\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.04417404532432556\n",
      "Critic Loss: 1.1878973245620728\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.02450893074274063\n",
      "Critic Loss: 1.9281010627746582\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.045293718576431274\n",
      "Critic Loss: 2.841151714324951\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.037315547466278076\n",
      "Critic Loss: 1.6467885971069336\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.03765127807855606\n",
      "Critic Loss: 1.8372827768325806\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.03218526765704155\n",
      "Critic Loss: 1.7356441020965576\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.034027956426143646\n",
      "Critic Loss: 1.4967451095581055\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.00665663555264473\n",
      "Critic Loss: 2.3016772270202637\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.0344962552189827\n",
      "Critic Loss: 3.159330129623413\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.016189299523830414\n",
      "Critic Loss: 1.6530245542526245\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.021312735974788666\n",
      "Critic Loss: 1.764298439025879\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.029948176816105843\n",
      "Critic Loss: 2.9799346923828125\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.04363759607076645\n",
      "Critic Loss: 2.8691043853759766\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.014048824086785316\n",
      "Critic Loss: 0.9260281324386597\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.036692146211862564\n",
      "Critic Loss: 2.156825065612793\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.03380966931581497\n",
      "Critic Loss: 2.4729456901550293\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.04001590609550476\n",
      "Critic Loss: 4.7177019119262695\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.0883219838142395\n",
      "Critic Loss: 1.3660861253738403\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.014559900388121605\n",
      "Critic Loss: 5.617026329040527\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.01568443700671196\n",
      "Critic Loss: 1.359208106994629\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.013845585286617279\n",
      "Critic Loss: 2.8447210788726807\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e9a66a283546348d285f5d3083b3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>66.61539</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>73.5</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.044</td></tr><tr><td>Loss/Critic_loss</td><td>2.84472</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.03125</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00903</td></tr><tr><td>Loss/Policy_loss</td><td>-0.01868</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.01385</td></tr><tr><td>Metric/Explained_variance</td><td>0.89242</td></tr><tr><td>Reward/Mean_train_reward</td><td>-36.96516</td></tr><tr><td>Reward/Mean_val_reward</td><td>-30.9715</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-29.50647</td></tr><tr><td>global_step</td><td>94</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-91</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/z4dlj2pl' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/z4dlj2pl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_042848-z4dlj2pl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0bdereef with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0005065810029301698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00039428783418726034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.019136652397261124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8705528039868401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 250, 250, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 4.634103828323751e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.16683875319009e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_044229-0bdereef</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/0bdereef' target=\"_blank\">dashing-sweep-92</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0bdereef' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0bdereef</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0005065810029301698, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00039428783418726034, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.019136652397261124, 'epochs': 10, 'exponential_factor': 0.8705528039868401, 'gamma': 0.99, 'hidden_sizes': [350, 250, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 4.634103828323751e-06, 'l2_factor': 7.16683875319009e-05, 'lrelu': 0.01, 'minibatch_size': 32, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 250, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0005065810029301698, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00039428783418726034, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.019136652397261124, 'epochs': 10, 'exponential_factor': 0.8705528039868401, 'gamma': 0.99, 'l1_factor': 4.634103828323751e-06, 'l2_factor': 7.16683875319009e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 250, 250, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.99, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0005065810029301698, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00039428783418726034, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.019136652397261124, 'epochs': 10, 'exponential_factor': 0.8705528039868401, 'gamma': 0.99, 'l1_factor': 4.634103828323751e-06, 'l2_factor': 7.16683875319009e-05, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0005065810029301698, 'critic_lr': 0.00039428783418726034, 'decay_method': 'exponential', 'exponential_factor': 0.8705528039868401, 'value_loss_factor': 1, 'entropy': 0.019136652397261124, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 4.634103828323751e-06, 'l2_factor': 7.16683875319009e-05, 'T': 256, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 250, 250, 250], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.37779465317726135\n",
      "Critic Loss: 29.52411460876465\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.32850250601768494\n",
      "Critic Loss: 19.450511932373047\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.17413273453712463\n",
      "Critic Loss: 31.73735237121582\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.1737743616104126\n",
      "Critic Loss: 20.889097213745117\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.08273801952600479\n",
      "Critic Loss: 7.694239616394043\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.08786045759916306\n",
      "Critic Loss: 5.813220977783203\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.0912378579378128\n",
      "Critic Loss: 3.8387084007263184\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.1477697193622589\n",
      "Critic Loss: 4.065549850463867\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.09107419848442078\n",
      "Critic Loss: 7.18668794631958\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.13727372884750366\n",
      "Critic Loss: 16.69615364074707\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.2215280383825302\n",
      "Critic Loss: 18.939537048339844\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.21203401684761047\n",
      "Critic Loss: 10.952600479125977\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.15410879254341125\n",
      "Critic Loss: 8.609444618225098\n",
      "\n",
      "New best validation reward reached in update [13/200]\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.18582755327224731\n",
      "Critic Loss: 4.195062637329102\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.20852911472320557\n",
      "Critic Loss: 8.797240257263184\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.14855368435382843\n",
      "Critic Loss: 12.523885726928711\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.19413639605045319\n",
      "Critic Loss: 10.977402687072754\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.09186062216758728\n",
      "Critic Loss: 5.55832052230835\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.1740330457687378\n",
      "Critic Loss: 7.892599105834961\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.22323691844940186\n",
      "Critic Loss: 4.709086894989014\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.1652441918849945\n",
      "Critic Loss: 17.816679000854492\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.17452579736709595\n",
      "Critic Loss: 4.928222179412842\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.1349843591451645\n",
      "Critic Loss: 6.574119567871094\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.18982669711112976\n",
      "Critic Loss: 3.870159149169922\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.15259748697280884\n",
      "Critic Loss: 6.269800186157227\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.26550671458244324\n",
      "Critic Loss: 4.36905574798584\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.1264711618423462\n",
      "Critic Loss: 7.438520908355713\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.10877496004104614\n",
      "Critic Loss: 8.918035507202148\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.32545942068099976\n",
      "Critic Loss: 7.850983619689941\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.11579594016075134\n",
      "Critic Loss: 6.755125045776367\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.09782211482524872\n",
      "Critic Loss: 8.22800064086914\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.15960589051246643\n",
      "Critic Loss: 4.160009860992432\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.19686055183410645\n",
      "Critic Loss: 4.090527057647705\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.16478967666625977\n",
      "Critic Loss: 3.7559938430786133\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.13205504417419434\n",
      "Critic Loss: 2.6734378337860107\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.17953112721443176\n",
      "Critic Loss: 5.1440582275390625\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.166129469871521\n",
      "Critic Loss: 5.03709602355957\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.178270161151886\n",
      "Critic Loss: 5.709632396697998\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.13400860130786896\n",
      "Critic Loss: 3.210277557373047\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.17642539739608765\n",
      "Critic Loss: 2.6219441890716553\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.18038451671600342\n",
      "Critic Loss: 4.8031697273254395\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.1423472911119461\n",
      "Critic Loss: 7.396714210510254\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.20093753933906555\n",
      "Critic Loss: 4.2526960372924805\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.1730443835258484\n",
      "Critic Loss: 5.253421783447266\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.10352694988250732\n",
      "Critic Loss: 2.5659384727478027\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.1501137912273407\n",
      "Critic Loss: 5.905022144317627\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.12831492722034454\n",
      "Critic Loss: 4.323559284210205\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.14858980476856232\n",
      "Critic Loss: 4.068577289581299\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.24311646819114685\n",
      "Critic Loss: 3.6243369579315186\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.27654826641082764\n",
      "Critic Loss: 8.644058227539062\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.2548491358757019\n",
      "Critic Loss: 4.049014091491699\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.20182986557483673\n",
      "Critic Loss: 4.438688278198242\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.16236941516399384\n",
      "Critic Loss: 3.582991123199463\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.2098497599363327\n",
      "Critic Loss: 3.799161434173584\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.20562030375003815\n",
      "Critic Loss: 7.688649654388428\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.14734219014644623\n",
      "Critic Loss: 3.4846973419189453\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.2418903410434723\n",
      "Critic Loss: 4.721769332885742\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.24650412797927856\n",
      "Critic Loss: 5.452212810516357\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.16600626707077026\n",
      "Critic Loss: 4.4008378982543945\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.24782179296016693\n",
      "Critic Loss: 3.358523368835449\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.13284654915332794\n",
      "Critic Loss: 3.3397130966186523\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.14847828447818756\n",
      "Critic Loss: 4.430619239807129\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.15613308548927307\n",
      "Critic Loss: 3.4850094318389893\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.18678444623947144\n",
      "Critic Loss: 4.407698631286621\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.17156952619552612\n",
      "Critic Loss: 3.7973382472991943\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.2699372172355652\n",
      "Critic Loss: 3.0283901691436768\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.17901980876922607\n",
      "Critic Loss: 3.752138137817383\n",
      "\n",
      "New best validation reward reached in update [67/200]\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.19411170482635498\n",
      "Critic Loss: 3.899522542953491\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.10629810392856598\n",
      "Critic Loss: 11.856098175048828\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.21195371448993683\n",
      "Critic Loss: 16.128950119018555\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.2929559051990509\n",
      "Critic Loss: 3.967860221862793\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.8976187705993652\n",
      "Critic Loss: 6.913939476013184\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.15022847056388855\n",
      "Critic Loss: 5.420700550079346\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.145614892244339\n",
      "Critic Loss: 3.2015771865844727\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.18526318669319153\n",
      "Critic Loss: 4.672501087188721\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.13862478733062744\n",
      "Critic Loss: 4.1551055908203125\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.24464967846870422\n",
      "Critic Loss: 2.569066286087036\n",
      "\n",
      "New best validation reward reached in update [77/200]\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.1411498337984085\n",
      "Critic Loss: 4.566826343536377\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.09860934317111969\n",
      "Critic Loss: 5.807702541351318\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.20893922448158264\n",
      "Critic Loss: 4.525644779205322\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.1446855366230011\n",
      "Critic Loss: 4.724767208099365\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.25018399953842163\n",
      "Critic Loss: 4.440457344055176\n",
      "\n",
      "New best validation reward reached in update [82/200]\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.14119023084640503\n",
      "Critic Loss: 3.5064473152160645\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.10866852104663849\n",
      "Critic Loss: 3.9855797290802\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.1992180049419403\n",
      "Critic Loss: 5.098318099975586\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.18099966645240784\n",
      "Critic Loss: 3.587526321411133\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.1179194301366806\n",
      "Critic Loss: 5.818721771240234\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.15925142168998718\n",
      "Critic Loss: 2.731016159057617\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.16176697611808777\n",
      "Critic Loss: 13.12051773071289\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.1191902607679367\n",
      "Critic Loss: 9.133235931396484\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.15770120918750763\n",
      "Critic Loss: 2.3716845512390137\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.19874265789985657\n",
      "Critic Loss: 3.591148853302002\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.4067663550376892\n",
      "Critic Loss: 11.022289276123047\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.22442802786827087\n",
      "Critic Loss: 9.975640296936035\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.10372047126293182\n",
      "Critic Loss: 3.173701524734497\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.16698941588401794\n",
      "Critic Loss: 5.5407915115356445\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.16741785407066345\n",
      "Critic Loss: 11.25993824005127\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.3301459550857544\n",
      "Critic Loss: 8.568266868591309\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.12299664318561554\n",
      "Critic Loss: 4.231476783752441\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.09625972807407379\n",
      "Critic Loss: 3.6865410804748535\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.23550263047218323\n",
      "Critic Loss: 4.292232513427734\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.16217169165611267\n",
      "Critic Loss: 4.86736536026001\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.286241352558136\n",
      "Critic Loss: 20.554269790649414\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.1635340452194214\n",
      "Critic Loss: 2.6698005199432373\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.20663084089756012\n",
      "Critic Loss: 5.578677654266357\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.16950947046279907\n",
      "Critic Loss: 3.9129638671875\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.1325235366821289\n",
      "Critic Loss: 4.083660125732422\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.2290879786014557\n",
      "Critic Loss: 3.1086413860321045\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.26456183195114136\n",
      "Critic Loss: 4.857511520385742\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.18771566450595856\n",
      "Critic Loss: 3.6965925693511963\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.17403259873390198\n",
      "Critic Loss: 5.824834823608398\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.14904257655143738\n",
      "Critic Loss: 3.1785888671875\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.1799071729183197\n",
      "Critic Loss: 4.938525676727295\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.177994966506958\n",
      "Critic Loss: 4.883565425872803\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.16843634843826294\n",
      "Critic Loss: 4.379350662231445\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.18600723147392273\n",
      "Critic Loss: 12.177770614624023\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9233153c84ef4bf0a760c70ff170b04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>168.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>170.2</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.03592</td></tr><tr><td>Loss/Critic_loss</td><td>12.17777</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.61377</td></tr><tr><td>Loss/KL_divergence</td><td>0.03254</td></tr><tr><td>Loss/Policy_loss</td><td>0.04767</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.18601</td></tr><tr><td>Metric/Explained_variance</td><td>0.24676</td></tr><tr><td>Reward/Mean_train_reward</td><td>-7.993</td></tr><tr><td>Reward/Mean_val_reward</td><td>7.8332</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>7.27326</td></tr><tr><td>global_step</td><td>116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dashing-sweep-92</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0bdereef' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0bdereef</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_044229-0bdereef\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ojzffjbi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0054534714479357324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0002850386939791313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0297418762920168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9723855316915349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 150, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 0.0006998240912728084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.304377440626881e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_045357-ojzffjbi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/ojzffjbi' target=\"_blank\">neat-sweep-93</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ojzffjbi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ojzffjbi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.0054534714479357324, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002850386939791313, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0297418762920168, 'epochs': 10, 'exponential_factor': 0.9723855316915349, 'gamma': 0.95, 'hidden_sizes': [250, 150, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 0.0006998240912728084, 'l2_factor': 7.304377440626881e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0054534714479357324, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002850386939791313, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0297418762920168, 'epochs': 10, 'exponential_factor': 0.9723855316915349, 'gamma': 0.95, 'l1_factor': 0.0006998240912728084, 'l2_factor': 7.304377440626881e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 150, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.0054534714479357324, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0002850386939791313, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0297418762920168, 'epochs': 10, 'exponential_factor': 0.9723855316915349, 'gamma': 0.95, 'l1_factor': 0.0006998240912728084, 'l2_factor': 7.304377440626881e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0054534714479357324, 'critic_lr': 0.0002850386939791313, 'decay_method': 'exponential', 'exponential_factor': 0.9723855316915349, 'value_loss_factor': 1, 'entropy': 0.0297418762920168, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 0.0006998240912728084, 'l2_factor': 7.304377440626881e-06, 'T': 512, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [250, 150, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 5.0705180168151855\n",
      "Critic Loss: 30.692121505737305\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 3.8486034870147705\n",
      "Critic Loss: 20.938417434692383\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 3.047020196914673\n",
      "Critic Loss: 14.642215728759766\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.5385168194770813\n",
      "Critic Loss: 6.548122406005859\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.6551867127418518\n",
      "Critic Loss: 12.979901313781738\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.18749359250068665\n",
      "Critic Loss: 8.142313003540039\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.14824765920639038\n",
      "Critic Loss: 9.732175827026367\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.09251715242862701\n",
      "Critic Loss: 12.612600326538086\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.029989847913384438\n",
      "Critic Loss: 12.02699089050293\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.03141244500875473\n",
      "Critic Loss: 13.801665306091309\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.03975318372249603\n",
      "Critic Loss: 10.501090049743652\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.023764094337821007\n",
      "Critic Loss: 15.187312126159668\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.010237570852041245\n",
      "Critic Loss: 14.412907600402832\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.010305189527571201\n",
      "Critic Loss: 15.881056785583496\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.034432899206876755\n",
      "Critic Loss: 14.272627830505371\n",
      "\n",
      "New best validation reward reached in update [15/200]\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.0028320257551968098\n",
      "Critic Loss: 12.617033958435059\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.040184397250413895\n",
      "Critic Loss: 12.91744327545166\n",
      "\n",
      "New best validation reward reached in update [17/200]\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.02779335156083107\n",
      "Critic Loss: 12.74166488647461\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.0003112929407507181\n",
      "Critic Loss: 12.64914608001709\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.00631822319701314\n",
      "Critic Loss: 11.501776695251465\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.02008666843175888\n",
      "Critic Loss: 10.327756881713867\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.015927115455269814\n",
      "Critic Loss: 7.1975998878479\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.0422293022274971\n",
      "Critic Loss: 6.591821193695068\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.009179515764117241\n",
      "Critic Loss: 7.3997907638549805\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.011410283856093884\n",
      "Critic Loss: 6.234466075897217\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.025113927200436592\n",
      "Critic Loss: 8.673558235168457\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.03617744892835617\n",
      "Critic Loss: 9.97896671295166\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.010431848466396332\n",
      "Critic Loss: 4.0050506591796875\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.008236769586801529\n",
      "Critic Loss: 8.432509422302246\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.007297135423868895\n",
      "Critic Loss: 7.201201915740967\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.00789326149970293\n",
      "Critic Loss: 6.048326015472412\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.005948695819824934\n",
      "Critic Loss: 6.052868843078613\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.008302773348987103\n",
      "Critic Loss: 5.534829139709473\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.014604760333895683\n",
      "Critic Loss: 4.842382431030273\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.0008124757441692054\n",
      "Critic Loss: 7.927059650421143\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.00317292008548975\n",
      "Critic Loss: 5.627829551696777\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.014686906710267067\n",
      "Critic Loss: 8.310955047607422\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.009364217519760132\n",
      "Critic Loss: 4.277119159698486\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.0092758284881711\n",
      "Critic Loss: 5.454909324645996\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.026653185486793518\n",
      "Critic Loss: 6.5289812088012695\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.004221814218908548\n",
      "Critic Loss: 4.818762302398682\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.00628715381026268\n",
      "Critic Loss: 4.888953685760498\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.02934264950454235\n",
      "Critic Loss: 4.236197471618652\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.024321451783180237\n",
      "Critic Loss: 7.009321689605713\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.01964634098112583\n",
      "Critic Loss: 4.682546138763428\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.0008353894809260964\n",
      "Critic Loss: 8.66996955871582\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.005140196997672319\n",
      "Critic Loss: 9.17451286315918\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.013480384834110737\n",
      "Critic Loss: 7.483245849609375\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.008332690224051476\n",
      "Critic Loss: 4.065319538116455\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.010063267312943935\n",
      "Critic Loss: 7.172288417816162\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.042960721999406815\n",
      "Critic Loss: 7.455140113830566\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.0022432547993957996\n",
      "Critic Loss: 4.752620697021484\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.012710973620414734\n",
      "Critic Loss: 13.389044761657715\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.024351364001631737\n",
      "Critic Loss: 8.993486404418945\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.007704562041908503\n",
      "Critic Loss: 6.488993167877197\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.006614013575017452\n",
      "Critic Loss: 7.147947311401367\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.002014952013269067\n",
      "Critic Loss: 4.964319229125977\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.01377387810498476\n",
      "Critic Loss: 9.47536563873291\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.008352172560989857\n",
      "Critic Loss: 4.898030757904053\n",
      "\n",
      "New best validation reward reached in update [59/200]\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.02285788208246231\n",
      "Critic Loss: 4.478579521179199\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.00485546700656414\n",
      "Critic Loss: 10.207367897033691\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.029408734291791916\n",
      "Critic Loss: 9.608377456665039\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.029899703338742256\n",
      "Critic Loss: 6.5484466552734375\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.010860771872103214\n",
      "Critic Loss: 8.399961471557617\n",
      "\n",
      "New best validation reward reached in update [64/200]\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.02357778325676918\n",
      "Critic Loss: 7.578222274780273\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.004880810156464577\n",
      "Critic Loss: 8.766925811767578\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.005978034809231758\n",
      "Critic Loss: 7.798413276672363\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.00791944283992052\n",
      "Critic Loss: 8.229421615600586\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.010354138910770416\n",
      "Critic Loss: 4.623581409454346\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.009972519241273403\n",
      "Critic Loss: 9.584704399108887\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.018310975283384323\n",
      "Critic Loss: 8.233342170715332\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.0065689850598573685\n",
      "Critic Loss: 5.9765214920043945\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.0024164514616131783\n",
      "Critic Loss: 5.601491928100586\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.005013931542634964\n",
      "Critic Loss: 5.539074897766113\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.004977550823241472\n",
      "Critic Loss: 6.256554126739502\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.007963008247315884\n",
      "Critic Loss: 5.865355014801025\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.0073660085909068584\n",
      "Critic Loss: 7.6116108894348145\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.0087635088711977\n",
      "Critic Loss: 9.297492027282715\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.026469966396689415\n",
      "Critic Loss: 6.741253852844238\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.0065957000479102135\n",
      "Critic Loss: 9.74492073059082\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.0005692963022738695\n",
      "Critic Loss: 8.820013046264648\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.010987228713929653\n",
      "Critic Loss: 6.175951957702637\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.007032306399196386\n",
      "Critic Loss: 7.382434844970703\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.019523754715919495\n",
      "Critic Loss: 6.913205623626709\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.01577104814350605\n",
      "Critic Loss: 5.699679851531982\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.016005339100956917\n",
      "Critic Loss: 6.6778244972229\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.011356547474861145\n",
      "Critic Loss: 10.828108787536621\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.0017970592016354203\n",
      "Critic Loss: 6.038912296295166\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.0021459590643644333\n",
      "Critic Loss: 9.570323944091797\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.023708360269665718\n",
      "Critic Loss: 7.378903388977051\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.010719717480242252\n",
      "Critic Loss: 6.877326011657715\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.001455030869692564\n",
      "Critic Loss: 7.859499931335449\n",
      "\n",
      "New best validation reward reached in update [92/200]\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.00025304045993834734\n",
      "Critic Loss: 4.8621063232421875\n",
      "\n",
      "New best validation reward reached in update [93/200]\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.00856342539191246\n",
      "Critic Loss: 4.313109874725342\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.0024653517175465822\n",
      "Critic Loss: 8.58465576171875\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.019981469959020615\n",
      "Critic Loss: 9.853251457214355\n",
      "\n",
      "New best validation reward reached in update [96/200]\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.031776171177625656\n",
      "Critic Loss: 7.76265811920166\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.004464501980692148\n",
      "Critic Loss: 7.44904088973999\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.007586942054331303\n",
      "Critic Loss: 1.4930100440979004\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.01951657049357891\n",
      "Critic Loss: 1.7518062591552734\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.032812248915433884\n",
      "Critic Loss: 3.8291237354278564\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.011071835644543171\n",
      "Critic Loss: 8.929706573486328\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.012804104015231133\n",
      "Critic Loss: 5.640727996826172\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.005953954998403788\n",
      "Critic Loss: 7.675725936889648\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -0.016840646043419838\n",
      "Critic Loss: 11.43529987335205\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.002753758104518056\n",
      "Critic Loss: 7.973479270935059\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.008781876415014267\n",
      "Critic Loss: 4.594238758087158\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.025126207619905472\n",
      "Critic Loss: 8.081075668334961\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -0.013729959726333618\n",
      "Critic Loss: 6.922401428222656\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -0.017899945378303528\n",
      "Critic Loss: 8.604852676391602\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -0.028556404635310173\n",
      "Critic Loss: 6.527286529541016\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.011537609621882439\n",
      "Critic Loss: 5.679457664489746\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.01634899340569973\n",
      "Critic Loss: 10.297670364379883\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -0.01529875211417675\n",
      "Critic Loss: 5.467939376831055\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -0.024114692583680153\n",
      "Critic Loss: 2.842193126678467\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.003049771301448345\n",
      "Critic Loss: 5.168514251708984\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -0.038785338401794434\n",
      "Critic Loss: 4.013912200927734\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -0.014509794302284718\n",
      "Critic Loss: 7.1782307624816895\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.027998032048344612\n",
      "Critic Loss: 11.80283260345459\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -0.011725598014891148\n",
      "Critic Loss: 11.827363014221191\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.0033364086411893368\n",
      "Critic Loss: 11.544524192810059\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.009832438081502914\n",
      "Critic Loss: 9.827786445617676\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -0.0143818911164999\n",
      "Critic Loss: 11.578770637512207\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.008511783555150032\n",
      "Critic Loss: 14.537424087524414\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -0.03148312121629715\n",
      "Critic Loss: 9.845010757446289\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: -0.004609165247529745\n",
      "Critic Loss: 11.178567886352539\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.01522542629390955\n",
      "Critic Loss: 7.980313301086426\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -0.00641336664557457\n",
      "Critic Loss: 9.450592994689941\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -0.026788199320435524\n",
      "Critic Loss: 10.006291389465332\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.015011045150458813\n",
      "Critic Loss: 15.340543746948242\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -0.01412085723131895\n",
      "Critic Loss: 11.805220603942871\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.02011759765446186\n",
      "Critic Loss: 13.430363655090332\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.023337550461292267\n",
      "Critic Loss: 16.48822021484375\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -0.01656515896320343\n",
      "Critic Loss: 11.710838317871094\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: -0.029336458072066307\n",
      "Critic Loss: 16.272689819335938\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.006068985443562269\n",
      "Critic Loss: 9.039068222045898\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.004442055709660053\n",
      "Critic Loss: 10.444380760192871\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.006791924126446247\n",
      "Critic Loss: 12.476552963256836\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: -0.012654036283493042\n",
      "Critic Loss: 12.486985206604004\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.01667075790464878\n",
      "Critic Loss: 12.913318634033203\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -0.034796491265296936\n",
      "Critic Loss: 10.965656280517578\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.002994808368384838\n",
      "Critic Loss: 15.782188415527344\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.016108497977256775\n",
      "Critic Loss: 9.952709197998047\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -0.007294586859643459\n",
      "Critic Loss: 14.031898498535156\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.0009366732556372881\n",
      "Critic Loss: 9.632758140563965\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ddb6d42e92427188c1589b56dedfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>53.625</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>52.2</td></tr><tr><td>Learning_rate/Actor</td><td>0.0001</td></tr><tr><td>Learning_rate/Critic</td><td>1e-05</td></tr><tr><td>Loss/Actor_loss</td><td>-0.02219</td></tr><tr><td>Loss/Critic_loss</td><td>9.63276</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.18623</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00659</td></tr><tr><td>Loss/Policy_loss</td><td>0.01309</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.00094</td></tr><tr><td>Metric/Explained_variance</td><td>0.25022</td></tr><tr><td>Reward/Mean_train_reward</td><td>-55.26738</td></tr><tr><td>Reward/Mean_val_reward</td><td>-60.0248</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-59.51088</td></tr><tr><td>global_step</td><td>145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-93</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/ojzffjbi' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/ojzffjbi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_045357-ojzffjbi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q76kj0op with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00016671551570304475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00013174262551976423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.029382194309433982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9059728709191304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 350, 250, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.1177056547242217e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 8.132121737519819e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_050826-q76kj0op</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/q76kj0op' target=\"_blank\">hearty-sweep-94</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/q76kj0op' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/q76kj0op</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'lrelu', 'actor_lr': 0.00016671551570304475, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013174262551976423, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029382194309433982, 'epochs': 10, 'exponential_factor': 0.9059728709191304, 'gamma': 0.99, 'hidden_sizes': [350, 350, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 1.1177056547242217e-05, 'l2_factor': 8.132121737519819e-06, 'lrelu': 0.01, 'minibatch_size': 64, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00016671551570304475, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013174262551976423, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029382194309433982, 'epochs': 10, 'exponential_factor': 0.9059728709191304, 'gamma': 0.99, 'l1_factor': 1.1177056547242217e-05, 'l2_factor': 8.132121737519819e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 350, 250, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00016671551570304475, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00013174262551976423, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.029382194309433982, 'epochs': 10, 'exponential_factor': 0.9059728709191304, 'gamma': 0.99, 'l1_factor': 1.1177056547242217e-05, 'l2_factor': 8.132121737519819e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00016671551570304475, 'critic_lr': 0.00013174262551976423, 'decay_method': 'exponential', 'exponential_factor': 0.9059728709191304, 'value_loss_factor': 1, 'entropy': 0.029382194309433982, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.1177056547242217e-05, 'l2_factor': 8.132121737519819e-06, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [350, 350, 250, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.14775677025318146\n",
      "Critic Loss: 24.537919998168945\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.12026363611221313\n",
      "Critic Loss: 21.27285385131836\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.20143187046051025\n",
      "Critic Loss: 7.996350288391113\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.15470609068870544\n",
      "Critic Loss: 10.655078887939453\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.14117935299873352\n",
      "Critic Loss: 8.11064338684082\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.16127771139144897\n",
      "Critic Loss: 10.08806324005127\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.15147851407527924\n",
      "Critic Loss: 7.788259506225586\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.16745351254940033\n",
      "Critic Loss: 9.205530166625977\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.19191990792751312\n",
      "Critic Loss: 10.780716896057129\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.15440113842487335\n",
      "Critic Loss: 7.855165958404541\n",
      "\n",
      "New best validation reward reached in update [10/200]\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.1394321322441101\n",
      "Critic Loss: 8.067837715148926\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.12293726950883865\n",
      "Critic Loss: 10.183354377746582\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.15044111013412476\n",
      "Critic Loss: 9.689659118652344\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.12555740773677826\n",
      "Critic Loss: 6.674844264984131\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.1285713165998459\n",
      "Critic Loss: 5.365988731384277\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.17880211770534515\n",
      "Critic Loss: 7.127146244049072\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.18444955348968506\n",
      "Critic Loss: 8.369657516479492\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.16816198825836182\n",
      "Critic Loss: 8.916812896728516\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.1555676907300949\n",
      "Critic Loss: 6.669075012207031\n",
      "\n",
      "New best validation reward reached in update [19/200]\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.14326661825180054\n",
      "Critic Loss: 6.185214042663574\n",
      "\n",
      "New best validation reward reached in update [20/200]\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.1844136118888855\n",
      "Critic Loss: 5.101436138153076\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.23344561457633972\n",
      "Critic Loss: 9.05459976196289\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.15646864473819733\n",
      "Critic Loss: 7.079951286315918\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.17435696721076965\n",
      "Critic Loss: 6.345263481140137\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.18559743463993073\n",
      "Critic Loss: 4.610197067260742\n",
      "\n",
      "New best validation reward reached in update [25/200]\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.1761760413646698\n",
      "Critic Loss: 4.120987892150879\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.13700737059116364\n",
      "Critic Loss: 8.512114524841309\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.14638392627239227\n",
      "Critic Loss: 5.390990734100342\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.16809138655662537\n",
      "Critic Loss: 4.444933891296387\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.18883536756038666\n",
      "Critic Loss: 5.438621997833252\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.16552892327308655\n",
      "Critic Loss: 4.080445766448975\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.15701498091220856\n",
      "Critic Loss: 5.853237628936768\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.2134324163198471\n",
      "Critic Loss: 6.421782493591309\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.14605183899402618\n",
      "Critic Loss: 7.289750099182129\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.17977194488048553\n",
      "Critic Loss: 5.486705303192139\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.152445450425148\n",
      "Critic Loss: 2.804598331451416\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.17589664459228516\n",
      "Critic Loss: 3.5058155059814453\n",
      "\n",
      "New best validation reward reached in update [37/200]\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.18416687846183777\n",
      "Critic Loss: 6.008964538574219\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.13211774826049805\n",
      "Critic Loss: 5.94277811050415\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.13754062354564667\n",
      "Critic Loss: 7.745094299316406\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.16526389122009277\n",
      "Critic Loss: 5.295993328094482\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.14386600255966187\n",
      "Critic Loss: 3.9289042949676514\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.19152508676052094\n",
      "Critic Loss: 4.366293430328369\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.20831646025180817\n",
      "Critic Loss: 4.515981674194336\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.16305141150951385\n",
      "Critic Loss: 5.595391750335693\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.14688314497470856\n",
      "Critic Loss: 5.349306583404541\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.13309618830680847\n",
      "Critic Loss: 5.414132118225098\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.18840086460113525\n",
      "Critic Loss: 4.671988487243652\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.13840921223163605\n",
      "Critic Loss: 2.9749155044555664\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.17640022933483124\n",
      "Critic Loss: 5.271547317504883\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.18641158938407898\n",
      "Critic Loss: 3.800097703933716\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.18181172013282776\n",
      "Critic Loss: 4.477202415466309\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.23917268216609955\n",
      "Critic Loss: 5.169288635253906\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.1579158902168274\n",
      "Critic Loss: 4.3027448654174805\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.17401555180549622\n",
      "Critic Loss: 5.649880409240723\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.1940755397081375\n",
      "Critic Loss: 7.0836076736450195\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.18090564012527466\n",
      "Critic Loss: 3.1867167949676514\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.12249111384153366\n",
      "Critic Loss: 5.104279041290283\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.18675073981285095\n",
      "Critic Loss: 7.222964286804199\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.17411577701568604\n",
      "Critic Loss: 5.116611003875732\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.19500643014907837\n",
      "Critic Loss: 7.539436340332031\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.1773982048034668\n",
      "Critic Loss: 5.603975772857666\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.13714899122714996\n",
      "Critic Loss: 5.7515387535095215\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.17791834473609924\n",
      "Critic Loss: 11.789323806762695\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.17810393869876862\n",
      "Critic Loss: 6.4768757820129395\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.16389602422714233\n",
      "Critic Loss: 6.243832588195801\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.1378858983516693\n",
      "Critic Loss: 4.167057514190674\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.16818086802959442\n",
      "Critic Loss: 7.221216201782227\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.18205012381076813\n",
      "Critic Loss: 6.629701614379883\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.15184243023395538\n",
      "Critic Loss: 5.2105326652526855\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.18676790595054626\n",
      "Critic Loss: 5.344987392425537\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.14194892346858978\n",
      "Critic Loss: 3.0971131324768066\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.1545088142156601\n",
      "Critic Loss: 3.4250402450561523\n",
      "\n",
      "New best validation reward reached in update [73/200]\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.18059490621089935\n",
      "Critic Loss: 5.756960868835449\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.1620456874370575\n",
      "Critic Loss: 4.133879661560059\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.17609283328056335\n",
      "Critic Loss: 2.741567850112915\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.1622873842716217\n",
      "Critic Loss: 7.613611221313477\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.17762242257595062\n",
      "Critic Loss: 4.094765663146973\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.1456090807914734\n",
      "Critic Loss: 6.678954601287842\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.16538286209106445\n",
      "Critic Loss: 6.275067329406738\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.14352765679359436\n",
      "Critic Loss: 5.078924655914307\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552b5c86093d4340a34646b908cbd003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>120.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>121.3</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.05429</td></tr><tr><td>Loss/Critic_loss</td><td>5.07892</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.37655</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00329</td></tr><tr><td>Loss/Policy_loss</td><td>-0.01385</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.14353</td></tr><tr><td>Metric/Explained_variance</td><td>0.57627</td></tr><tr><td>Reward/Mean_train_reward</td><td>-1.691</td></tr><tr><td>Reward/Mean_val_reward</td><td>3.6683</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-0.10275</td></tr><tr><td>global_step</td><td>81</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-94</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/q76kj0op' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/q76kj0op</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_050826-q76kj0op\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y4zehi84 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0001625436695896466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00017691365326878136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.04277513476487068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8620759035516059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 350, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 7.3055771312428e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.529350425054039e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_052137-y4zehi84</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/y4zehi84' target=\"_blank\">fresh-sweep-95</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/y4zehi84' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/y4zehi84</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.0001625436695896466, 'adv_std': False, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017691365326878136, 'decay_method': 'exponential', 'dropout_prob': 0.2, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04277513476487068, 'epochs': 10, 'exponential_factor': 0.8620759035516059, 'gamma': 0.99, 'hidden_sizes': [150, 350, 150, 350], 'initialization': 'normal', 'input_size': 10, 'l1_factor': 7.3055771312428e-05, 'l2_factor': 3.529350425054039e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.99, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0001625436695896466, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017691365326878136, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04277513476487068, 'epochs': 10, 'exponential_factor': 0.8620759035516059, 'gamma': 0.99, 'l1_factor': 7.3055771312428e-05, 'l2_factor': 3.529350425054039e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 350, 150, 350], 'output_size': 6, 'dropout_prob': 0.2, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.99, 'initialization': 'normal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0001625436695896466, 'adv_std': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00017691365326878136, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.04277513476487068, 'epochs': 10, 'exponential_factor': 0.8620759035516059, 'gamma': 0.99, 'l1_factor': 7.3055771312428e-05, 'l2_factor': 3.529350425054039e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0001625436695896466, 'critic_lr': 0.00017691365326878136, 'decay_method': 'exponential', 'exponential_factor': 0.8620759035516059, 'value_loss_factor': 1, 'entropy': 0.04277513476487068, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 7.3055771312428e-05, 'l2_factor': 3.529350425054039e-06, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': False, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.2, 'hidden_sizes': [150, 350, 150, 350], 'initialization': 'normal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.99, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 42.93401336669922\n",
      "Critic Loss: 29.179067611694336\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 61.0601692199707\n",
      "Critic Loss: 49.98491668701172\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 29.037630081176758\n",
      "Critic Loss: 20.820476531982422\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 30.945465087890625\n",
      "Critic Loss: 24.128337860107422\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 28.118268966674805\n",
      "Critic Loss: 24.2154598236084\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 22.527667999267578\n",
      "Critic Loss: 18.093955993652344\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 18.942726135253906\n",
      "Critic Loss: 16.25563621520996\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 19.571718215942383\n",
      "Critic Loss: 14.299903869628906\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 26.399370193481445\n",
      "Critic Loss: 19.6702880859375\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 26.276674270629883\n",
      "Critic Loss: 20.706016540527344\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 25.782819747924805\n",
      "Critic Loss: 22.419355392456055\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 22.89000129699707\n",
      "Critic Loss: 19.528682708740234\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 19.970727920532227\n",
      "Critic Loss: 15.054237365722656\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 30.95995330810547\n",
      "Critic Loss: 26.499361038208008\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 23.939420700073242\n",
      "Critic Loss: 16.197429656982422\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 24.097549438476562\n",
      "Critic Loss: 16.714685440063477\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 23.352632522583008\n",
      "Critic Loss: 20.401538848876953\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 21.963348388671875\n",
      "Critic Loss: 13.36600112915039\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 17.907041549682617\n",
      "Critic Loss: 15.766444206237793\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 11.688179016113281\n",
      "Critic Loss: 10.375596046447754\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 21.975343704223633\n",
      "Critic Loss: 20.169784545898438\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 23.323530197143555\n",
      "Critic Loss: 19.645248413085938\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 14.081135749816895\n",
      "Critic Loss: 12.749066352844238\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 8.176278114318848\n",
      "Critic Loss: 8.574897766113281\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 16.788894653320312\n",
      "Critic Loss: 14.635354042053223\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 25.063446044921875\n",
      "Critic Loss: 18.188465118408203\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 16.39390754699707\n",
      "Critic Loss: 12.429465293884277\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 10.192412376403809\n",
      "Critic Loss: 11.950094223022461\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 30.366880416870117\n",
      "Critic Loss: 25.54290199279785\n",
      "\n",
      "New best validation reward reached in update [29/200]\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 24.806825637817383\n",
      "Critic Loss: 20.551246643066406\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 21.687841415405273\n",
      "Critic Loss: 16.331838607788086\n",
      "\n",
      "New best validation reward reached in update [31/200]\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 18.550518035888672\n",
      "Critic Loss: 15.291474342346191\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 18.75455665588379\n",
      "Critic Loss: 14.055632591247559\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 20.427148818969727\n",
      "Critic Loss: 18.239078521728516\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 23.040624618530273\n",
      "Critic Loss: 17.915847778320312\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 21.736522674560547\n",
      "Critic Loss: 18.2753849029541\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 4.6652512550354\n",
      "Critic Loss: 7.957889556884766\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 20.852285385131836\n",
      "Critic Loss: 18.274187088012695\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 18.321435928344727\n",
      "Critic Loss: 16.423105239868164\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 29.804367065429688\n",
      "Critic Loss: 21.226871490478516\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 17.385717391967773\n",
      "Critic Loss: 17.02914047241211\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 19.221681594848633\n",
      "Critic Loss: 17.96141815185547\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 18.168987274169922\n",
      "Critic Loss: 14.646800994873047\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 19.496360778808594\n",
      "Critic Loss: 14.99388599395752\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 17.90322494506836\n",
      "Critic Loss: 15.996826171875\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 17.399919509887695\n",
      "Critic Loss: 14.611946105957031\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 23.022010803222656\n",
      "Critic Loss: 17.538509368896484\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 18.731847763061523\n",
      "Critic Loss: 15.464051246643066\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 12.06745719909668\n",
      "Critic Loss: 9.17671012878418\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 18.21361541748047\n",
      "Critic Loss: 14.673877716064453\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 19.611515045166016\n",
      "Critic Loss: 13.160228729248047\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 9.33554744720459\n",
      "Critic Loss: 11.28597640991211\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 7.023797512054443\n",
      "Critic Loss: 9.364943504333496\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 11.757817268371582\n",
      "Critic Loss: 10.154726028442383\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 17.25603675842285\n",
      "Critic Loss: 14.351841926574707\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 16.355588912963867\n",
      "Critic Loss: 14.692676544189453\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 11.960686683654785\n",
      "Critic Loss: 9.966798782348633\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 22.798377990722656\n",
      "Critic Loss: 14.820493698120117\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 16.246734619140625\n",
      "Critic Loss: 14.64128303527832\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 13.968903541564941\n",
      "Critic Loss: 10.644129753112793\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 20.29155731201172\n",
      "Critic Loss: 16.340091705322266\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 15.595501899719238\n",
      "Critic Loss: 14.8379487991333\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51b7060c2ba41739aa1afa6e5e57210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>41.2</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>37.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>14.67965</td></tr><tr><td>Loss/Critic_loss</td><td>14.83795</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.7141</td></tr><tr><td>Loss/KL_divergence</td><td>0.00079</td></tr><tr><td>Loss/Policy_loss</td><td>14.75297</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>15.5955</td></tr><tr><td>Metric/Explained_variance</td><td>0.22239</td></tr><tr><td>Reward/Mean_train_reward</td><td>-82.9278</td></tr><tr><td>Reward/Mean_val_reward</td><td>-83.7916</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-80.6032</td></tr><tr><td>global_step</td><td>62</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-95</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/y4zehi84' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/y4zehi84</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_052137-y4zehi84\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0l8eaz23 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0002420052755556511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.00020101834771530535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.03786513383268597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.8763155602967676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [350, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 2.6913833897612094e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 8.920771445586116e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_052447-0l8eaz23</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/0l8eaz23' target=\"_blank\">confused-sweep-96</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0l8eaz23' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0l8eaz23</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'tanh', 'actor_lr': 0.0002420052755556511, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020101834771530535, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03786513383268597, 'epochs': 10, 'exponential_factor': 0.8763155602967676, 'gamma': 0.9, 'hidden_sizes': [350, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 2.6913833897612094e-06, 'l2_factor': 8.920771445586116e-05, 'lrelu': 0.001, 'minibatch_size': 256, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0002420052755556511, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020101834771530535, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03786513383268597, 'epochs': 10, 'exponential_factor': 0.8763155602967676, 'gamma': 0.9, 'l1_factor': 2.6913833897612094e-06, 'l2_factor': 8.920771445586116e-05, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [350, 150], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.001, 'bn': False, 'momentum': 0.9, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.0002420052755556511, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.00020101834771530535, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.03786513383268597, 'epochs': 10, 'exponential_factor': 0.8763155602967676, 'gamma': 0.9, 'l1_factor': 2.6913833897612094e-06, 'l2_factor': 8.920771445586116e-05, 'minibatch_size': 256, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0002420052755556511, 'critic_lr': 0.00020101834771530535, 'decay_method': 'exponential', 'exponential_factor': 0.8763155602967676, 'value_loss_factor': 1, 'entropy': 0.03786513383268597, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 2.6913833897612094e-06, 'l2_factor': 8.920771445586116e-05, 'T': 256, 'minibatch_size': 256, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [350, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.001, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: -0.056074224412441254\n",
      "Critic Loss: 15.036839485168457\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.0656067430973053\n",
      "Critic Loss: 14.992066383361816\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.025763358920812607\n",
      "Critic Loss: 7.953411102294922\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.019447557628154755\n",
      "Critic Loss: 6.725994110107422\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.024545855820178986\n",
      "Critic Loss: 11.674243927001953\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.015711143612861633\n",
      "Critic Loss: 8.731319427490234\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.025330469012260437\n",
      "Critic Loss: 12.523468017578125\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.023607369512319565\n",
      "Critic Loss: 10.139589309692383\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.020542632788419724\n",
      "Critic Loss: 8.426788330078125\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.013637233525514603\n",
      "Critic Loss: 9.567132949829102\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.017669104039669037\n",
      "Critic Loss: 9.982904434204102\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.012784406542778015\n",
      "Critic Loss: 9.999547004699707\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.013918768614530563\n",
      "Critic Loss: 10.058134078979492\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.011352095752954483\n",
      "Critic Loss: 7.826568603515625\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.01210680603981018\n",
      "Critic Loss: 7.838860988616943\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.013841874897480011\n",
      "Critic Loss: 8.156742095947266\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: -0.014093145728111267\n",
      "Critic Loss: 13.388238906860352\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.017437338829040527\n",
      "Critic Loss: 8.35969066619873\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.008679233491420746\n",
      "Critic Loss: 9.03332805633545\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.010849040001630783\n",
      "Critic Loss: 7.60128927230835\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: -0.0064847432076931\n",
      "Critic Loss: 9.865503311157227\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.008869830518960953\n",
      "Critic Loss: 8.737630844116211\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.015484549105167389\n",
      "Critic Loss: 8.508052825927734\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.011491235345602036\n",
      "Critic Loss: 6.301077842712402\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.00904509425163269\n",
      "Critic Loss: 8.629973411560059\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.009163141250610352\n",
      "Critic Loss: 8.195374488830566\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.00961904227733612\n",
      "Critic Loss: 11.621712684631348\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.011736877262592316\n",
      "Critic Loss: 9.73739242553711\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.006797861307859421\n",
      "Critic Loss: 10.418889045715332\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: -0.009717289358377457\n",
      "Critic Loss: 7.625705242156982\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.012041117995977402\n",
      "Critic Loss: 8.076156616210938\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.011227302253246307\n",
      "Critic Loss: 7.28419828414917\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.004629239439964294\n",
      "Critic Loss: 10.38672161102295\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.010434925556182861\n",
      "Critic Loss: 7.614108085632324\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: -0.010041233152151108\n",
      "Critic Loss: 8.063271522521973\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: -0.007500208914279938\n",
      "Critic Loss: 13.462533950805664\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: -0.00813743844628334\n",
      "Critic Loss: 7.142658710479736\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.012751132249832153\n",
      "Critic Loss: 7.858700752258301\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: -0.009008277207612991\n",
      "Critic Loss: 8.306535720825195\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: -0.009151145815849304\n",
      "Critic Loss: 7.317463397979736\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.009889531880617142\n",
      "Critic Loss: 7.993070602416992\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: -0.008309174329042435\n",
      "Critic Loss: 10.782154083251953\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.008566141128540039\n",
      "Critic Loss: 5.986547946929932\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.009230822324752808\n",
      "Critic Loss: 8.534028053283691\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.009915109723806381\n",
      "Critic Loss: 8.278314590454102\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: -0.005289062857627869\n",
      "Critic Loss: 10.939310073852539\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.010790705680847168\n",
      "Critic Loss: 13.916848182678223\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: -0.008501876145601273\n",
      "Critic Loss: 8.958226203918457\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.00792362168431282\n",
      "Critic Loss: 7.503625869750977\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.009643610566854477\n",
      "Critic Loss: 6.716246128082275\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: -0.013239257037639618\n",
      "Critic Loss: 7.818229675292969\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: -0.00646311417222023\n",
      "Critic Loss: 8.86074161529541\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.011314239352941513\n",
      "Critic Loss: 7.481498718261719\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.011702727526426315\n",
      "Critic Loss: 8.04346752166748\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: -0.010483525693416595\n",
      "Critic Loss: 11.072781562805176\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: -0.00655924528837204\n",
      "Critic Loss: 9.982921600341797\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.008375216275453568\n",
      "Critic Loss: 9.11176872253418\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.010631483048200607\n",
      "Critic Loss: 7.949627876281738\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.003320842981338501\n",
      "Critic Loss: 7.6283440589904785\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.006537958979606628\n",
      "Critic Loss: 5.642549991607666\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.012182708829641342\n",
      "Critic Loss: 6.341512680053711\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: -0.005147192627191544\n",
      "Critic Loss: 11.68233871459961\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.00832868367433548\n",
      "Critic Loss: 7.431904315948486\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.011269282549619675\n",
      "Critic Loss: 7.102232933044434\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.008163850754499435\n",
      "Critic Loss: 8.047815322875977\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: -0.008488450199365616\n",
      "Critic Loss: 7.9954447746276855\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.010045699775218964\n",
      "Critic Loss: 5.725225925445557\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: -0.011156752705574036\n",
      "Critic Loss: 8.30156135559082\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: -0.011604789644479752\n",
      "Critic Loss: 8.43312931060791\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: -0.008525479584932327\n",
      "Critic Loss: 8.504385948181152\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: -0.01135987788438797\n",
      "Critic Loss: 7.675970554351807\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.010874796658754349\n",
      "Critic Loss: 7.9268951416015625\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: -0.007426857948303223\n",
      "Critic Loss: 7.549493789672852\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: -0.0044935159385204315\n",
      "Critic Loss: 11.898783683776855\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: -0.008636873215436935\n",
      "Critic Loss: 7.645298004150391\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: -0.008243370801210403\n",
      "Critic Loss: 8.594575881958008\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: -0.008580207824707031\n",
      "Critic Loss: 7.550537109375\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: -0.009290650486946106\n",
      "Critic Loss: 7.497652053833008\n",
      "\n",
      "New best validation reward reached in update [78/200]\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.008616741746664047\n",
      "Critic Loss: 6.993440628051758\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: -0.008630078285932541\n",
      "Critic Loss: 11.966057777404785\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.007371675223112106\n",
      "Critic Loss: 13.318758964538574\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.006741289049386978\n",
      "Critic Loss: 8.233149528503418\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: -0.010787371546030045\n",
      "Critic Loss: 8.213784217834473\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: -0.013633456081151962\n",
      "Critic Loss: 8.229196548461914\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: -0.0056257955729961395\n",
      "Critic Loss: 8.685308456420898\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.007598474621772766\n",
      "Critic Loss: 12.932015419006348\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: -0.010099656879901886\n",
      "Critic Loss: 6.12752628326416\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: -0.011628616601228714\n",
      "Critic Loss: 7.257449150085449\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: -0.011657625436782837\n",
      "Critic Loss: 7.86278772354126\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.011369485408067703\n",
      "Critic Loss: 8.484569549560547\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: -0.008474543690681458\n",
      "Critic Loss: 7.999138355255127\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: -0.0070858001708984375\n",
      "Critic Loss: 8.841822624206543\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: -0.009414568543434143\n",
      "Critic Loss: 7.710834503173828\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.007466822862625122\n",
      "Critic Loss: 11.090537071228027\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: -0.005920883268117905\n",
      "Critic Loss: 6.921404838562012\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: -0.0053232163190841675\n",
      "Critic Loss: 8.825150489807129\n",
      "\n",
      "New best validation reward reached in update [96/200]\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: -0.007444571703672409\n",
      "Critic Loss: 11.753472328186035\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: -0.009445134550333023\n",
      "Critic Loss: 8.270830154418945\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: -0.00886811688542366\n",
      "Critic Loss: 8.3202543258667\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: -0.011037353426218033\n",
      "Critic Loss: 7.6688032150268555\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: -0.008693855255842209\n",
      "Critic Loss: 6.160402774810791\n",
      "\n",
      "New best validation reward reached in update [101/200]\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: -0.009112764149904251\n",
      "Critic Loss: 9.93802261352539\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: -0.008538823574781418\n",
      "Critic Loss: 9.633434295654297\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: -0.00982951745390892\n",
      "Critic Loss: 10.734643936157227\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: -0.008478749543428421\n",
      "Critic Loss: 8.933910369873047\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: -0.010560918599367142\n",
      "Critic Loss: 8.888914108276367\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: -0.014162037521600723\n",
      "Critic Loss: 12.923711776733398\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: -0.007528360933065414\n",
      "Critic Loss: 9.98291015625\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: -0.01072503998875618\n",
      "Critic Loss: 8.66909122467041\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: -0.009743224829435349\n",
      "Critic Loss: 5.836318016052246\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: -0.0062316469848155975\n",
      "Critic Loss: 8.779611587524414\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: -0.010892678052186966\n",
      "Critic Loss: 7.409790992736816\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: -0.014161814004182816\n",
      "Critic Loss: 10.318227767944336\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: -0.011260796338319778\n",
      "Critic Loss: 7.716529369354248\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: -0.006906930357217789\n",
      "Critic Loss: 11.704543113708496\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: -0.007213879376649857\n",
      "Critic Loss: 7.4481353759765625\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: -0.006053458899259567\n",
      "Critic Loss: 8.055084228515625\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: -0.01247287169098854\n",
      "Critic Loss: 10.09237003326416\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: -0.00391218438744545\n",
      "Critic Loss: 10.062895774841309\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: -0.00692686066031456\n",
      "Critic Loss: 8.843341827392578\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: -0.010795745998620987\n",
      "Critic Loss: 7.613910675048828\n",
      "\n",
      "New best validation reward reached in update [121/200]\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: -0.009971518069505692\n",
      "Critic Loss: 11.153281211853027\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: -0.00962313637137413\n",
      "Critic Loss: 13.847322463989258\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: -0.014653537422418594\n",
      "Critic Loss: 9.061254501342773\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: -0.007100861519575119\n",
      "Critic Loss: 11.445255279541016\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: -0.013033535331487656\n",
      "Critic Loss: 10.770490646362305\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: -0.00865459069609642\n",
      "Critic Loss: 7.826260089874268\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: -0.010588210076093674\n",
      "Critic Loss: 8.054991722106934\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: -0.01906706765294075\n",
      "Critic Loss: 7.941516399383545\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: -0.0031959302723407745\n",
      "Critic Loss: 11.152633666992188\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: -0.010746482759714127\n",
      "Critic Loss: 10.939332962036133\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -0.003291469067335129\n",
      "Critic Loss: 11.938772201538086\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: -0.0058626048266887665\n",
      "Critic Loss: 8.9407320022583\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: -0.01039331778883934\n",
      "Critic Loss: 7.607224941253662\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: -0.014424208551645279\n",
      "Critic Loss: 9.19028377532959\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: -0.011757481843233109\n",
      "Critic Loss: 9.134069442749023\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: -0.008158866316080093\n",
      "Critic Loss: 10.533798217773438\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: -0.01084008440375328\n",
      "Critic Loss: 8.53512954711914\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: -0.011723678559064865\n",
      "Critic Loss: 11.784793853759766\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: -0.009223643690347672\n",
      "Critic Loss: 7.289341449737549\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: -0.011118095368146896\n",
      "Critic Loss: 7.616903305053711\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: -0.01520291343331337\n",
      "Critic Loss: 10.005171775817871\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: -0.006891760975122452\n",
      "Critic Loss: 8.679495811462402\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: -0.00802452489733696\n",
      "Critic Loss: 8.808801651000977\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: -0.012163732200860977\n",
      "Critic Loss: 7.245574474334717\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: -0.012818720191717148\n",
      "Critic Loss: 6.968425750732422\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: -0.012080002576112747\n",
      "Critic Loss: 8.82595443725586\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: -0.013914067298173904\n",
      "Critic Loss: 11.561235427856445\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: -0.007763024419546127\n",
      "Critic Loss: 7.663183689117432\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: -0.015826035290956497\n",
      "Critic Loss: 8.571272850036621\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: -0.008017998188734055\n",
      "Critic Loss: 9.17199420928955\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: -0.010634120553731918\n",
      "Critic Loss: 8.05311107635498\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cc2ffa28e3470788aee89425dae82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>42.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>46.4</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.05991</td></tr><tr><td>Loss/Critic_loss</td><td>8.05311</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.56565</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00125</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00062</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.01063</td></tr><tr><td>Metric/Explained_variance</td><td>0.19168</td></tr><tr><td>Reward/Mean_train_reward</td><td>-71.849</td></tr><tr><td>Reward/Mean_val_reward</td><td>-63.9186</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-69.05373</td></tr><tr><td>global_step</td><td>152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-96</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/0l8eaz23' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/0l8eaz23</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_052447-0l8eaz23\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x1bhoakz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00035885936435946795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0011369456031649192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0459592267784181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9849727586449928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [150, 150, 150, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 1.068037321520035e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 2.8266716305906706e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_052945-x1bhoakz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/x1bhoakz' target=\"_blank\">vibrant-sweep-97</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/x1bhoakz' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/x1bhoakz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 256, 'activation': 'lrelu', 'actor_lr': 0.00035885936435946795, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011369456031649192, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0459592267784181, 'epochs': 10, 'exponential_factor': 0.9849727586449928, 'gamma': 0.95, 'hidden_sizes': [150, 150, 150, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 1.068037321520035e-05, 'l2_factor': 2.8266716305906706e-06, 'lrelu': 0.01, 'minibatch_size': 128, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00035885936435946795, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011369456031649192, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0459592267784181, 'epochs': 10, 'exponential_factor': 0.9849727586449928, 'gamma': 0.95, 'l1_factor': 1.068037321520035e-05, 'l2_factor': 2.8266716305906706e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [150, 150, 150, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.01, 'bn': True, 'momentum': 0.95, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 256, 'actor_lr': 0.00035885936435946795, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0011369456031649192, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0459592267784181, 'epochs': 10, 'exponential_factor': 0.9849727586449928, 'gamma': 0.95, 'l1_factor': 1.068037321520035e-05, 'l2_factor': 2.8266716305906706e-06, 'minibatch_size': 128, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00035885936435946795, 'critic_lr': 0.0011369456031649192, 'decay_method': 'exponential', 'exponential_factor': 0.9849727586449928, 'value_loss_factor': 1, 'entropy': 0.0459592267784181, 'gamma': 0.95, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 1.068037321520035e-05, 'l2_factor': 2.8266716305906706e-06, 'T': 256, 'minibatch_size': 128, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [150, 150, 150, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: -0.05091378092765808\n",
      "Critic Loss: 20.35647201538086\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.06388828903436661\n",
      "Critic Loss: 23.71050262451172\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: -0.055083852261304855\n",
      "Critic Loss: 14.845030784606934\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.029538776725530624\n",
      "Critic Loss: 9.604360580444336\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: -0.0174816083163023\n",
      "Critic Loss: 6.322795867919922\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: -0.03310053050518036\n",
      "Critic Loss: 15.578628540039062\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.0066871196031570435\n",
      "Critic Loss: 7.521461486816406\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.026607776060700417\n",
      "Critic Loss: 11.61821174621582\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.020842360332608223\n",
      "Critic Loss: 6.846469879150391\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.003799519967287779\n",
      "Critic Loss: 8.007694244384766\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.023389175534248352\n",
      "Critic Loss: 10.503216743469238\n",
      "\n",
      "New best validation reward reached in update [11/200]\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.0076479301787912846\n",
      "Critic Loss: 3.9400081634521484\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.00346044497564435\n",
      "Critic Loss: 4.713875770568848\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.026094814762473106\n",
      "Critic Loss: 8.944765090942383\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.009609563276171684\n",
      "Critic Loss: 5.500133037567139\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: -0.0075875455513596535\n",
      "Critic Loss: 5.469267845153809\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.026349596679210663\n",
      "Critic Loss: 11.199380874633789\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.0437031127512455\n",
      "Critic Loss: 5.384912014007568\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.007052948232740164\n",
      "Critic Loss: 4.670469760894775\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: -0.006710135843604803\n",
      "Critic Loss: 4.123826026916504\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.002571149729192257\n",
      "Critic Loss: 4.241500377655029\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.0025003068149089813\n",
      "Critic Loss: 3.1248042583465576\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.016180727630853653\n",
      "Critic Loss: 2.94087815284729\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.017218763008713722\n",
      "Critic Loss: 9.354256629943848\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.023109858855605125\n",
      "Critic Loss: 6.4442138671875\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.024126354604959488\n",
      "Critic Loss: 7.75601863861084\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.013749067671597004\n",
      "Critic Loss: 4.867160797119141\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.03471812605857849\n",
      "Critic Loss: 8.830123901367188\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.0010774098336696625\n",
      "Critic Loss: 1.9947729110717773\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.016308054327964783\n",
      "Critic Loss: 7.64487361907959\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: -0.004043248947709799\n",
      "Critic Loss: 3.770908832550049\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.04224180802702904\n",
      "Critic Loss: 16.19467544555664\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: -0.0030535762198269367\n",
      "Critic Loss: 7.775001525878906\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.006694222800433636\n",
      "Critic Loss: 5.572995662689209\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.01073405146598816\n",
      "Critic Loss: 3.3475680351257324\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.02576303668320179\n",
      "Critic Loss: 3.5637476444244385\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.013076674193143845\n",
      "Critic Loss: 3.583597183227539\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.005034293979406357\n",
      "Critic Loss: 4.9098029136657715\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.012159589678049088\n",
      "Critic Loss: 6.073092460632324\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.034127578139305115\n",
      "Critic Loss: 8.14959716796875\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.005674491170793772\n",
      "Critic Loss: 4.702939510345459\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.01009614858776331\n",
      "Critic Loss: 2.697237014770508\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.024792790412902832\n",
      "Critic Loss: 2.500105619430542\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.007684711832553148\n",
      "Critic Loss: 7.018337726593018\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.01191627886146307\n",
      "Critic Loss: 3.9886631965637207\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.007862146943807602\n",
      "Critic Loss: 1.4327855110168457\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.00898248702287674\n",
      "Critic Loss: 2.5092132091522217\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.00247493339702487\n",
      "Critic Loss: 3.902510166168213\n",
      "\n",
      "New best validation reward reached in update [48/200]\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: -0.002121331635862589\n",
      "Critic Loss: 4.729952335357666\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.006401116028428078\n",
      "Critic Loss: 5.916490077972412\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.010139680467545986\n",
      "Critic Loss: 3.5922069549560547\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.005710529629141092\n",
      "Critic Loss: 4.995532035827637\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.011448024772107601\n",
      "Critic Loss: 4.695737361907959\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.0036465320736169815\n",
      "Critic Loss: 5.579994201660156\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.0008449628949165344\n",
      "Critic Loss: 4.173917293548584\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.006455542519688606\n",
      "Critic Loss: 1.631465196609497\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.011098691262304783\n",
      "Critic Loss: 5.696224689483643\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.0034074904397130013\n",
      "Critic Loss: 1.5915968418121338\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: -0.006434508133679628\n",
      "Critic Loss: 5.489358901977539\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.004883327055722475\n",
      "Critic Loss: 1.1006900072097778\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: -0.003671342972666025\n",
      "Critic Loss: 3.1071791648864746\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.02455523982644081\n",
      "Critic Loss: 1.895424485206604\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.0007179351523518562\n",
      "Critic Loss: 0.8414257764816284\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.014104582369327545\n",
      "Critic Loss: 1.4331998825073242\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.0018896358087658882\n",
      "Critic Loss: 2.0309391021728516\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.030925001949071884\n",
      "Critic Loss: 1.567495584487915\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.0007097269408404827\n",
      "Critic Loss: 5.735992431640625\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.00878283940255642\n",
      "Critic Loss: 2.176990032196045\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.005746655631810427\n",
      "Critic Loss: 3.463468313217163\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.00010775122791528702\n",
      "Critic Loss: 7.359813213348389\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.030280523002147675\n",
      "Critic Loss: 4.330788612365723\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: -0.008088880218565464\n",
      "Critic Loss: 2.3659684658050537\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.007939551025629044\n",
      "Critic Loss: 6.552464008331299\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.024067889899015427\n",
      "Critic Loss: 4.817040920257568\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.006896567530930042\n",
      "Critic Loss: 4.936158657073975\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.0097176693379879\n",
      "Critic Loss: 5.662746429443359\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.024554971605539322\n",
      "Critic Loss: 2.2550253868103027\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.017471356317400932\n",
      "Critic Loss: 7.464646339416504\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.010167071595788002\n",
      "Critic Loss: 4.980869770050049\n",
      "\n",
      "New best validation reward reached in update [79/200]\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.032534752041101456\n",
      "Critic Loss: 1.498921513557434\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.0030939211137592793\n",
      "Critic Loss: 2.941939115524292\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.02282252348959446\n",
      "Critic Loss: 2.464663505554199\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.021905938163399696\n",
      "Critic Loss: 2.5773916244506836\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.03079543448984623\n",
      "Critic Loss: 4.838156223297119\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.016517112031579018\n",
      "Critic Loss: 4.7302165031433105\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.018559040501713753\n",
      "Critic Loss: 4.379145622253418\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.019951440393924713\n",
      "Critic Loss: 1.7215015888214111\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.033967867493629456\n",
      "Critic Loss: 4.498080253601074\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.036636192351579666\n",
      "Critic Loss: 6.88894510269165\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: -0.0008952165953814983\n",
      "Critic Loss: 5.634224891662598\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.019667835906147957\n",
      "Critic Loss: 7.31359338760376\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.020153090357780457\n",
      "Critic Loss: 2.3850295543670654\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.005662334151566029\n",
      "Critic Loss: 10.717430114746094\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: 0.02302493155002594\n",
      "Critic Loss: 2.216540575027466\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.01978432387113571\n",
      "Critic Loss: 3.7855710983276367\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.013072799891233444\n",
      "Critic Loss: 3.7433485984802246\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.004762531723827124\n",
      "Critic Loss: 2.563774585723877\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.01860138215124607\n",
      "Critic Loss: 2.5710911750793457\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.020104125142097473\n",
      "Critic Loss: 5.296877861022949\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.0328558124601841\n",
      "Critic Loss: 4.482842922210693\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.023010345175862312\n",
      "Critic Loss: 5.079664707183838\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.0035706651397049427\n",
      "Critic Loss: 5.095391273498535\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.05208100378513336\n",
      "Critic Loss: 7.423794269561768\n",
      "\n",
      "New best validation reward reached in update [103/200]\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.021430280059576035\n",
      "Critic Loss: 1.6920634508132935\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.022433847188949585\n",
      "Critic Loss: 2.027219772338867\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.0029899864457547665\n",
      "Critic Loss: 5.253444194793701\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.03278415650129318\n",
      "Critic Loss: 5.323185920715332\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.008803637698292732\n",
      "Critic Loss: 2.3733158111572266\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.03521263599395752\n",
      "Critic Loss: 4.194964408874512\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.006762409117072821\n",
      "Critic Loss: 1.1860692501068115\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.00994489248842001\n",
      "Critic Loss: 3.8835654258728027\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.00848488137125969\n",
      "Critic Loss: 1.1696758270263672\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.016259267926216125\n",
      "Critic Loss: 1.2452285289764404\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.014527620747685432\n",
      "Critic Loss: 3.7171247005462646\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.019002610817551613\n",
      "Critic Loss: 1.5321675539016724\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.01593809947371483\n",
      "Critic Loss: 3.800206184387207\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.04166824370622635\n",
      "Critic Loss: 1.6798317432403564\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.02580023556947708\n",
      "Critic Loss: 0.8080794215202332\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.008509065955877304\n",
      "Critic Loss: 1.9387140274047852\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.01799280196428299\n",
      "Critic Loss: 5.3609418869018555\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.028535181656479836\n",
      "Critic Loss: 4.944417476654053\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.018252484500408173\n",
      "Critic Loss: 6.194735527038574\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.02090451866388321\n",
      "Critic Loss: 7.584584712982178\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.027162794023752213\n",
      "Critic Loss: 6.498876571655273\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.00804192665964365\n",
      "Critic Loss: 8.51370620727539\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.010442785918712616\n",
      "Critic Loss: 13.67837142944336\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.038792289793491364\n",
      "Critic Loss: 6.16708517074585\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.0132808992639184\n",
      "Critic Loss: 3.7916722297668457\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.03682712838053703\n",
      "Critic Loss: 5.654487609863281\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.04044410586357117\n",
      "Critic Loss: 6.605685234069824\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.04165145754814148\n",
      "Critic Loss: 9.863688468933105\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: -0.00516150239855051\n",
      "Critic Loss: 4.773376941680908\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.013805579394102097\n",
      "Critic Loss: 9.719711303710938\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.048677898943424225\n",
      "Critic Loss: 1.842956781387329\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.040251389145851135\n",
      "Critic Loss: 9.634590148925781\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.04197398200631142\n",
      "Critic Loss: 5.196402072906494\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.029126595705747604\n",
      "Critic Loss: 3.6363675594329834\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.04635275900363922\n",
      "Critic Loss: 2.103280782699585\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.026575790718197823\n",
      "Critic Loss: 2.238682508468628\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.024387210607528687\n",
      "Critic Loss: 2.516437530517578\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.01824304088950157\n",
      "Critic Loss: 1.2834405899047852\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.00914229266345501\n",
      "Critic Loss: 1.8694024085998535\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 0.03082067146897316\n",
      "Critic Loss: 5.716328144073486\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.06499932706356049\n",
      "Critic Loss: 2.3749263286590576\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b11ab21feef486ca208b761e130f771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>132.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>128.8</td></tr><tr><td>Learning_rate/Actor</td><td>4e-05</td></tr><tr><td>Learning_rate/Critic</td><td>0.00013</td></tr><tr><td>Loss/Actor_loss</td><td>-0.01159</td></tr><tr><td>Loss/Critic_loss</td><td>2.37493</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.09953</td></tr><tr><td>Loss/KL_divergence</td><td>0.00365</td></tr><tr><td>Loss/Policy_loss</td><td>0.03895</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.065</td></tr><tr><td>Metric/Explained_variance</td><td>-0.24489</td></tr><tr><td>Reward/Mean_train_reward</td><td>22.571</td></tr><tr><td>Reward/Mean_val_reward</td><td>6.8958</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-6.70764</td></tr><tr><td>global_step</td><td>144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-sweep-97</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/x1bhoakz' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/x1bhoakz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_052945-x1bhoakz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1izhgv97 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.0001005445142864693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0021163384057797567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.0011815322211500177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.91625657352732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 250, 150, 350]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 3.299869328037109e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 1.913925119536716e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_053911-1izhgv97</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/1izhgv97' target=\"_blank\">true-sweep-98</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/1izhgv97' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/1izhgv97</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.0001005445142864693, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0021163384057797567, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0011815322211500177, 'epochs': 10, 'exponential_factor': 0.91625657352732, 'gamma': 0.9, 'hidden_sizes': [250, 250, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 3.299869328037109e-05, 'l2_factor': 1.913925119536716e-06, 'lrelu': 0.01, 'minibatch_size': 64, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0001005445142864693, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0021163384057797567, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0011815322211500177, 'epochs': 10, 'exponential_factor': 0.91625657352732, 'gamma': 0.9, 'l1_factor': 3.299869328037109e-05, 'l2_factor': 1.913925119536716e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 250, 150, 350], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'tanh', 'lrelu': 0.01, 'bn': True, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.0001005445142864693, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0021163384057797567, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.0011815322211500177, 'epochs': 10, 'exponential_factor': 0.91625657352732, 'gamma': 0.9, 'l1_factor': 3.299869328037109e-05, 'l2_factor': 1.913925119536716e-06, 'minibatch_size': 64, 'target_kl': 0.01, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.0001005445142864693, 'critic_lr': 0.0021163384057797567, 'decay_method': 'exponential', 'exponential_factor': 0.91625657352732, 'value_loss_factor': 1, 'entropy': 0.0011815322211500177, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 3.299869328037109e-05, 'l2_factor': 1.913925119536716e-06, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.01, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.1, 'hidden_sizes': [250, 250, 150, 350], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.01, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.3214235007762909\n",
      "Critic Loss: 19.25237464904785\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.3564974367618561\n",
      "Critic Loss: 11.31915283203125\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.3170628845691681\n",
      "Critic Loss: 9.366158485412598\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.32937562465667725\n",
      "Critic Loss: 7.3529815673828125\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.277251273393631\n",
      "Critic Loss: 8.490083694458008\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.321372389793396\n",
      "Critic Loss: 5.538133144378662\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.2975700795650482\n",
      "Critic Loss: 5.240506649017334\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.31207162141799927\n",
      "Critic Loss: 7.955419540405273\n",
      "\n",
      "New best validation reward reached in update [8/200]\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.31442761421203613\n",
      "Critic Loss: 7.231404781341553\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.35870012640953064\n",
      "Critic Loss: 8.392457008361816\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.31089070439338684\n",
      "Critic Loss: 7.261201858520508\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.3041020929813385\n",
      "Critic Loss: 2.213224411010742\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.315855473279953\n",
      "Critic Loss: 4.273125648498535\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.30379822850227356\n",
      "Critic Loss: 8.597650527954102\n",
      "\n",
      "New best validation reward reached in update [14/200]\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.29429471492767334\n",
      "Critic Loss: 4.7930498123168945\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.3296978771686554\n",
      "Critic Loss: 4.14210319519043\n",
      "\n",
      "New best validation reward reached in update [16/200]\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.3037405014038086\n",
      "Critic Loss: 4.797831058502197\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.3063523471355438\n",
      "Critic Loss: 3.46832013130188\n",
      "\n",
      "New best validation reward reached in update [18/200]\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.31018710136413574\n",
      "Critic Loss: 3.9593544006347656\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.2994481325149536\n",
      "Critic Loss: 8.821699142456055\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.30936017632484436\n",
      "Critic Loss: 3.386244297027588\n",
      "\n",
      "New best validation reward reached in update [21/200]\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.31195735931396484\n",
      "Critic Loss: 1.9551644325256348\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.38898706436157227\n",
      "Critic Loss: 1.7665998935699463\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.37643253803253174\n",
      "Critic Loss: 2.7161731719970703\n",
      "\n",
      "New best validation reward reached in update [24/200]\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.28752145171165466\n",
      "Critic Loss: 2.523533344268799\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.2979542016983032\n",
      "Critic Loss: 1.459381103515625\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.31551119685173035\n",
      "Critic Loss: 1.698709487915039\n",
      "\n",
      "New best validation reward reached in update [27/200]\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.3692704439163208\n",
      "Critic Loss: 2.0510408878326416\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.32288992404937744\n",
      "Critic Loss: 1.7308313846588135\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.3135766088962555\n",
      "Critic Loss: 1.4260802268981934\n",
      "\n",
      "New best validation reward reached in update [30/200]\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.2967141568660736\n",
      "Critic Loss: 2.4864883422851562\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.3567550778388977\n",
      "Critic Loss: 1.7450683116912842\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.3633193075656891\n",
      "Critic Loss: 2.4990792274475098\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.29955923557281494\n",
      "Critic Loss: 2.2353227138519287\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.36710596084594727\n",
      "Critic Loss: 1.2441715002059937\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.33666351437568665\n",
      "Critic Loss: 0.9213476181030273\n",
      "\n",
      "New best validation reward reached in update [36/200]\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.3228934407234192\n",
      "Critic Loss: 1.675511121749878\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.36299049854278564\n",
      "Critic Loss: 2.0526418685913086\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.32025596499443054\n",
      "Critic Loss: 2.8042876720428467\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.31882259249687195\n",
      "Critic Loss: 1.7803999185562134\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: 0.3948664367198944\n",
      "Critic Loss: 2.210644483566284\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.31412696838378906\n",
      "Critic Loss: 1.175533652305603\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.3140381872653961\n",
      "Critic Loss: 0.8037432432174683\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.3056269884109497\n",
      "Critic Loss: 0.7774993777275085\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.3268592059612274\n",
      "Critic Loss: 2.7253189086914062\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.35117900371551514\n",
      "Critic Loss: 3.3712329864501953\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.2968359887599945\n",
      "Critic Loss: 2.049335479736328\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.2933681905269623\n",
      "Critic Loss: 1.4216645956039429\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.3030596673488617\n",
      "Critic Loss: 1.3943259716033936\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.33406776189804077\n",
      "Critic Loss: 1.5604658126831055\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.30485478043556213\n",
      "Critic Loss: 2.5959391593933105\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.3113163709640503\n",
      "Critic Loss: 3.2198500633239746\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.31879353523254395\n",
      "Critic Loss: 2.3001763820648193\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.2978345453739166\n",
      "Critic Loss: 2.375511407852173\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.31427672505378723\n",
      "Critic Loss: 1.6733345985412598\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.304107129573822\n",
      "Critic Loss: 0.6893777251243591\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.3794170320034027\n",
      "Critic Loss: 3.0209121704101562\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.31109726428985596\n",
      "Critic Loss: 3.2022740840911865\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.3174808919429779\n",
      "Critic Loss: 1.277277946472168\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.33933109045028687\n",
      "Critic Loss: 3.742086887359619\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.34322187304496765\n",
      "Critic Loss: 3.549077033996582\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.2778143882751465\n",
      "Critic Loss: 1.3331189155578613\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.37087664008140564\n",
      "Critic Loss: 1.4909743070602417\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.40481439232826233\n",
      "Critic Loss: 1.3473984003067017\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.34587663412094116\n",
      "Critic Loss: 0.8546082973480225\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.3394153118133545\n",
      "Critic Loss: 3.8408889770507812\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.34080860018730164\n",
      "Critic Loss: 1.4219759702682495\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.3109797537326813\n",
      "Critic Loss: 3.052184581756592\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.3506207764148712\n",
      "Critic Loss: 1.9631247520446777\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.32432445883750916\n",
      "Critic Loss: 1.9283833503723145\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.3290935754776001\n",
      "Critic Loss: 0.7369095087051392\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.3371957540512085\n",
      "Critic Loss: 1.1359573602676392\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.33613115549087524\n",
      "Critic Loss: 1.1355936527252197\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.2958475947380066\n",
      "Critic Loss: 1.050273060798645\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.3269801437854767\n",
      "Critic Loss: 2.364820718765259\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.31283074617385864\n",
      "Critic Loss: 1.4056181907653809\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.326010137796402\n",
      "Critic Loss: 1.1611881256103516\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.3528117835521698\n",
      "Critic Loss: 1.5520918369293213\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.32706257700920105\n",
      "Critic Loss: 1.3038831949234009\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.29284948110580444\n",
      "Critic Loss: 0.692865788936615\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.33094385266304016\n",
      "Critic Loss: 2.9108028411865234\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.32550930976867676\n",
      "Critic Loss: 3.149190664291382\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.359313428401947\n",
      "Critic Loss: 1.3768603801727295\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.3078319728374481\n",
      "Critic Loss: 1.9941612482070923\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.30750298500061035\n",
      "Critic Loss: 1.9128152132034302\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.30270788073539734\n",
      "Critic Loss: 1.9197794198989868\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7e998e2bc441bfb348a8b04908ceb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>159.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>120.3</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.00644</td></tr><tr><td>Loss/Critic_loss</td><td>1.91978</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.89422</td></tr><tr><td>Loss/KL_divergence</td><td>0.02474</td></tr><tr><td>Loss/Policy_loss</td><td>-0.00538</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.30271</td></tr><tr><td>Metric/Explained_variance</td><td>0.52546</td></tr><tr><td>Reward/Mean_train_reward</td><td>33.214</td></tr><tr><td>Reward/Mean_val_reward</td><td>10.9873</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>9.69065</td></tr><tr><td>global_step</td><td>86</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-98</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/1izhgv97' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/1izhgv97</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_053911-1izhgv97\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l017mh79 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: lrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.005238121836147737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004446965773165525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.02211632785631272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9842149713003936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 250]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: orthogonal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 7.726751825109328e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 3.7788446711619257e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_055211-l017mh79</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/l017mh79' target=\"_blank\">honest-sweep-99</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/l017mh79' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/l017mh79</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 512, 'activation': 'lrelu', 'actor_lr': 0.005238121836147737, 'adv_std': True, 'bn': False, 'clipping_epsilon': 0.2, 'critic_lr': 0.004446965773165525, 'decay_method': 'exponential', 'dropout_prob': 0.1, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02211632785631272, 'epochs': 10, 'exponential_factor': 0.9842149713003936, 'gamma': 0.9, 'hidden_sizes': [250, 350, 250], 'initialization': 'orthogonal', 'input_size': 10, 'l1_factor': 7.726751825109328e-05, 'l2_factor': 3.7788446711619257e-06, 'lrelu': 0.1, 'minibatch_size': 32, 'momentum': 0.9, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.005238121836147737, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004446965773165525, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02211632785631272, 'epochs': 10, 'exponential_factor': 0.9842149713003936, 'gamma': 0.9, 'l1_factor': 7.726751825109328e-05, 'l2_factor': 3.7788446711619257e-06, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 250], 'output_size': 6, 'dropout_prob': 0.1, 'activation': 'lrelu', 'lrelu': 0.1, 'bn': False, 'momentum': 0.9, 'initialization': 'orthogonal', 'GAE_lambda': 0.95, 'T': 512, 'actor_lr': 0.005238121836147737, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.004446965773165525, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.02211632785631272, 'epochs': 10, 'exponential_factor': 0.9842149713003936, 'gamma': 0.9, 'l1_factor': 7.726751825109328e-05, 'l2_factor': 3.7788446711619257e-06, 'minibatch_size': 32, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.005238121836147737, 'critic_lr': 0.004446965773165525, 'decay_method': 'exponential', 'exponential_factor': 0.9842149713003936, 'value_loss_factor': 1, 'entropy': 0.02211632785631272, 'gamma': 0.9, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 7.726751825109328e-05, 'l2_factor': 3.7788446711619257e-06, 'T': 512, 'minibatch_size': 32, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'lrelu', 'bn': False, 'dropout_prob': 0.1, 'hidden_sizes': [250, 350, 250], 'initialization': 'orthogonal', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.9, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.7978513836860657\n",
      "Critic Loss: 27.973356246948242\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.05589630454778671\n",
      "Critic Loss: 1.9110398292541504\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.032418496906757355\n",
      "Critic Loss: 2.287057399749756\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.06867422163486481\n",
      "Critic Loss: 1.6404483318328857\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.5220072865486145\n",
      "Critic Loss: 12.842338562011719\n",
      "\n",
      "New best validation reward reached in update [5/200]\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.6086151003837585\n",
      "Critic Loss: 14.169570922851562\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.003054052358493209\n",
      "Critic Loss: 5.368655204772949\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.0365104004740715\n",
      "Critic Loss: 10.172040939331055\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.19064070284366608\n",
      "Critic Loss: 19.192968368530273\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.10405828803777695\n",
      "Critic Loss: 3.2176923751831055\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.005077581387013197\n",
      "Critic Loss: 2.424689292907715\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.06544250249862671\n",
      "Critic Loss: 0.37600478529930115\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: 0.5514318943023682\n",
      "Critic Loss: 14.602782249450684\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.07092452049255371\n",
      "Critic Loss: 1.134061574935913\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.03607824444770813\n",
      "Critic Loss: 1.1056805849075317\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.023029737174510956\n",
      "Critic Loss: 1.3292837142944336\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.016898643225431442\n",
      "Critic Loss: 1.9716609716415405\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: 0.0203278549015522\n",
      "Critic Loss: 0.654243528842926\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.07447515428066254\n",
      "Critic Loss: 2.7242143154144287\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.6706336140632629\n",
      "Critic Loss: 14.41551685333252\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.29766181111335754\n",
      "Critic Loss: 0.12777671217918396\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.04255008324980736\n",
      "Critic Loss: 4.973089218139648\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.025995157659053802\n",
      "Critic Loss: 0.009340399876236916\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.019003337249159813\n",
      "Critic Loss: 6.700654983520508\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: 0.015267674811184406\n",
      "Critic Loss: 0.007750270888209343\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.012048923410475254\n",
      "Critic Loss: 6.622754096984863\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: 0.013782434165477753\n",
      "Critic Loss: 0.013337898999452591\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.010094594210386276\n",
      "Critic Loss: 4.130159854888916\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.0302157960832119\n",
      "Critic Loss: 0.0035233162343502045\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.42094990611076355\n",
      "Critic Loss: 16.75372886657715\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.007702933624386787\n",
      "Critic Loss: 2.2689437866210938\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.035655949264764786\n",
      "Critic Loss: 1.3153942823410034\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.03749159723520279\n",
      "Critic Loss: 0.23906037211418152\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.02310342714190483\n",
      "Critic Loss: 0.37084275484085083\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.016942983493208885\n",
      "Critic Loss: 0.2712957561016083\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.013785791583359241\n",
      "Critic Loss: 0.21153956651687622\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.050244152545928955\n",
      "Critic Loss: 0.23427589237689972\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.08885250985622406\n",
      "Critic Loss: 2.2880187034606934\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.7158485054969788\n",
      "Critic Loss: 21.039745330810547\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.08542883396148682\n",
      "Critic Loss: 2.4042134284973145\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.014299331232905388\n",
      "Critic Loss: 0.5897969007492065\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.23686471581459045\n",
      "Critic Loss: 0.2551608085632324\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: 0.03696698695421219\n",
      "Critic Loss: 3.1806726455688477\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.030326347798109055\n",
      "Critic Loss: 0.6090038418769836\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.025827044621109962\n",
      "Critic Loss: 2.4698779582977295\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.02254416234791279\n",
      "Critic Loss: 2.1529765129089355\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.01994689181447029\n",
      "Critic Loss: 1.7430505752563477\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.01785321906208992\n",
      "Critic Loss: 1.3012464046478271\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.016139153391122818\n",
      "Critic Loss: 2.478248357772827\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.014662294648587704\n",
      "Critic Loss: 1.0314223766326904\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.013405699282884598\n",
      "Critic Loss: 1.5484697818756104\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.01234552450478077\n",
      "Critic Loss: 1.4898416996002197\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: -0.08548065274953842\n",
      "Critic Loss: 0.9141916632652283\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.2611163258552551\n",
      "Critic Loss: 17.475658416748047\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 2.0183098316192627\n",
      "Critic Loss: 12.03216552734375\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.5537528395652771\n",
      "Critic Loss: 17.984140396118164\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.4285295903682709\n",
      "Critic Loss: 11.317159652709961\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.7517731189727783\n",
      "Critic Loss: 10.700037956237793\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.18566852807998657\n",
      "Critic Loss: 0.10364362597465515\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.09363974630832672\n",
      "Critic Loss: 4.298899173736572\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.06648633629083633\n",
      "Critic Loss: 0.08150683343410492\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.051034364849328995\n",
      "Critic Loss: 4.239963531494141\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.041054144501686096\n",
      "Critic Loss: 0.14741627871990204\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.03406594693660736\n",
      "Critic Loss: 5.331502437591553\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.02891874499619007\n",
      "Critic Loss: 0.1694672405719757\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.024921098724007607\n",
      "Critic Loss: 7.747170448303223\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bc3fd396af42369b94c4ab81aef58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>1.0</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>1.0</td></tr><tr><td>Learning_rate/Actor</td><td>0.00186</td></tr><tr><td>Learning_rate/Critic</td><td>0.00158</td></tr><tr><td>Loss/Actor_loss</td><td>-0.0</td></tr><tr><td>Loss/Critic_loss</td><td>7.74717</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.0</td></tr><tr><td>Loss/KL_divergence</td><td>0.0</td></tr><tr><td>Loss/Policy_loss</td><td>-0.0</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.02492</td></tr><tr><td>Reward/Mean_train_reward</td><td>-100.0</td></tr><tr><td>Reward/Mean_val_reward</td><td>-100.0</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>-92.39899</td></tr><tr><td>global_step</td><td>66</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-99</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/l017mh79' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/l017mh79</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_055211-l017mh79\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fp8tmb8c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tGAE_lambda: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tT: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.00934487810343775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_std: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbn: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclipping_epsilon: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0030054045005490308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_method: exponential\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_delta: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tentropy: 0.024138576274802023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texponential_factor: 0.9037897758585156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [250, 350, 150, 150]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: uniform\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_factor: 7.15488721828977e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_factor: 7.886315722037178e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrelu: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_kl: 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdates_per_val: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_episodes: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_loss_factor: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136c18cda824458bbf1665a83824fd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777779226502, max=1.0â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_060004-fp8tmb8c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/fp8tmb8c' target=\"_blank\">stoic-sweep-100</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/sweeps/62savqn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fp8tmb8c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fp8tmb8c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config del trial\n",
      "{'GAE_lambda': 0.95, 'T': 1024, 'activation': 'tanh', 'actor_lr': 0.00934487810343775, 'adv_std': True, 'bn': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0030054045005490308, 'decay_method': 'exponential', 'dropout_prob': 0.3, 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024138576274802023, 'epochs': 10, 'exponential_factor': 0.9037897758585156, 'gamma': 0.99, 'hidden_sizes': [250, 350, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'l1_factor': 7.15488721828977e-06, 'l2_factor': 7.886315722037178e-06, 'lrelu': 0.1, 'minibatch_size': 64, 'momentum': 0.95, 'output_size': 6, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos actor\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00934487810343775, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0030054045005490308, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024138576274802023, 'epochs': 10, 'exponential_factor': 0.9037897758585156, 'gamma': 0.99, 'l1_factor': 7.15488721828977e-06, 'l2_factor': 7.886315722037178e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "Atributos critic\n",
      "{'input_size': 10, 'hidden_sizes': [250, 350, 150, 150], 'output_size': 6, 'dropout_prob': 0.3, 'activation': 'tanh', 'lrelu': 0.1, 'bn': True, 'momentum': 0.95, 'initialization': 'uniform', 'GAE_lambda': 0.95, 'T': 1024, 'actor_lr': 0.00934487810343775, 'adv_std': True, 'clipping_epsilon': 0.2, 'critic_lr': 0.0030054045005490308, 'decay_method': 'exponential', 'early_stopping_delta': 0, 'early_stopping_patience': 30, 'entropy': 0.024138576274802023, 'epochs': 10, 'exponential_factor': 0.9037897758585156, 'gamma': 0.99, 'l1_factor': 7.15488721828977e-06, 'l2_factor': 7.886315722037178e-06, 'minibatch_size': 64, 'target_kl': 0.02, 'updates': 200, 'updates_per_val': 1, 'val_episodes': 10, 'value_loss_factor': 1}\n",
      "\n",
      "cpu\n",
      "Atributos agente\n",
      "{'actor_lr': 0.00934487810343775, 'critic_lr': 0.0030054045005490308, 'decay_method': 'exponential', 'exponential_factor': 0.9037897758585156, 'value_loss_factor': 1, 'entropy': 0.024138576274802023, 'gamma': 0.99, 'GAE_lambda': 0.95, 'clipping_epsilon': 0.2, 'l1_factor': 7.15488721828977e-06, 'l2_factor': 7.886315722037178e-06, 'T': 1024, 'minibatch_size': 64, 'epochs': 10, 'updates': 200, 'val_episodes': 10, 'updates_per_val': 1, 'target_kl': 0.02, 'adv_std': True, 'early_stopping_patience': 30, 'early_stopping_delta': 0, 'activation': 'tanh', 'bn': True, 'dropout_prob': 0.3, 'hidden_sizes': [250, 350, 150, 150], 'initialization': 'uniform', 'input_size': 10, 'lrelu': 0.1, 'momentum': 0.95, 'output_size': 6}\n",
      "Update [1/200]\n",
      "Actor Loss: 0.06854049116373062\n",
      "Critic Loss: 47.06919860839844\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: 0.2567405104637146\n",
      "Critic Loss: 17.358848571777344\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.15870222449302673\n",
      "Critic Loss: 14.961835861206055\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: 0.09147889912128448\n",
      "Critic Loss: 12.62038516998291\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.04081638902425766\n",
      "Critic Loss: 9.045783042907715\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.0023729847744107246\n",
      "Critic Loss: 4.816196918487549\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: 0.05414025858044624\n",
      "Critic Loss: 12.666853904724121\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: 0.06117274612188339\n",
      "Critic Loss: 8.828885078430176\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: 0.0681358054280281\n",
      "Critic Loss: 8.933662414550781\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: 0.04043593630194664\n",
      "Critic Loss: 9.111041069030762\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: 0.015354442410171032\n",
      "Critic Loss: 4.8150129318237305\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: 0.040628332644701004\n",
      "Critic Loss: 6.622151851654053\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.008006448857486248\n",
      "Critic Loss: 5.026076316833496\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: 0.2025531679391861\n",
      "Critic Loss: 9.741992950439453\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: 0.02240416593849659\n",
      "Critic Loss: 5.274008750915527\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.04442507028579712\n",
      "Critic Loss: 7.411399841308594\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.0014253836125135422\n",
      "Critic Loss: 7.0886077880859375\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.050171200186014175\n",
      "Critic Loss: 5.278500080108643\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: -0.001696474850177765\n",
      "Critic Loss: 5.646306991577148\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.08567633479833603\n",
      "Critic Loss: 7.203370571136475\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.001470813062041998\n",
      "Critic Loss: 7.573139667510986\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: -0.04269278794527054\n",
      "Critic Loss: 7.636855602264404\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: -0.020282577723264694\n",
      "Critic Loss: 8.796697616577148\n",
      "\n",
      "New best validation reward reached in update [23/200]\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: 0.05851880460977554\n",
      "Critic Loss: 4.8476409912109375\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.02860076166689396\n",
      "Critic Loss: 5.303285598754883\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: 0.0021085157059133053\n",
      "Critic Loss: 3.991374969482422\n",
      "\n",
      "New best validation reward reached in update [26/200]\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.03864341229200363\n",
      "Critic Loss: 4.2643327713012695\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: -0.03436224162578583\n",
      "Critic Loss: 5.841297626495361\n",
      "\n",
      "New best validation reward reached in update [28/200]\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: -0.012898883782327175\n",
      "Critic Loss: 6.637629508972168\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.05443968623876572\n",
      "Critic Loss: 6.8312506675720215\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.10195010900497437\n",
      "Critic Loss: 4.48446798324585\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: -0.024414826184511185\n",
      "Critic Loss: 4.8462443351745605\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.024900754913687706\n",
      "Critic Loss: 4.789310455322266\n",
      "\n",
      "New best validation reward reached in update [33/200]\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: -0.012782691046595573\n",
      "Critic Loss: 7.176548004150391\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.004914475604891777\n",
      "Critic Loss: 4.17042875289917\n",
      "\n",
      "New best validation reward reached in update [35/200]\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.04837554320693016\n",
      "Critic Loss: 8.98706340789795\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.14470919966697693\n",
      "Critic Loss: 7.107450485229492\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: 0.014226149767637253\n",
      "Critic Loss: 8.119760513305664\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.028936590999364853\n",
      "Critic Loss: 4.835160255432129\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.03991881012916565\n",
      "Critic Loss: 4.0706353187561035\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.001229273620992899\n",
      "Critic Loss: 5.401399612426758\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.010721740312874317\n",
      "Critic Loss: 9.758833885192871\n",
      "\n",
      "New best validation reward reached in update [42/200]\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.04651995375752449\n",
      "Critic Loss: 7.782279014587402\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: -0.0014685369096696377\n",
      "Critic Loss: 6.202709197998047\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: 0.016597116366028786\n",
      "Critic Loss: 7.213752269744873\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.002402651123702526\n",
      "Critic Loss: 8.201563835144043\n",
      "\n",
      "New best validation reward reached in update [46/200]\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: -0.03182562068104744\n",
      "Critic Loss: 6.044492244720459\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.013283193111419678\n",
      "Critic Loss: 3.616004705429077\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.021349379792809486\n",
      "Critic Loss: 8.220015525817871\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: -0.0348137766122818\n",
      "Critic Loss: 7.060602188110352\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.044462013989686966\n",
      "Critic Loss: 5.965753078460693\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.013377778232097626\n",
      "Critic Loss: 10.931293487548828\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.008571397513151169\n",
      "Critic Loss: 7.409048080444336\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: -0.0071877529844641685\n",
      "Critic Loss: 7.308834552764893\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.031287699937820435\n",
      "Critic Loss: 7.361240386962891\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.012039008550345898\n",
      "Critic Loss: 5.376576900482178\n",
      "\n",
      "New best validation reward reached in update [56/200]\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: -0.016679203137755394\n",
      "Critic Loss: 4.518156051635742\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: -0.009087997488677502\n",
      "Critic Loss: 3.4283671379089355\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.011934839189052582\n",
      "Critic Loss: 8.435012817382812\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: -0.018797796219587326\n",
      "Critic Loss: 3.5692615509033203\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.01212338451296091\n",
      "Critic Loss: 5.808985710144043\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.025368671864271164\n",
      "Critic Loss: 10.134544372558594\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: -0.00333290733397007\n",
      "Critic Loss: 5.460048198699951\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: -0.006266976241022348\n",
      "Critic Loss: 3.3910961151123047\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: -0.011040319688618183\n",
      "Critic Loss: 5.6466875076293945\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.00562908872961998\n",
      "Critic Loss: 4.541284561157227\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: -0.010347172617912292\n",
      "Critic Loss: 7.4127197265625\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.12361226230859756\n",
      "Critic Loss: 6.731655120849609\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.01634729653596878\n",
      "Critic Loss: 5.316030979156494\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.026052897796034813\n",
      "Critic Loss: 6.8695149421691895\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.04049262776970863\n",
      "Critic Loss: 9.376273155212402\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.06825773417949677\n",
      "Critic Loss: 4.5597944259643555\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.0008724466897547245\n",
      "Critic Loss: 8.065783500671387\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.050697773694992065\n",
      "Critic Loss: 11.83692741394043\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.027510089799761772\n",
      "Critic Loss: 5.990269660949707\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.011454750783741474\n",
      "Critic Loss: 6.853724956512451\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.01725727878510952\n",
      "Critic Loss: 6.583003520965576\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.0033343518152832985\n",
      "Critic Loss: 9.259845733642578\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: -0.007070804014801979\n",
      "Critic Loss: 9.55757999420166\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.07767592370510101\n",
      "Critic Loss: 12.282615661621094\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: 0.05166079103946686\n",
      "Critic Loss: 7.173123359680176\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: -0.010036134161055088\n",
      "Critic Loss: 5.2195234298706055\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.010769279673695564\n",
      "Critic Loss: 4.321938991546631\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.002869458869099617\n",
      "Critic Loss: 6.285647869110107\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.036202799528837204\n",
      "Critic Loss: 8.572678565979004\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: -0.019983461126685143\n",
      "Critic Loss: 7.973902225494385\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ed309e86724cdca9469d2c08dfe1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Actor</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Learning_rate/Critic</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Critic_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Entropy_bonus</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/KL_divergence</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Policy_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Metric/Explained_variance</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_train_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Mean_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>153.16667</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>186.3</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>-0.04758</td></tr><tr><td>Loss/Critic_loss</td><td>7.9739</td></tr><tr><td>Loss/Entropy_bonus</td><td>1.21701</td></tr><tr><td>Loss/KL_divergence</td><td>-0.01401</td></tr><tr><td>Loss/Policy_loss</td><td>-0.0182</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>-0.01998</td></tr><tr><td>Metric/Explained_variance</td><td>0.44368</td></tr><tr><td>Reward/Mean_train_reward</td><td>6.39217</td></tr><tr><td>Reward/Mean_val_reward</td><td>21.2933</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>10.43823</td></tr><tr><td>global_step</td><td>86</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-sweep-100</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fp8tmb8c' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fp8tmb8c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_060004-fp8tmb8c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, hp_opt, project=\"TFM_project\", count=100)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
