{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from Environment import Car, CarEnv\n",
    "from ModelsTorch import Actor, Critic\n",
    "from AgentTorch import PPOAgent\n",
    "import pygame\n",
    "from utils import compute_borders, scale_image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import re\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by -summary_metrics.Reward/Mean_val_reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glowing-sweep-2 \n",
      "\n",
      "Run ID: k9ou4bcn\n",
      "Best Validation Reward: 548.787109375\n",
      "Run Config Hyperparameters:\n",
      "T: 1024\n",
      "bn: True\n",
      "gamma: 0.95\n",
      "lrelu: 0.1\n",
      "epochs: 10\n",
      "adv_std: False\n",
      "entropy: 0.018354509685286766\n",
      "updates: 200\n",
      "actor_lr: 0.0006178173389342254\n",
      "momentum: 0.99\n",
      "critic_lr: 0.003042924238226867\n",
      "l1_factor: 2.985720538166668e-06\n",
      "l2_factor: 3.2565996268418414e-05\n",
      "target_kl: 0.03\n",
      "GAE_lambda: 0.95\n",
      "activation: tanh\n",
      "input_size: 10\n",
      "output_size: 6\n",
      "decay_method: exponential\n",
      "dropout_prob: 0\n",
      "hidden_sizes: [350, 350, 150]\n",
      "val_episodes: 10\n",
      "initialization: uniform\n",
      "minibatch_size: 64\n",
      "updates_per_val: 1\n",
      "clipping_epsilon: 0.2\n",
      "value_loss_factor: 1\n",
      "exponential_factor: 0.9132888346855556\n",
      "early_stopping_delta: 0\n",
      "early_stopping_patience: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'glowing-sweep-2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run(sweep_id='62savqn0', name=None):\n",
    "    # Initialize the W&B API\n",
    "    api = wandb.Api()\n",
    "    # Retrieve the sweep object\n",
    "    sweep_id = \"antoniosg00/TFM_project/\" + sweep_id\n",
    "    sweep = api.sweep(sweep_id)\n",
    "    if name is None:\n",
    "        run = sweep.best_run()\n",
    "    else:\n",
    "        run = [r for r in sweep.runs if r.name==name][-1]\n",
    "\n",
    "    print()\n",
    "    print(run.name, '\\n')\n",
    "    print(f\"Run ID: {run.id}\")\n",
    "    print(f\"Best Validation Reward: {run.history()['Reward/Mean_val_reward'].max()}\")\n",
    "    print(\"Run Config Hyperparameters:\")\n",
    "    for key, value in run.config.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    return run\n",
    "\n",
    "best_run = get_run()\n",
    "best_run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mantoniosg00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34722\\Desktop\\IA\\Proyectos\\CarRL\\wandb\\run-20240630_112843-fv04uc63</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antoniosg00/TFM_project/runs/fv04uc63' target=\"_blank\">Job_2</a></strong> to <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antoniosg00/TFM_project' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fv04uc63' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fv04uc63</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Update [1/200]\n",
      "Actor Loss: -0.034408312290906906\n",
      "Critic Loss: 23.194528579711914\n",
      "\n",
      "New best validation reward reached in update [1/200]\n",
      "\n",
      "Update [2/200]\n",
      "Actor Loss: -0.037445612251758575\n",
      "Critic Loss: 15.564847946166992\n",
      "\n",
      "New best validation reward reached in update [2/200]\n",
      "\n",
      "Update [3/200]\n",
      "Actor Loss: 0.0075699929147958755\n",
      "Critic Loss: 8.681387901306152\n",
      "\n",
      "New best validation reward reached in update [3/200]\n",
      "\n",
      "Update [4/200]\n",
      "Actor Loss: -0.025292839854955673\n",
      "Critic Loss: 10.776342391967773\n",
      "\n",
      "New best validation reward reached in update [4/200]\n",
      "\n",
      "Update [5/200]\n",
      "Actor Loss: 0.01025007851421833\n",
      "Critic Loss: 8.873035430908203\n",
      "\n",
      "Update [6/200]\n",
      "Actor Loss: 0.0011148592457175255\n",
      "Critic Loss: 10.080915451049805\n",
      "\n",
      "New best validation reward reached in update [6/200]\n",
      "\n",
      "Update [7/200]\n",
      "Actor Loss: -0.0012286603450775146\n",
      "Critic Loss: 6.988119602203369\n",
      "\n",
      "New best validation reward reached in update [7/200]\n",
      "\n",
      "Update [8/200]\n",
      "Actor Loss: -0.015909193083643913\n",
      "Critic Loss: 5.781500339508057\n",
      "\n",
      "Update [9/200]\n",
      "Actor Loss: -0.015271419659256935\n",
      "Critic Loss: 5.80258846282959\n",
      "\n",
      "New best validation reward reached in update [9/200]\n",
      "\n",
      "Update [10/200]\n",
      "Actor Loss: -0.020451892167329788\n",
      "Critic Loss: 8.104846000671387\n",
      "\n",
      "Update [11/200]\n",
      "Actor Loss: -0.01602601818740368\n",
      "Critic Loss: 6.992556571960449\n",
      "\n",
      "Update [12/200]\n",
      "Actor Loss: -0.02189074084162712\n",
      "Critic Loss: 8.496091842651367\n",
      "\n",
      "New best validation reward reached in update [12/200]\n",
      "\n",
      "Update [13/200]\n",
      "Actor Loss: -0.020361529663205147\n",
      "Critic Loss: 4.935574054718018\n",
      "\n",
      "Update [14/200]\n",
      "Actor Loss: -0.008886238560080528\n",
      "Critic Loss: 5.419893264770508\n",
      "\n",
      "Update [15/200]\n",
      "Actor Loss: -0.005261484067887068\n",
      "Critic Loss: 6.091736316680908\n",
      "\n",
      "Update [16/200]\n",
      "Actor Loss: 0.026919379830360413\n",
      "Critic Loss: 6.071364879608154\n",
      "\n",
      "Update [17/200]\n",
      "Actor Loss: 0.037007469683885574\n",
      "Critic Loss: 4.909753799438477\n",
      "\n",
      "Update [18/200]\n",
      "Actor Loss: -0.006269353441894054\n",
      "Critic Loss: 5.918184280395508\n",
      "\n",
      "Update [19/200]\n",
      "Actor Loss: 0.019086599349975586\n",
      "Critic Loss: 6.703847885131836\n",
      "\n",
      "Update [20/200]\n",
      "Actor Loss: 0.03454536944627762\n",
      "Critic Loss: 5.363117694854736\n",
      "\n",
      "Update [21/200]\n",
      "Actor Loss: 0.0051079704426229\n",
      "Critic Loss: 5.358107089996338\n",
      "\n",
      "Update [22/200]\n",
      "Actor Loss: 0.02603144198656082\n",
      "Critic Loss: 5.254661560058594\n",
      "\n",
      "Update [23/200]\n",
      "Actor Loss: 0.01648814231157303\n",
      "Critic Loss: 8.357893943786621\n",
      "\n",
      "Update [24/200]\n",
      "Actor Loss: -0.02280326932668686\n",
      "Critic Loss: 4.524557590484619\n",
      "\n",
      "Update [25/200]\n",
      "Actor Loss: -0.0022332705557346344\n",
      "Critic Loss: 7.691952228546143\n",
      "\n",
      "Update [26/200]\n",
      "Actor Loss: -0.016190305352211\n",
      "Critic Loss: 5.384426116943359\n",
      "\n",
      "Update [27/200]\n",
      "Actor Loss: -0.0021019307896494865\n",
      "Critic Loss: 7.364541530609131\n",
      "\n",
      "Update [28/200]\n",
      "Actor Loss: 0.006729401182383299\n",
      "Critic Loss: 6.839114665985107\n",
      "\n",
      "Update [29/200]\n",
      "Actor Loss: 0.026655659079551697\n",
      "Critic Loss: 5.231999397277832\n",
      "\n",
      "Update [30/200]\n",
      "Actor Loss: 0.013313781470060349\n",
      "Critic Loss: 5.452230453491211\n",
      "\n",
      "Update [31/200]\n",
      "Actor Loss: 0.02847723290324211\n",
      "Critic Loss: 4.649991035461426\n",
      "\n",
      "Update [32/200]\n",
      "Actor Loss: 0.004356405232101679\n",
      "Critic Loss: 4.957778453826904\n",
      "\n",
      "Update [33/200]\n",
      "Actor Loss: 0.015282943844795227\n",
      "Critic Loss: 4.945831775665283\n",
      "\n",
      "Update [34/200]\n",
      "Actor Loss: 0.003852228168398142\n",
      "Critic Loss: 5.800584316253662\n",
      "\n",
      "Update [35/200]\n",
      "Actor Loss: 0.007612899411469698\n",
      "Critic Loss: 6.617295265197754\n",
      "\n",
      "Update [36/200]\n",
      "Actor Loss: 0.007921434938907623\n",
      "Critic Loss: 5.19597864151001\n",
      "\n",
      "Update [37/200]\n",
      "Actor Loss: 0.019922476261854172\n",
      "Critic Loss: 4.733405113220215\n",
      "\n",
      "Update [38/200]\n",
      "Actor Loss: -0.0028786822222173214\n",
      "Critic Loss: 7.608425140380859\n",
      "\n",
      "Update [39/200]\n",
      "Actor Loss: 0.018704835325479507\n",
      "Critic Loss: 6.402866840362549\n",
      "\n",
      "Update [40/200]\n",
      "Actor Loss: 0.021414248272776604\n",
      "Critic Loss: 6.666049480438232\n",
      "\n",
      "New best validation reward reached in update [40/200]\n",
      "\n",
      "Update [41/200]\n",
      "Actor Loss: -0.007516482844948769\n",
      "Critic Loss: 4.488100051879883\n",
      "\n",
      "New best validation reward reached in update [41/200]\n",
      "\n",
      "Update [42/200]\n",
      "Actor Loss: 0.004448136314749718\n",
      "Critic Loss: 6.295434951782227\n",
      "\n",
      "Update [43/200]\n",
      "Actor Loss: -0.008329857140779495\n",
      "Critic Loss: 4.3558125495910645\n",
      "\n",
      "New best validation reward reached in update [43/200]\n",
      "\n",
      "Update [44/200]\n",
      "Actor Loss: 0.0004648622125387192\n",
      "Critic Loss: 4.218569278717041\n",
      "\n",
      "New best validation reward reached in update [44/200]\n",
      "\n",
      "Update [45/200]\n",
      "Actor Loss: -0.010799946263432503\n",
      "Critic Loss: 3.79548978805542\n",
      "\n",
      "Update [46/200]\n",
      "Actor Loss: 0.010442421771585941\n",
      "Critic Loss: 3.883275032043457\n",
      "\n",
      "Update [47/200]\n",
      "Actor Loss: 0.017257343977689743\n",
      "Critic Loss: 3.221485137939453\n",
      "\n",
      "Update [48/200]\n",
      "Actor Loss: 0.030095156282186508\n",
      "Critic Loss: 4.791359901428223\n",
      "\n",
      "Update [49/200]\n",
      "Actor Loss: 0.026425248011946678\n",
      "Critic Loss: 6.556638240814209\n",
      "\n",
      "Update [50/200]\n",
      "Actor Loss: 0.015275446698069572\n",
      "Critic Loss: 5.768401622772217\n",
      "\n",
      "Update [51/200]\n",
      "Actor Loss: 0.013554519973695278\n",
      "Critic Loss: 3.8634538650512695\n",
      "\n",
      "Update [52/200]\n",
      "Actor Loss: 0.004361481871455908\n",
      "Critic Loss: 3.582249641418457\n",
      "\n",
      "New best validation reward reached in update [52/200]\n",
      "\n",
      "Update [53/200]\n",
      "Actor Loss: 0.031131329014897346\n",
      "Critic Loss: 5.226396560668945\n",
      "\n",
      "Update [54/200]\n",
      "Actor Loss: 0.03484874218702316\n",
      "Critic Loss: 5.62515115737915\n",
      "\n",
      "New best validation reward reached in update [54/200]\n",
      "\n",
      "Update [55/200]\n",
      "Actor Loss: 0.02629336528480053\n",
      "Critic Loss: 8.761483192443848\n",
      "\n",
      "New best validation reward reached in update [55/200]\n",
      "\n",
      "Update [56/200]\n",
      "Actor Loss: 0.012492254376411438\n",
      "Critic Loss: 5.197195529937744\n",
      "\n",
      "Update [57/200]\n",
      "Actor Loss: 0.0004613329656422138\n",
      "Critic Loss: 3.787055730819702\n",
      "\n",
      "Update [58/200]\n",
      "Actor Loss: 0.039387185126543045\n",
      "Critic Loss: 7.244579315185547\n",
      "\n",
      "Update [59/200]\n",
      "Actor Loss: 0.004341418389230967\n",
      "Critic Loss: 3.2483201026916504\n",
      "\n",
      "Update [60/200]\n",
      "Actor Loss: 0.02565952017903328\n",
      "Critic Loss: 4.775899410247803\n",
      "\n",
      "Update [61/200]\n",
      "Actor Loss: 0.009727264754474163\n",
      "Critic Loss: 4.657116889953613\n",
      "\n",
      "Update [62/200]\n",
      "Actor Loss: 0.0015548733063042164\n",
      "Critic Loss: 6.684968948364258\n",
      "\n",
      "New best validation reward reached in update [62/200]\n",
      "\n",
      "Update [63/200]\n",
      "Actor Loss: 0.0005664648488163948\n",
      "Critic Loss: 6.092956066131592\n",
      "\n",
      "Update [64/200]\n",
      "Actor Loss: 0.031149208545684814\n",
      "Critic Loss: 8.550914764404297\n",
      "\n",
      "Update [65/200]\n",
      "Actor Loss: 0.025586441159248352\n",
      "Critic Loss: 5.743901252746582\n",
      "\n",
      "New best validation reward reached in update [65/200]\n",
      "\n",
      "Update [66/200]\n",
      "Actor Loss: 0.020936956629157066\n",
      "Critic Loss: 4.309422492980957\n",
      "\n",
      "Update [67/200]\n",
      "Actor Loss: 0.01641198806464672\n",
      "Critic Loss: 4.887246131896973\n",
      "\n",
      "Update [68/200]\n",
      "Actor Loss: 0.014960061758756638\n",
      "Critic Loss: 4.294278144836426\n",
      "\n",
      "Update [69/200]\n",
      "Actor Loss: 0.01879860647022724\n",
      "Critic Loss: 3.6323864459991455\n",
      "\n",
      "Update [70/200]\n",
      "Actor Loss: 0.04970507323741913\n",
      "Critic Loss: 5.220015525817871\n",
      "\n",
      "Update [71/200]\n",
      "Actor Loss: 0.027642633765935898\n",
      "Critic Loss: 3.7824184894561768\n",
      "\n",
      "Update [72/200]\n",
      "Actor Loss: 0.01725122705101967\n",
      "Critic Loss: 9.545201301574707\n",
      "\n",
      "Update [73/200]\n",
      "Actor Loss: 0.015284597873687744\n",
      "Critic Loss: 5.46104097366333\n",
      "\n",
      "Update [74/200]\n",
      "Actor Loss: 0.026057593524456024\n",
      "Critic Loss: 6.231138229370117\n",
      "\n",
      "Update [75/200]\n",
      "Actor Loss: 0.024818889796733856\n",
      "Critic Loss: 3.1816277503967285\n",
      "\n",
      "Update [76/200]\n",
      "Actor Loss: 0.02638847567141056\n",
      "Critic Loss: 4.520595550537109\n",
      "\n",
      "Update [77/200]\n",
      "Actor Loss: 0.035025134682655334\n",
      "Critic Loss: 3.1804542541503906\n",
      "\n",
      "Update [78/200]\n",
      "Actor Loss: 0.01614004746079445\n",
      "Critic Loss: 7.186564922332764\n",
      "\n",
      "Update [79/200]\n",
      "Actor Loss: 0.02692466601729393\n",
      "Critic Loss: 6.734424591064453\n",
      "\n",
      "Update [80/200]\n",
      "Actor Loss: 0.03257497027516365\n",
      "Critic Loss: 7.281041145324707\n",
      "\n",
      "Update [81/200]\n",
      "Actor Loss: -0.003381319809705019\n",
      "Critic Loss: 4.670324325561523\n",
      "\n",
      "New best validation reward reached in update [81/200]\n",
      "\n",
      "Update [82/200]\n",
      "Actor Loss: 0.023092802613973618\n",
      "Critic Loss: 3.990469217300415\n",
      "\n",
      "Update [83/200]\n",
      "Actor Loss: 0.02900148369371891\n",
      "Critic Loss: 6.470632553100586\n",
      "\n",
      "Update [84/200]\n",
      "Actor Loss: 0.01924622617661953\n",
      "Critic Loss: 6.399300575256348\n",
      "\n",
      "Update [85/200]\n",
      "Actor Loss: 0.03176424652338028\n",
      "Critic Loss: 5.102709770202637\n",
      "\n",
      "Update [86/200]\n",
      "Actor Loss: 0.015542613342404366\n",
      "Critic Loss: 7.293025970458984\n",
      "\n",
      "Update [87/200]\n",
      "Actor Loss: 0.01634075678884983\n",
      "Critic Loss: 5.806553840637207\n",
      "\n",
      "Update [88/200]\n",
      "Actor Loss: 0.029234329238533974\n",
      "Critic Loss: 5.565644264221191\n",
      "\n",
      "Update [89/200]\n",
      "Actor Loss: 0.016171466559171677\n",
      "Critic Loss: 5.204667568206787\n",
      "\n",
      "Update [90/200]\n",
      "Actor Loss: 0.02527955174446106\n",
      "Critic Loss: 6.0450310707092285\n",
      "\n",
      "Update [91/200]\n",
      "Actor Loss: 0.01962972804903984\n",
      "Critic Loss: 4.395691871643066\n",
      "\n",
      "Update [92/200]\n",
      "Actor Loss: 0.025227917358279228\n",
      "Critic Loss: 4.391692161560059\n",
      "\n",
      "Update [93/200]\n",
      "Actor Loss: 0.016811294481158257\n",
      "Critic Loss: 6.615273475646973\n",
      "\n",
      "New best validation reward reached in update [93/200]\n",
      "\n",
      "Update [94/200]\n",
      "Actor Loss: -0.0017287391237914562\n",
      "Critic Loss: 4.983705997467041\n",
      "\n",
      "Update [95/200]\n",
      "Actor Loss: 0.027936553582549095\n",
      "Critic Loss: 7.873335838317871\n",
      "\n",
      "Update [96/200]\n",
      "Actor Loss: 0.018750660121440887\n",
      "Critic Loss: 7.177013397216797\n",
      "\n",
      "Update [97/200]\n",
      "Actor Loss: 0.024376604706048965\n",
      "Critic Loss: 4.485164642333984\n",
      "\n",
      "Update [98/200]\n",
      "Actor Loss: 0.00248198164626956\n",
      "Critic Loss: 3.9484286308288574\n",
      "\n",
      "Update [99/200]\n",
      "Actor Loss: 0.03726433590054512\n",
      "Critic Loss: 6.570394039154053\n",
      "\n",
      "Update [100/200]\n",
      "Actor Loss: 0.018376832827925682\n",
      "Critic Loss: 12.240257263183594\n",
      "\n",
      "Update [101/200]\n",
      "Actor Loss: 0.019848544150590897\n",
      "Critic Loss: 7.544816970825195\n",
      "\n",
      "Update [102/200]\n",
      "Actor Loss: 0.016379177570343018\n",
      "Critic Loss: 6.710140228271484\n",
      "\n",
      "Update [103/200]\n",
      "Actor Loss: 0.021825725212693214\n",
      "Critic Loss: 8.427811622619629\n",
      "\n",
      "Update [104/200]\n",
      "Actor Loss: 0.02683872915804386\n",
      "Critic Loss: 3.9911913871765137\n",
      "\n",
      "Update [105/200]\n",
      "Actor Loss: 0.017477726563811302\n",
      "Critic Loss: 7.281595706939697\n",
      "\n",
      "Update [106/200]\n",
      "Actor Loss: 0.014353206381201744\n",
      "Critic Loss: 5.231026649475098\n",
      "\n",
      "Update [107/200]\n",
      "Actor Loss: 0.04266417399048805\n",
      "Critic Loss: 6.787593841552734\n",
      "\n",
      "Update [108/200]\n",
      "Actor Loss: 0.019482014700770378\n",
      "Critic Loss: 5.214217662811279\n",
      "\n",
      "Update [109/200]\n",
      "Actor Loss: 0.018732590600848198\n",
      "Critic Loss: 7.8709917068481445\n",
      "\n",
      "Update [110/200]\n",
      "Actor Loss: 0.03597291186451912\n",
      "Critic Loss: 7.230252265930176\n",
      "\n",
      "Update [111/200]\n",
      "Actor Loss: 0.0019567017443478107\n",
      "Critic Loss: 4.540353775024414\n",
      "\n",
      "Update [112/200]\n",
      "Actor Loss: 0.016200199723243713\n",
      "Critic Loss: 6.377388000488281\n",
      "\n",
      "Update [113/200]\n",
      "Actor Loss: 0.020539307966828346\n",
      "Critic Loss: 5.3939361572265625\n",
      "\n",
      "Update [114/200]\n",
      "Actor Loss: 0.012363366782665253\n",
      "Critic Loss: 3.822352409362793\n",
      "\n",
      "Update [115/200]\n",
      "Actor Loss: 0.027993477880954742\n",
      "Critic Loss: 5.107299327850342\n",
      "\n",
      "Update [116/200]\n",
      "Actor Loss: 0.01904132217168808\n",
      "Critic Loss: 6.65738582611084\n",
      "\n",
      "Update [117/200]\n",
      "Actor Loss: 0.022432247176766396\n",
      "Critic Loss: 3.809478282928467\n",
      "\n",
      "Update [118/200]\n",
      "Actor Loss: 0.017634904012084007\n",
      "Critic Loss: 4.587281703948975\n",
      "\n",
      "Update [119/200]\n",
      "Actor Loss: 0.02440941520035267\n",
      "Critic Loss: 4.3518171310424805\n",
      "\n",
      "Update [120/200]\n",
      "Actor Loss: 0.015247995033860207\n",
      "Critic Loss: 8.342713356018066\n",
      "\n",
      "Update [121/200]\n",
      "Actor Loss: 0.01509212888777256\n",
      "Critic Loss: 6.385375022888184\n",
      "\n",
      "Update [122/200]\n",
      "Actor Loss: 0.02375587448477745\n",
      "Critic Loss: 9.024412155151367\n",
      "\n",
      "New best validation reward reached in update [122/200]\n",
      "\n",
      "Update [123/200]\n",
      "Actor Loss: 0.030523283407092094\n",
      "Critic Loss: 5.528933525085449\n",
      "\n",
      "Update [124/200]\n",
      "Actor Loss: 0.028748363256454468\n",
      "Critic Loss: 4.944862365722656\n",
      "\n",
      "Update [125/200]\n",
      "Actor Loss: 0.011322205886244774\n",
      "Critic Loss: 5.300623893737793\n",
      "\n",
      "Update [126/200]\n",
      "Actor Loss: 0.023882409557700157\n",
      "Critic Loss: 6.0229172706604\n",
      "\n",
      "Update [127/200]\n",
      "Actor Loss: 0.021914426237344742\n",
      "Critic Loss: 6.142603874206543\n",
      "\n",
      "Update [128/200]\n",
      "Actor Loss: 0.006520245689898729\n",
      "Critic Loss: 4.541229248046875\n",
      "\n",
      "Update [129/200]\n",
      "Actor Loss: 0.02502022683620453\n",
      "Critic Loss: 8.068336486816406\n",
      "\n",
      "Update [130/200]\n",
      "Actor Loss: 0.03275115042924881\n",
      "Critic Loss: 6.3749918937683105\n",
      "\n",
      "Update [131/200]\n",
      "Actor Loss: 0.023339122533798218\n",
      "Critic Loss: 4.488631725311279\n",
      "\n",
      "Update [132/200]\n",
      "Actor Loss: 0.029332853853702545\n",
      "Critic Loss: 5.178440093994141\n",
      "\n",
      "Update [133/200]\n",
      "Actor Loss: 0.03463895618915558\n",
      "Critic Loss: 7.273166656494141\n",
      "\n",
      "Update [134/200]\n",
      "Actor Loss: 0.023337915539741516\n",
      "Critic Loss: 6.2311506271362305\n",
      "\n",
      "Update [135/200]\n",
      "Actor Loss: 0.02583511359989643\n",
      "Critic Loss: 4.435746669769287\n",
      "\n",
      "Update [136/200]\n",
      "Actor Loss: 0.02887002006173134\n",
      "Critic Loss: 3.9388320446014404\n",
      "\n",
      "Update [137/200]\n",
      "Actor Loss: 0.009526770561933517\n",
      "Critic Loss: 5.16791296005249\n",
      "\n",
      "Update [138/200]\n",
      "Actor Loss: 0.023187974467873573\n",
      "Critic Loss: 4.644929885864258\n",
      "\n",
      "Update [139/200]\n",
      "Actor Loss: 0.023289617151021957\n",
      "Critic Loss: 6.551279544830322\n",
      "\n",
      "Update [140/200]\n",
      "Actor Loss: 0.07968305796384811\n",
      "Critic Loss: 7.221580982208252\n",
      "\n",
      "Update [141/200]\n",
      "Actor Loss: 0.024401631206274033\n",
      "Critic Loss: 8.346273422241211\n",
      "\n",
      "New best validation reward reached in update [141/200]\n",
      "\n",
      "Update [142/200]\n",
      "Actor Loss: 0.011350393295288086\n",
      "Critic Loss: 7.550477981567383\n",
      "\n",
      "Update [143/200]\n",
      "Actor Loss: 0.025897720828652382\n",
      "Critic Loss: 7.7946648597717285\n",
      "\n",
      "Update [144/200]\n",
      "Actor Loss: 0.025264602154493332\n",
      "Critic Loss: 5.7446441650390625\n",
      "\n",
      "Update [145/200]\n",
      "Actor Loss: 0.03215774521231651\n",
      "Critic Loss: 7.802402496337891\n",
      "\n",
      "Update [146/200]\n",
      "Actor Loss: 0.021713532507419586\n",
      "Critic Loss: 5.19959020614624\n",
      "\n",
      "Update [147/200]\n",
      "Actor Loss: 0.02177480235695839\n",
      "Critic Loss: 5.021418571472168\n",
      "\n",
      "Update [148/200]\n",
      "Actor Loss: 0.028482189401984215\n",
      "Critic Loss: 8.382152557373047\n",
      "\n",
      "Update [149/200]\n",
      "Actor Loss: 0.040797021239995956\n",
      "Critic Loss: 8.338325500488281\n",
      "\n",
      "Update [150/200]\n",
      "Actor Loss: 0.024437475949525833\n",
      "Critic Loss: 5.566249847412109\n",
      "\n",
      "Update [151/200]\n",
      "Actor Loss: 0.03564932197332382\n",
      "Critic Loss: 7.212717533111572\n",
      "\n",
      "Update [152/200]\n",
      "Actor Loss: 0.013936571776866913\n",
      "Critic Loss: 7.758328914642334\n",
      "\n",
      "Update [153/200]\n",
      "Actor Loss: 0.012342581525444984\n",
      "Critic Loss: 4.801058769226074\n",
      "\n",
      "Update [154/200]\n",
      "Actor Loss: 0.025821704417467117\n",
      "Critic Loss: 6.198018550872803\n",
      "\n",
      "Update [155/200]\n",
      "Actor Loss: 0.08469075709581375\n",
      "Critic Loss: 5.971317768096924\n",
      "\n",
      "Update [156/200]\n",
      "Actor Loss: 0.012177947908639908\n",
      "Critic Loss: 5.894742488861084\n",
      "\n",
      "Update [157/200]\n",
      "Actor Loss: 0.029210560023784637\n",
      "Critic Loss: 4.898673057556152\n",
      "\n",
      "Update [158/200]\n",
      "Actor Loss: 0.029476672410964966\n",
      "Critic Loss: 6.537909507751465\n",
      "\n",
      "Update [159/200]\n",
      "Actor Loss: 0.029396187514066696\n",
      "Critic Loss: 5.476537227630615\n",
      "\n",
      "Update [160/200]\n",
      "Actor Loss: 0.02656797133386135\n",
      "Critic Loss: 4.630481719970703\n",
      "\n",
      "Update [161/200]\n",
      "Actor Loss: 0.020403530448675156\n",
      "Critic Loss: 4.591792583465576\n",
      "\n",
      "Update [162/200]\n",
      "Actor Loss: 0.01920468546450138\n",
      "Critic Loss: 5.557389736175537\n",
      "\n",
      "Update [163/200]\n",
      "Actor Loss: 0.019999444484710693\n",
      "Critic Loss: 6.07605504989624\n",
      "\n",
      "New best validation reward reached in update [163/200]\n",
      "\n",
      "Update [164/200]\n",
      "Actor Loss: 0.01897738128900528\n",
      "Critic Loss: 3.7373130321502686\n",
      "\n",
      "Update [165/200]\n",
      "Actor Loss: 0.022211182862520218\n",
      "Critic Loss: 4.989857196807861\n",
      "\n",
      "Update [166/200]\n",
      "Actor Loss: 0.030779734253883362\n",
      "Critic Loss: 3.9805002212524414\n",
      "\n",
      "Update [167/200]\n",
      "Actor Loss: 0.033822692930698395\n",
      "Critic Loss: 3.915750741958618\n",
      "\n",
      "Update [168/200]\n",
      "Actor Loss: 0.026627840474247932\n",
      "Critic Loss: 3.7167625427246094\n",
      "\n",
      "Update [169/200]\n",
      "Actor Loss: 0.02724308893084526\n",
      "Critic Loss: 6.959432601928711\n",
      "\n",
      "Update [170/200]\n",
      "Actor Loss: 0.03580332174897194\n",
      "Critic Loss: 5.721868515014648\n",
      "\n",
      "Update [171/200]\n",
      "Actor Loss: 0.028521418571472168\n",
      "Critic Loss: 7.915407180786133\n",
      "\n",
      "New best validation reward reached in update [171/200]\n",
      "\n",
      "Update [172/200]\n",
      "Actor Loss: 0.033262334764003754\n",
      "Critic Loss: 6.131842613220215\n",
      "\n",
      "Update [173/200]\n",
      "Actor Loss: 0.02888869121670723\n",
      "Critic Loss: 6.06633186340332\n",
      "\n",
      "Update [174/200]\n",
      "Actor Loss: 0.029986131936311722\n",
      "Critic Loss: 6.052089214324951\n",
      "\n",
      "Update [175/200]\n",
      "Actor Loss: 0.03716448321938515\n",
      "Critic Loss: 5.7710394859313965\n",
      "\n",
      "Update [176/200]\n",
      "Actor Loss: 0.04077363759279251\n",
      "Critic Loss: 5.35126256942749\n",
      "\n",
      "Update [177/200]\n",
      "Actor Loss: 0.023675352334976196\n",
      "Critic Loss: 4.713292598724365\n",
      "\n",
      "Update [178/200]\n",
      "Actor Loss: 0.021987304091453552\n",
      "Critic Loss: 5.56329870223999\n",
      "\n",
      "Update [179/200]\n",
      "Actor Loss: 0.031731076538562775\n",
      "Critic Loss: 4.131610870361328\n",
      "\n",
      "Update [180/200]\n",
      "Actor Loss: 0.015225391834974289\n",
      "Critic Loss: 5.7231926918029785\n",
      "\n",
      "Update [181/200]\n",
      "Actor Loss: 0.014914721250534058\n",
      "Critic Loss: 6.576479911804199\n",
      "\n",
      "Update [182/200]\n",
      "Actor Loss: 0.03320935368537903\n",
      "Critic Loss: 6.1947407722473145\n",
      "\n",
      "Update [183/200]\n",
      "Actor Loss: 0.021460505202412605\n",
      "Critic Loss: 6.897184371948242\n",
      "\n",
      "Update [184/200]\n",
      "Actor Loss: 0.024965675547719002\n",
      "Critic Loss: 4.546607971191406\n",
      "\n",
      "Update [185/200]\n",
      "Actor Loss: 0.021619293838739395\n",
      "Critic Loss: 4.33882999420166\n",
      "\n",
      "Update [186/200]\n",
      "Actor Loss: 0.033321261405944824\n",
      "Critic Loss: 4.955922603607178\n",
      "\n",
      "Update [187/200]\n",
      "Actor Loss: 0.0284133143723011\n",
      "Critic Loss: 7.357837677001953\n",
      "\n",
      "Update [188/200]\n",
      "Actor Loss: 0.04368702694773674\n",
      "Critic Loss: 7.699546813964844\n",
      "\n",
      "Update [189/200]\n",
      "Actor Loss: 0.030291130766272545\n",
      "Critic Loss: 7.806392192840576\n",
      "\n",
      "Update [190/200]\n",
      "Actor Loss: 0.04492060840129852\n",
      "Critic Loss: 11.877447128295898\n",
      "\n",
      "Update [191/200]\n",
      "Actor Loss: 0.021401720121502876\n",
      "Critic Loss: 6.0633087158203125\n",
      "\n",
      "Update [192/200]\n",
      "Actor Loss: 0.04264094680547714\n",
      "Critic Loss: 6.472266674041748\n",
      "\n",
      "Update [193/200]\n",
      "Actor Loss: 0.02391783893108368\n",
      "Critic Loss: 4.693917751312256\n",
      "\n",
      "Update [194/200]\n",
      "Actor Loss: 0.01867358200252056\n",
      "Critic Loss: 7.214555740356445\n",
      "\n",
      "Update [195/200]\n",
      "Actor Loss: 0.025731127709150314\n",
      "Critic Loss: 4.878794193267822\n",
      "\n",
      "Update [196/200]\n",
      "Actor Loss: 0.026136230677366257\n",
      "Critic Loss: 5.220057010650635\n",
      "\n",
      "Update [197/200]\n",
      "Actor Loss: 0.018261147662997246\n",
      "Critic Loss: 5.245687484741211\n",
      "\n",
      "Update [198/200]\n",
      "Actor Loss: 0.02648121863603592\n",
      "Critic Loss: 6.081254959106445\n",
      "\n",
      "Update [199/200]\n",
      "Actor Loss: 0.0406113937497139\n",
      "Critic Loss: 5.252334117889404\n",
      "\n",
      "Update [200/200]\n",
      "Actor Loss: 0.041650693863630295\n",
      "Critic Loss: 3.4981276988983154\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb9965e30f3445b8b80c222ce11b5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>▁▂▂▂▂▂▂▂▂▂▃▃▄▄▂▂▃▂▃█▄▄▅▄▄▃▄▃▇▅▄▇▃██▃██▅▅</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>▁▂▃▂▂▂▂▂▃▃▃▄▅▄▃▄▆▆▆▆▇▄▆▇█▇▆█▇▇▆▇▇█▇█▆▆▇▅</td></tr><tr><td>Learning_rate/Actor</td><td>█▇▆▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning_rate/Critic</td><td>█▇▆▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/Actor_loss</td><td>▁▄▃▆▆▃▅▅▅▅▅▆▅▆▆▆▇▇▇▅▆▆▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇█▆█</td></tr><tr><td>Loss/Critic_loss</td><td>█▅▄▂▂▂▂▂▃▁▁▂▃▁▅▃▁▂▂▁▃▂▃▂▄▂▃▂▂▄▃▃▁▁▂▂▂▃▃▁</td></tr><tr><td>Loss/Entropy_bonus</td><td>█▇▅▄▁▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▂▂▁▁▁▂▂▁▁▁▂▂</td></tr><tr><td>Loss/KL_divergence</td><td>▅▅▆█▆▁▄▄▄▄▃▄▄▃▃▃▂▃▄▄▃▄▅▃▃▃▃▃▄▃▄▄▃▃▃▄▅▃▃▄</td></tr><tr><td>Loss/Policy_loss</td><td>▁▅▂▆▅▁▄▄▄▄▄▅▄▅▅▆▆▇▇▄▆▆▅▆▆▅▆▆▆▇▆▇▆▇▇▆▆█▆█</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>▁▄▂▇▆▃▅▅▅▅▅▅▄▆▆▆▆▇▆▄▆▆▆▆▆▅▆▆▆▇▆▇▆▇▇▆▆█▆█</td></tr><tr><td>Metric/Explained_variance</td><td>▃▄▆▇▇▇▇▇▆▇█▇▁█▃▃▃▄▅█▄▅▄▄▃▄▃▃▃▃▃▃▄▄▂▃▃▃▄▄</td></tr><tr><td>Reward/Mean_train_reward</td><td>▁▂▁▂▁▁▁▁▂▂▂▂▃▃▂▂▂▂▂█▃▃▄▄▄▃▄▂█▄▃█▂██▂██▅▅</td></tr><tr><td>Reward/Mean_val_reward</td><td>▁▁▂▂▁▂▂▂▂▂▂▃▄▃▂▃▅▅▅▅▆▃▅▆▇▆▆▇▇▆▆▇▇█▆▇▅▆▆▄</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▅▅▅▆▅▅▆▇▇▆▇▇▇▇▇███▇▇▇▇▆</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration/Mean_train_ep_duration</td><td>240.5</td></tr><tr><td>Duration/Mean_val_ep_duration</td><td>191.10001</td></tr><tr><td>Learning_rate/Actor</td><td>0.0</td></tr><tr><td>Learning_rate/Critic</td><td>0.0</td></tr><tr><td>Loss/Actor_loss</td><td>0.00794</td></tr><tr><td>Loss/Critic_loss</td><td>3.49813</td></tr><tr><td>Loss/Entropy_bonus</td><td>0.48926</td></tr><tr><td>Loss/KL_divergence</td><td>-0.00122</td></tr><tr><td>Loss/Policy_loss</td><td>0.02102</td></tr><tr><td>Loss/Regularized_Actor_loss</td><td>0.04165</td></tr><tr><td>Metric/Explained_variance</td><td>0.17723</td></tr><tr><td>Reward/Mean_train_reward</td><td>322.85953</td></tr><tr><td>Reward/Mean_val_reward</td><td>199.0381</td></tr><tr><td>Reward/Smoothed_val_reward</td><td>267.39975</td></tr><tr><td>global_step</td><td>200</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Job_2</strong> at: <a href='https://wandb.ai/antoniosg00/TFM_project/runs/fv04uc63' target=\"_blank\">https://wandb.ai/antoniosg00/TFM_project/runs/fv04uc63</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240630_112843-fv04uc63\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training cell\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "experiment = int(input('Número del experimento'))\n",
    "wandb.tensorboard.patch(root_logdir='runs\\\\ppo_experiment_tfm\\\\training\\\\'+str(experiment), tensorboard_x=False, save=False)\n",
    "\n",
    "actor = Actor(**best_run.config)\n",
    "critic = Critic(**best_run.config)\n",
    "\n",
    "circuit_path = 'images\\\\circuits\\\\level3.png'\n",
    "circuit_edges, finish_edges, finish_position = compute_borders(circuit_path, \"images\\\\finish_template.png\")\n",
    "track_img = pygame.image.load(circuit_path)\n",
    "finish_img = pygame.image.load(\"images\\\\finish_image.png\")\n",
    "car_img = scale_image(pygame.image.load(\"images\\\\red-car.png\"), 0.35)\n",
    "images = [(track_img, (0, 0)), (finish_img, finish_position)]\n",
    "\n",
    "car = Car(car_img, acceleration=0.2, num_radars=9)\n",
    "env = CarEnv(car, circuit_edges, finish_edges, num_actions=6)\n",
    "\n",
    "wandb.init(\n",
    "    project='TFM_project', \n",
    "    entity='antoniosg00', \n",
    "    name='Job_'+str(experiment),\n",
    "    config=best_run.config,\n",
    ")\n",
    "\n",
    "wandb.watch(actor, log_freq=10)\n",
    "wandb.watch(critic, log_freq=10)\n",
    "\n",
    "saves = 'saves_tfm\\\\' + str(experiment)\n",
    "agent = PPOAgent(actor, critic, log_dir='runs\\\\ppo_experiment_tfm\\\\training\\\\'+str(experiment), **best_run.config)\n",
    "\n",
    "update_rewards, val_rewards = agent.train(env, env, images, save_path=saves, updates_per_flush=20, val_fps=None, val_plot=False, val_verbose=False)\n",
    "agent.close_writer()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_171_518.59.pth\n"
     ]
    }
   ],
   "source": [
    "def obtener_numero_archivo(nombre_archivo):\n",
    "    return int(re.search(r'checkpoint_(\\d+)', nombre_archivo).group(1))\n",
    "\n",
    "def obtener_archivo_mayor_numero(directorio):\n",
    "    archivos = os.listdir(directorio)\n",
    "    archivos_checkpoint = [archivo for archivo in archivos if re.match(r'checkpoint_\\d+', archivo)]\n",
    "    archivo_mayor = max(archivos_checkpoint, key=obtener_numero_archivo)\n",
    "    return archivo_mayor\n",
    "\n",
    "# Locating checkpoint\n",
    "directorio = 'saves_tfm\\\\' + str(experiment)\n",
    "archivo_mayor = obtener_archivo_mayor_numero(directorio)\n",
    "print(archivo_mayor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Loading models\n",
    "actor = Actor(**best_run.config)\n",
    "critic = Critic(**best_run.config)\n",
    "\n",
    "# Loading Agent and saved checkpoint\n",
    "agent = PPOAgent(actor, critic, log_dir='runs\\\\ppo_experiment_tfm\\\\training\\\\'+str(experiment), **best_run.config)\n",
    "agent.load_checkpoint(directorio + '\\\\' + archivo_mayor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent validation cell\n",
    "# 5 levels of circuits can be chosen (training with level 3)\n",
    "\n",
    "val_circuit_path = 'images\\\\circuits\\\\level3.png'  # Modify level here\n",
    "val_circuit_edges, val_finish_edges, val_finish_position = compute_borders(val_circuit_path, \"images\\\\finish_template.png\")\n",
    "val_track_img = pygame.image.load(val_circuit_path)\n",
    "val_finish_img = pygame.image.load(\"images\\\\finish_image.png\")\n",
    "val_car_img = scale_image(pygame.image.load(\"images\\\\red-car.png\"), 0.35)\n",
    "val_images = [(val_track_img, (0, 0)), (val_finish_img, val_finish_position)]\n",
    "\n",
    "val_car = Car(car_img, acceleration=0.2, num_radars=9)\n",
    "val_env = CarEnv(val_car, val_circuit_edges, val_finish_edges, num_actions=6)\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "rew = agent.validation(val_env, val_images, fps=15, episodes=1, plot=True)\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
